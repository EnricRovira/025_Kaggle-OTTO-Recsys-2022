{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 21:28:09.681107: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 21:28:09.741832: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-28 21:28:09.757439: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-28 21:28:10.119091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-28 21:28:10.119118: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-28 21:28:10.119121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 21:28:10.537923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 21:28:10.552159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 21:28:10.552261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from models import build_model_bert4Rec\n",
    "from dataloader import Bert4RecDataLoader\n",
    "\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 7740021.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_ITEMS: 1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.5/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "print(f'NUM_ITEMS: {NUM_ITEMS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 21:28:20.402515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 21:28:20.403321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 21:28:20.403402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 21:28:20.403442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 21:28:20.797847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 21:28:20.797927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 21:28:20.797971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 21:28:20.798015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21875 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "20110it [00:25, 777.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5727"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.5/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=val')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                num_items=NUM_ITEMS, \n",
    "                                seq_len=20, \n",
    "                                seq_len_target=None,\n",
    "                                batch_size=32, \n",
    "                                mask_prob=0.4, \n",
    "                                reverse_prob=0.25, \n",
    "                                get_session=True,\n",
    "                                is_val=True,\n",
    "                                is_test=False,\n",
    "                                shuffle=False).get_generator()\n",
    "# Val\n",
    "list_sessions_val = []\n",
    "for batch in tqdm(dataloader):\n",
    "    features, targets, session = batch\n",
    "    list_sessions_val = list_sessions_val + session.numpy().tolist()\n",
    "print(len(list_sessions_val))\n",
    "# 20110it [00:27, 720.48it/s]\n",
    "\n",
    "del dataloader, batch, features, targets, session\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = pl.read_parquet(\n",
    "    '../0_Data/data_optimized/train.parquet'\n",
    ")\n",
    "df_test = pl.read_parquet(\n",
    "    '../0_Data/data_optimized/test.parquet'\n",
    ")\n",
    "\n",
    "# df_train = df_train_all.filter(~(pl.col('session').is_in(list_sessions_val)))\n",
    "df_val = df_train_all.filter(pl.col('session').is_in(list_sessions_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rule based predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 643503/643503 [00:04<00:00, 153577.76it/s]\n"
     ]
    }
   ],
   "source": [
    "session_types = ['clicks', 'carts', 'orders']\n",
    "\n",
    "val_session_items = df_val.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "val_session_types = df_val.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "val_sessions = val_session_items.index\n",
    "\n",
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "list_labels, list_sessions = [], []\n",
    "for session, seq_items, seq_types in tqdm(zip(val_sessions, val_session_items, val_session_types), total=len(val_session_items)):\n",
    "    if len(seq_items) >= 20:\n",
    "        # if we have enough aids (over equals 20) we don't need to look for candidates! we just use the old logic\n",
    "        weights=np.logspace(0.1, 1, len(seq_items), base=2, endpoint=True)-1\n",
    "        aids_temp=defaultdict(lambda: 0)\n",
    "        for aid,w,t in zip(seq_items, weights, seq_types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "            \n",
    "        sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n",
    "        list_labels.append(sorted_aids[:20])\n",
    "    else:\n",
    "        list_labels.append([0])\n",
    "    list_sessions.append(session)\n",
    "\n",
    "del val_session_items, val_session_types\n",
    "gc.collect()\n",
    "\n",
    "df_val_rule = pd.DataFrame({\n",
    "    'session' : list_sessions,\n",
    "    'prediction' : list_labels,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4REC_CONFIG:\n",
    "    seed = 42 \n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.5/'\n",
    "    restore_last_chekpoint = (True, 'model_bert4rec_complete_0.10/checkpoints/', 'ckpt-22')\n",
    "    model_name = 'model_bert4rec_complete_0.10'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 10_000_000\n",
    "    batch_size = 32\n",
    "    tup_scheduler_grad_accum = (5, 10, 1_500_000) #(start_grad_accum, max_grad_accum, ramp_up_samples)\n",
    "    seq_len = 30\n",
    "    mask_prob = 0.4\n",
    "    reverse_prob = 0.5\n",
    "    emb_dim = 128\n",
    "    trf_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 3\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 250\n",
    "    clipnorm = 1.0\n",
    "    num_iters_save_checkpoint = 25_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    weight_decay = 1e-1\n",
    "    log_wandb = True\n",
    "\n",
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0 \n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.current_loss_scale\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.good_steps\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_time_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_time_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_time_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_time_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_time_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_time_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_time_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_time_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [11:09,  7.47it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=NUM_ITEMS, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.10/checkpoints'))\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.5/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=30, \n",
    "                                     seq_len_target=30, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_past_items, list_predictions, list_trues, list_types = [], [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target, idx_mask = targets\n",
    "    idxs = idx_mask.numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x]-1 for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([dict_map[_target]-1 for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "        list_past_items.append(seq_items.numpy()[:, :, 0])\n",
    "    if num_batch==5_000:\n",
    "        break\n",
    "\n",
    "df_val_model = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'past_items' : np.concatenate(list_past_items).tolist(),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val_model['qt_trues'] = df_val_model['trues'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>prediction</th>\n",
       "      <th>past_items</th>\n",
       "      <th>predictions</th>\n",
       "      <th>trues</th>\n",
       "      <th>type</th>\n",
       "      <th>qt_trues</th>\n",
       "      <th>predictions_final</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>[1188425, 818697, 462252, 1607328, 1040888, 18...</td>\n",
       "      <td>[669987, 595366, 1059168, 300686, 875947, 2619...</td>\n",
       "      <td>[959208, 194870, 664490, 1138707, 1506936, 709...</td>\n",
       "      <td>[1317635, 937348, 189208, 1223839, 1729837, 84...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>20</td>\n",
       "      <td>[1188425, 818697, 462252, 1607328, 1040888, 18...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>[1188425, 818697, 462252, 1607328, 1040888, 18...</td>\n",
       "      <td>[669987, 595366, 1059168, 300686, 875947, 2619...</td>\n",
       "      <td>[709987, 194870, 1055626, 1501826, 1546211, 39...</td>\n",
       "      <td>[185144, 461938]</td>\n",
       "      <td>carts</td>\n",
       "      <td>2</td>\n",
       "      <td>[1188425, 818697, 462252, 1607328, 1040888, 18...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>[1188425, 818697, 462252, 1607328, 1040888, 18...</td>\n",
       "      <td>[669987, 595366, 1059168, 300686, 875947, 2619...</td>\n",
       "      <td>[1501826, 470713, 1569605, 709987, 1101316, 19...</td>\n",
       "      <td>[]</td>\n",
       "      <td>orders</td>\n",
       "      <td>0</td>\n",
       "      <td>[1188425, 818697, 462252, 1607328, 1040888, 18...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156</td>\n",
       "      <td>[123997, 368888, 835255, 1395588, 132129, 1398...</td>\n",
       "      <td>[1192186, 0, 292147, 353566, 973977, 1093217, ...</td>\n",
       "      <td>[1456869, 1483563, 1626136, 1003990, 677909, 8...</td>\n",
       "      <td>[1319681, 1395588, 1546630, 1136391, 1185930, ...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>19</td>\n",
       "      <td>[123997, 368888, 835255, 1395588, 132129, 1398...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156</td>\n",
       "      <td>[123997, 368888, 835255, 1395588, 132129, 1398...</td>\n",
       "      <td>[1192186, 0, 292147, 353566, 973977, 1093217, ...</td>\n",
       "      <td>[1483563, 1456869, 627404, 834930, 89925, 1626...</td>\n",
       "      <td>[1395588]</td>\n",
       "      <td>carts</td>\n",
       "      <td>1</td>\n",
       "      <td>[123997, 368888, 835255, 1395588, 132129, 1398...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480091</th>\n",
       "      <td>12899671</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[224347, 666582, 293066, 602580, 311287, 18463...</td>\n",
       "      <td>[]</td>\n",
       "      <td>carts</td>\n",
       "      <td>0</td>\n",
       "      <td>[224347, 666582, 293066, 602580, 311287, 18463...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480092</th>\n",
       "      <td>12899671</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[224347, 666582, 293066, 602580, 166037, 29023...</td>\n",
       "      <td>[]</td>\n",
       "      <td>orders</td>\n",
       "      <td>0</td>\n",
       "      <td>[224347, 666582, 293066, 602580, 166037, 29023...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480093</th>\n",
       "      <td>12899754</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1016692, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1438223, 231487, 1675253, 1448403, 1820122, 1...</td>\n",
       "      <td>[922732]</td>\n",
       "      <td>clicks</td>\n",
       "      <td>1</td>\n",
       "      <td>[1438223, 231487, 1675253, 1448403, 1820122, 1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480094</th>\n",
       "      <td>12899754</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1016692, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1438223, 1084167, 1387295, 1258519, 1751083, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>carts</td>\n",
       "      <td>0</td>\n",
       "      <td>[1438223, 1084167, 1387295, 1258519, 1751083, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480095</th>\n",
       "      <td>12899754</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1016692, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1438223, 231487, 1099895, 1289295, 1387295, 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>orders</td>\n",
       "      <td>0</td>\n",
       "      <td>[1438223, 231487, 1099895, 1289295, 1387295, 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480096 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         session                                         prediction  \\\n",
       "0             94  [1188425, 818697, 462252, 1607328, 1040888, 18...   \n",
       "1             94  [1188425, 818697, 462252, 1607328, 1040888, 18...   \n",
       "2             94  [1188425, 818697, 462252, 1607328, 1040888, 18...   \n",
       "3            156  [123997, 368888, 835255, 1395588, 132129, 1398...   \n",
       "4            156  [123997, 368888, 835255, 1395588, 132129, 1398...   \n",
       "...          ...                                                ...   \n",
       "480091  12899671                                                [0]   \n",
       "480092  12899671                                                [0]   \n",
       "480093  12899754                                                [0]   \n",
       "480094  12899754                                                [0]   \n",
       "480095  12899754                                                [0]   \n",
       "\n",
       "                                               past_items  \\\n",
       "0       [669987, 595366, 1059168, 300686, 875947, 2619...   \n",
       "1       [669987, 595366, 1059168, 300686, 875947, 2619...   \n",
       "2       [669987, 595366, 1059168, 300686, 875947, 2619...   \n",
       "3       [1192186, 0, 292147, 353566, 973977, 1093217, ...   \n",
       "4       [1192186, 0, 292147, 353566, 973977, 1093217, ...   \n",
       "...                                                   ...   \n",
       "480091  [158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "480092  [158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "480093  [1016692, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "480094  [1016692, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "480095  [1016692, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              predictions  \\\n",
       "0       [959208, 194870, 664490, 1138707, 1506936, 709...   \n",
       "1       [709987, 194870, 1055626, 1501826, 1546211, 39...   \n",
       "2       [1501826, 470713, 1569605, 709987, 1101316, 19...   \n",
       "3       [1456869, 1483563, 1626136, 1003990, 677909, 8...   \n",
       "4       [1483563, 1456869, 627404, 834930, 89925, 1626...   \n",
       "...                                                   ...   \n",
       "480091  [224347, 666582, 293066, 602580, 311287, 18463...   \n",
       "480092  [224347, 666582, 293066, 602580, 166037, 29023...   \n",
       "480093  [1438223, 231487, 1675253, 1448403, 1820122, 1...   \n",
       "480094  [1438223, 1084167, 1387295, 1258519, 1751083, ...   \n",
       "480095  [1438223, 231487, 1099895, 1289295, 1387295, 1...   \n",
       "\n",
       "                                                    trues    type  qt_trues  \\\n",
       "0       [1317635, 937348, 189208, 1223839, 1729837, 84...  clicks        20   \n",
       "1                                        [185144, 461938]   carts         2   \n",
       "2                                                      []  orders         0   \n",
       "3       [1319681, 1395588, 1546630, 1136391, 1185930, ...  clicks        19   \n",
       "4                                               [1395588]   carts         1   \n",
       "...                                                   ...     ...       ...   \n",
       "480091                                                 []   carts         0   \n",
       "480092                                                 []  orders         0   \n",
       "480093                                           [922732]  clicks         1   \n",
       "480094                                                 []   carts         0   \n",
       "480095                                                 []  orders         0   \n",
       "\n",
       "                                        predictions_final  score  \n",
       "0       [1188425, 818697, 462252, 1607328, 1040888, 18...    0.0  \n",
       "1       [1188425, 818697, 462252, 1607328, 1040888, 18...    1.0  \n",
       "2       [1188425, 818697, 462252, 1607328, 1040888, 18...    NaN  \n",
       "3       [123997, 368888, 835255, 1395588, 132129, 1398...    0.0  \n",
       "4       [123997, 368888, 835255, 1395588, 132129, 1398...    1.0  \n",
       "...                                                   ...    ...  \n",
       "480091  [224347, 666582, 293066, 602580, 311287, 18463...    NaN  \n",
       "480092  [224347, 666582, 293066, 602580, 166037, 29023...    NaN  \n",
       "480093  [1438223, 231487, 1675253, 1448403, 1820122, 1...    0.0  \n",
       "480094  [1438223, 1084167, 1387295, 1258519, 1751083, ...    NaN  \n",
       "480095  [1438223, 231487, 1099895, 1289295, 1387295, 1...    NaN  \n",
       "\n",
       "[480096 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480096/480096 [00:01<00:00, 282165.08it/s]\n",
      "100%|██████████| 480096/480096 [00:02<00:00, 196862.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>qt_trues</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.800960e+05</td>\n",
       "      <td>480096.000000</td>\n",
       "      <td>201701.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.458205e+06</td>\n",
       "      <td>1.544068</td>\n",
       "      <td>0.530755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.719837e+06</td>\n",
       "      <td>3.529577</td>\n",
       "      <td>0.495674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.400000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.243194e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.449878e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.685902e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289975e+07</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session       qt_trues          score\n",
       "count  4.800960e+05  480096.000000  201701.000000\n",
       "mean   6.458205e+06       1.544068       0.530755\n",
       "std    3.719837e+06       3.529577       0.495674\n",
       "min    9.400000e+01       0.000000       0.000000\n",
       "25%    3.243194e+06       0.000000       0.000000\n",
       "50%    6.449878e+06       0.000000       1.000000\n",
       "75%    9.685902e+06       1.000000       1.000000\n",
       "max    1.289975e+07      30.000000       1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.7613601893625642,\n",
       " 'clicks': 0.4558214065074135,\n",
       " 'orders': 0.8298199206770427}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.7719\n"
     ]
    }
   ],
   "source": [
    "df_val_merge = df_val_rule.merge(df_val_model, how='inner', on='session')\n",
    "df_val_merge['predictions_final'] = df_val_merge.progress_apply(lambda x : x['predictions'] if len(x['prediction'])==1 else x['prediction'], axis=1)\n",
    "df_val_merge['score'] = df_val_merge.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions_final'], x['type']), axis=1)\n",
    "\n",
    "display(df_val_merge.describe())\n",
    "dict_scores = df_val_merge.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# # Model\n",
    "# {'carts': 0.37454512439145493,\n",
    "#  'clicks': 0.3244825988467875,\n",
    "#  'orders': 0.5052842557053815}\n",
    "# Kaggle Metric: 0.4480\n",
    "\n",
    "# rule\n",
    "# {'carts': 0.5068184776077022,\n",
    "#  'clicks': 0.16846427100494235,\n",
    "#  'orders': 0.5224797601872758}\n",
    "# Kaggle Metric: 0.4824\n",
    "\n",
    "# final\n",
    "# {'carts': 0.7613601893625642,\n",
    "#  'clicks': 0.4558214065074135,\n",
    "#  'orders': 0.8298199206770427}\n",
    "# Kaggle Metric: 0.7719"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0432fa0070c5c9f7d9e158f590013ccc765eb84f02e6f69521746370c3bf6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
