{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 20:26:40.906952: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 20:26:40.975780: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-28 20:26:40.991789: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-28 20:26:41.327321: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-28 20:26:41.327347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-28 20:26:41.327350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 20:26:41.766596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 20:26:41.780936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 20:26:41.781025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from models import build_model_bert4Rec\n",
    "from dataloader import Bert4RecDataLoader\n",
    "\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 7990549.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_ITEMS: 1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.5/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "print(f'NUM_ITEMS: {NUM_ITEMS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 20:26:47.498260: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 20:26:47.498966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 20:26:47.502197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 20:26:47.502266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 20:26:47.863580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 20:26:47.863665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 20:26:47.863711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-28 20:26:47.863756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21874 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "20110it [00:27, 734.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5727"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.5/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=val')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                num_items=NUM_ITEMS, \n",
    "                                seq_len=20, \n",
    "                                seq_len_target=None,\n",
    "                                batch_size=32, \n",
    "                                mask_prob=0.4, \n",
    "                                reverse_prob=0.25, \n",
    "                                get_session=True,\n",
    "                                is_val=True,\n",
    "                                is_test=False,\n",
    "                                shuffle=False).get_generator()\n",
    "# Val\n",
    "list_sessions_val = []\n",
    "for batch in tqdm(dataloader):\n",
    "    features, targets, session = batch\n",
    "    list_sessions_val = list_sessions_val + session.numpy().tolist()\n",
    "print(len(list_sessions_val))\n",
    "# 20110it [00:27, 720.48it/s]\n",
    "\n",
    "del dataloader, batch, features, targets, session\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = pl.read_parquet(\n",
    "    '../0_Data/data_optimized/train.parquet'\n",
    ")\n",
    "df_test = pl.read_parquet(\n",
    "    '../0_Data/data_optimized/test.parquet'\n",
    ")\n",
    "\n",
    "# df_train = df_train_all.filter(~(pl.col('session').is_in(list_sessions_val)))\n",
    "# df_val = df_train_all.filter(pl.col('session').is_in(list_sessions_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# df_train_all_grouped = (\n",
    "#     df_train_all.groupby('session')\n",
    "#                 .agg(pl.count('aid').alias('qt_events'))\n",
    "#                 .with_column((pl.col('session') / pl.col('qt_events')).alias('new_session'))\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Rule based predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 643503/643503 [00:04<00:00, 157181.16it/s]\n"
     ]
    }
   ],
   "source": [
    "session_types = ['clicks', 'carts', 'orders']\n",
    "\n",
    "val_session_items = df_val.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "val_session_types = df_val.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "val_sessions = val_session_items.index\n",
    "\n",
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "list_labels, list_sessions = [], []\n",
    "for session, seq_items, seq_types in tqdm(zip(val_sessions, val_session_items, val_session_types), total=len(val_session_items)):\n",
    "    if len(seq_items) >= 20:\n",
    "        # if we have enough aids (over equals 20) we don't need to look for candidates! we just use the old logic\n",
    "        weights=np.logspace(0.1, 1, len(seq_items), base=2, endpoint=True)-1\n",
    "        aids_temp=defaultdict(lambda: 0)\n",
    "        for aid,w,t in zip(seq_items, weights, seq_types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "            \n",
    "        sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n",
    "        list_labels.append(sorted_aids[:20])\n",
    "    else:\n",
    "        list_labels.append([0])\n",
    "    list_sessions.append(session)\n",
    "\n",
    "# del val_session_items, val_session_types\n",
    "# gc.collect()\n",
    "\n",
    "df_val_rule = pd.DataFrame({\n",
    "    'session' : list_sessions,\n",
    "    'prediction' : list_labels,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4REC_CONFIG:\n",
    "    seed = 42 \n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.5/'\n",
    "    restore_last_chekpoint = (True, 'model_bert4rec_complete_0.10/checkpoints/', 'ckpt-22')\n",
    "    model_name = 'model_bert4rec_complete_0.10'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 10_000_000\n",
    "    batch_size = 32\n",
    "    tup_scheduler_grad_accum = (5, 10, 1_500_000) #(start_grad_accum, max_grad_accum, ramp_up_samples)\n",
    "    seq_len = 30\n",
    "    mask_prob = 0.4\n",
    "    reverse_prob = 0.5\n",
    "    emb_dim = 128\n",
    "    trf_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 3\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 250\n",
    "    clipnorm = 1.0\n",
    "    num_iters_save_checkpoint = 25_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    weight_decay = 1e-1\n",
    "    log_wandb = True\n",
    "\n",
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0 \n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 20:22:41.631666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "0it [00:00, ?it/s]2022-11-28 20:22:42.784170: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "500it [01:08,  7.35it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=NUM_ITEMS, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.10/checkpoints'))\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.5/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=30, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_past_items, list_predictions, list_trues, list_types = [], [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target, idx_mask = targets\n",
    "    idxs = idx_mask.numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([dict_map[_target] for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "        list_past_items.append(seq_items.numpy()[:, :, 0])\n",
    "    if num_batch==500:\n",
    "        break\n",
    "\n",
    "df_val_model = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'past_items' : np.concatenate(list_past_items).tolist(),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "df_val_model['qt_trues'] = df_val_model['trues'].apply(lambda x : len(x))\n",
    "# df_val_model['score'] = df_val_model.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "# display(df_val_model.describe())\n",
    "# dict_scores = df_val_model.groupby('type')['score'].mean().to_dict()\n",
    "# display(dict_scores)\n",
    "# kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "# print(f'Kaggle Metric: {kaggle_metric:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48096/48096 [00:00<00:00, 308704.20it/s]\n",
      "100%|██████████| 48096/48096 [00:00<00:00, 221836.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>qt_trues</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.809600e+04</td>\n",
       "      <td>48096.000000</td>\n",
       "      <td>20109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.409855e+06</td>\n",
       "      <td>1.399451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.715819e+06</td>\n",
       "      <td>2.914157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.630000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.190015e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.383588e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.627672e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289967e+07</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session      qt_trues    score\n",
       "count  4.809600e+04  48096.000000  20109.0\n",
       "mean   6.409855e+06      1.399451      0.0\n",
       "std    3.715819e+06      2.914157      0.0\n",
       "min    9.630000e+02      0.000000      0.0\n",
       "25%    3.190015e+06      0.000000      0.0\n",
       "50%    6.383588e+06      0.000000      0.0\n",
       "75%    9.627672e+06      1.000000      0.0\n",
       "max    1.289967e+07     20.000000      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.0, 'clicks': 0.0, 'orders': 0.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.0000\n"
     ]
    }
   ],
   "source": [
    "df_val_merge = df_val_rule.merge(df_val_model, how='inner', on='session')\n",
    "df_val_merge['predictions_final'] = df_val_merge.progress_apply(lambda x : x['predictions'] if len(x['prediction'])==1 else x['prediction'], axis=1)\n",
    "df_val_merge['score'] = df_val_merge.progress_apply(lambda x: get_score_metric(x['trues'], x['prediction'], x['type']), axis=1)\n",
    "\n",
    "display(df_val_merge.describe())\n",
    "dict_scores = df_val_merge.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31792,\n",
       " 1176945,\n",
       " 650288,\n",
       " 81849,\n",
       " 1538191,\n",
       " 509463,\n",
       " 762720,\n",
       " 953572,\n",
       " 750856,\n",
       " 1610239]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_session_items[963][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>prediction</th>\n",
       "      <th>past_items</th>\n",
       "      <th>predictions</th>\n",
       "      <th>trues</th>\n",
       "      <th>type</th>\n",
       "      <th>qt_trues</th>\n",
       "      <th>predictions_final</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>963</td>\n",
       "      <td>[1452543, 1108815, 1610239, 1490942, 314510, 1...</td>\n",
       "      <td>[901859, 779569, 1032407, 779569, 667411, 0, 0...</td>\n",
       "      <td>[82494, 700085, 890996, 1798917, 1797903, 6733...</td>\n",
       "      <td>[1673504, 1783329, 653442, 476064, 713284, 145...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>16</td>\n",
       "      <td>[1452543, 1108815, 1610239, 1490942, 314510, 1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>963</td>\n",
       "      <td>[1452543, 1108815, 1610239, 1490942, 314510, 1...</td>\n",
       "      <td>[901859, 779569, 1032407, 779569, 667411, 0, 0...</td>\n",
       "      <td>[82494, 700085, 1797903, 890996, 673346, 16122...</td>\n",
       "      <td>[1452544, 314511]</td>\n",
       "      <td>carts</td>\n",
       "      <td>2</td>\n",
       "      <td>[1452543, 1108815, 1610239, 1490942, 314510, 1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>963</td>\n",
       "      <td>[1452543, 1108815, 1610239, 1490942, 314510, 1...</td>\n",
       "      <td>[901859, 779569, 1032407, 779569, 667411, 0, 0...</td>\n",
       "      <td>[700085, 82494, 1610240, 1798917, 1797903, 184...</td>\n",
       "      <td>[]</td>\n",
       "      <td>orders</td>\n",
       "      <td>0</td>\n",
       "      <td>[1452543, 1108815, 1610239, 1490942, 314510, 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3457</td>\n",
       "      <td>[1070168, 1527878, 1509228, 937698, 1375098, 1...</td>\n",
       "      <td>[539303, 0, 395667, 0, 0, 621312, 1087682, 0, ...</td>\n",
       "      <td>[65249, 1642635, 1554131, 347272, 109480, 1717...</td>\n",
       "      <td>[1350241, 470434, 683426, 1148357, 120197, 184...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>16</td>\n",
       "      <td>[1070168, 1527878, 1509228, 937698, 1375098, 1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3457</td>\n",
       "      <td>[1070168, 1527878, 1509228, 937698, 1375098, 1...</td>\n",
       "      <td>[539303, 0, 395667, 0, 0, 621312, 1087682, 0, ...</td>\n",
       "      <td>[65249, 1642635, 347272, 1747646, 118125, 2332...</td>\n",
       "      <td>[1350241]</td>\n",
       "      <td>carts</td>\n",
       "      <td>1</td>\n",
       "      <td>[1070168, 1527878, 1509228, 937698, 1375098, 1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48091</th>\n",
       "      <td>12899579</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1065959, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1508063, 650985, 276917, 506760, 1296040, 180...</td>\n",
       "      <td>[]</td>\n",
       "      <td>carts</td>\n",
       "      <td>0</td>\n",
       "      <td>[1508063, 650985, 276917, 506760, 1296040, 180...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48092</th>\n",
       "      <td>12899579</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1065959, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1508063, 650985, 276917, 506760, 1296040, 579...</td>\n",
       "      <td>[]</td>\n",
       "      <td>orders</td>\n",
       "      <td>0</td>\n",
       "      <td>[1508063, 650985, 276917, 506760, 1296040, 579...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48093</th>\n",
       "      <td>12899671</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[224348, 666583, 293067, 29024, 984460, 729055...</td>\n",
       "      <td>[1271128]</td>\n",
       "      <td>clicks</td>\n",
       "      <td>1</td>\n",
       "      <td>[224348, 666583, 293067, 29024, 984460, 729055...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48094</th>\n",
       "      <td>12899671</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[224348, 666583, 293067, 602581, 311288, 18463...</td>\n",
       "      <td>[]</td>\n",
       "      <td>carts</td>\n",
       "      <td>0</td>\n",
       "      <td>[224348, 666583, 293067, 602581, 311288, 18463...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48095</th>\n",
       "      <td>12899671</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[224348, 666583, 293067, 602581, 166038, 29024...</td>\n",
       "      <td>[]</td>\n",
       "      <td>orders</td>\n",
       "      <td>0</td>\n",
       "      <td>[224348, 666583, 293067, 602581, 166038, 29024...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48096 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session                                         prediction  \\\n",
       "0           963  [1452543, 1108815, 1610239, 1490942, 314510, 1...   \n",
       "1           963  [1452543, 1108815, 1610239, 1490942, 314510, 1...   \n",
       "2           963  [1452543, 1108815, 1610239, 1490942, 314510, 1...   \n",
       "3          3457  [1070168, 1527878, 1509228, 937698, 1375098, 1...   \n",
       "4          3457  [1070168, 1527878, 1509228, 937698, 1375098, 1...   \n",
       "...         ...                                                ...   \n",
       "48091  12899579                                                [0]   \n",
       "48092  12899579                                                [0]   \n",
       "48093  12899671                                                [0]   \n",
       "48094  12899671                                                [0]   \n",
       "48095  12899671                                                [0]   \n",
       "\n",
       "                                              past_items  \\\n",
       "0      [901859, 779569, 1032407, 779569, 667411, 0, 0...   \n",
       "1      [901859, 779569, 1032407, 779569, 667411, 0, 0...   \n",
       "2      [901859, 779569, 1032407, 779569, 667411, 0, 0...   \n",
       "3      [539303, 0, 395667, 0, 0, 621312, 1087682, 0, ...   \n",
       "4      [539303, 0, 395667, 0, 0, 621312, 1087682, 0, ...   \n",
       "...                                                  ...   \n",
       "48091  [1065959, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "48092  [1065959, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "48093  [158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "48094  [158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "48095  [158569, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                                             predictions  \\\n",
       "0      [82494, 700085, 890996, 1798917, 1797903, 6733...   \n",
       "1      [82494, 700085, 1797903, 890996, 673346, 16122...   \n",
       "2      [700085, 82494, 1610240, 1798917, 1797903, 184...   \n",
       "3      [65249, 1642635, 1554131, 347272, 109480, 1717...   \n",
       "4      [65249, 1642635, 347272, 1747646, 118125, 2332...   \n",
       "...                                                  ...   \n",
       "48091  [1508063, 650985, 276917, 506760, 1296040, 180...   \n",
       "48092  [1508063, 650985, 276917, 506760, 1296040, 579...   \n",
       "48093  [224348, 666583, 293067, 29024, 984460, 729055...   \n",
       "48094  [224348, 666583, 293067, 602581, 311288, 18463...   \n",
       "48095  [224348, 666583, 293067, 602581, 166038, 29024...   \n",
       "\n",
       "                                                   trues    type  qt_trues  \\\n",
       "0      [1673504, 1783329, 653442, 476064, 713284, 145...  clicks        16   \n",
       "1                                      [1452544, 314511]   carts         2   \n",
       "2                                                     []  orders         0   \n",
       "3      [1350241, 470434, 683426, 1148357, 120197, 184...  clicks        16   \n",
       "4                                              [1350241]   carts         1   \n",
       "...                                                  ...     ...       ...   \n",
       "48091                                                 []   carts         0   \n",
       "48092                                                 []  orders         0   \n",
       "48093                                          [1271128]  clicks         1   \n",
       "48094                                                 []   carts         0   \n",
       "48095                                                 []  orders         0   \n",
       "\n",
       "                                       predictions_final  score  \n",
       "0      [1452543, 1108815, 1610239, 1490942, 314510, 1...    0.0  \n",
       "1      [1452543, 1108815, 1610239, 1490942, 314510, 1...    0.0  \n",
       "2      [1452543, 1108815, 1610239, 1490942, 314510, 1...    NaN  \n",
       "3      [1070168, 1527878, 1509228, 937698, 1375098, 1...    0.0  \n",
       "4      [1070168, 1527878, 1509228, 937698, 1375098, 1...    0.0  \n",
       "...                                                  ...    ...  \n",
       "48091  [1508063, 650985, 276917, 506760, 1296040, 180...    NaN  \n",
       "48092  [1508063, 650985, 276917, 506760, 1296040, 579...    NaN  \n",
       "48093  [224348, 666583, 293067, 29024, 984460, 729055...    0.0  \n",
       "48094  [224348, 666583, 293067, 602581, 311288, 18463...    NaN  \n",
       "48095  [224348, 666583, 293067, 602581, 166038, 29024...    NaN  \n",
       "\n",
       "[48096 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0432fa0070c5c9f7d9e158f590013ccc765eb84f02e6f69521746370c3bf6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
