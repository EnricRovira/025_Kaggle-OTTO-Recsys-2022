{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.3_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 3307671.00it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "SEED = 12\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.3/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*16)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=False).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_time_encoding, seq_time_encoding_target = seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding), (seq_items_target_all[:, 0], seq_type_target_all[:, 0]), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "\n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items)), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items))\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_target[:, 0]\n",
    "  \n",
    "  \n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 10, 1]), TensorShape([32, 10, 1]), TensorShape([32, 10, 8])]\n",
      "[313896  31313      0      0      0      0      0      0      0      0]\n",
      "[1 1 1 0 0 0 0 0 0 0]\n",
      "[     0      0 313896      0      0      0      0      0      0      0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.3/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=train')]\n",
    "\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=1_855_603, \n",
    "                                     seq_len=10, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.35, \n",
    "                                     reverse_prob=0.2, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# # Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    break\n",
    "\n",
    "# # # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     target, type_target = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 6\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            # embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(3+1, model_cfg.emb_dim)\n",
    "        self.mlp_proj_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_encoding(x_seq_encoding, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_time_encoding + x_seq_past_type)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        ones = tf.ones(tf.shape(y_true))\n",
    "        y_pred = y_pred\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "def recall_top_k(top_k=1):\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_true)[0]\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.float32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.float32)\n",
    "        cum_sum = tf.zeros(n_samples)\n",
    "        for i in tf.range(top_k):\n",
    "            indexes_i = top_index[:, :, i]\n",
    "            is_true = tf.reduce_sum(tf.cast(tf.equal(y_true, indexes_i), tf.float32), axis=-1)/tf.reduce_sum(mask, -1)\n",
    "            cum_sum += (is_true/tf.cast(i+1, tf.float32))\n",
    "        return tf.reduce_mean(cum_sum)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(64, 20_000)\n",
    "plt.plot(tmp_lr(tf.range(187_500 * 1, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n",
      "Epoch 1/5\n",
      "      6/Unknown - 4s 237ms/step - loss: 14.0935WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0262s vs `on_train_batch_end` time: 0.1755s). Check your callbacks.\n",
      "  21363/Unknown - 5005s 234ms/step - loss: 12.4350"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 60\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.model_name}/', compile=False)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mCustomSchedule(BERT4REC_CONFIG\u001b[39m.\u001b[39mscheduler_scaler, warmup_steps\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mwarmup_steps)),\n\u001b[0;32m     56\u001b[0m               loss\u001b[39m=\u001b[39mcustom_loss_bert4rec(),\n\u001b[0;32m     57\u001b[0m               metrics\u001b[39m=\u001b[39m[]\u001b[39m#mrr_topk_categorical(top_k=20)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 60\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataloader,\n\u001b[0;32m     61\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[0;32m     62\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mBERT4REC_CONFIG\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m     63\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[early_stop],\n\u001b[0;32m     64\u001b[0m                     epochs\u001b[39m=\u001b[39;49mBERT4REC_CONFIG\u001b[39m.\u001b[39;49mepochs,\n\u001b[0;32m     65\u001b[0m                     \u001b[39m# steps_per_epoch=10_000,\u001b[39;49;00m\n\u001b[0;32m     66\u001b[0m                     \u001b[39m# validation_steps=2_000,\u001b[39;49;00m\n\u001b[0;32m     67\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)     \n\u001b[0;32m     69\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/seq_len\u001b[39m\u001b[39m{\u001b[39;00mBERT4REC_CONFIG\u001b[39m.\u001b[39mseq_len\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mBERT4REC_CONFIG\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, include_optimizer\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m model\u001b[39m.\u001b[39msave_weights(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/weights/seq_len\u001b[39m\u001b[39m{\u001b[39;00mBERT4REC_CONFIG\u001b[39m.\u001b[39mseq_len\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mBERT4REC_CONFIG\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, save_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m'\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1389\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1391\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    561\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 563\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    555\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 557\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    558\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1188\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1190\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class BERT4REC_CONFIG:\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.3/'\n",
    "    model_name = 'model_bert4rec_complete_v0.4'\n",
    "    num_records_dataset = 12_000_000\n",
    "    batch_size = 64\n",
    "    seq_len = 10\n",
    "    mask_prob = 0.35\n",
    "    reverse_prob = 0.2\n",
    "    emb_dim = 16\n",
    "    trf_dim = 16\n",
    "    num_heads = 2\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 5\n",
    "    early_stopping = 5\n",
    "    scheduler_scaler = 64 \n",
    "    warmup_steps = 20_000\n",
    "\n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "early_stop = ReturnBestEarlyStopping(monitor='val_loss', mode=\"min\", patience=BERT4REC_CONFIG.early_stopping, verbose=1, restore_best_weights=True)\n",
    " \n",
    "tf.keras.backend.clear_session()\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.model_name}/', compile=False)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, warmup_steps=BERT4REC_CONFIG.warmup_steps)),\n",
    "              loss=custom_loss_bert4rec(),\n",
    "              metrics=[]#mrr_topk_categorical(top_k=20)\n",
    ")\n",
    "\n",
    "history = model.fit(train_dataloader,\n",
    "                    validation_data=val_dataloader,\n",
    "                    batch_size=BERT4REC_CONFIG.batch_size,\n",
    "                    callbacks=[early_stop],\n",
    "                    epochs=BERT4REC_CONFIG.epochs,\n",
    "                    # steps_per_epoch=10_000,\n",
    "                    # validation_steps=2_000,\n",
    "                    verbose=1)     \n",
    "\n",
    "model.save(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.model_name}', include_optimizer=False)\n",
    "model.save_weights(f'../2_Models/weights/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.model_name}', save_format='tf') \n",
    "\n",
    "# model_bert4rec_complete_v0.2.4\n",
    "# Epoch 1/5\n",
    "#  Train: 29310/Unknown - 14878s 222ms/step - loss: 12.6271\n",
    "#  Val:    1062/Unknown - 164s 154ms/step - loss: 11.1852\n",
    "\n",
    "# model_bert4rec_complete_v0.3 (kaggle)\n",
    "#  Train: 50000/Unknown - 14878s 297ms/step - loss: 11.2429\n",
    "#  Val:    2000/Unknown - 164s 154ms/step - loss: 8.1546\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [02:39, 31.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>list_trues</th>\n",
       "      <th>list_type_trues</th>\n",
       "      <th>list_predictions</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>972023</td>\n",
       "      <td>[438554, 586148, 424684, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[163610, 789301, 54853, 847856, 835966, 426530...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3145948</td>\n",
       "      <td>[597062, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[391939, 1225741, 595541, 712992, 1117985, 303...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1306646</td>\n",
       "      <td>[41555, 41555, 12270, 887388, 201746, 298020, ...</td>\n",
       "      <td>[1, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 2, ...</td>\n",
       "      <td>[753196, 1172221, 1150803, 1141989, 312331, 88...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2963039</td>\n",
       "      <td>[1299623, 1120748, 766684, 1189998, 0, 1010303...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4908, 587512, 789301, 642820, 847856, 1005285...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4050371</td>\n",
       "      <td>[786108, 1303277, 792985, 538149, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1141989, 1108383, 1151996, 353732, 1117985, 3...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160027</th>\n",
       "      <td>1152060</td>\n",
       "      <td>[1309, 242993, 158024, 1309, 158024, 597833, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[4908, 469725, 766037, 753296, 191582, 789301,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160028</th>\n",
       "      <td>3779058</td>\n",
       "      <td>[729262, 1185729, 431649, 617250, 729262, 5425...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[737679, 697107, 1225981, 448340, 622924, 1940...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160029</th>\n",
       "      <td>11562895</td>\n",
       "      <td>[342822, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[342822, 1096493, 107937, 23781, 567910, 11046...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160030</th>\n",
       "      <td>733924</td>\n",
       "      <td>[836663, 114725, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1133996, 462567, 1210482, 41476, 182533, 8438...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160031</th>\n",
       "      <td>2066158</td>\n",
       "      <td>[1181512, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[654077, 926400, 561244, 1289187, 248873, 7769...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160032 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         session                                         list_trues  \\\n",
       "0         972023  [438554, 586148, 424684, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1        3145948  [597062, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "2        1306646  [41555, 41555, 12270, 887388, 201746, 298020, ...   \n",
       "3        2963039  [1299623, 1120748, 766684, 1189998, 0, 1010303...   \n",
       "4        4050371  [786108, 1303277, 792985, 538149, 0, 0, 0, 0, ...   \n",
       "...          ...                                                ...   \n",
       "160027   1152060  [1309, 242993, 158024, 1309, 158024, 597833, 1...   \n",
       "160028   3779058  [729262, 1185729, 431649, 617250, 729262, 5425...   \n",
       "160029  11562895  [342822, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "160030    733924  [836663, 114725, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "160031   2066158  [1181512, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          list_type_trues  \\\n",
       "0       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2       [1, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 2, ...   \n",
       "3       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                   ...   \n",
       "160027  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "160028  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "160029  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "160030  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "160031  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         list_predictions score  type  \n",
       "0       [163610, 789301, 54853, 847856, 835966, 426530...   0.0     1  \n",
       "1       [391939, 1225741, 595541, 712992, 1117985, 303...   0.0     1  \n",
       "2       [753196, 1172221, 1150803, 1141989, 312331, 88...   0.0     1  \n",
       "3       [4908, 587512, 789301, 642820, 847856, 1005285...   0.0     1  \n",
       "4       [1141989, 1108383, 1151996, 353732, 1117985, 3...   0.0     1  \n",
       "...                                                   ...   ...   ...  \n",
       "160027  [4908, 469725, 766037, 753296, 191582, 789301,...   0.0     1  \n",
       "160028  [737679, 697107, 1225981, 448340, 622924, 1940...   0.0     1  \n",
       "160029  [342822, 1096493, 107937, 23781, 567910, 11046...   1.0     2  \n",
       "160030  [1133996, 462567, 1210482, 41476, 182533, 8438...   0.0     1  \n",
       "160031  [654077, 926400, 561244, 1289187, 248873, 7769...   0.0     1  \n",
       "\n",
       "[160032 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.600320e+05</td>\n",
       "      <td>160032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.372260e+06</td>\n",
       "      <td>1.111878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.714617e+06</td>\n",
       "      <td>0.373970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.142520e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.340550e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.563548e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289970e+07</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session           type\n",
       "count  1.600320e+05  160032.000000\n",
       "mean   6.372260e+06       1.111878\n",
       "std    3.714617e+06       0.373970\n",
       "min    1.990000e+02       1.000000\n",
       "25%    3.142520e+06       1.000000\n",
       "50%    6.340550e+06       1.000000\n",
       "75%    9.563548e+06       1.000000\n",
       "max    1.289970e+07       3.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "type\n",
       "1    0.035740\n",
       "2    0.092375\n",
       "3    0.071738\n",
       "Name: score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.0743\n"
     ]
    }
   ],
   "source": [
    "def get_score_click(y_true, y_pred, y_type):\n",
    "    y_true = [y for y, t in zip(y_true, y_type) if t==1]\n",
    "    assert len(y_true)>=1\n",
    "    topk = len(y_pred)\n",
    "    score = 0\n",
    "    for k in range(topk):\n",
    "        # Only first target\n",
    "        if y_pred[k] == y_true[0]:\n",
    "            score = 1\n",
    "    return score\n",
    "\n",
    "def get_score_cart_order(y_true, y_pred, y_type, type_idx):\n",
    "    y_true = [y for y, t in zip(y_true, y_type) if t==type_idx]\n",
    "    assert len(y_true)>=1\n",
    "    if len(y_true)==0: return 0\n",
    "    topk = len(y_pred)\n",
    "    score = 0\n",
    "    for k in range(topk):\n",
    "        if y_pred[k] in y_true:\n",
    "            score += 1\n",
    "    return score/len(y_true)\n",
    "\n",
    "def get_metric(y_true, y_pred, y_true_type, type_of_target):\n",
    "    list_scores = []\n",
    "    for idx in range(y_true.shape[0]):\n",
    "        y_true_type_idx = np.asarray([x for x in y_true_type[idx] if x!= 0])\n",
    "        y_true_idx = np.asarray([x for x in y_true[idx] if x!= 0])\n",
    "        if len(y_true_idx)==0:\n",
    "            # print('a')\n",
    "            score = None\n",
    "        else:\n",
    "            y_true_idx, idxs_ = np.unique(y_true_idx, return_index=True)\n",
    "            y_true_type_idx = y_true_type_idx[idxs_]\n",
    "            y_pred_idx = y_pred[idx]\n",
    "            type_idx = type_of_target[idx]      \n",
    "            ###\n",
    "            if type_idx==1:\n",
    "                score = get_score_click(y_true_idx, y_pred_idx, y_true_type_idx)\n",
    "            else:\n",
    "                score = get_score_cart_order(y_true_idx, y_pred_idx, y_true_type_idx, type_idx)\n",
    "        list_scores.append(score)\n",
    "    return list_scores\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# model = models.load_model('../2_Models/seq_len20_model_bert4rec_complete_v0.4/', compile=False)\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.3/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=10, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_trues, list_types, list_scores = [], [], [], []\n",
    "list_sessions, list_type_target = [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    target, type_target = targets\n",
    "    idxs_past = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    preds = model(features, training=False)\n",
    "    preds = tf.gather(preds, indices=idxs_past, axis=1, batch_dims=1)\n",
    "    type = type_target[:, 0]\n",
    "    ###\n",
    "    topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "    scores = get_metric(target.numpy(), topk_idxs.numpy(), type_target.numpy(), type.numpy())\n",
    "    list_scores.append(scores)\n",
    "    list_predictions.append(topk_idxs.numpy())\n",
    "    list_trues.append(target.numpy())\n",
    "    list_types.append(type.numpy())\n",
    "    list_sessions.append(session.numpy())\n",
    "    list_type_target.append(type_target.numpy())\n",
    "    if num_batch == 5_000:\n",
    "        break\n",
    "    \n",
    "df_scores_metric = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'list_trues' : np.concatenate(list_trues).tolist(),\n",
    "    'list_type_trues' : np.concatenate(list_type_target).tolist(),\n",
    "    'list_predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'score' : np.concatenate(list_scores),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "display(df_scores_metric)\n",
    "display(df_scores_metric.describe())\n",
    "display(df_scores_metric.groupby('type')['score'].mean())\n",
    "score_clicks = df_scores_metric.groupby('type')['score'].mean()[1]\n",
    "score_carts = df_scores_metric.groupby('type')['score'].mean()[2]\n",
    "score_orders = df_scores_metric.groupby('type')['score'].mean()[3]\n",
    "kaggle_metric = 0.1*score_clicks + 0.3*score_carts + 0.6*score_orders\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# v0.3 seqlen=10\n",
    "# type\n",
    "# 1    0.160703\n",
    "# 2    0.323972\n",
    "# 3    0.347853\n",
    "# Kaggle Metric: 0.33358\n",
    "\n",
    "# v0.4 seqlen=10\n",
    "# type\n",
    "# 1    0.151429\n",
    "# 2    0.400343\n",
    "# 3    0.428708\n",
    "# Name: score, dtype: float64\n",
    "# Kaggle Metric: 0.3925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:02,  6.49it/s]"
     ]
    }
   ],
   "source": [
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.keras.backend.clear_session()\n",
    "# model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.2.4/', compile=False)\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.3/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=1_855_603, \n",
    "                                     seq_len=10,  \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, target, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 52244it [2:47:45,  5.19it/s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m name_submission \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msubmission_\u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39m\u001b[39m__str__\u001b[39m()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df_inference \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\n\u001b[0;32m      4\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39msession\u001b[39;49m\u001b[39m'\u001b[39;49m : np\u001b[39m.\u001b[39;49mconcatenate(list_sessions),\n\u001b[0;32m      5\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mpredictions\u001b[39;49m\u001b[39m'\u001b[39;49m : np\u001b[39m.\u001b[39;49mconcatenate(list_predictions)\u001b[39m.\u001b[39;49mtolist(),\n\u001b[0;32m      6\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m : np\u001b[39m.\u001b[39;49mconcatenate(list_types)\n\u001b[0;32m      7\u001b[0m })\n\u001b[0;32m      9\u001b[0m df_inference[\u001b[39m'\u001b[39m\u001b[39msession_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_inference[\u001b[39m'\u001b[39m\u001b[39msession\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m df_inference[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m df_inference[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_inference[\u001b[39m'\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x : \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(y) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m x]))\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:614\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    608\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    609\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    612\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    613\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 614\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    615\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    616\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:464\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    456\u001b[0m     arrays \u001b[39m=\u001b[39m [\n\u001b[0;32m    457\u001b[0m         x\n\u001b[0;32m    458\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    459\u001b[0m         \u001b[39melse\u001b[39;00m x\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    460\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m    461\u001b[0m     ]\n\u001b[0;32m    462\u001b[0m     \u001b[39m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(\n\u001b[0;32m    465\u001b[0m     arrays, data_names, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy\n\u001b[0;32m    466\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    117\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    120\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:635\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    634\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 635\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    637\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    638\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    640\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c4b929e2472036a63dc2b4145b104daea13432f82a7dbc65e279332da4f8b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
