{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.2_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "SEED = 12\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*16)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=False).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_time_encoding, seq_time_encoding_target = seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding), (seq_items_target_all[:, 0], seq_type_target_all[:, 0]), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "\n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items)), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items))\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            idxs_target = idxs_target[:-1]\n",
    "        # !!! DOES NOT WORK\n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        # if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == 0:\n",
    "        #     idxs_inputs = tf.cast([qt_size_seq], tf.int64)\n",
    "        #     idxs_target = idxs_target[:-1]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_target[:, 0]\n",
    "  \n",
    "  \n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 10, 1]), TensorShape([32, 10, 1]), TensorShape([32, 10, 8])]\n",
      "[ 895558  358402 1466109   80223  351336       0 1466109   80223 1466109\n",
      "   80223]\n",
      "[1 1 1 1 1 1 1 2 2 3]\n",
      "[    0     0     0     0     0 80223     0     0     0     0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.2/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.2/na_split=train')]\n",
    "\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=1_855_603, \n",
    "                                     seq_len=10, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.3, \n",
    "                                     reverse_prob=0.2, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# # Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    break\n",
    "\n",
    "# # # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     target, type_target = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 1\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(3+1, model_cfg.emb_dim)\n",
    "        self.mlp_proj_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_encoding(x_seq_encoding, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_time_encoding + x_seq_past_type)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        ones = tf.ones(tf.shape(y_true))\n",
    "        y_pred = y_pred\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "def recall_top_k(top_k=1):\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_true)[0]\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.float32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.float32)\n",
    "        cum_sum = tf.zeros(n_samples)\n",
    "        for i in tf.range(top_k):\n",
    "            indexes_i = top_index[:, :, i]\n",
    "            is_true = tf.reduce_sum(tf.cast(tf.equal(y_true, indexes_i), tf.float32), axis=-1)/tf.reduce_sum(mask, -1)\n",
    "            cum_sum += (is_true/tf.cast(i+1, tf.float32))\n",
    "        return tf.reduce_mean(cum_sum)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 20_000)\n",
    "plt.plot(tmp_lr(tf.range(174_000 * 1, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n",
      "Epoch 1/5\n",
      "      6/Unknown - 3s 205ms/step - loss: 14.4314WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0242s vs `on_train_batch_end` time: 0.1505s). Check your callbacks.\n",
      "  29310/Unknown - 6512s 222ms/step - loss: 12.6271"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 55\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.model_name}/', compile=False)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mCustomSchedule(\u001b[39m128\u001b[39m, warmup_steps\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mwarmup_steps)),\n\u001b[0;32m     51\u001b[0m               loss\u001b[39m=\u001b[39mcustom_loss_bert4rec(),\n\u001b[0;32m     52\u001b[0m               metrics\u001b[39m=\u001b[39m[]\u001b[39m#mrr_topk_categorical(top_k=20)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m )\n\u001b[1;32m---> 55\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataloader,\n\u001b[0;32m     56\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[0;32m     57\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mBERT4REC_CONFIG\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m     58\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[early_stop],\n\u001b[0;32m     59\u001b[0m                     epochs\u001b[39m=\u001b[39;49mBERT4REC_CONFIG\u001b[39m.\u001b[39;49mepochs,\n\u001b[0;32m     60\u001b[0m                     \u001b[39m# steps_per_epoch=10_000,\u001b[39;49;00m\n\u001b[0;32m     61\u001b[0m                     \u001b[39m# validation_steps=2_000,\u001b[39;49;00m\n\u001b[0;32m     62\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)     \n\u001b[0;32m     64\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/seq_len\u001b[39m\u001b[39m{\u001b[39;00mBERT4REC_CONFIG\u001b[39m.\u001b[39mseq_len\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mBERT4REC_CONFIG\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, include_optimizer\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     65\u001b[0m model\u001b[39m.\u001b[39msave_weights(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/weights/seq_len\u001b[39m\u001b[39m{\u001b[39;00mBERT4REC_CONFIG\u001b[39m.\u001b[39mseq_len\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mBERT4REC_CONFIG\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, save_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m'\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1389\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1391\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    561\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 563\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    555\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 557\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    558\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1188\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1190\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class BERT4REC_CONFIG:\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.2/'\n",
    "    model_name = 'model_bert4rec_complete_v0.2.4'\n",
    "    batch_size = 40\n",
    "    seq_len = 10\n",
    "    mask_prob = 0.3\n",
    "    reverse_prob = 0.2\n",
    "    emb_dim = 16\n",
    "    trf_dim = 16\n",
    "    num_heads = 2\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 5\n",
    "    early_stopping = 5\n",
    "    warmup_steps = 20_000\n",
    "\n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=1_855_603, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=1_855_603, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "early_stop = ReturnBestEarlyStopping(monitor='val_loss', mode=\"min\", patience=BERT4REC_CONFIG.early_stopping, verbose=1, restore_best_weights=True)\n",
    " \n",
    "model = build_model_bert4Rec(num_items=1_855_603, model_cfg=BERT4REC_CONFIG)\n",
    "# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.model_name}/', compile=False)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=CustomSchedule(128, warmup_steps=BERT4REC_CONFIG.warmup_steps)),\n",
    "              loss=custom_loss_bert4rec(),\n",
    "              metrics=[]#mrr_topk_categorical(top_k=20)\n",
    ")\n",
    "\n",
    "history = model.fit(train_dataloader,\n",
    "                    validation_data=val_dataloader,\n",
    "                    batch_size=BERT4REC_CONFIG.batch_size,\n",
    "                    callbacks=[early_stop],\n",
    "                    epochs=BERT4REC_CONFIG.epochs,\n",
    "                    # steps_per_epoch=10_000,\n",
    "                    # validation_steps=2_000,\n",
    "                    verbose=1)     \n",
    "\n",
    "model.save(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.model_name}', include_optimizer=False)\n",
    "model.save_weights(f'../2_Models/weights/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.model_name}', save_format='tf') \n",
    "\n",
    "# model_bert4rec_complete_v0.2.3\n",
    "# Epoch 1/5\n",
    "#  Train: 39143/Unknown - 8413s 215ms/step - loss: 12.6893\n",
    "#  Val:    1062/Unknown - 164s 154ms/step - loss: 12.1702\n",
    "\n",
    "# model_bert4rec_complete_v0.2.4\n",
    "# Epoch 1/5\n",
    "#  Train: 29310/Unknown - 6512s 222ms/step - loss: 12.6271\n",
    "#  Val:    1062/Unknown - 164s 154ms/step - loss: 11.1852\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [02:35, 32.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>list_trues</th>\n",
       "      <th>list_type_trues</th>\n",
       "      <th>list_predictions</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6705177</td>\n",
       "      <td>[754053, 963788, 963788, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[963788, 1326476, 368513, 797765, 362778, 1308...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12511749</td>\n",
       "      <td>[546090, 700403, 137089, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[76823, 700403, 322371, 1502123, 1347179, 1346...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5202191</td>\n",
       "      <td>[184720, 1782551, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[129870, 95489, 1056532, 1640772, 1585626, 691...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10461538</td>\n",
       "      <td>[1783595, 1685975, 107885, 1799360, 0, 0, 0, 0...</td>\n",
       "      <td>[3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3980, 105842, 1810973, 814709, 800392, 148739...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11635708</td>\n",
       "      <td>[851050, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1072144, 1519664, 257477, 1474543, 1382329, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160027</th>\n",
       "      <td>10535905</td>\n",
       "      <td>[198456, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1636725, 95489, 1712352, 691810, 654389, 1497...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160028</th>\n",
       "      <td>10736591</td>\n",
       "      <td>[1532782, 1736087, 1532782, 434224, 0, 0, 0, 0...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1532782, 352193, 1294925, 892872, 1304793, 39...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160029</th>\n",
       "      <td>11604736</td>\n",
       "      <td>[1506738, 386769, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[386769, 1152547, 1267746, 143308, 1728319, 16...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160030</th>\n",
       "      <td>8918940</td>\n",
       "      <td>[1843874, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[964215, 818698, 714525, 1473793, 1506914, 118...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160031</th>\n",
       "      <td>2441304</td>\n",
       "      <td>[902525, 1159769, 781635, 1159769, 1319267, 17...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[496181, 1140716, 688180, 861402, 1331425, 962...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160032 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         session                                         list_trues  \\\n",
       "0        6705177  [754053, 963788, 963788, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1       12511749  [546090, 700403, 137089, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2        5202191  [184720, 1782551, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "3       10461538  [1783595, 1685975, 107885, 1799360, 0, 0, 0, 0...   \n",
       "4       11635708  [851050, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "...          ...                                                ...   \n",
       "160027  10535905  [198456, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "160028  10736591  [1532782, 1736087, 1532782, 434224, 0, 0, 0, 0...   \n",
       "160029  11604736  [1506738, 386769, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "160030   8918940  [1843874, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "160031   2441304  [902525, 1159769, 781635, 1159769, 1319267, 17...   \n",
       "\n",
       "                                          list_type_trues  \\\n",
       "0       [1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3       [3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                   ...   \n",
       "160027  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "160028  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "160029  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "160030  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "160031  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                         list_predictions  score  type  \n",
       "0       [963788, 1326476, 368513, 797765, 362778, 1308...    0.0     1  \n",
       "1       [76823, 700403, 322371, 1502123, 1347179, 1346...    1.0     1  \n",
       "2       [129870, 95489, 1056532, 1640772, 1585626, 691...    0.0     1  \n",
       "3       [3980, 105842, 1810973, 814709, 800392, 148739...    0.0     3  \n",
       "4       [1072144, 1519664, 257477, 1474543, 1382329, 1...    0.0     1  \n",
       "...                                                   ...    ...   ...  \n",
       "160027  [1636725, 95489, 1712352, 691810, 654389, 1497...    0.0     1  \n",
       "160028  [1532782, 352193, 1294925, 892872, 1304793, 39...    1.0     1  \n",
       "160029  [386769, 1152547, 1267746, 143308, 1728319, 16...    0.0     1  \n",
       "160030  [964215, 818698, 714525, 1473793, 1506914, 118...    0.0     1  \n",
       "160031  [496181, 1140716, 688180, 861402, 1331425, 962...    0.0     1  \n",
       "\n",
       "[160032 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.600320e+05</td>\n",
       "      <td>160032.000000</td>\n",
       "      <td>160032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.365173e+06</td>\n",
       "      <td>0.177902</td>\n",
       "      <td>1.111234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.711311e+06</td>\n",
       "      <td>0.379317</td>\n",
       "      <td>0.372765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.154786e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.327434e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.563679e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289966e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session          score           type\n",
       "count  1.600320e+05  160032.000000  160032.000000\n",
       "mean   6.365173e+06       0.177902       1.111234\n",
       "std    3.711311e+06       0.379317       0.372765\n",
       "min    3.900000e+01       0.000000       1.000000\n",
       "25%    3.154786e+06       0.000000       1.000000\n",
       "50%    6.327434e+06       0.000000       1.000000\n",
       "75%    9.563679e+06       0.000000       1.000000\n",
       "max    1.289966e+07       1.000000       3.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "type\n",
       "1    0.162391\n",
       "2    0.322248\n",
       "3    0.368825\n",
       "Name: score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.3342\n"
     ]
    }
   ],
   "source": [
    "def get_score_click(y_true, y_pred, y_type):\n",
    "    y_true = [y for y, t in zip(y_true, y_type) if t==1]\n",
    "    assert len(y_true)>=1\n",
    "    topk = len(y_pred)\n",
    "    score = 0\n",
    "    for k in range(topk):\n",
    "        # Only first target\n",
    "        if y_pred[k] == y_true[0]:\n",
    "            score = 1\n",
    "    return score\n",
    "\n",
    "def get_score_cart_order(y_true, y_pred, y_type, type_idx):\n",
    "    y_true = [y for y, t in zip(y_true, y_type) if t==type_idx]\n",
    "    assert len(y_true)>=1\n",
    "    topk = len(y_pred)\n",
    "    score = 0\n",
    "    for k in range(topk):\n",
    "        if y_pred[k] in y_true:\n",
    "            score += 1\n",
    "    return score/len(y_true)\n",
    "\n",
    "def get_metric(y_true, y_pred, y_true_type, type_of_target):\n",
    "    list_scores = []\n",
    "    for idx in range(y_true.shape[0]):\n",
    "        y_true_type_idx = np.asarray([x for x in y_true_type[idx] if x!= 0])\n",
    "        y_true_idx = np.asarray([x for x in y_true[idx] if x!= 0])\n",
    "        # y_true_idx, idxs_ = np.unique(y_true_idx, return_index=True)\n",
    "        # y_true_type_idx = y_true_type_idx[idxs_]\n",
    "        y_pred_idx = y_pred[idx]\n",
    "        type_idx = type_of_target[idx]      \n",
    "        ###\n",
    "        if type_idx==1:\n",
    "            score = get_score_click(y_true_idx, y_pred_idx, y_true_type_idx)\n",
    "        else:\n",
    "            score = get_score_cart_order(y_true_idx, y_pred_idx, y_true_type_idx, type_idx)\n",
    "        list_scores.append(score)\n",
    "    return list_scores\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.3/', compile=False)\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.2/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.2/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=1_855_603, \n",
    "                                     seq_len=10, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_trues, list_types, list_scores = [], [], [], []\n",
    "list_sessions, list_type_target = [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    target, type_target = targets\n",
    "    idxs_past = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    preds = model(features, training=False)\n",
    "    preds = tf.gather(preds, indices=idxs_past, axis=1, batch_dims=1)\n",
    "    type = type_target[:, 0]\n",
    "    ###\n",
    "    topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "    scores = get_metric(target.numpy(), topk_idxs.numpy(), type_target.numpy(), type.numpy())\n",
    "    list_scores.append(scores)\n",
    "    list_predictions.append(topk_idxs.numpy())\n",
    "    list_trues.append(target.numpy())\n",
    "    list_types.append(type.numpy())\n",
    "    list_sessions.append(session.numpy())\n",
    "    list_type_target.append(type_target.numpy())\n",
    "    if num_batch == 5_000:\n",
    "        break\n",
    "    \n",
    "df_scores_metric = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'list_trues' : np.concatenate(list_trues).tolist(),\n",
    "    'list_type_trues' : np.concatenate(list_type_target).tolist(),\n",
    "    'list_predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'score' : np.concatenate(list_scores),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "display(df_scores_metric)\n",
    "display(df_scores_metric.describe())\n",
    "display(df_scores_metric.groupby('type')['score'].mean())\n",
    "score_clicks = df_scores_metric.groupby('type')['score'].mean()[1]\n",
    "score_carts = df_scores_metric.groupby('type')['score'].mean()[2]\n",
    "score_orders = df_scores_metric.groupby('type')['score'].mean()[3]\n",
    "kaggle_metric = 0.1*score_clicks + 0.3*score_carts + 0.6*score_orders\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# v0.2.4 seqlen=10\n",
    "# type\n",
    "# 1    0.027986\n",
    "# 2    0.065574\n",
    "# 3    0.068966\n",
    "\n",
    "# v0.3 seqlen=10\n",
    "# type\n",
    "# 1    0.160703\n",
    "# 2    0.323972\n",
    "# 3    0.347853\n",
    "# Kaggle Metric: 0.33358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:14,  6.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.keras.backend.clear_session()\n",
    "model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.2.4/', compile=False)\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.2/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.2/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=1_855_603, \n",
    "                                     seq_len=10,  \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, target, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs.numpy())\n",
    "        list_types.append([type_])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 52244it [2:47:45,  5.19it/s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5015409, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5015409, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c4b929e2472036a63dc2b4145b104daea13432f82a7dbc65e279332da4f8b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
