{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:32:03.361260: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 00:32:03.428344: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-21 00:32:03.708133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-21 00:32:03.708161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-21 00:32:03.708163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:32:03.993252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 00:32:04.006751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 00:32:04.006833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 8146995.28it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "SEED = 12\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.4/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False, drop_remainder=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "        self.drop_remainder = drop_remainder\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        \n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        # dataset = dataset.map(self.normalize_features, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*50, reshuffle_each_iteration=True)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=self.drop_remainder).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        seq_recency = tf.concat([seq_recency, tf.zeros((1, tf.shape(seq_recency)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        idx_masked = tf.clip_by_value(tf.shape(seq_items)[0], 0, self.seq_len-1)\n",
    "        seq_items, _ = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding, seq_recency), (seq_items_target_all[:, 0], seq_type_target_all[:, 0], idx_masked), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        seq_recency = seq_recency[-self.seq_len:, :]\n",
    "        idx_masked = tf.clip_by_value(tf.shape(seq_items)[0], 0, self.seq_len-1)\n",
    "        # Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        seq_recency = tf.concat([seq_recency, tf.zeros((1, tf.shape(seq_recency)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, _ = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding, seq_recency), idx_masked, session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), idx_masked\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            seq_recency = tf.reverse(seq_recency, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_recency = seq_recency[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_recency = tf.zeros((len(idxs_inputs), seq_recency.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_recency = tf.tensor_scatter_nd_update(seq_recency, idxs_inputs, updates_recency)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32) \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), seq_target[:, 0]\n",
    "  \n",
    "    def normalize_features(self, features):\n",
    "        return (features - tf.constant(5.45)/tf.constant(1.09))\n",
    "\n",
    "    # def normalize_features(self, features, targets=None, session=None):\n",
    "    #     seq_items, seq_type, seq_time_encoding, seq_recency = features\n",
    "    #     seq_recency = (seq_recency - tf.constant(5.45)/tf.constant(1.09))\n",
    "    #     features = (seq_items, seq_type, seq_time_encoding, seq_recency)\n",
    "    #     return features, targets, session\n",
    "\n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        features[3].set_shape((self.seq_len, 1))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:32:05.774542: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 00:32:05.775157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 00:32:05.775237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 00:32:05.775276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 00:32:06.049848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 00:32:06.049927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 00:32:06.049971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 00:32:06.050016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21469 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 20, 1]), TensorShape([32, 20, 1]), TensorShape([32, 20, 8]), TensorShape([32, 20, 1])]\n",
      "[878879      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1]\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.4/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=test')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.4, \n",
    "                                     reverse_prob=0.25, \n",
    "                                     get_session=True,\n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "# # Train\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     break\n",
    "\n",
    "# # Test\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    idx_mask = target\n",
    "    break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     target, type_target, idx_mask = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 2\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "print(idx_mask[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time, seq_recency\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.std_init = np.sqrt(1/(model_cfg.emb_dim*3)).round(4)\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(\n",
    "            3+1, \n",
    "            model_cfg.emb_dim,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)\n",
    "        )\n",
    "        self.mlp_proj_time_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        ])\n",
    "        # self.mlp_proj_conts = tf.keras.models.Sequential([\n",
    "        #    tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "        #    tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)),\n",
    "        #    tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        # ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding, x_seq_recency = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_time_encoding(x_seq_encoding, training=training)\n",
    "        # x_seq_recency = self.mlp_proj_conts(x_seq_recency, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_past_type + x_seq_time_encoding)# + x_seq_recency)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        ones = tf.ones(tf.shape(y_true))\n",
    "        y_pred = y_pred\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "def recall_top_k(top_k=1, seq_len=10):\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_pred)[0]\n",
    "        y_true = tf.cast(y_true, tf.int64)\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.int32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.int64)\n",
    "        # cum_sum = tf.zeros(n_samples, tf.int32)\n",
    "        result = tf.constant(0, tf.int32)\n",
    "        for i in tf.range(seq_len):\n",
    "            indexes_i = top_index[:, i, :]\n",
    "            is_true = tf.reduce_sum(tf.reduce_max(tf.where(y_true[:, i:i+1]==indexes_i, 1, 0), -1) * mask[:, i])\n",
    "            result += is_true\n",
    "        return tf.cast(result, tf.float32) / (tf.cast(tf.reduce_sum(mask), tf.float32) + 1e-8)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "finetune_lr = CustomSchedule(512, 5_000, weight_decay=None)\n",
    "plt.plot(tmp_lr(tf.range(10_000_000 // (32* 5), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n",
    "\n",
    "plt.plot(finetune_lr(tf.range(2_300_000 // (32), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g)\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        global_gradients = zip(global_gradients, model.trainable_variables)\n",
    "        optimizer.apply_gradients(global_gradients)\n",
    "        global_gradients = []\n",
    "    return global_gradients\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, **kwargs):\n",
    "    # l_loss = kwargs['loss']\n",
    "    num_accum_steps = tf.cast(kwargs['num_accum_steps'], tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss / num_accum_steps)\n",
    "\n",
    "    gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(gradients)\n",
    "    # gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    # l_loss(loss)\n",
    "    return gradients, predictions\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions)\n",
    "    l_loss(loss)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.6f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name='', dict_config=None):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"),\n",
    "               config=dict_config)\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "\n",
    "def grad_accum_scheduler(num_samples, list_scheduler, max_grad_accum):\n",
    "    if num_samples >= len(list_scheduler):\n",
    "        return max_grad_accum\n",
    "    return list_scheduler[num_samples]\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n",
      "================================================================================\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:32:07.247211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2022-11-21 00:32:07.915852: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x20f759e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-21 00:32:07.915867: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2022-11-21 00:32:07.930974: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model_bert4_rec/encoder_transformer_block/dropout_1/dropout/random_uniform/RandomUniform\n",
      "2022-11-21 00:32:07.933716: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-11-21 00:32:08.969564: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-11-21 00:32:09.487799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Epoch]1/1 [Time]2.30 [Step]0 [Batch]0 [Speed]2299.25ms/step [Loss]0.0000 [Metrics]{'train_loss:0.000000 train_recall_k:0.000000'}\n",
      "aaa\n",
      "[Val Epoch]1/1 [Time]2.54 [Step]1 [Batch]0 [Speed]2537.95ms/step [Loss]11.3798 [Metrics]{'val_loss:11.379755 val_recall_k:0.785235'}\n",
      "[Val Epoch]1/1 [Time]19.23 [Step]201 [Batch]200 [Speed]96.14ms/step [Loss]11.2023 [Metrics]{'val_loss:11.202313 val_recall_k:0.829326'}\n",
      "[Val Epoch]1/1 [Time]36.08 [Step]401 [Batch]400 [Speed]90.21ms/step [Loss]11.2032 [Metrics]{'val_loss:11.203155 val_recall_k:0.829557'}\n",
      "[Val Epoch]1/1 [Time]52.78 [Step]601 [Batch]600 [Speed]87.97ms/step [Loss]11.2019 [Metrics]{'val_loss:11.201858 val_recall_k:0.829974'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m inputs, target \u001b[39m=\u001b[39m val_batch_data\n\u001b[1;32m    137\u001b[0m predictions \u001b[39m=\u001b[39m test_step(inputs, target\u001b[39m=\u001b[39mtarget, loss\u001b[39m=\u001b[39mval_loss)\n\u001b[0;32m--> 138\u001b[0m val_recall_k(recall_function(target, predictions))\n\u001b[1;32m    139\u001b[0m val_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    140\u001b[0m \u001b[39mif\u001b[39;00m val_batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_val \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn [6], line 192\u001b[0m, in \u001b[0;36mrecall_top_k.<locals>.recall\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    190\u001b[0m n_samples \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mshape(y_pred)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    191\u001b[0m y_true \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(y_true, tf\u001b[39m.\u001b[39mint64)\n\u001b[0;32m--> 192\u001b[0m mask \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlogical_not(tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mequal(y_true, \u001b[39m0\u001b[39;49m)), tf\u001b[39m.\u001b[39mint32)\n\u001b[1;32m    193\u001b[0m _, top_index \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mtop_k(y_pred, top_k) \n\u001b[1;32m    194\u001b[0m top_index \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(top_index, tf\u001b[39m.\u001b[39mint64)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1923\u001b[0m, in \u001b[0;36mequal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.equal\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mequal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1890\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_binary_elementwise_api\n\u001b[1;32m   1891\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1892\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mequal\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1893\u001b[0m   \u001b[39m\"\"\"Returns the truth value of (x == y) element-wise.\u001b[39;00m\n\u001b[1;32m   1894\u001b[0m \n\u001b[1;32m   1895\u001b[0m \u001b[39m  Performs a [broadcast](\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[39m    `tf.errors.InvalidArgumentError`: If shapes of arguments are incompatible\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1923\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mequal(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:3301\u001b[0m, in \u001b[0;36mequal\u001b[0;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[1;32m   3299\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3300\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3301\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3302\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mEqual\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, y, \u001b[39m\"\u001b[39;49m\u001b[39mincompatible_shape_error\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   3303\u001b[0m       incompatible_shape_error)\n\u001b[1;32m   3304\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3305\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '1_Model_v0.4.ipynb'\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.4/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.7/checkpoints/', 'ckpt-27')\n",
    "    model_name = 'model_bert4rec_complete_0.7.1'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 10_000_000\n",
    "    batch_size = 32\n",
    "    # num_grad_accum_steps = 5\n",
    "    tup_scheduler_grad_accum = (5, 5, 500_000) #(start_grad_accum, max_grad_accum, ramp_up_samples)\n",
    "    seq_len = 20\n",
    "    mask_prob = 0.4\n",
    "    reverse_prob = 0.25\n",
    "    emb_dim = 128\n",
    "    trf_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 1\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 200\n",
    "    clipnorm = 1.0\n",
    "    num_iters_save_checkpoint = 5_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    weight_decay = 1e-1\n",
    "    log_wandb = False\n",
    "\n",
    "list_scheduler = np.linspace(BERT4REC_CONFIG.tup_scheduler_grad_accum[0], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[1], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[2]).astype(np.uint8).tolist()\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}', dict_config=dict_config)\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm,\n",
    "                            weight_decay=BERT4REC_CONFIG.weight_decay)                  \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = custom_loss_bert4rec()\n",
    "recall_function = recall_top_k(top_k=20, seq_len=BERT4REC_CONFIG.seq_len)\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "train_recall_k = tf.keras.metrics.Mean(name='train_recall_k')\n",
    "val_recall_k = tf.keras.metrics.Mean(name='val_recall_k')\n",
    "\n",
    "##############################################\n",
    "\n",
    "global_gradients = []\n",
    "total_step, val_step, total_samples = 0, 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss, train_recall_k, val_recall_k)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        grad_accum = grad_accum_scheduler(total_samples,\n",
    "                                          list_scheduler=list_scheduler, \n",
    "                                          max_grad_accum=BERT4REC_CONFIG.tup_scheduler_grad_accum[1])                              \n",
    "        step_gradients, predictions = train_step(inputs, target=target, loss=train_loss, num_accum_steps=grad_accum)\n",
    "        global_gradients = backward_optimization(grad_accum, global_gradients, step_gradients, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_recall_k(recall_function(target, predictions))\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss, train_recall_k]}\n",
    "            # train_dict_metrics.update({'lr' : optimizer.learning_rate.numpy().astype(np.float32), 'grad_accum' : grad_accum, 'total_samples' : total_samples})\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step // grad_accum)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                train_dict_metrics.update({'step_grad' : total_step//grad_accum, 'step' : total_step})\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics)     \n",
    "        total_step += 1  \n",
    "        total_samples += BERT4REC_CONFIG.batch_size * grad_accum if total_step % grad_accum==0 else 0\n",
    "        if total_step>grad_accum and (total_step//grad_accum) % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')\n",
    "        break        \n",
    "\n",
    "     \n",
    "    for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "        inputs, target = val_batch_data\n",
    "        predictions = test_step(inputs, target=target, loss=val_loss)\n",
    "        val_recall_k(recall_function(target, predictions))\n",
    "        val_step += 1\n",
    "        if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "            val_dict_metrics = {x.name : x.result() for x in [val_loss, val_recall_k]}\n",
    "            fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "                # if val_batch_num==0:\n",
    "                #     log_wandb_metrics(step=None, plot_image=True, \n",
    "                #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "    \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss, train_recall_k, val_recall_k]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', num_step=epoch, dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [00:49,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.current_loss_scale\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.good_steps\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_time_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_time_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_time_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_time_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_conts.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_conts.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_conts.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_conts.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_time_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_time_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_time_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_time_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_conts.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_conts.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_conts.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_conts.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [02:20,  7.11it/s]\n",
      "100%|██████████| 192192/192192 [00:00<00:00, 232582.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.921920e+05</td>\n",
       "      <td>81269.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.373092e+06</td>\n",
       "      <td>0.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.720560e+06</td>\n",
       "      <td>0.428915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.129786e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.354874e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.572168e+06</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289973e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session         score\n",
       "count  1.921920e+05  81269.000000\n",
       "mean   6.373092e+06      0.262000\n",
       "std    3.720560e+06      0.428915\n",
       "min    1.600000e+01      0.000000\n",
       "25%    3.129786e+06      0.000000\n",
       "50%    6.354874e+06      0.000000\n",
       "75%    9.572168e+06      0.500000\n",
       "max    1.289973e+07      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.33366857321771026,\n",
       " 'clicks': 0.22240758913967942,\n",
       " 'orders': 0.49849532489193765}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.4214\n"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0\n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.7/checkpoints'))\n",
    "# model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.4_finetuned/', compile=False)\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.4/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_predictions, list_trues, list_types = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target, idx_mask = targets\n",
    "    idxs = idx_mask.numpy() #tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "    if num_batch==1_000:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.7 - ckpt14\n",
    "# {'carts': 0.3439392821182184,\n",
    "#  'clicks': 0.23017664376840039,\n",
    "#  'orders': 0.5087165589251029}\n",
    "# Kaggle Metric: 0.4314\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.7 - ckpt27\n",
    "# {'carts': 0.3470019827927542,\n",
    "#  'clicks': 0.23410206084396468,\n",
    "#  'orders': 0.514586102958196}\n",
    "# Kaggle Metric: 0.4363\n",
    "\n",
    "# import wandb\n",
    "# api = wandb.Api()\n",
    "\n",
    "# run = api.run(\"<path to run>\")\n",
    "# run.summary[\"kaggle_metric\"] = metric\n",
    "# run.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f45ccb37ed492fa4febf17b0d7c976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666824068333123, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/enric/SSD1TB/KAGGLE/025_Kaggle-OTTO Recsys-2022/1_Scripts/wandb/run-20221120_190041-3nxxmndm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/3nxxmndm\" target=\"_blank\">model_bert4rec_complete_0.7_finetune_fold_0</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Fold: 0\n",
      "========================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4033/Unknown - 481s 119ms/step - loss: 7.8932 - recall_20: 0.3776"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 51\u001b[0m\n\u001b[1;32m     45\u001b[0m ckpt\u001b[39m.\u001b[39mrestore(tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mlatest_checkpoint(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/model_bert4rec_complete_0.7/checkpoints\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     46\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m4e-5\u001b[39m, \n\u001b[1;32m     47\u001b[0m                                         clipnorm\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, weight_decay\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m),\n\u001b[1;32m     48\u001b[0m               loss\u001b[39m=\u001b[39mloss_function,\n\u001b[1;32m     49\u001b[0m               metrics\u001b[39m=\u001b[39m[recall_function])\n\u001b[0;32m---> 51\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataloader,\n\u001b[1;32m     52\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m     53\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     54\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[WandbCallback()],\n\u001b[1;32m     55\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     56\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     58\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/model_bert4rec_complete_0.7_finetuned_fold_\u001b[39m\u001b[39m{\u001b[39;00mnum_fold\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)                   \n\u001b[1;32m     59\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "list_paths = ['../tfrecords/tfrecords_v0.4/na_split=test_aug/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=test_aug')]# + \\\n",
    "            #  ['../tfrecords/tfrecords_v0.4/na_split=val_aug/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=val_aug')] \n",
    "np.random.shuffle(list_paths)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for num_fold, (train_idxs, val_idxs) in enumerate(kfold.split(list_paths)):\n",
    "    train_paths = np.asarray(list_paths)[train_idxs]\n",
    "    val_paths = np.asarray(list_paths)[val_idxs]\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        time_suffix = datetime.now().__str__().split('.')[0]\n",
    "        dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "        init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_finetune_fold_{num_fold}', dict_config=dict_config)\n",
    "    print('===='*30)\n",
    "    print(f'Fold: {num_fold}')\n",
    "    print('===='*30)\n",
    "\n",
    "    train_dataloader = Bert4RecDataLoader(train_paths, \n",
    "                                         num_items=NUM_ITEMS, \n",
    "                                        seq_len=20,  \n",
    "                                        batch_size=32, \n",
    "                                        mask_prob=0.35, \n",
    "                                        reverse_prob=0.25,  \n",
    "                                        is_val=False,\n",
    "                                        is_test=False,\n",
    "                                        get_session=False,\n",
    "                                        shuffle=True).get_generator()\n",
    "\n",
    "    val_dataloader = Bert4RecDataLoader(val_paths, \n",
    "                                        num_items=NUM_ITEMS, \n",
    "                                        seq_len=20,  \n",
    "                                        batch_size=32, \n",
    "                                        mask_prob=0.35, \n",
    "                                        reverse_prob=0.25,  \n",
    "                                        is_val=True,\n",
    "                                        is_test=False,\n",
    "                                        get_session=False,\n",
    "                                        shuffle=False).get_generator()\n",
    "\n",
    "    loss_function = custom_loss_bert4rec()\n",
    "    recall_function = recall_top_k(top_k=20, seq_len=BERT4REC_CONFIG.seq_len)\n",
    "    model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "    ckpt = tf.train.Checkpoint(model=model)\n",
    "    ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.7/checkpoints'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=4e-5, \n",
    "                                            clipnorm=1.0, weight_decay=1e-4),\n",
    "                  loss=loss_function,\n",
    "                  metrics=[recall_function])\n",
    "\n",
    "    history = model.fit(train_dataloader,\n",
    "                        validation_data=val_dataloader,\n",
    "                        batch_size=32,\n",
    "                        callbacks=[WandbCallback()],\n",
    "                        epochs=1,\n",
    "                        verbose=1)\n",
    "\n",
    "    model.save(f'../2_Models/model_bert4rec_complete_0.7_finetuned_fold_{num_fold}/')                   \n",
    "    wandb.finish()\n",
    "\n",
    "# 173/Unknown - 22s 113ms/step - loss: 7.9368 - recall_20: 0.3452\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 19:15:23.433225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "0it [00:00, ?it/s]2022-11-20 19:15:24.337587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "26122it [55:08,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.7/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.4/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, idxs, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    idxs = idxs.numpy()\n",
    "    # idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 26122it [54:28,  7.99it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")\n",
    "\n",
    "import gzip\n",
    "with open(f'../3_Submissions/{name_submission}.csv', 'rb') as f_in, gzip.open(f'../3_Submissions/{name_submission}.csv.gz', 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0432fa0070c5c9f7d9e158f590013ccc765eb84f02e6f69521746370c3bf6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
