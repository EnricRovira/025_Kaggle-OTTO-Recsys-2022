{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:00:05.529521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-27 21:00:05.596492: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-27 21:00:05.612008: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-27 21:00:05.888491: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-27 21:00:05.888518: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-27 21:00:05.888521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:00:06.181841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 21:00:06.195190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 21:00:06.195274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 8195499.97it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.5/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False, drop_remainder=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "        self.drop_remainder = drop_remainder\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        \n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        # dataset = dataset.map(self.normalize_features, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*50, reshuffle_each_iteration=True)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=self.drop_remainder).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        seq_recency = tf.concat([seq_recency, tf.zeros((1, tf.shape(seq_recency)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        idx_masked = tf.clip_by_value(tf.shape(seq_items)[0], 0, self.seq_len-1)\n",
    "        seq_items, _ = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding, seq_recency), (seq_items_target_all[:, 0], seq_type_target_all[:, 0], idx_masked), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        seq_recency = seq_recency[-self.seq_len:, :]\n",
    "        idx_masked = tf.clip_by_value(tf.shape(seq_items)[0], 0, self.seq_len-1)\n",
    "        # Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        seq_recency = tf.concat([seq_recency, tf.zeros((1, tf.shape(seq_recency)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, _ = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding, seq_recency), idx_masked, session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), idx_masked\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            seq_recency = tf.reverse(seq_recency, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_recency = seq_recency[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_recency = tf.zeros((len(idxs_inputs), seq_recency.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_recency = tf.tensor_scatter_nd_update(seq_recency, idxs_inputs, updates_recency)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32) \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), seq_target[:, 0]\n",
    "  \n",
    "    def normalize_features(self, features):\n",
    "        return (features - tf.constant(5.45)/tf.constant(1.09))\n",
    "\n",
    "    # def normalize_features(self, features, targets=None, session=None):\n",
    "    #     seq_items, seq_type, seq_time_encoding, seq_recency = features\n",
    "    #     seq_recency = (seq_recency - tf.constant(5.45)/tf.constant(1.09))\n",
    "    #     features = (seq_items, seq_type, seq_time_encoding, seq_recency)\n",
    "    #     return features, targets, session\n",
    "\n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        features[3].set_shape((self.seq_len, 1))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:00:22.404734: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-27 21:00:22.406529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 21:00:22.406656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 21:00:22.406731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 21:00:22.662343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 21:00:22.662428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 21:00:22.662473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 21:00:22.662518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21932 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 20, 1]), TensorShape([32, 20, 1]), TensorShape([32, 20, 8]), TensorShape([32, 20, 1])]\n",
      "[916625      0      0 617111 146355      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[     0 916625 916625      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.5/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=train')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.4, \n",
    "                                     reverse_prob=0.25, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    break\n",
    "\n",
    "# # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     idx_mask = target\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     target, type_target, idx_mask = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 2\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(idx_mask[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time, seq_recency\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = positional_encoding(length=seq_len, depth=d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        pos_encoding = self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return pos_encoding   \n",
    "\n",
    "\n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.std_init = np.sqrt(1/(model_cfg.emb_dim*3)).round(4) #0.02 if model_cfg.trf_dim < 1024 else \n",
    "        self.pos_embed = PositionalEmbedding(model_cfg.trf_dim, model_cfg.seq_len)\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(\n",
    "            3+1, \n",
    "            model_cfg.emb_dim,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)\n",
    "        )\n",
    "        self.mlp_proj_time_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        ])\n",
    "        # self.mlp_proj_conts = tf.keras.models.Sequential([\n",
    "        #    tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "        #    tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)),\n",
    "        #    tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        # ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding, x_seq_recency = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_pos_embed = self.pos_embed(x_seq_past[:, :, 0])\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_time_encoding(x_seq_encoding, training=training)\n",
    "        # x_seq_recency = self.mlp_proj_conts(x_seq_recency, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        # x = x_seq_past_items * (x_ones + x_seq_past_type + x_seq_time_encoding + x_pos_embed)\n",
    "        x = x_seq_past_items * (x_ones + x_seq_past_type + x_seq_time_encoding)\n",
    "        x = x + x_pos_embed\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "# def custom_loss_bert4rec(tensor_weights=None):\n",
    "#     # @tf.function(jit_compile=True)\n",
    "#     def loss(y_true, y_pred):\n",
    "#         mask = tf.where(y_true >= 1, 1., 0.)\n",
    "#         loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "#         if tensor_weights is not None:\n",
    "#             weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "#             return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "#         else:\n",
    "#             return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "#     loss.__name__ = f'loss_bert4rec'\n",
    "#     return loss\n",
    "\n",
    "def weighted_loss_bert4rec(apply_weights=False):\n",
    "    # @tf.function(jit_compile=True)\n",
    "    def loss(y_true, y_pred, y_type):\n",
    "        y_type = tf.squeeze(y_type, -1)\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if apply_weights:\n",
    "            w_clicks = tf.cast(y_type==1, tf.float32) * 0.1\n",
    "            w_cart = tf.cast(y_type==2, tf.float32) * 0.3\n",
    "            w_order = tf.cast(y_type==3, tf.float32) * 0.6\n",
    "            weights = tf.reduce_max(tf.stack([w_clicks, w_cart, w_order], axis=-1), -1)\n",
    "            return tf.reduce_sum(loss * mask * weights) / (tf.reduce_sum(mask * weights) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'weighted_loss_bert4rec'\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def custom_accuracy():\n",
    "    def masked_accuracy(y_true, y_pred, y_type):\n",
    "        y_pred = tf.argmax(y_pred, axis=2)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        y_type = y_type[:, :, 0]\n",
    "        mask_padding = y_true != 0\n",
    "        mask_clicks = y_type == 1\n",
    "        mask_carts = y_type == 2\n",
    "        mask_orders = y_type == 3\n",
    "        match = y_true == y_pred\n",
    "        match_clicks = match & mask_padding & mask_clicks\n",
    "        match_carts = match & mask_padding & mask_carts\n",
    "        match_orders = match & mask_padding & mask_orders\n",
    "        match_clicks, mask_clicks = tf.cast(match_clicks, dtype=tf.float32), tf.cast(mask_clicks, dtype=tf.float32)\n",
    "        match_carts, mask_carts = tf.cast(match_carts, dtype=tf.float32), tf.cast(mask_carts, dtype=tf.float32)\n",
    "        match_orders, mask_orders = tf.cast(match_orders, dtype=tf.float32), tf.cast(mask_orders, dtype=tf.float32)\n",
    "        mask_padding = tf.cast(mask_padding, dtype=tf.float32)\n",
    "        acc_clicks = tf.reduce_sum(match_clicks)/(tf.reduce_sum(mask_clicks * mask_padding)+1e-8)\n",
    "        acc_carts = tf.reduce_sum(match_carts)/(tf.reduce_sum(mask_carts * mask_padding)+1e-8)\n",
    "        acc_orders = tf.reduce_sum(match_orders)/(tf.reduce_sum(mask_orders * mask_padding)+1e-8)\n",
    "        # score = 0.1*acc_clicks + 0.3*acc_carts + 0.6*acc_orders\n",
    "        return acc_clicks, acc_carts, acc_orders\n",
    "    masked_accuracy.__name__ = f'seq_acc'\n",
    "    return masked_accuracy\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "\n",
    "def recall_top_k(top_k=1, seq_len=10):\n",
    "    # @tf.function\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_pred)[0]\n",
    "        y_true = tf.cast(y_true, tf.int64)\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.int32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.int64)\n",
    "        # cum_sum = tf.zeros(n_samples, tf.int32)\n",
    "        result = tf.constant(0, tf.int32)\n",
    "        for i in tf.range(seq_len):\n",
    "            indexes_i = top_index[:, i, :]\n",
    "            is_true = tf.reduce_sum(tf.reduce_max(tf.where(y_true[:, i:i+1]==indexes_i, 1, 0), -1) * mask[:, i])\n",
    "            result += is_true\n",
    "        return tf.cast(result, tf.float32) / (tf.cast(tf.reduce_sum(mask), tf.float32) + 1e-8)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name\n",
    "\n",
    "def set_seed(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "finetune_lr = CustomSchedule(512, 5_000, weight_decay=None)\n",
    "plt.plot(tmp_lr(tf.range(10_000_000 // (32* 5), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n",
    "\n",
    "plt.plot(finetune_lr(tf.range(2_300_000 // (32), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g)\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        optimizer.apply_gradients(zip(global_gradients, model.trainable_variables))\n",
    "        global_gradients = []\n",
    "        total_step += 1\n",
    "    return global_gradients, total_step\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, model, optimizer, num_accum_steps, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions, seq_type)\n",
    "        acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss) / num_accum_steps\n",
    "\n",
    "    gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(gradients)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions, seq_type)\n",
    "    acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.6f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name='', dict_config=None):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"),\n",
    "               config=dict_config)\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "\n",
    "def grad_accum_scheduler(num_samples, list_scheduler, max_grad_accum):\n",
    "    if num_samples >= len(list_scheduler):\n",
    "        return max_grad_accum\n",
    "    return list_scheduler[num_samples]\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menric1296\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce38649b74b435986c2b680ef115ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668173699993835, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/enric/SSD1TB/KAGGLE/025_Kaggle-OTTO Recsys-2022/1_Scripts/wandb/run-20221127_210116-1qopqx0i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/1qopqx0i\" target=\"_blank\">model_bert4rec_complete_0.9_2022-11-27 21:01:14</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n",
      "================================================================================\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 21:01:20.922752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:436: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2022-11-27 21:01:21.954995: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1fec4b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-27 21:01:21.955016: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2022-11-27 21:01:21.972101: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model_bert4_rec/encoder_transformer_block/dropout_1/dropout/random_uniform/RandomUniform\n",
      "2022-11-27 21:01:21.974879: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-11-27 21:01:23.202614: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-11-27 21:01:23.658279: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Epoch]1/2 [Time]2.84 [Step]1 [Batch]0 [Speed]2836.76ms/step [Loss]14.2873 [Metrics]{'train_loss:14.287274 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000000 grad_accum:1.000000 total_samples:0.000000'}\n",
      "Saving checkpoint for epoch 1 at step 1 on path model_bert4rec_complete_0.9\n",
      "[Train Epoch]1/2 [Time]54.33 [Step]501 [Batch]500 [Speed]108.66ms/step [Loss]14.1550 [Metrics]{'train_loss:14.154951 train_acc_clicks:0.000028 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000044 grad_accum:1.000000 total_samples:16000.000000'}\n",
      "[Train Epoch]1/2 [Time]101.05 [Step]1001 [Batch]1000 [Speed]101.05ms/step [Loss]13.8798 [Metrics]{'train_loss:13.879839 train_acc_clicks:0.000054 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000088 grad_accum:1.000000 total_samples:32000.000000'}\n",
      "[Train Epoch]1/2 [Time]147.81 [Step]1501 [Batch]1500 [Speed]98.54ms/step [Loss]13.6901 [Metrics]{'train_loss:13.690085 train_acc_clicks:0.000061 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000133 grad_accum:1.000000 total_samples:48000.000000'}\n",
      "[Train Epoch]1/2 [Time]194.28 [Step]2001 [Batch]2000 [Speed]97.14ms/step [Loss]13.5614 [Metrics]{'train_loss:13.561418 train_acc_clicks:0.000103 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000177 grad_accum:1.000000 total_samples:64000.000000'}\n",
      "[Train Epoch]1/2 [Time]240.53 [Step]2501 [Batch]2500 [Speed]96.21ms/step [Loss]13.4464 [Metrics]{'train_loss:13.446436 train_acc_clicks:0.000197 train_acc_carts:0.000363 train_acc_orders:0.000000 lr:0.000221 grad_accum:1.000000 total_samples:80000.000000'}\n",
      "[Train Epoch]1/2 [Time]286.27 [Step]3001 [Batch]3000 [Speed]95.42ms/step [Loss]13.3523 [Metrics]{'train_loss:13.352315 train_acc_clicks:0.000304 train_acc_carts:0.000362 train_acc_orders:0.000000 lr:0.000265 grad_accum:1.000000 total_samples:96000.000000'}\n",
      "[Train Epoch]1/2 [Time]332.76 [Step]3501 [Batch]3500 [Speed]95.07ms/step [Loss]13.2718 [Metrics]{'train_loss:13.271784 train_acc_clicks:0.000352 train_acc_carts:0.000443 train_acc_orders:0.000000 lr:0.000309 grad_accum:1.000000 total_samples:112000.000000'}\n",
      "[Train Epoch]1/2 [Time]379.27 [Step]4001 [Batch]4000 [Speed]94.82ms/step [Loss]13.1988 [Metrics]{'train_loss:13.198785 train_acc_clicks:0.000368 train_acc_carts:0.000423 train_acc_orders:0.000250 lr:0.000354 grad_accum:1.000000 total_samples:128000.000000'}\n",
      "[Train Epoch]1/2 [Time]425.71 [Step]4501 [Batch]4500 [Speed]94.60ms/step [Loss]13.1380 [Metrics]{'train_loss:13.138016 train_acc_clicks:0.000373 train_acc_carts:0.000401 train_acc_orders:0.000222 lr:0.000398 grad_accum:1.000000 total_samples:144000.000000'}\n",
      "[Train Epoch]1/2 [Time]472.03 [Step]5001 [Batch]5000 [Speed]94.41ms/step [Loss]13.0873 [Metrics]{'train_loss:13.087252 train_acc_clicks:0.000398 train_acc_carts:0.000597 train_acc_orders:0.000200 lr:0.000442 grad_accum:1.000000 total_samples:160000.000000'}\n",
      "[Train Epoch]1/2 [Time]518.45 [Step]5501 [Batch]5500 [Speed]94.26ms/step [Loss]13.0393 [Metrics]{'train_loss:13.039289 train_acc_clicks:0.000397 train_acc_carts:0.000671 train_acc_orders:0.000227 lr:0.000486 grad_accum:1.000000 total_samples:176000.000000'}\n",
      "[Train Epoch]1/2 [Time]564.83 [Step]6001 [Batch]6000 [Speed]94.14ms/step [Loss]12.9995 [Metrics]{'train_loss:12.999454 train_acc_clicks:0.000393 train_acc_carts:0.000713 train_acc_orders:0.000222 lr:0.000530 grad_accum:1.000000 total_samples:192000.000000'}\n",
      "[Train Epoch]1/2 [Time]610.85 [Step]6501 [Batch]6500 [Speed]93.98ms/step [Loss]12.9610 [Metrics]{'train_loss:12.960961 train_acc_clicks:0.000421 train_acc_carts:0.000685 train_acc_orders:0.000205 lr:0.000575 grad_accum:1.000000 total_samples:208000.000000'}\n",
      "[Train Epoch]1/2 [Time]656.65 [Step]7001 [Batch]7000 [Speed]93.81ms/step [Loss]12.9253 [Metrics]{'train_loss:12.925320 train_acc_clicks:0.000422 train_acc_carts:0.000889 train_acc_orders:0.000238 lr:0.000619 grad_accum:1.000000 total_samples:224000.000000'}\n",
      "[Train Epoch]1/2 [Time]702.43 [Step]7501 [Batch]7500 [Speed]93.66ms/step [Loss]12.8925 [Metrics]{'train_loss:12.892516 train_acc_clicks:0.000470 train_acc_carts:0.000907 train_acc_orders:0.000256 lr:0.000663 grad_accum:1.000000 total_samples:240000.000000'}\n",
      "[Train Epoch]1/2 [Time]747.05 [Step]7907 [Batch]8000 [Speed]93.38ms/step [Loss]12.8617 [Metrics]{'train_loss:12.861680 train_acc_clicks:0.000489 train_acc_carts:0.001079 train_acc_orders:0.000281 lr:0.000699 grad_accum:2.000000 total_samples:256032.000000'}\n",
      "[Train Epoch]1/2 [Time]788.78 [Step]8157 [Batch]8500 [Speed]92.80ms/step [Loss]12.8310 [Metrics]{'train_loss:12.831045 train_acc_clicks:0.000512 train_acc_carts:0.001184 train_acc_orders:0.000323 lr:0.000721 grad_accum:2.000000 total_samples:272032.000000'}\n",
      "[Train Epoch]1/2 [Time]829.94 [Step]8407 [Batch]9000 [Speed]92.22ms/step [Loss]12.8035 [Metrics]{'train_loss:12.803469 train_acc_clicks:0.000528 train_acc_carts:0.001271 train_acc_orders:0.000306 lr:0.000743 grad_accum:2.000000 total_samples:288032.000000'}\n",
      "[Train Epoch]1/2 [Time]867.99 [Step]8657 [Batch]9500 [Speed]91.37ms/step [Loss]12.7762 [Metrics]{'train_loss:12.776197 train_acc_clicks:0.000559 train_acc_carts:0.001412 train_acc_orders:0.000289 lr:0.000765 grad_accum:2.000000 total_samples:304032.000000'}\n",
      "[Train Epoch]1/2 [Time]906.04 [Step]8907 [Batch]10000 [Speed]90.60ms/step [Loss]12.7521 [Metrics]{'train_loss:12.752094 train_acc_clicks:0.000614 train_acc_carts:0.001431 train_acc_orders:0.000325 lr:0.000787 grad_accum:2.000000 total_samples:320032.000000'}\n",
      "[Train Epoch]1/2 [Time]944.14 [Step]9157 [Batch]10500 [Speed]89.92ms/step [Loss]12.7278 [Metrics]{'train_loss:12.727757 train_acc_clicks:0.000657 train_acc_carts:0.001586 train_acc_orders:0.000325 lr:0.000809 grad_accum:2.000000 total_samples:336032.000000'}\n",
      "[Train Epoch]1/2 [Time]982.23 [Step]9407 [Batch]11000 [Speed]89.29ms/step [Loss]12.7044 [Metrics]{'train_loss:12.704397 train_acc_clicks:0.000688 train_acc_carts:0.001719 train_acc_orders:0.000414 lr:0.000831 grad_accum:2.000000 total_samples:352032.000000'}\n",
      "[Train Epoch]1/2 [Time]1020.32 [Step]9657 [Batch]11500 [Speed]88.72ms/step [Loss]12.6817 [Metrics]{'train_loss:12.681684 train_acc_clicks:0.000703 train_acc_carts:0.001800 train_acc_orders:0.000425 lr:0.000854 grad_accum:2.000000 total_samples:368032.000000'}\n",
      "[Train Epoch]1/2 [Time]1059.99 [Step]9907 [Batch]12000 [Speed]88.33ms/step [Loss]12.6600 [Metrics]{'train_loss:12.659984 train_acc_clicks:0.000731 train_acc_carts:0.001821 train_acc_orders:0.000637 lr:0.000876 grad_accum:2.000000 total_samples:384032.000000'}\n",
      "[Train Epoch]1/2 [Time]1101.23 [Step]10157 [Batch]12500 [Speed]88.10ms/step [Loss]12.6383 [Metrics]{'train_loss:12.638304 train_acc_clicks:0.000781 train_acc_carts:0.002026 train_acc_orders:0.000658 lr:0.000877 grad_accum:2.000000 total_samples:400032.000000'}\n",
      "[Train Epoch]1/2 [Time]1142.83 [Step]10407 [Batch]13000 [Speed]87.91ms/step [Loss]12.6151 [Metrics]{'train_loss:12.615119 train_acc_clicks:0.000842 train_acc_carts:0.002139 train_acc_orders:0.000759 lr:0.000866 grad_accum:2.000000 total_samples:416032.000000'}\n",
      "[Train Epoch]1/2 [Time]1184.55 [Step]10657 [Batch]13500 [Speed]87.74ms/step [Loss]12.5921 [Metrics]{'train_loss:12.592113 train_acc_clicks:0.000908 train_acc_carts:0.002249 train_acc_orders:0.000814 lr:0.000856 grad_accum:2.000000 total_samples:432032.000000'}\n",
      "[Train Epoch]1/2 [Time]1226.19 [Step]10907 [Batch]14000 [Speed]87.58ms/step [Loss]12.5696 [Metrics]{'train_loss:12.569613 train_acc_clicks:0.000980 train_acc_carts:0.002462 train_acc_orders:0.001016 lr:0.000846 grad_accum:2.000000 total_samples:448032.000000'}\n",
      "[Train Epoch]1/2 [Time]1267.95 [Step]11157 [Batch]14500 [Speed]87.44ms/step [Loss]12.5467 [Metrics]{'train_loss:12.546681 train_acc_clicks:0.001076 train_acc_carts:0.002637 train_acc_orders:0.001046 lr:0.000837 grad_accum:2.000000 total_samples:464032.000000'}\n",
      "[Train Epoch]1/2 [Time]1309.44 [Step]11407 [Batch]15000 [Speed]87.30ms/step [Loss]12.5225 [Metrics]{'train_loss:12.522494 train_acc_clicks:0.001168 train_acc_carts:0.002857 train_acc_orders:0.001149 lr:0.000828 grad_accum:2.000000 total_samples:480032.000000'}\n",
      "[Train Epoch]1/2 [Time]1351.18 [Step]11657 [Batch]15500 [Speed]87.17ms/step [Loss]12.4974 [Metrics]{'train_loss:12.497415 train_acc_clicks:0.001286 train_acc_carts:0.003171 train_acc_orders:0.001444 lr:0.000819 grad_accum:2.000000 total_samples:496032.000000'}\n",
      "[Train Epoch]1/2 [Time]1391.94 [Step]11844 [Batch]16000 [Speed]87.00ms/step [Loss]12.4719 [Metrics]{'train_loss:12.471916 train_acc_clicks:0.001406 train_acc_carts:0.003518 train_acc_orders:0.001545 lr:0.000812 grad_accum:3.000000 total_samples:512000.000000'}\n",
      "[Train Epoch]1/2 [Time]1432.37 [Step]12011 [Batch]16500 [Speed]86.81ms/step [Loss]12.4445 [Metrics]{'train_loss:12.444539 train_acc_clicks:0.001558 train_acc_carts:0.003918 train_acc_orders:0.001921 lr:0.000807 grad_accum:3.000000 total_samples:528032.000000'}\n",
      "[Train Epoch]1/2 [Time]1472.74 [Step]12178 [Batch]17000 [Speed]86.63ms/step [Loss]12.4192 [Metrics]{'train_loss:12.419198 train_acc_clicks:0.001704 train_acc_carts:0.004418 train_acc_orders:0.001954 lr:0.000801 grad_accum:3.000000 total_samples:543968.000000'}\n",
      "[Train Epoch]1/2 [Time]1513.12 [Step]12344 [Batch]17500 [Speed]86.46ms/step [Loss]12.3928 [Metrics]{'train_loss:12.392800 train_acc_clicks:0.001863 train_acc_carts:0.004975 train_acc_orders:0.002475 lr:0.000796 grad_accum:3.000000 total_samples:560000.000000'}\n",
      "[Train Epoch]1/2 [Time]1553.72 [Step]12511 [Batch]18000 [Speed]86.32ms/step [Loss]12.3662 [Metrics]{'train_loss:12.366171 train_acc_clicks:0.002033 train_acc_carts:0.005581 train_acc_orders:0.002925 lr:0.000790 grad_accum:3.000000 total_samples:576032.000000'}\n",
      "[Train Epoch]1/2 [Time]1594.47 [Step]12678 [Batch]18500 [Speed]86.19ms/step [Loss]12.3386 [Metrics]{'train_loss:12.338632 train_acc_clicks:0.002217 train_acc_carts:0.006190 train_acc_orders:0.003331 lr:0.000785 grad_accum:3.000000 total_samples:591968.000000'}\n",
      "[Train Epoch]1/2 [Time]1635.28 [Step]12844 [Batch]19000 [Speed]86.07ms/step [Loss]12.3125 [Metrics]{'train_loss:12.312458 train_acc_clicks:0.002393 train_acc_carts:0.006760 train_acc_orders:0.003709 lr:0.000780 grad_accum:3.000000 total_samples:608000.000000'}\n",
      "[Train Epoch]1/2 [Time]1674.50 [Step]13011 [Batch]19500 [Speed]85.87ms/step [Loss]12.2863 [Metrics]{'train_loss:12.286270 train_acc_clicks:0.002585 train_acc_carts:0.007340 train_acc_orders:0.004104 lr:0.000775 grad_accum:3.000000 total_samples:624032.000000'}\n",
      "[Train Epoch]1/2 [Time]1711.72 [Step]13178 [Batch]20000 [Speed]85.59ms/step [Loss]12.2587 [Metrics]{'train_loss:12.258681 train_acc_clicks:0.002807 train_acc_carts:0.008220 train_acc_orders:0.005085 lr:0.000770 grad_accum:3.000000 total_samples:639968.000000'}\n",
      "[Train Epoch]1/2 [Time]1749.00 [Step]13344 [Batch]20500 [Speed]85.32ms/step [Loss]12.2323 [Metrics]{'train_loss:12.232322 train_acc_clicks:0.003041 train_acc_carts:0.009233 train_acc_orders:0.005964 lr:0.000765 grad_accum:3.000000 total_samples:656000.000000'}\n",
      "[Train Epoch]1/2 [Time]1786.33 [Step]13511 [Batch]21000 [Speed]85.06ms/step [Loss]12.2054 [Metrics]{'train_loss:12.205358 train_acc_clicks:0.003297 train_acc_carts:0.010414 train_acc_orders:0.006581 lr:0.000760 grad_accum:3.000000 total_samples:672032.000000'}\n",
      "[Train Epoch]1/2 [Time]1823.61 [Step]13678 [Batch]21500 [Speed]84.82ms/step [Loss]12.1789 [Metrics]{'train_loss:12.178902 train_acc_clicks:0.003533 train_acc_carts:0.011688 train_acc_orders:0.007541 lr:0.000756 grad_accum:3.000000 total_samples:687968.000000'}\n",
      "[Train Epoch]1/2 [Time]1860.87 [Step]13844 [Batch]22000 [Speed]84.59ms/step [Loss]12.1515 [Metrics]{'train_loss:12.151511 train_acc_clicks:0.003806 train_acc_carts:0.013061 train_acc_orders:0.008248 lr:0.000751 grad_accum:3.000000 total_samples:704000.000000'}\n",
      "[Train Epoch]1/2 [Time]1898.10 [Step]14011 [Batch]22500 [Speed]84.36ms/step [Loss]12.1237 [Metrics]{'train_loss:12.123722 train_acc_clicks:0.004103 train_acc_carts:0.014409 train_acc_orders:0.008944 lr:0.000747 grad_accum:3.000000 total_samples:720032.000000'}\n",
      "[Train Epoch]1/2 [Time]1935.30 [Step]14178 [Batch]23000 [Speed]84.14ms/step [Loss]12.0956 [Metrics]{'train_loss:12.095619 train_acc_clicks:0.004397 train_acc_carts:0.016071 train_acc_orders:0.010044 lr:0.000742 grad_accum:3.000000 total_samples:735968.000000'}\n",
      "[Train Epoch]1/2 [Time]1972.54 [Step]14340 [Batch]23500 [Speed]83.94ms/step [Loss]12.0687 [Metrics]{'train_loss:12.068677 train_acc_clicks:0.004736 train_acc_carts:0.017713 train_acc_orders:0.011252 lr:0.000738 grad_accum:4.000000 total_samples:752128.000000'}\n",
      "[Train Epoch]1/2 [Time]2009.35 [Step]14465 [Batch]24000 [Speed]83.72ms/step [Loss]12.0395 [Metrics]{'train_loss:12.039528 train_acc_clicks:0.005113 train_acc_carts:0.019682 train_acc_orders:0.012434 lr:0.000735 grad_accum:4.000000 total_samples:768128.000000'}\n",
      "[Train Epoch]1/2 [Time]2046.17 [Step]14590 [Batch]24500 [Speed]83.52ms/step [Loss]12.0114 [Metrics]{'train_loss:12.011404 train_acc_clicks:0.005493 train_acc_carts:0.021634 train_acc_orders:0.014283 lr:0.000732 grad_accum:4.000000 total_samples:784128.000000'}\n",
      "[Train Epoch]1/2 [Time]2082.99 [Step]14715 [Batch]25000 [Speed]83.32ms/step [Loss]11.9828 [Metrics]{'train_loss:11.982793 train_acc_clicks:0.005887 train_acc_carts:0.023695 train_acc_orders:0.015938 lr:0.000729 grad_accum:4.000000 total_samples:800128.000000'}\n",
      "Saving checkpoint for epoch 1 at step 14715 on path model_bert4rec_complete_0.9\n",
      "[Train Epoch]1/2 [Time]2123.84 [Step]14840 [Batch]25500 [Speed]83.29ms/step [Loss]11.9529 [Metrics]{'train_loss:11.952878 train_acc_clicks:0.006293 train_acc_carts:0.025959 train_acc_orders:0.017925 lr:0.000726 grad_accum:4.000000 total_samples:816128.000000'}\n",
      "[Train Epoch]1/2 [Time]2160.66 [Step]14965 [Batch]26000 [Speed]83.10ms/step [Loss]11.9250 [Metrics]{'train_loss:11.925030 train_acc_clicks:0.006728 train_acc_carts:0.028040 train_acc_orders:0.019615 lr:0.000723 grad_accum:4.000000 total_samples:832128.000000'}\n",
      "[Train Epoch]1/2 [Time]2198.85 [Step]15090 [Batch]26500 [Speed]82.98ms/step [Loss]11.8978 [Metrics]{'train_loss:11.897814 train_acc_clicks:0.007124 train_acc_carts:0.030480 train_acc_orders:0.021883 lr:0.000720 grad_accum:4.000000 total_samples:848128.000000'}\n",
      "[Train Epoch]1/2 [Time]2239.44 [Step]15215 [Batch]27000 [Speed]82.94ms/step [Loss]11.8692 [Metrics]{'train_loss:11.869235 train_acc_clicks:0.007544 train_acc_carts:0.033110 train_acc_orders:0.023655 lr:0.000717 grad_accum:4.000000 total_samples:864128.000000'}\n",
      "[Train Epoch]1/2 [Time]2279.48 [Step]15340 [Batch]27500 [Speed]82.89ms/step [Loss]11.8409 [Metrics]{'train_loss:11.840907 train_acc_clicks:0.007971 train_acc_carts:0.035667 train_acc_orders:0.025599 lr:0.000714 grad_accum:4.000000 total_samples:880128.000000'}\n",
      "[Train Epoch]1/2 [Time]2319.20 [Step]15465 [Batch]28000 [Speed]82.83ms/step [Loss]11.8143 [Metrics]{'train_loss:11.814257 train_acc_clicks:0.008388 train_acc_carts:0.038176 train_acc_orders:0.027582 lr:0.000711 grad_accum:4.000000 total_samples:896128.000000'}\n",
      "[Train Epoch]1/2 [Time]2358.95 [Step]15590 [Batch]28500 [Speed]82.77ms/step [Loss]11.7879 [Metrics]{'train_loss:11.787894 train_acc_clicks:0.008834 train_acc_carts:0.041001 train_acc_orders:0.029325 lr:0.000708 grad_accum:4.000000 total_samples:912128.000000'}\n",
      "[Train Epoch]1/2 [Time]2399.23 [Step]15715 [Batch]29000 [Speed]82.73ms/step [Loss]11.7614 [Metrics]{'train_loss:11.761378 train_acc_clicks:0.009245 train_acc_carts:0.043740 train_acc_orders:0.031539 lr:0.000705 grad_accum:4.000000 total_samples:928128.000000'}\n",
      "[Train Epoch]1/2 [Time]2439.69 [Step]15840 [Batch]29500 [Speed]82.70ms/step [Loss]11.7342 [Metrics]{'train_loss:11.734188 train_acc_clicks:0.009688 train_acc_carts:0.046382 train_acc_orders:0.033706 lr:0.000702 grad_accum:4.000000 total_samples:944128.000000'}\n",
      "[Train Epoch]1/2 [Time]2480.10 [Step]15965 [Batch]30000 [Speed]82.67ms/step [Loss]11.7076 [Metrics]{'train_loss:11.707592 train_acc_clicks:0.010119 train_acc_carts:0.048926 train_acc_orders:0.035859 lr:0.000700 grad_accum:4.000000 total_samples:960128.000000'}\n",
      "[Train Epoch]1/2 [Time]2520.51 [Step]16090 [Batch]30500 [Speed]82.64ms/step [Loss]11.6817 [Metrics]{'train_loss:11.681743 train_acc_clicks:0.010573 train_acc_carts:0.051417 train_acc_orders:0.038360 lr:0.000697 grad_accum:4.000000 total_samples:976128.000000'}\n",
      "[Train Epoch]1/2 [Time]2560.80 [Step]16215 [Batch]31000 [Speed]82.61ms/step [Loss]11.6550 [Metrics]{'train_loss:11.655027 train_acc_clicks:0.011057 train_acc_carts:0.053948 train_acc_orders:0.041018 lr:0.000694 grad_accum:4.000000 total_samples:992128.000000'}\n",
      "[Train Epoch]1/2 [Time]2600.89 [Step]16328 [Batch]31500 [Speed]82.57ms/step [Loss]11.6288 [Metrics]{'train_loss:11.628832 train_acc_clicks:0.011487 train_acc_carts:0.056702 train_acc_orders:0.043366 lr:0.000692 grad_accum:5.000000 total_samples:1008224.000000'}\n",
      "[Train Epoch]1/2 [Time]2640.64 [Step]16428 [Batch]32000 [Speed]82.52ms/step [Loss]11.6027 [Metrics]{'train_loss:11.602682 train_acc_clicks:0.011937 train_acc_carts:0.059436 train_acc_orders:0.045572 lr:0.000690 grad_accum:5.000000 total_samples:1024224.000000'}\n",
      "[Train Epoch]1/2 [Time]2680.46 [Step]16528 [Batch]32500 [Speed]82.48ms/step [Loss]11.5781 [Metrics]{'train_loss:11.578071 train_acc_clicks:0.012397 train_acc_carts:0.062051 train_acc_orders:0.047865 lr:0.000688 grad_accum:5.000000 total_samples:1040224.000000'}\n",
      "[Train Epoch]1/2 [Time]2720.21 [Step]16628 [Batch]33000 [Speed]82.43ms/step [Loss]11.5527 [Metrics]{'train_loss:11.552675 train_acc_clicks:0.012838 train_acc_carts:0.064545 train_acc_orders:0.050111 lr:0.000685 grad_accum:5.000000 total_samples:1056224.000000'}\n",
      "[Train Epoch]1/2 [Time]2759.83 [Step]16728 [Batch]33500 [Speed]82.38ms/step [Loss]11.5282 [Metrics]{'train_loss:11.528165 train_acc_clicks:0.013293 train_acc_carts:0.066993 train_acc_orders:0.052450 lr:0.000683 grad_accum:5.000000 total_samples:1072224.000000'}\n",
      "[Train Epoch]1/2 [Time]2799.73 [Step]16828 [Batch]34000 [Speed]82.34ms/step [Loss]11.5039 [Metrics]{'train_loss:11.503896 train_acc_clicks:0.013708 train_acc_carts:0.069482 train_acc_orders:0.054383 lr:0.000681 grad_accum:5.000000 total_samples:1088224.000000'}\n",
      "[Train Epoch]1/2 [Time]2839.41 [Step]16928 [Batch]34500 [Speed]82.30ms/step [Loss]11.4796 [Metrics]{'train_loss:11.479616 train_acc_clicks:0.014128 train_acc_carts:0.072484 train_acc_orders:0.056974 lr:0.000679 grad_accum:5.000000 total_samples:1104224.000000'}\n",
      "[Train Epoch]1/2 [Time]2876.02 [Step]17028 [Batch]35000 [Speed]82.17ms/step [Loss]11.4559 [Metrics]{'train_loss:11.455860 train_acc_clicks:0.014554 train_acc_carts:0.075205 train_acc_orders:0.059264 lr:0.000677 grad_accum:5.000000 total_samples:1120224.000000'}\n",
      "[Train Epoch]1/2 [Time]2912.64 [Step]17128 [Batch]35500 [Speed]82.05ms/step [Loss]11.4329 [Metrics]{'train_loss:11.432932 train_acc_clicks:0.014938 train_acc_carts:0.077923 train_acc_orders:0.061113 lr:0.000675 grad_accum:5.000000 total_samples:1136224.000000'}\n",
      "[Train Epoch]1/2 [Time]2949.27 [Step]17228 [Batch]36000 [Speed]81.92ms/step [Loss]11.4101 [Metrics]{'train_loss:11.410110 train_acc_clicks:0.015332 train_acc_carts:0.080403 train_acc_orders:0.063399 lr:0.000673 grad_accum:5.000000 total_samples:1152224.000000'}\n",
      "[Train Epoch]1/2 [Time]2985.88 [Step]17328 [Batch]36500 [Speed]81.80ms/step [Loss]11.3869 [Metrics]{'train_loss:11.386907 train_acc_clicks:0.015729 train_acc_carts:0.083147 train_acc_orders:0.065601 lr:0.000671 grad_accum:5.000000 total_samples:1168224.000000'}\n",
      "[Train Epoch]1/2 [Time]3022.55 [Step]17428 [Batch]37000 [Speed]81.69ms/step [Loss]11.3645 [Metrics]{'train_loss:11.364485 train_acc_clicks:0.016138 train_acc_carts:0.085715 train_acc_orders:0.067923 lr:0.000670 grad_accum:5.000000 total_samples:1184224.000000'}\n",
      "[Train Epoch]1/2 [Time]3059.22 [Step]17528 [Batch]37500 [Speed]81.58ms/step [Loss]11.3420 [Metrics]{'train_loss:11.341988 train_acc_clicks:0.016513 train_acc_carts:0.088425 train_acc_orders:0.070047 lr:0.000668 grad_accum:5.000000 total_samples:1200224.000000'}\n",
      "[Train Epoch]1/2 [Time]3095.90 [Step]17628 [Batch]38000 [Speed]81.47ms/step [Loss]11.3202 [Metrics]{'train_loss:11.320232 train_acc_clicks:0.016897 train_acc_carts:0.090893 train_acc_orders:0.072024 lr:0.000666 grad_accum:5.000000 total_samples:1216224.000000'}\n",
      "[Train Epoch]1/2 [Time]3132.50 [Step]17728 [Batch]38500 [Speed]81.36ms/step [Loss]11.2982 [Metrics]{'train_loss:11.298188 train_acc_clicks:0.017294 train_acc_carts:0.093267 train_acc_orders:0.074042 lr:0.000664 grad_accum:5.000000 total_samples:1232224.000000'}\n",
      "[Train Epoch]1/2 [Time]3171.44 [Step]17828 [Batch]39000 [Speed]81.32ms/step [Loss]11.2772 [Metrics]{'train_loss:11.277239 train_acc_clicks:0.017708 train_acc_carts:0.095449 train_acc_orders:0.076108 lr:0.000662 grad_accum:5.000000 total_samples:1248224.000000'}\n",
      "[Train Epoch]1/2 [Time]3211.71 [Step]17928 [Batch]39500 [Speed]81.31ms/step [Loss]11.2555 [Metrics]{'train_loss:11.255480 train_acc_clicks:0.018113 train_acc_carts:0.097802 train_acc_orders:0.078167 lr:0.000660 grad_accum:5.000000 total_samples:1264224.000000'}\n",
      "[Train Epoch]1/2 [Time]3251.97 [Step]18028 [Batch]40000 [Speed]81.30ms/step [Loss]11.2357 [Metrics]{'train_loss:11.235741 train_acc_clicks:0.018457 train_acc_carts:0.099918 train_acc_orders:0.079966 lr:0.000658 grad_accum:5.000000 total_samples:1280224.000000'}\n",
      "[Train Epoch]1/2 [Time]3292.06 [Step]18128 [Batch]40500 [Speed]81.29ms/step [Loss]11.2150 [Metrics]{'train_loss:11.214978 train_acc_clicks:0.018814 train_acc_carts:0.102039 train_acc_orders:0.081657 lr:0.000656 grad_accum:5.000000 total_samples:1296224.000000'}\n",
      "[Train Epoch]1/2 [Time]3332.06 [Step]18228 [Batch]41000 [Speed]81.27ms/step [Loss]11.1941 [Metrics]{'train_loss:11.194073 train_acc_clicks:0.019197 train_acc_carts:0.104406 train_acc_orders:0.083571 lr:0.000655 grad_accum:5.000000 total_samples:1312224.000000'}\n",
      "[Train Epoch]1/2 [Time]3371.86 [Step]18328 [Batch]41500 [Speed]81.25ms/step [Loss]11.1746 [Metrics]{'train_loss:11.174579 train_acc_clicks:0.019559 train_acc_carts:0.106516 train_acc_orders:0.085318 lr:0.000653 grad_accum:5.000000 total_samples:1328224.000000'}\n",
      "[Train Epoch]1/2 [Time]3411.92 [Step]18428 [Batch]42000 [Speed]81.24ms/step [Loss]11.1538 [Metrics]{'train_loss:11.153770 train_acc_clicks:0.019937 train_acc_carts:0.108734 train_acc_orders:0.087071 lr:0.000651 grad_accum:5.000000 total_samples:1344224.000000'}\n",
      "[Train Epoch]1/2 [Time]3451.74 [Step]18528 [Batch]42500 [Speed]81.22ms/step [Loss]11.1335 [Metrics]{'train_loss:11.133469 train_acc_clicks:0.020314 train_acc_carts:0.110612 train_acc_orders:0.088649 lr:0.000649 grad_accum:5.000000 total_samples:1360224.000000'}\n",
      "[Train Epoch]1/2 [Time]3491.45 [Step]18628 [Batch]43000 [Speed]81.20ms/step [Loss]11.1132 [Metrics]{'train_loss:11.113241 train_acc_clicks:0.020699 train_acc_carts:0.112524 train_acc_orders:0.090251 lr:0.000648 grad_accum:5.000000 total_samples:1376224.000000'}\n",
      "[Train Epoch]1/2 [Time]3531.23 [Step]18728 [Batch]43500 [Speed]81.18ms/step [Loss]11.0940 [Metrics]{'train_loss:11.093956 train_acc_clicks:0.021072 train_acc_carts:0.114455 train_acc_orders:0.092197 lr:0.000646 grad_accum:5.000000 total_samples:1392224.000000'}\n",
      "[Train Epoch]1/2 [Time]3570.82 [Step]18828 [Batch]44000 [Speed]81.15ms/step [Loss]11.0741 [Metrics]{'train_loss:11.074139 train_acc_clicks:0.021419 train_acc_carts:0.116430 train_acc_orders:0.094016 lr:0.000644 grad_accum:5.000000 total_samples:1408224.000000'}\n",
      "[Train Epoch]1/2 [Time]3610.70 [Step]18928 [Batch]44500 [Speed]81.14ms/step [Loss]11.0545 [Metrics]{'train_loss:11.054505 train_acc_clicks:0.021805 train_acc_carts:0.118342 train_acc_orders:0.095859 lr:0.000642 grad_accum:5.000000 total_samples:1424224.000000'}\n",
      "[Train Epoch]1/2 [Time]3650.75 [Step]19028 [Batch]45000 [Speed]81.13ms/step [Loss]11.0353 [Metrics]{'train_loss:11.035346 train_acc_clicks:0.022153 train_acc_carts:0.120200 train_acc_orders:0.097375 lr:0.000641 grad_accum:5.000000 total_samples:1440224.000000'}\n",
      "[Train Epoch]1/2 [Time]3690.86 [Step]19128 [Batch]45500 [Speed]81.12ms/step [Loss]11.0163 [Metrics]{'train_loss:11.016280 train_acc_clicks:0.022504 train_acc_carts:0.122056 train_acc_orders:0.099101 lr:0.000639 grad_accum:5.000000 total_samples:1456224.000000'}\n",
      "[Train Epoch]1/2 [Time]3730.96 [Step]19228 [Batch]46000 [Speed]81.11ms/step [Loss]10.9973 [Metrics]{'train_loss:10.997335 train_acc_clicks:0.022847 train_acc_carts:0.123815 train_acc_orders:0.101162 lr:0.000637 grad_accum:5.000000 total_samples:1472224.000000'}\n",
      "[Train Epoch]1/2 [Time]3771.01 [Step]19328 [Batch]46500 [Speed]81.10ms/step [Loss]10.9790 [Metrics]{'train_loss:10.978976 train_acc_clicks:0.023178 train_acc_carts:0.125533 train_acc_orders:0.102890 lr:0.000636 grad_accum:5.000000 total_samples:1488224.000000'}\n",
      "[Train Epoch]1/2 [Time]3810.82 [Step]19428 [Batch]47000 [Speed]81.08ms/step [Loss]10.9600 [Metrics]{'train_loss:10.960032 train_acc_clicks:0.023525 train_acc_carts:0.127505 train_acc_orders:0.104564 lr:0.000634 grad_accum:5.000000 total_samples:1504224.000000'}\n",
      "[Train Epoch]1/2 [Time]3849.25 [Step]19528 [Batch]47500 [Speed]81.04ms/step [Loss]10.9425 [Metrics]{'train_loss:10.942531 train_acc_clicks:0.023862 train_acc_carts:0.129480 train_acc_orders:0.106189 lr:0.000633 grad_accum:5.000000 total_samples:1520224.000000'}\n",
      "[Train Epoch]1/2 [Time]3885.82 [Step]19628 [Batch]48000 [Speed]80.95ms/step [Loss]10.9255 [Metrics]{'train_loss:10.925518 train_acc_clicks:0.024180 train_acc_carts:0.131098 train_acc_orders:0.107930 lr:0.000631 grad_accum:5.000000 total_samples:1536224.000000'}\n",
      "[Train Epoch]1/2 [Time]3922.39 [Step]19728 [Batch]48500 [Speed]80.87ms/step [Loss]10.9077 [Metrics]{'train_loss:10.907676 train_acc_clicks:0.024507 train_acc_carts:0.132714 train_acc_orders:0.109684 lr:0.000629 grad_accum:5.000000 total_samples:1552224.000000'}\n",
      "[Train Epoch]1/2 [Time]3958.99 [Step]19828 [Batch]49000 [Speed]80.80ms/step [Loss]10.8901 [Metrics]{'train_loss:10.890077 train_acc_clicks:0.024832 train_acc_carts:0.134311 train_acc_orders:0.111407 lr:0.000628 grad_accum:5.000000 total_samples:1568224.000000'}\n",
      "[Train Epoch]1/2 [Time]3995.52 [Step]19928 [Batch]49500 [Speed]80.72ms/step [Loss]10.8731 [Metrics]{'train_loss:10.873064 train_acc_clicks:0.025156 train_acc_carts:0.136099 train_acc_orders:0.113013 lr:0.000626 grad_accum:5.000000 total_samples:1584224.000000'}\n",
      "[Train Epoch]1/2 [Time]4032.06 [Step]20028 [Batch]50000 [Speed]80.64ms/step [Loss]10.8560 [Metrics]{'train_loss:10.855990 train_acc_clicks:0.025451 train_acc_carts:0.137877 train_acc_orders:0.114591 lr:0.000625 grad_accum:5.000000 total_samples:1600224.000000'}\n",
      "Saving checkpoint for epoch 1 at step 20028 on path model_bert4rec_complete_0.9\n",
      "[Train Epoch]1/2 [Time]4072.72 [Step]20128 [Batch]50500 [Speed]80.65ms/step [Loss]10.8384 [Metrics]{'train_loss:10.838428 train_acc_clicks:0.025766 train_acc_carts:0.139399 train_acc_orders:0.115908 lr:0.000623 grad_accum:5.000000 total_samples:1616224.000000'}\n",
      "[Train Epoch]1/2 [Time]4109.33 [Step]20228 [Batch]51000 [Speed]80.58ms/step [Loss]10.8209 [Metrics]{'train_loss:10.820873 train_acc_clicks:0.026091 train_acc_carts:0.141122 train_acc_orders:0.117121 lr:0.000621 grad_accum:5.000000 total_samples:1632224.000000'}\n",
      "[Train Epoch]1/2 [Time]4145.96 [Step]20328 [Batch]51500 [Speed]80.50ms/step [Loss]10.8041 [Metrics]{'train_loss:10.804062 train_acc_clicks:0.026390 train_acc_carts:0.142594 train_acc_orders:0.118319 lr:0.000620 grad_accum:5.000000 total_samples:1648224.000000'}\n",
      "[Train Epoch]1/2 [Time]4182.52 [Step]20428 [Batch]52000 [Speed]80.43ms/step [Loss]10.7871 [Metrics]{'train_loss:10.787126 train_acc_clicks:0.026695 train_acc_carts:0.144143 train_acc_orders:0.119624 lr:0.000618 grad_accum:5.000000 total_samples:1664224.000000'}\n",
      "[Train Epoch]1/2 [Time]4219.09 [Step]20528 [Batch]52500 [Speed]80.36ms/step [Loss]10.7706 [Metrics]{'train_loss:10.770593 train_acc_clicks:0.026990 train_acc_carts:0.145747 train_acc_orders:0.120856 lr:0.000617 grad_accum:5.000000 total_samples:1680224.000000'}\n",
      "[Train Epoch]1/2 [Time]4255.67 [Step]20628 [Batch]53000 [Speed]80.30ms/step [Loss]10.7542 [Metrics]{'train_loss:10.754194 train_acc_clicks:0.027288 train_acc_carts:0.147258 train_acc_orders:0.122094 lr:0.000615 grad_accum:5.000000 total_samples:1696224.000000'}\n",
      "[Train Epoch]1/2 [Time]4292.27 [Step]20728 [Batch]53500 [Speed]80.23ms/step [Loss]10.7377 [Metrics]{'train_loss:10.737720 train_acc_clicks:0.027566 train_acc_carts:0.148814 train_acc_orders:0.123318 lr:0.000614 grad_accum:5.000000 total_samples:1712224.000000'}\n",
      "[Train Epoch]1/2 [Time]4328.82 [Step]20828 [Batch]54000 [Speed]80.16ms/step [Loss]10.7225 [Metrics]{'train_loss:10.722464 train_acc_clicks:0.027844 train_acc_carts:0.150439 train_acc_orders:0.124657 lr:0.000612 grad_accum:5.000000 total_samples:1728224.000000'}\n",
      "[Train Epoch]1/2 [Time]4365.40 [Step]20928 [Batch]54500 [Speed]80.10ms/step [Loss]10.7068 [Metrics]{'train_loss:10.706763 train_acc_clicks:0.028133 train_acc_carts:0.151892 train_acc_orders:0.126046 lr:0.000611 grad_accum:5.000000 total_samples:1744224.000000'}\n",
      "[Train Epoch]1/2 [Time]4401.91 [Step]21028 [Batch]55000 [Speed]80.03ms/step [Loss]10.6922 [Metrics]{'train_loss:10.692247 train_acc_clicks:0.028383 train_acc_carts:0.153592 train_acc_orders:0.127382 lr:0.000610 grad_accum:5.000000 total_samples:1760224.000000'}\n",
      "[Train Epoch]1/2 [Time]4438.45 [Step]21128 [Batch]55500 [Speed]79.97ms/step [Loss]10.6773 [Metrics]{'train_loss:10.677290 train_acc_clicks:0.028645 train_acc_carts:0.155046 train_acc_orders:0.128523 lr:0.000608 grad_accum:5.000000 total_samples:1776224.000000'}\n",
      "[Train Epoch]1/2 [Time]4475.01 [Step]21228 [Batch]56000 [Speed]79.91ms/step [Loss]10.6620 [Metrics]{'train_loss:10.661954 train_acc_clicks:0.028910 train_acc_carts:0.156422 train_acc_orders:0.129679 lr:0.000607 grad_accum:5.000000 total_samples:1792224.000000'}\n",
      "[Train Epoch]1/2 [Time]4511.62 [Step]21328 [Batch]56500 [Speed]79.85ms/step [Loss]10.6472 [Metrics]{'train_loss:10.647159 train_acc_clicks:0.029165 train_acc_carts:0.157755 train_acc_orders:0.131026 lr:0.000605 grad_accum:5.000000 total_samples:1808224.000000'}\n",
      "[Train Epoch]1/2 [Time]4548.21 [Step]21428 [Batch]57000 [Speed]79.79ms/step [Loss]10.6323 [Metrics]{'train_loss:10.632321 train_acc_clicks:0.029411 train_acc_carts:0.159167 train_acc_orders:0.132352 lr:0.000604 grad_accum:5.000000 total_samples:1824224.000000'}\n",
      "[Train Epoch]1/2 [Time]4584.76 [Step]21528 [Batch]57500 [Speed]79.73ms/step [Loss]10.6173 [Metrics]{'train_loss:10.617345 train_acc_clicks:0.029688 train_acc_carts:0.160385 train_acc_orders:0.133600 lr:0.000602 grad_accum:5.000000 total_samples:1840224.000000'}\n",
      "[Train Epoch]1/2 [Time]4621.26 [Step]21628 [Batch]58000 [Speed]79.68ms/step [Loss]10.6031 [Metrics]{'train_loss:10.603125 train_acc_clicks:0.029935 train_acc_carts:0.161709 train_acc_orders:0.134725 lr:0.000601 grad_accum:5.000000 total_samples:1856224.000000'}\n",
      "[Train Epoch]1/2 [Time]4657.85 [Step]21728 [Batch]58500 [Speed]79.62ms/step [Loss]10.5887 [Metrics]{'train_loss:10.588729 train_acc_clicks:0.030179 train_acc_carts:0.163046 train_acc_orders:0.135866 lr:0.000600 grad_accum:5.000000 total_samples:1872224.000000'}\n",
      "[Train Epoch]1/2 [Time]4694.42 [Step]21828 [Batch]59000 [Speed]79.57ms/step [Loss]10.5740 [Metrics]{'train_loss:10.574022 train_acc_clicks:0.030437 train_acc_carts:0.164464 train_acc_orders:0.137020 lr:0.000598 grad_accum:5.000000 total_samples:1888224.000000'}\n",
      "[Train Epoch]1/2 [Time]4731.04 [Step]21928 [Batch]59500 [Speed]79.51ms/step [Loss]10.5609 [Metrics]{'train_loss:10.560919 train_acc_clicks:0.030670 train_acc_carts:0.165826 train_acc_orders:0.138160 lr:0.000597 grad_accum:5.000000 total_samples:1904224.000000'}\n",
      "[Train Epoch]1/2 [Time]4767.60 [Step]22028 [Batch]60000 [Speed]79.46ms/step [Loss]10.5476 [Metrics]{'train_loss:10.547608 train_acc_clicks:0.030910 train_acc_carts:0.167160 train_acc_orders:0.139243 lr:0.000596 grad_accum:5.000000 total_samples:1920224.000000'}\n",
      "[Train Epoch]1/2 [Time]4804.19 [Step]22128 [Batch]60500 [Speed]79.41ms/step [Loss]10.5337 [Metrics]{'train_loss:10.533721 train_acc_clicks:0.031159 train_acc_carts:0.168500 train_acc_orders:0.140024 lr:0.000594 grad_accum:5.000000 total_samples:1936224.000000'}\n",
      "[Train Epoch]1/2 [Time]4840.71 [Step]22228 [Batch]61000 [Speed]79.36ms/step [Loss]10.5203 [Metrics]{'train_loss:10.520270 train_acc_clicks:0.031396 train_acc_carts:0.169676 train_acc_orders:0.141176 lr:0.000593 grad_accum:5.000000 total_samples:1952224.000000'}\n",
      "[Train Epoch]1/2 [Time]4877.30 [Step]22328 [Batch]61500 [Speed]79.31ms/step [Loss]10.5069 [Metrics]{'train_loss:10.506861 train_acc_clicks:0.031626 train_acc_carts:0.170928 train_acc_orders:0.142343 lr:0.000592 grad_accum:5.000000 total_samples:1968224.000000'}\n",
      "[Train Epoch]1/2 [Time]4913.87 [Step]22428 [Batch]62000 [Speed]79.26ms/step [Loss]10.4938 [Metrics]{'train_loss:10.493758 train_acc_clicks:0.031857 train_acc_carts:0.172122 train_acc_orders:0.143404 lr:0.000590 grad_accum:5.000000 total_samples:1984224.000000'}\n",
      "[Train Epoch]1/2 [Time]4950.42 [Step]22528 [Batch]62500 [Speed]79.21ms/step [Loss]10.4803 [Metrics]{'train_loss:10.480284 train_acc_clicks:0.032089 train_acc_carts:0.173352 train_acc_orders:0.144512 lr:0.000589 grad_accum:5.000000 total_samples:2000224.000000'}\n",
      "[Train Epoch]1/2 [Time]4987.02 [Step]22628 [Batch]63000 [Speed]79.16ms/step [Loss]10.4675 [Metrics]{'train_loss:10.467480 train_acc_clicks:0.032321 train_acc_carts:0.174619 train_acc_orders:0.145540 lr:0.000588 grad_accum:5.000000 total_samples:2016224.000000'}\n",
      "[Train Epoch]1/2 [Time]5026.07 [Step]22728 [Batch]63500 [Speed]79.15ms/step [Loss]10.4547 [Metrics]{'train_loss:10.454692 train_acc_clicks:0.032543 train_acc_carts:0.175787 train_acc_orders:0.146329 lr:0.000586 grad_accum:5.000000 total_samples:2032224.000000'}\n",
      "[Train Epoch]1/2 [Time]5065.79 [Step]22828 [Batch]64000 [Speed]79.15ms/step [Loss]10.4411 [Metrics]{'train_loss:10.441115 train_acc_clicks:0.032790 train_acc_carts:0.176947 train_acc_orders:0.147312 lr:0.000585 grad_accum:5.000000 total_samples:2048224.000000'}\n",
      "[Train Epoch]1/2 [Time]5105.79 [Step]22928 [Batch]64500 [Speed]79.16ms/step [Loss]10.4277 [Metrics]{'train_loss:10.427734 train_acc_clicks:0.033019 train_acc_carts:0.178045 train_acc_orders:0.148509 lr:0.000584 grad_accum:5.000000 total_samples:2064224.000000'}\n",
      "[Train Epoch]1/2 [Time]5145.78 [Step]23028 [Batch]65000 [Speed]79.17ms/step [Loss]10.4145 [Metrics]{'train_loss:10.414525 train_acc_clicks:0.033259 train_acc_carts:0.179123 train_acc_orders:0.149572 lr:0.000582 grad_accum:5.000000 total_samples:2080224.000000'}\n",
      "[Train Epoch]1/2 [Time]5185.76 [Step]23128 [Batch]65500 [Speed]79.17ms/step [Loss]10.4021 [Metrics]{'train_loss:10.402102 train_acc_clicks:0.033485 train_acc_carts:0.180089 train_acc_orders:0.150402 lr:0.000581 grad_accum:5.000000 total_samples:2096224.000000'}\n",
      "[Train Epoch]1/2 [Time]5225.44 [Step]23228 [Batch]66000 [Speed]79.17ms/step [Loss]10.3891 [Metrics]{'train_loss:10.389063 train_acc_clicks:0.033692 train_acc_carts:0.181251 train_acc_orders:0.151356 lr:0.000580 grad_accum:5.000000 total_samples:2112224.000000'}\n",
      "[Train Epoch]1/2 [Time]5265.17 [Step]23328 [Batch]66500 [Speed]79.18ms/step [Loss]10.3766 [Metrics]{'train_loss:10.376598 train_acc_clicks:0.033910 train_acc_carts:0.182248 train_acc_orders:0.152282 lr:0.000579 grad_accum:5.000000 total_samples:2128224.000000'}\n",
      "[Train Epoch]1/2 [Time]5304.91 [Step]23428 [Batch]67000 [Speed]79.18ms/step [Loss]10.3640 [Metrics]{'train_loss:10.363971 train_acc_clicks:0.034122 train_acc_carts:0.183299 train_acc_orders:0.153211 lr:0.000577 grad_accum:5.000000 total_samples:2144224.000000'}\n",
      "[Train Epoch]1/2 [Time]5344.69 [Step]23528 [Batch]67500 [Speed]79.18ms/step [Loss]10.3511 [Metrics]{'train_loss:10.351137 train_acc_clicks:0.034343 train_acc_carts:0.184420 train_acc_orders:0.154252 lr:0.000576 grad_accum:5.000000 total_samples:2160224.000000'}\n",
      "[Train Epoch]1/2 [Time]5384.36 [Step]23628 [Batch]68000 [Speed]79.18ms/step [Loss]10.3390 [Metrics]{'train_loss:10.339034 train_acc_clicks:0.034551 train_acc_carts:0.185430 train_acc_orders:0.155108 lr:0.000575 grad_accum:5.000000 total_samples:2176224.000000'}\n",
      "[Train Epoch]1/2 [Time]5424.32 [Step]23728 [Batch]68500 [Speed]79.19ms/step [Loss]10.3266 [Metrics]{'train_loss:10.326570 train_acc_clicks:0.034753 train_acc_carts:0.186544 train_acc_orders:0.155910 lr:0.000574 grad_accum:5.000000 total_samples:2192224.000000'}\n",
      "[Train Epoch]1/2 [Time]5464.02 [Step]23828 [Batch]69000 [Speed]79.19ms/step [Loss]10.3149 [Metrics]{'train_loss:10.314878 train_acc_clicks:0.034942 train_acc_carts:0.187639 train_acc_orders:0.156856 lr:0.000573 grad_accum:5.000000 total_samples:2208224.000000'}\n",
      "[Train Epoch]1/2 [Time]5504.10 [Step]23928 [Batch]69500 [Speed]79.20ms/step [Loss]10.3032 [Metrics]{'train_loss:10.303198 train_acc_clicks:0.035131 train_acc_carts:0.188746 train_acc_orders:0.157623 lr:0.000571 grad_accum:5.000000 total_samples:2224224.000000'}\n",
      "[Train Epoch]1/2 [Time]5544.45 [Step]24028 [Batch]70000 [Speed]79.21ms/step [Loss]10.2915 [Metrics]{'train_loss:10.291549 train_acc_clicks:0.035322 train_acc_carts:0.189704 train_acc_orders:0.158465 lr:0.000570 grad_accum:5.000000 total_samples:2240224.000000'}\n",
      "[Train Epoch]1/2 [Time]5584.57 [Step]24128 [Batch]70500 [Speed]79.21ms/step [Loss]10.2796 [Metrics]{'train_loss:10.279628 train_acc_clicks:0.035519 train_acc_carts:0.190605 train_acc_orders:0.159466 lr:0.000569 grad_accum:5.000000 total_samples:2256224.000000'}\n",
      "[Train Epoch]1/2 [Time]5624.68 [Step]24228 [Batch]71000 [Speed]79.22ms/step [Loss]10.2673 [Metrics]{'train_loss:10.267331 train_acc_clicks:0.035734 train_acc_carts:0.191553 train_acc_orders:0.160539 lr:0.000568 grad_accum:5.000000 total_samples:2272224.000000'}\n",
      "[Train Epoch]1/2 [Time]5664.28 [Step]24328 [Batch]71500 [Speed]79.22ms/step [Loss]10.2556 [Metrics]{'train_loss:10.255597 train_acc_clicks:0.035946 train_acc_carts:0.192477 train_acc_orders:0.161453 lr:0.000567 grad_accum:5.000000 total_samples:2288224.000000'}\n",
      "[Train Epoch]1/2 [Time]5703.93 [Step]24428 [Batch]72000 [Speed]79.22ms/step [Loss]10.2441 [Metrics]{'train_loss:10.244060 train_acc_clicks:0.036148 train_acc_carts:0.193319 train_acc_orders:0.162191 lr:0.000566 grad_accum:5.000000 total_samples:2304224.000000'}\n",
      "[Train Epoch]1/2 [Time]5743.76 [Step]24528 [Batch]72500 [Speed]79.22ms/step [Loss]10.2327 [Metrics]{'train_loss:10.232677 train_acc_clicks:0.036351 train_acc_carts:0.194224 train_acc_orders:0.163065 lr:0.000564 grad_accum:5.000000 total_samples:2320224.000000'}\n",
      "[Train Epoch]1/2 [Time]5783.81 [Step]24628 [Batch]73000 [Speed]79.23ms/step [Loss]10.2214 [Metrics]{'train_loss:10.221367 train_acc_clicks:0.036551 train_acc_carts:0.195184 train_acc_orders:0.163817 lr:0.000563 grad_accum:5.000000 total_samples:2336224.000000'}\n",
      "[Train Epoch]1/2 [Time]5824.09 [Step]24728 [Batch]73500 [Speed]79.24ms/step [Loss]10.2105 [Metrics]{'train_loss:10.210485 train_acc_clicks:0.036748 train_acc_carts:0.196084 train_acc_orders:0.164465 lr:0.000562 grad_accum:5.000000 total_samples:2352224.000000'}\n",
      "[Train Epoch]1/2 [Time]5863.98 [Step]24828 [Batch]74000 [Speed]79.24ms/step [Loss]10.1991 [Metrics]{'train_loss:10.199112 train_acc_clicks:0.036935 train_acc_carts:0.196957 train_acc_orders:0.165350 lr:0.000561 grad_accum:5.000000 total_samples:2368224.000000'}\n",
      "[Train Epoch]1/2 [Time]5904.06 [Step]24928 [Batch]74500 [Speed]79.25ms/step [Loss]10.1883 [Metrics]{'train_loss:10.188302 train_acc_clicks:0.037119 train_acc_carts:0.197892 train_acc_orders:0.165939 lr:0.000560 grad_accum:5.000000 total_samples:2384224.000000'}\n",
      "[Train Epoch]1/2 [Time]5944.16 [Step]25028 [Batch]75000 [Speed]79.26ms/step [Loss]10.1779 [Metrics]{'train_loss:10.177916 train_acc_clicks:0.037300 train_acc_carts:0.198855 train_acc_orders:0.166602 lr:0.000559 grad_accum:5.000000 total_samples:2400224.000000'}\n",
      "Saving checkpoint for epoch 1 at step 25028 on path model_bert4rec_complete_0.9\n",
      "[Train Epoch]1/2 [Time]5988.35 [Step]25128 [Batch]75500 [Speed]79.32ms/step [Loss]10.1674 [Metrics]{'train_loss:10.167420 train_acc_clicks:0.037464 train_acc_carts:0.199960 train_acc_orders:0.167173 lr:0.000558 grad_accum:5.000000 total_samples:2416224.000000'}\n",
      "[Train Epoch]1/2 [Time]6028.17 [Step]25228 [Batch]76000 [Speed]79.32ms/step [Loss]10.1571 [Metrics]{'train_loss:10.157086 train_acc_clicks:0.037636 train_acc_carts:0.200955 train_acc_orders:0.168009 lr:0.000556 grad_accum:5.000000 total_samples:2432224.000000'}\n",
      "[Train Epoch]1/2 [Time]6067.49 [Step]25328 [Batch]76500 [Speed]79.31ms/step [Loss]10.1469 [Metrics]{'train_loss:10.146914 train_acc_clicks:0.037804 train_acc_carts:0.201989 train_acc_orders:0.168742 lr:0.000555 grad_accum:5.000000 total_samples:2448224.000000'}\n",
      "[Train Epoch]1/2 [Time]6107.02 [Step]25428 [Batch]77000 [Speed]79.31ms/step [Loss]10.1372 [Metrics]{'train_loss:10.137193 train_acc_clicks:0.037973 train_acc_carts:0.202949 train_acc_orders:0.169551 lr:0.000554 grad_accum:5.000000 total_samples:2464224.000000'}\n",
      "[Train Epoch]1/2 [Time]6147.05 [Step]25528 [Batch]77500 [Speed]79.32ms/step [Loss]10.1276 [Metrics]{'train_loss:10.127570 train_acc_clicks:0.038122 train_acc_carts:0.203953 train_acc_orders:0.170177 lr:0.000553 grad_accum:5.000000 total_samples:2480224.000000'}\n",
      "[Train Epoch]1/2 [Time]6187.44 [Step]25628 [Batch]78000 [Speed]79.33ms/step [Loss]10.1179 [Metrics]{'train_loss:10.117925 train_acc_clicks:0.038274 train_acc_carts:0.204952 train_acc_orders:0.170723 lr:0.000552 grad_accum:5.000000 total_samples:2496224.000000'}\n",
      "[Train Epoch]1/2 [Time]6227.68 [Step]25728 [Batch]78500 [Speed]79.33ms/step [Loss]10.1086 [Metrics]{'train_loss:10.108605 train_acc_clicks:0.038417 train_acc_carts:0.205928 train_acc_orders:0.171451 lr:0.000551 grad_accum:5.000000 total_samples:2512224.000000'}\n",
      "[Train Epoch]1/2 [Time]6267.73 [Step]25828 [Batch]79000 [Speed]79.34ms/step [Loss]10.0988 [Metrics]{'train_loss:10.098782 train_acc_clicks:0.038573 train_acc_carts:0.206847 train_acc_orders:0.172157 lr:0.000550 grad_accum:5.000000 total_samples:2528224.000000'}\n",
      "[Train Epoch]1/2 [Time]6307.61 [Step]25928 [Batch]79500 [Speed]79.34ms/step [Loss]10.0891 [Metrics]{'train_loss:10.089123 train_acc_clicks:0.038739 train_acc_carts:0.207615 train_acc_orders:0.172985 lr:0.000549 grad_accum:5.000000 total_samples:2544224.000000'}\n",
      "[Train Epoch]1/2 [Time]6347.51 [Step]26028 [Batch]80000 [Speed]79.34ms/step [Loss]10.0795 [Metrics]{'train_loss:10.079491 train_acc_clicks:0.038886 train_acc_carts:0.208641 train_acc_orders:0.173618 lr:0.000548 grad_accum:5.000000 total_samples:2560224.000000'}\n",
      "[Train Epoch]1/2 [Time]6387.13 [Step]26128 [Batch]80500 [Speed]79.34ms/step [Loss]10.0695 [Metrics]{'train_loss:10.069466 train_acc_clicks:0.039054 train_acc_carts:0.209544 train_acc_orders:0.174255 lr:0.000547 grad_accum:5.000000 total_samples:2576224.000000'}\n",
      "[Train Epoch]1/2 [Time]6427.10 [Step]26228 [Batch]81000 [Speed]79.35ms/step [Loss]10.0598 [Metrics]{'train_loss:10.059801 train_acc_clicks:0.039211 train_acc_carts:0.210264 train_acc_orders:0.174919 lr:0.000546 grad_accum:5.000000 total_samples:2592224.000000'}\n",
      "[Train Epoch]1/2 [Time]6466.97 [Step]26328 [Batch]81500 [Speed]79.35ms/step [Loss]10.0500 [Metrics]{'train_loss:10.049987 train_acc_clicks:0.039362 train_acc_carts:0.211051 train_acc_orders:0.175623 lr:0.000545 grad_accum:5.000000 total_samples:2608224.000000'}\n",
      "[Train Epoch]1/2 [Time]6506.49 [Step]26428 [Batch]82000 [Speed]79.35ms/step [Loss]10.0406 [Metrics]{'train_loss:10.040575 train_acc_clicks:0.039518 train_acc_carts:0.211897 train_acc_orders:0.176238 lr:0.000544 grad_accum:5.000000 total_samples:2624224.000000'}\n",
      "[Train Epoch]1/2 [Time]6546.16 [Step]26528 [Batch]82500 [Speed]79.35ms/step [Loss]10.0318 [Metrics]{'train_loss:10.031794 train_acc_clicks:0.039667 train_acc_carts:0.212882 train_acc_orders:0.176671 lr:0.000543 grad_accum:5.000000 total_samples:2640224.000000'}\n",
      "[Train Epoch]1/2 [Time]6586.23 [Step]26628 [Batch]83000 [Speed]79.35ms/step [Loss]10.0229 [Metrics]{'train_loss:10.022912 train_acc_clicks:0.039813 train_acc_carts:0.213791 train_acc_orders:0.177332 lr:0.000542 grad_accum:5.000000 total_samples:2656224.000000'}\n",
      "[Train Epoch]1/2 [Time]6626.26 [Step]26728 [Batch]83500 [Speed]79.36ms/step [Loss]10.0137 [Metrics]{'train_loss:10.013684 train_acc_clicks:0.039951 train_acc_carts:0.214636 train_acc_orders:0.178006 lr:0.000541 grad_accum:5.000000 total_samples:2672224.000000'}\n",
      "[Train Epoch]1/2 [Time]6666.27 [Step]26828 [Batch]84000 [Speed]79.36ms/step [Loss]10.0043 [Metrics]{'train_loss:10.004292 train_acc_clicks:0.040099 train_acc_carts:0.215323 train_acc_orders:0.178567 lr:0.000540 grad_accum:5.000000 total_samples:2688224.000000'}\n",
      "[Train Epoch]1/2 [Time]6705.86 [Step]26928 [Batch]84500 [Speed]79.36ms/step [Loss]9.9945 [Metrics]{'train_loss:9.994524 train_acc_clicks:0.040257 train_acc_carts:0.216028 train_acc_orders:0.179358 lr:0.000539 grad_accum:5.000000 total_samples:2704224.000000'}\n",
      "[Train Epoch]1/2 [Time]6745.52 [Step]27028 [Batch]85000 [Speed]79.36ms/step [Loss]9.9850 [Metrics]{'train_loss:9.985033 train_acc_clicks:0.040412 train_acc_carts:0.216774 train_acc_orders:0.179934 lr:0.000538 grad_accum:5.000000 total_samples:2720224.000000'}\n",
      "[Train Epoch]1/2 [Time]6785.46 [Step]27128 [Batch]85500 [Speed]79.36ms/step [Loss]9.9757 [Metrics]{'train_loss:9.975709 train_acc_clicks:0.040566 train_acc_carts:0.217359 train_acc_orders:0.180601 lr:0.000537 grad_accum:5.000000 total_samples:2736224.000000'}\n",
      "[Train Epoch]1/2 [Time]6824.32 [Step]27228 [Batch]86000 [Speed]79.35ms/step [Loss]9.9667 [Metrics]{'train_loss:9.966717 train_acc_clicks:0.040723 train_acc_carts:0.217958 train_acc_orders:0.181076 lr:0.000536 grad_accum:5.000000 total_samples:2752224.000000'}\n",
      "[Train Epoch]1/2 [Time]6860.92 [Step]27328 [Batch]86500 [Speed]79.32ms/step [Loss]9.9576 [Metrics]{'train_loss:9.957642 train_acc_clicks:0.040867 train_acc_carts:0.218600 train_acc_orders:0.181604 lr:0.000535 grad_accum:5.000000 total_samples:2768224.000000'}\n",
      "[Train Epoch]1/2 [Time]6897.43 [Step]27428 [Batch]87000 [Speed]79.28ms/step [Loss]9.9488 [Metrics]{'train_loss:9.948759 train_acc_clicks:0.041031 train_acc_carts:0.219184 train_acc_orders:0.182041 lr:0.000534 grad_accum:5.000000 total_samples:2784224.000000'}\n",
      "[Train Epoch]1/2 [Time]6933.99 [Step]27528 [Batch]87500 [Speed]79.25ms/step [Loss]9.9395 [Metrics]{'train_loss:9.939517 train_acc_clicks:0.041170 train_acc_carts:0.219869 train_acc_orders:0.182632 lr:0.000533 grad_accum:5.000000 total_samples:2800224.000000'}\n",
      "[Train Epoch]1/2 [Time]6970.56 [Step]27628 [Batch]88000 [Speed]79.21ms/step [Loss]9.9305 [Metrics]{'train_loss:9.930548 train_acc_clicks:0.041309 train_acc_carts:0.220624 train_acc_orders:0.183315 lr:0.000532 grad_accum:5.000000 total_samples:2816224.000000'}\n",
      "[Train Epoch]1/2 [Time]7007.14 [Step]27728 [Batch]88500 [Speed]79.18ms/step [Loss]9.9217 [Metrics]{'train_loss:9.921708 train_acc_clicks:0.041464 train_acc_carts:0.221334 train_acc_orders:0.183842 lr:0.000531 grad_accum:5.000000 total_samples:2832224.000000'}\n",
      "[Train Epoch]1/2 [Time]7043.70 [Step]27828 [Batch]89000 [Speed]79.14ms/step [Loss]9.9130 [Metrics]{'train_loss:9.913010 train_acc_clicks:0.041603 train_acc_carts:0.222000 train_acc_orders:0.184546 lr:0.000530 grad_accum:5.000000 total_samples:2848224.000000'}\n",
      "[Train Epoch]1/2 [Time]7080.28 [Step]27928 [Batch]89500 [Speed]79.11ms/step [Loss]9.9043 [Metrics]{'train_loss:9.904325 train_acc_clicks:0.041735 train_acc_carts:0.222690 train_acc_orders:0.185107 lr:0.000529 grad_accum:5.000000 total_samples:2864224.000000'}\n",
      "[Train Epoch]1/2 [Time]7116.85 [Step]28028 [Batch]90000 [Speed]79.08ms/step [Loss]9.8959 [Metrics]{'train_loss:9.895890 train_acc_clicks:0.041871 train_acc_carts:0.223386 train_acc_orders:0.185665 lr:0.000528 grad_accum:5.000000 total_samples:2880224.000000'}\n",
      "[Train Epoch]1/2 [Time]7153.40 [Step]28128 [Batch]90500 [Speed]79.04ms/step [Loss]9.8880 [Metrics]{'train_loss:9.887997 train_acc_clicks:0.042001 train_acc_carts:0.224148 train_acc_orders:0.186065 lr:0.000527 grad_accum:5.000000 total_samples:2896224.000000'}\n",
      "[Train Epoch]1/2 [Time]7190.02 [Step]28228 [Batch]91000 [Speed]79.01ms/step [Loss]9.8795 [Metrics]{'train_loss:9.879472 train_acc_clicks:0.042140 train_acc_carts:0.224713 train_acc_orders:0.186820 lr:0.000526 grad_accum:5.000000 total_samples:2912224.000000'}\n",
      "[Train Epoch]1/2 [Time]7226.61 [Step]28328 [Batch]91500 [Speed]78.98ms/step [Loss]9.8709 [Metrics]{'train_loss:9.870904 train_acc_clicks:0.042283 train_acc_carts:0.225275 train_acc_orders:0.187408 lr:0.000525 grad_accum:5.000000 total_samples:2928224.000000'}\n",
      "[Train Epoch]1/2 [Time]7263.26 [Step]28428 [Batch]92000 [Speed]78.95ms/step [Loss]9.8624 [Metrics]{'train_loss:9.862423 train_acc_clicks:0.042422 train_acc_carts:0.225857 train_acc_orders:0.188027 lr:0.000524 grad_accum:5.000000 total_samples:2944224.000000'}\n",
      "[Train Epoch]1/2 [Time]7299.83 [Step]28528 [Batch]92500 [Speed]78.92ms/step [Loss]9.8541 [Metrics]{'train_loss:9.854057 train_acc_clicks:0.042560 train_acc_carts:0.226390 train_acc_orders:0.188655 lr:0.000523 grad_accum:5.000000 total_samples:2960224.000000'}\n",
      "[Train Epoch]1/2 [Time]7336.38 [Step]28628 [Batch]93000 [Speed]78.89ms/step [Loss]9.8456 [Metrics]{'train_loss:9.845572 train_acc_clicks:0.042708 train_acc_carts:0.226916 train_acc_orders:0.189237 lr:0.000522 grad_accum:5.000000 total_samples:2976224.000000'}\n",
      "[Train Epoch]1/2 [Time]7372.98 [Step]28728 [Batch]93500 [Speed]78.86ms/step [Loss]9.8371 [Metrics]{'train_loss:9.837132 train_acc_clicks:0.042858 train_acc_carts:0.227510 train_acc_orders:0.189739 lr:0.000521 grad_accum:5.000000 total_samples:2992224.000000'}\n",
      "[Train Epoch]1/2 [Time]7409.55 [Step]28828 [Batch]94000 [Speed]78.83ms/step [Loss]9.8285 [Metrics]{'train_loss:9.828466 train_acc_clicks:0.043006 train_acc_carts:0.228068 train_acc_orders:0.190356 lr:0.000521 grad_accum:5.000000 total_samples:3008224.000000'}\n",
      "[Train Epoch]1/2 [Time]7446.17 [Step]28928 [Batch]94500 [Speed]78.80ms/step [Loss]9.8201 [Metrics]{'train_loss:9.820096 train_acc_clicks:0.043142 train_acc_carts:0.228642 train_acc_orders:0.190922 lr:0.000520 grad_accum:5.000000 total_samples:3024224.000000'}\n",
      "[Train Epoch]1/2 [Time]7482.76 [Step]29028 [Batch]95000 [Speed]78.77ms/step [Loss]9.8121 [Metrics]{'train_loss:9.812072 train_acc_clicks:0.043269 train_acc_carts:0.229277 train_acc_orders:0.191400 lr:0.000519 grad_accum:5.000000 total_samples:3040224.000000'}\n",
      "[Train Epoch]1/2 [Time]7519.32 [Step]29128 [Batch]95500 [Speed]78.74ms/step [Loss]9.8042 [Metrics]{'train_loss:9.804161 train_acc_clicks:0.043394 train_acc_carts:0.229861 train_acc_orders:0.192020 lr:0.000518 grad_accum:5.000000 total_samples:3056224.000000'}\n",
      "[Train Epoch]1/2 [Time]7555.90 [Step]29228 [Batch]96000 [Speed]78.71ms/step [Loss]9.7961 [Metrics]{'train_loss:9.796140 train_acc_clicks:0.043534 train_acc_carts:0.230468 train_acc_orders:0.192572 lr:0.000517 grad_accum:5.000000 total_samples:3072224.000000'}\n",
      "[Train Epoch]1/2 [Time]7592.47 [Step]29328 [Batch]96500 [Speed]78.68ms/step [Loss]9.7882 [Metrics]{'train_loss:9.788170 train_acc_clicks:0.043663 train_acc_carts:0.231015 train_acc_orders:0.193152 lr:0.000516 grad_accum:5.000000 total_samples:3088224.000000'}\n",
      "[Train Epoch]1/2 [Time]7629.08 [Step]29428 [Batch]97000 [Speed]78.65ms/step [Loss]9.7803 [Metrics]{'train_loss:9.780251 train_acc_clicks:0.043785 train_acc_carts:0.231589 train_acc_orders:0.193632 lr:0.000515 grad_accum:5.000000 total_samples:3104224.000000'}\n",
      "[Train Epoch]1/2 [Time]7665.64 [Step]29528 [Batch]97500 [Speed]78.62ms/step [Loss]9.7720 [Metrics]{'train_loss:9.772038 train_acc_clicks:0.043915 train_acc_carts:0.232181 train_acc_orders:0.194068 lr:0.000514 grad_accum:5.000000 total_samples:3120224.000000'}\n",
      "[Train Epoch]1/2 [Time]7702.21 [Step]29628 [Batch]98000 [Speed]78.59ms/step [Loss]9.7641 [Metrics]{'train_loss:9.764073 train_acc_clicks:0.044041 train_acc_carts:0.232768 train_acc_orders:0.194572 lr:0.000514 grad_accum:5.000000 total_samples:3136224.000000'}\n",
      "[Train Epoch]1/2 [Time]7738.78 [Step]29728 [Batch]98500 [Speed]78.57ms/step [Loss]9.7564 [Metrics]{'train_loss:9.756424 train_acc_clicks:0.044162 train_acc_carts:0.233331 train_acc_orders:0.195106 lr:0.000513 grad_accum:5.000000 total_samples:3152224.000000'}\n",
      "[Train Epoch]1/2 [Time]7775.35 [Step]29828 [Batch]99000 [Speed]78.54ms/step [Loss]9.7485 [Metrics]{'train_loss:9.748471 train_acc_clicks:0.044286 train_acc_carts:0.233835 train_acc_orders:0.195656 lr:0.000512 grad_accum:5.000000 total_samples:3168224.000000'}\n",
      "[Train Epoch]1/2 [Time]7811.93 [Step]29928 [Batch]99500 [Speed]78.51ms/step [Loss]9.7403 [Metrics]{'train_loss:9.740317 train_acc_clicks:0.044418 train_acc_carts:0.234266 train_acc_orders:0.196214 lr:0.000511 grad_accum:5.000000 total_samples:3184224.000000'}\n",
      "[Train Epoch]1/2 [Time]7848.49 [Step]30028 [Batch]100000 [Speed]78.48ms/step [Loss]9.7324 [Metrics]{'train_loss:9.732387 train_acc_clicks:0.044559 train_acc_carts:0.234729 train_acc_orders:0.196781 lr:0.000510 grad_accum:5.000000 total_samples:3200224.000000'}\n",
      "Saving checkpoint for epoch 1 at step 30028 on path model_bert4rec_complete_0.9\n",
      "[Train Epoch]1/2 [Time]7889.30 [Step]30128 [Batch]100500 [Speed]78.50ms/step [Loss]9.7247 [Metrics]{'train_loss:9.724677 train_acc_clicks:0.044687 train_acc_carts:0.235194 train_acc_orders:0.197265 lr:0.000509 grad_accum:5.000000 total_samples:3216224.000000'}\n",
      "[Train Epoch]1/2 [Time]7925.89 [Step]30228 [Batch]101000 [Speed]78.47ms/step [Loss]9.7167 [Metrics]{'train_loss:9.716713 train_acc_clicks:0.044810 train_acc_carts:0.235656 train_acc_orders:0.197744 lr:0.000508 grad_accum:5.000000 total_samples:3232224.000000'}\n",
      "[Train Epoch]1/2 [Time]7962.48 [Step]30328 [Batch]101500 [Speed]78.45ms/step [Loss]9.7091 [Metrics]{'train_loss:9.709142 train_acc_clicks:0.044924 train_acc_carts:0.236147 train_acc_orders:0.198222 lr:0.000508 grad_accum:5.000000 total_samples:3248224.000000'}\n",
      "[Train Epoch]1/2 [Time]7999.06 [Step]30428 [Batch]102000 [Speed]78.42ms/step [Loss]9.7014 [Metrics]{'train_loss:9.701402 train_acc_clicks:0.045045 train_acc_carts:0.236626 train_acc_orders:0.198640 lr:0.000507 grad_accum:5.000000 total_samples:3264224.000000'}\n",
      "[Train Epoch]1/2 [Time]8035.62 [Step]30528 [Batch]102500 [Speed]78.40ms/step [Loss]9.6936 [Metrics]{'train_loss:9.693579 train_acc_clicks:0.045166 train_acc_carts:0.237114 train_acc_orders:0.199095 lr:0.000506 grad_accum:5.000000 total_samples:3280224.000000'}\n",
      "[Train Epoch]1/2 [Time]8072.18 [Step]30628 [Batch]103000 [Speed]78.37ms/step [Loss]9.6862 [Metrics]{'train_loss:9.686166 train_acc_clicks:0.045283 train_acc_carts:0.237642 train_acc_orders:0.199516 lr:0.000505 grad_accum:5.000000 total_samples:3296224.000000'}\n",
      "[Train Epoch]1/2 [Time]8108.80 [Step]30728 [Batch]103500 [Speed]78.35ms/step [Loss]9.6787 [Metrics]{'train_loss:9.678660 train_acc_clicks:0.045404 train_acc_carts:0.238202 train_acc_orders:0.199913 lr:0.000504 grad_accum:5.000000 total_samples:3312224.000000'}\n",
      "[Train Epoch]1/2 [Time]8145.30 [Step]30828 [Batch]104000 [Speed]78.32ms/step [Loss]9.6716 [Metrics]{'train_loss:9.671597 train_acc_clicks:0.045519 train_acc_carts:0.238706 train_acc_orders:0.200358 lr:0.000503 grad_accum:5.000000 total_samples:3328224.000000'}\n",
      "[Train Epoch]1/2 [Time]8181.81 [Step]30928 [Batch]104500 [Speed]78.29ms/step [Loss]9.6645 [Metrics]{'train_loss:9.664457 train_acc_clicks:0.045640 train_acc_carts:0.239216 train_acc_orders:0.200809 lr:0.000503 grad_accum:5.000000 total_samples:3344224.000000'}\n",
      "[Train Epoch]1/2 [Time]8218.36 [Step]31028 [Batch]105000 [Speed]78.27ms/step [Loss]9.6575 [Metrics]{'train_loss:9.657470 train_acc_clicks:0.045747 train_acc_carts:0.239693 train_acc_orders:0.201189 lr:0.000502 grad_accum:5.000000 total_samples:3360224.000000'}\n",
      "[Train Epoch]1/2 [Time]8254.91 [Step]31128 [Batch]105500 [Speed]78.25ms/step [Loss]9.6504 [Metrics]{'train_loss:9.650381 train_acc_clicks:0.045862 train_acc_carts:0.240232 train_acc_orders:0.201676 lr:0.000501 grad_accum:5.000000 total_samples:3376224.000000'}\n",
      "[Train Epoch]1/2 [Time]8291.45 [Step]31228 [Batch]106000 [Speed]78.22ms/step [Loss]9.6431 [Metrics]{'train_loss:9.643126 train_acc_clicks:0.045972 train_acc_carts:0.240768 train_acc_orders:0.202213 lr:0.000500 grad_accum:5.000000 total_samples:3392224.000000'}\n",
      "[Train Epoch]1/2 [Time]8328.02 [Step]31328 [Batch]106500 [Speed]78.20ms/step [Loss]9.6359 [Metrics]{'train_loss:9.635944 train_acc_clicks:0.046086 train_acc_carts:0.241242 train_acc_orders:0.202703 lr:0.000499 grad_accum:5.000000 total_samples:3408224.000000'}\n",
      "[Train Epoch]1/2 [Time]8364.58 [Step]31428 [Batch]107000 [Speed]78.17ms/step [Loss]9.6291 [Metrics]{'train_loss:9.629146 train_acc_clicks:0.046190 train_acc_carts:0.241665 train_acc_orders:0.203061 lr:0.000499 grad_accum:5.000000 total_samples:3424224.000000'}\n",
      "[Train Epoch]1/2 [Time]8401.13 [Step]31528 [Batch]107500 [Speed]78.15ms/step [Loss]9.6224 [Metrics]{'train_loss:9.622400 train_acc_clicks:0.046301 train_acc_carts:0.242118 train_acc_orders:0.203593 lr:0.000498 grad_accum:5.000000 total_samples:3440224.000000'}\n",
      "[Train Epoch]1/2 [Time]8437.70 [Step]31628 [Batch]108000 [Speed]78.13ms/step [Loss]9.6158 [Metrics]{'train_loss:9.615796 train_acc_clicks:0.046411 train_acc_carts:0.242665 train_acc_orders:0.204056 lr:0.000497 grad_accum:5.000000 total_samples:3456224.000000'}\n",
      "[Train Epoch]1/2 [Time]8474.26 [Step]31728 [Batch]108500 [Speed]78.10ms/step [Loss]9.6093 [Metrics]{'train_loss:9.609347 train_acc_clicks:0.046505 train_acc_carts:0.243168 train_acc_orders:0.204493 lr:0.000496 grad_accum:5.000000 total_samples:3472224.000000'}\n",
      "[Train Epoch]1/2 [Time]8510.80 [Step]31828 [Batch]109000 [Speed]78.08ms/step [Loss]9.6027 [Metrics]{'train_loss:9.602671 train_acc_clicks:0.046618 train_acc_carts:0.243714 train_acc_orders:0.204771 lr:0.000495 grad_accum:5.000000 total_samples:3488224.000000'}\n",
      "[Train Epoch]1/2 [Time]8547.33 [Step]31928 [Batch]109500 [Speed]78.06ms/step [Loss]9.5963 [Metrics]{'train_loss:9.596251 train_acc_clicks:0.046710 train_acc_carts:0.244225 train_acc_orders:0.205249 lr:0.000495 grad_accum:5.000000 total_samples:3504224.000000'}\n",
      "[Train Epoch]1/2 [Time]8583.85 [Step]32028 [Batch]110000 [Speed]78.03ms/step [Loss]9.5900 [Metrics]{'train_loss:9.590017 train_acc_clicks:0.046817 train_acc_carts:0.244654 train_acc_orders:0.205498 lr:0.000494 grad_accum:5.000000 total_samples:3520224.000000'}\n",
      "[Train Epoch]1/2 [Time]8620.35 [Step]32128 [Batch]110500 [Speed]78.01ms/step [Loss]9.5839 [Metrics]{'train_loss:9.583908 train_acc_clicks:0.046912 train_acc_carts:0.245242 train_acc_orders:0.205846 lr:0.000493 grad_accum:5.000000 total_samples:3536224.000000'}\n",
      "[Train Epoch]1/2 [Time]8656.89 [Step]32228 [Batch]111000 [Speed]77.99ms/step [Loss]9.5783 [Metrics]{'train_loss:9.578303 train_acc_clicks:0.046988 train_acc_carts:0.246057 train_acc_orders:0.206115 lr:0.000492 grad_accum:5.000000 total_samples:3552224.000000'}\n",
      "[Train Epoch]1/2 [Time]8693.48 [Step]32328 [Batch]111500 [Speed]77.97ms/step [Loss]9.5721 [Metrics]{'train_loss:9.572065 train_acc_clicks:0.047087 train_acc_carts:0.246540 train_acc_orders:0.206581 lr:0.000492 grad_accum:5.000000 total_samples:3568224.000000'}\n",
      "[Train Epoch]1/2 [Time]8730.05 [Step]32428 [Batch]112000 [Speed]77.95ms/step [Loss]9.5656 [Metrics]{'train_loss:9.565612 train_acc_clicks:0.047196 train_acc_carts:0.247022 train_acc_orders:0.207080 lr:0.000491 grad_accum:5.000000 total_samples:3584224.000000'}\n",
      "[Train Epoch]1/2 [Time]8766.60 [Step]32528 [Batch]112500 [Speed]77.93ms/step [Loss]9.5591 [Metrics]{'train_loss:9.559116 train_acc_clicks:0.047303 train_acc_carts:0.247389 train_acc_orders:0.207355 lr:0.000490 grad_accum:5.000000 total_samples:3600224.000000'}\n",
      "[Train Epoch]1/2 [Time]8803.13 [Step]32628 [Batch]113000 [Speed]77.90ms/step [Loss]9.5525 [Metrics]{'train_loss:9.552523 train_acc_clicks:0.047409 train_acc_carts:0.247754 train_acc_orders:0.207787 lr:0.000489 grad_accum:5.000000 total_samples:3616224.000000'}\n",
      "[Train Epoch]1/2 [Time]8839.66 [Step]32728 [Batch]113500 [Speed]77.88ms/step [Loss]9.5462 [Metrics]{'train_loss:9.546182 train_acc_clicks:0.047508 train_acc_carts:0.248126 train_acc_orders:0.208176 lr:0.000489 grad_accum:5.000000 total_samples:3632224.000000'}\n",
      "[Train Epoch]1/2 [Time]8876.23 [Step]32828 [Batch]114000 [Speed]77.86ms/step [Loss]9.5396 [Metrics]{'train_loss:9.539636 train_acc_clicks:0.047611 train_acc_carts:0.248555 train_acc_orders:0.208579 lr:0.000488 grad_accum:5.000000 total_samples:3648224.000000'}\n",
      "[Train Epoch]1/2 [Time]8912.78 [Step]32928 [Batch]114500 [Speed]77.84ms/step [Loss]9.5330 [Metrics]{'train_loss:9.532971 train_acc_clicks:0.047714 train_acc_carts:0.248972 train_acc_orders:0.209034 lr:0.000487 grad_accum:5.000000 total_samples:3664224.000000'}\n",
      "[Train Epoch]1/2 [Time]8949.36 [Step]33028 [Batch]115000 [Speed]77.82ms/step [Loss]9.5263 [Metrics]{'train_loss:9.526259 train_acc_clicks:0.047830 train_acc_carts:0.249323 train_acc_orders:0.209349 lr:0.000486 grad_accum:5.000000 total_samples:3680224.000000'}\n",
      "[Train Epoch]1/2 [Time]8985.86 [Step]33128 [Batch]115500 [Speed]77.80ms/step [Loss]9.5199 [Metrics]{'train_loss:9.519946 train_acc_clicks:0.047922 train_acc_carts:0.249732 train_acc_orders:0.209703 lr:0.000486 grad_accum:5.000000 total_samples:3696224.000000'}\n",
      "[Train Epoch]1/2 [Time]9022.40 [Step]33228 [Batch]116000 [Speed]77.78ms/step [Loss]9.5136 [Metrics]{'train_loss:9.513577 train_acc_clicks:0.048026 train_acc_carts:0.250178 train_acc_orders:0.209992 lr:0.000485 grad_accum:5.000000 total_samples:3712224.000000'}\n",
      "[Train Epoch]1/2 [Time]9058.93 [Step]33328 [Batch]116500 [Speed]77.76ms/step [Loss]9.5071 [Metrics]{'train_loss:9.507130 train_acc_clicks:0.048121 train_acc_carts:0.250549 train_acc_orders:0.210464 lr:0.000484 grad_accum:5.000000 total_samples:3728224.000000'}\n",
      "[Train Epoch]1/2 [Time]9095.46 [Step]33428 [Batch]117000 [Speed]77.74ms/step [Loss]9.5009 [Metrics]{'train_loss:9.500863 train_acc_clicks:0.048211 train_acc_carts:0.250892 train_acc_orders:0.210793 lr:0.000483 grad_accum:5.000000 total_samples:3744224.000000'}\n",
      "[Train Epoch]1/2 [Time]9132.03 [Step]33528 [Batch]117500 [Speed]77.72ms/step [Loss]9.4946 [Metrics]{'train_loss:9.494626 train_acc_clicks:0.048295 train_acc_carts:0.251411 train_acc_orders:0.211231 lr:0.000483 grad_accum:5.000000 total_samples:3760224.000000'}\n",
      "[Train Epoch]1/2 [Time]9168.61 [Step]33628 [Batch]118000 [Speed]77.70ms/step [Loss]9.4886 [Metrics]{'train_loss:9.488619 train_acc_clicks:0.048390 train_acc_carts:0.251815 train_acc_orders:0.211657 lr:0.000482 grad_accum:5.000000 total_samples:3776224.000000'}\n",
      "[Train Epoch]1/2 [Time]9205.17 [Step]33728 [Batch]118500 [Speed]77.68ms/step [Loss]9.4826 [Metrics]{'train_loss:9.482616 train_acc_clicks:0.048487 train_acc_carts:0.252198 train_acc_orders:0.211975 lr:0.000481 grad_accum:5.000000 total_samples:3792224.000000'}\n",
      "[Train Epoch]1/2 [Time]9241.72 [Step]33828 [Batch]119000 [Speed]77.66ms/step [Loss]9.4766 [Metrics]{'train_loss:9.476625 train_acc_clicks:0.048580 train_acc_carts:0.252583 train_acc_orders:0.212296 lr:0.000481 grad_accum:5.000000 total_samples:3808224.000000'}\n",
      "[Train Epoch]1/2 [Time]9278.28 [Step]33928 [Batch]119500 [Speed]77.64ms/step [Loss]9.4706 [Metrics]{'train_loss:9.470560 train_acc_clicks:0.048664 train_acc_carts:0.253035 train_acc_orders:0.212681 lr:0.000480 grad_accum:5.000000 total_samples:3824224.000000'}\n",
      "[Train Epoch]1/2 [Time]9314.85 [Step]34028 [Batch]120000 [Speed]77.62ms/step [Loss]9.4644 [Metrics]{'train_loss:9.464404 train_acc_clicks:0.048754 train_acc_carts:0.253406 train_acc_orders:0.213063 lr:0.000479 grad_accum:5.000000 total_samples:3840224.000000'}\n",
      "[Train Epoch]1/2 [Time]9351.41 [Step]34128 [Batch]120500 [Speed]77.61ms/step [Loss]9.4583 [Metrics]{'train_loss:9.458255 train_acc_clicks:0.048853 train_acc_carts:0.253722 train_acc_orders:0.213470 lr:0.000478 grad_accum:5.000000 total_samples:3856224.000000'}\n",
      "[Train Epoch]1/2 [Time]9387.96 [Step]34228 [Batch]121000 [Speed]77.59ms/step [Loss]9.4527 [Metrics]{'train_loss:9.452653 train_acc_clicks:0.048945 train_acc_carts:0.254122 train_acc_orders:0.213801 lr:0.000478 grad_accum:5.000000 total_samples:3872224.000000'}\n",
      "[Train Epoch]1/2 [Time]9424.48 [Step]34328 [Batch]121500 [Speed]77.57ms/step [Loss]9.4471 [Metrics]{'train_loss:9.447148 train_acc_clicks:0.049025 train_acc_carts:0.254579 train_acc_orders:0.214093 lr:0.000477 grad_accum:5.000000 total_samples:3888224.000000'}\n",
      "[Train Epoch]1/2 [Time]9461.02 [Step]34428 [Batch]122000 [Speed]77.55ms/step [Loss]9.4415 [Metrics]{'train_loss:9.441532 train_acc_clicks:0.049104 train_acc_carts:0.255075 train_acc_orders:0.214409 lr:0.000476 grad_accum:5.000000 total_samples:3904224.000000'}\n",
      "[Train Epoch]1/2 [Time]9497.67 [Step]34528 [Batch]122500 [Speed]77.53ms/step [Loss]9.4359 [Metrics]{'train_loss:9.435859 train_acc_clicks:0.049188 train_acc_carts:0.255471 train_acc_orders:0.214767 lr:0.000476 grad_accum:5.000000 total_samples:3920224.000000'}\n",
      "[Train Epoch]1/2 [Time]9534.25 [Step]34628 [Batch]123000 [Speed]77.51ms/step [Loss]9.4299 [Metrics]{'train_loss:9.429857 train_acc_clicks:0.049276 train_acc_carts:0.255808 train_acc_orders:0.215211 lr:0.000475 grad_accum:5.000000 total_samples:3936224.000000'}\n",
      "[Train Epoch]1/2 [Time]9570.80 [Step]34728 [Batch]123500 [Speed]77.50ms/step [Loss]9.4239 [Metrics]{'train_loss:9.423921 train_acc_clicks:0.049365 train_acc_carts:0.256287 train_acc_orders:0.215660 lr:0.000474 grad_accum:5.000000 total_samples:3952224.000000'}\n",
      "[Train Epoch]1/2 [Time]9607.32 [Step]34828 [Batch]124000 [Speed]77.48ms/step [Loss]9.4182 [Metrics]{'train_loss:9.418170 train_acc_clicks:0.049454 train_acc_carts:0.256762 train_acc_orders:0.216128 lr:0.000474 grad_accum:5.000000 total_samples:3968224.000000'}\n",
      "[Train Epoch]1/2 [Time]9643.88 [Step]34928 [Batch]124500 [Speed]77.46ms/step [Loss]9.4125 [Metrics]{'train_loss:9.412457 train_acc_clicks:0.049544 train_acc_carts:0.257178 train_acc_orders:0.216545 lr:0.000473 grad_accum:5.000000 total_samples:3984224.000000'}\n",
      "[Train Epoch]1/2 [Time]9680.42 [Step]35028 [Batch]125000 [Speed]77.44ms/step [Loss]9.4068 [Metrics]{'train_loss:9.406817 train_acc_clicks:0.049627 train_acc_carts:0.257577 train_acc_orders:0.216889 lr:0.000472 grad_accum:5.000000 total_samples:4000224.000000'}\n",
      "Saving checkpoint for epoch 1 at step 35028 on path model_bert4rec_complete_0.9\n",
      "[Train Epoch]1/2 [Time]9721.04 [Step]35128 [Batch]125500 [Speed]77.46ms/step [Loss]9.4013 [Metrics]{'train_loss:9.401279 train_acc_clicks:0.049718 train_acc_carts:0.257905 train_acc_orders:0.217158 lr:0.000472 grad_accum:5.000000 total_samples:4016224.000000'}\n",
      "[Train Epoch]1/2 [Time]9757.60 [Step]35228 [Batch]126000 [Speed]77.44ms/step [Loss]9.3954 [Metrics]{'train_loss:9.395368 train_acc_clicks:0.049806 train_acc_carts:0.258211 train_acc_orders:0.217568 lr:0.000471 grad_accum:5.000000 total_samples:4032224.000000'}\n",
      "[Train Epoch]1/2 [Time]9794.13 [Step]35328 [Batch]126500 [Speed]77.42ms/step [Loss]9.3898 [Metrics]{'train_loss:9.389768 train_acc_clicks:0.049898 train_acc_carts:0.258516 train_acc_orders:0.217946 lr:0.000470 grad_accum:5.000000 total_samples:4048224.000000'}\n",
      "[Train Epoch]1/2 [Time]9830.65 [Step]35428 [Batch]127000 [Speed]77.41ms/step [Loss]9.3841 [Metrics]{'train_loss:9.384074 train_acc_clicks:0.049980 train_acc_carts:0.258752 train_acc_orders:0.218310 lr:0.000470 grad_accum:5.000000 total_samples:4064224.000000'}\n",
      "[Train Epoch]1/2 [Time]9867.17 [Step]35528 [Batch]127500 [Speed]77.39ms/step [Loss]9.3786 [Metrics]{'train_loss:9.378556 train_acc_clicks:0.050068 train_acc_carts:0.259070 train_acc_orders:0.218618 lr:0.000469 grad_accum:5.000000 total_samples:4080224.000000'}\n",
      "[Train Epoch]1/2 [Time]9903.71 [Step]35628 [Batch]128000 [Speed]77.37ms/step [Loss]9.3730 [Metrics]{'train_loss:9.373013 train_acc_clicks:0.050155 train_acc_carts:0.259371 train_acc_orders:0.218971 lr:0.000468 grad_accum:5.000000 total_samples:4096224.000000'}\n",
      "[Train Epoch]1/2 [Time]9940.23 [Step]35728 [Batch]128500 [Speed]77.36ms/step [Loss]9.3677 [Metrics]{'train_loss:9.367743 train_acc_clicks:0.050228 train_acc_carts:0.259780 train_acc_orders:0.219234 lr:0.000468 grad_accum:5.000000 total_samples:4112224.000000'}\n",
      "[Train Epoch]1/2 [Time]9976.78 [Step]35828 [Batch]129000 [Speed]77.34ms/step [Loss]9.3624 [Metrics]{'train_loss:9.362424 train_acc_clicks:0.050300 train_acc_carts:0.260222 train_acc_orders:0.219593 lr:0.000467 grad_accum:5.000000 total_samples:4128224.000000'}\n",
      "[Train Epoch]1/2 [Time]10013.35 [Step]35928 [Batch]129500 [Speed]77.32ms/step [Loss]9.3572 [Metrics]{'train_loss:9.357237 train_acc_clicks:0.050373 train_acc_carts:0.260670 train_acc_orders:0.219836 lr:0.000466 grad_accum:5.000000 total_samples:4144224.000000'}\n",
      "[Train Epoch]1/2 [Time]10049.87 [Step]36028 [Batch]130000 [Speed]77.31ms/step [Loss]9.3518 [Metrics]{'train_loss:9.351834 train_acc_clicks:0.050451 train_acc_carts:0.261088 train_acc_orders:0.220227 lr:0.000466 grad_accum:5.000000 total_samples:4160224.000000'}\n",
      "[Train Epoch]1/2 [Time]10086.43 [Step]36128 [Batch]130500 [Speed]77.29ms/step [Loss]9.3466 [Metrics]{'train_loss:9.346622 train_acc_clicks:0.050526 train_acc_carts:0.261461 train_acc_orders:0.220540 lr:0.000465 grad_accum:5.000000 total_samples:4176224.000000'}\n",
      "[Train Epoch]1/2 [Time]10123.02 [Step]36228 [Batch]131000 [Speed]77.27ms/step [Loss]9.3413 [Metrics]{'train_loss:9.341273 train_acc_clicks:0.050606 train_acc_carts:0.261845 train_acc_orders:0.220829 lr:0.000464 grad_accum:5.000000 total_samples:4192224.000000'}\n",
      "[Train Epoch]1/2 [Time]10159.59 [Step]36328 [Batch]131500 [Speed]77.26ms/step [Loss]9.3362 [Metrics]{'train_loss:9.336173 train_acc_clicks:0.050679 train_acc_carts:0.262264 train_acc_orders:0.221221 lr:0.000464 grad_accum:5.000000 total_samples:4208224.000000'}\n",
      "[Train Epoch]1/2 [Time]10196.16 [Step]36428 [Batch]132000 [Speed]77.24ms/step [Loss]9.3313 [Metrics]{'train_loss:9.331319 train_acc_clicks:0.050749 train_acc_carts:0.262592 train_acc_orders:0.221429 lr:0.000463 grad_accum:5.000000 total_samples:4224224.000000'}\n",
      "[Train Epoch]1/2 [Time]10232.72 [Step]36528 [Batch]132500 [Speed]77.23ms/step [Loss]9.3264 [Metrics]{'train_loss:9.326424 train_acc_clicks:0.050820 train_acc_carts:0.262981 train_acc_orders:0.221683 lr:0.000462 grad_accum:5.000000 total_samples:4240224.000000'}\n",
      "[Train Epoch]1/2 [Time]10269.22 [Step]36628 [Batch]133000 [Speed]77.21ms/step [Loss]9.3212 [Metrics]{'train_loss:9.321241 train_acc_clicks:0.050894 train_acc_carts:0.263289 train_acc_orders:0.221952 lr:0.000462 grad_accum:5.000000 total_samples:4256224.000000'}\n",
      "[Train Epoch]1/2 [Time]10305.78 [Step]36728 [Batch]133500 [Speed]77.20ms/step [Loss]9.3158 [Metrics]{'train_loss:9.315784 train_acc_clicks:0.050973 train_acc_carts:0.263537 train_acc_orders:0.222324 lr:0.000461 grad_accum:5.000000 total_samples:4272224.000000'}\n",
      "[Train Epoch]1/2 [Time]10342.31 [Step]36828 [Batch]134000 [Speed]77.18ms/step [Loss]9.3104 [Metrics]{'train_loss:9.310380 train_acc_clicks:0.051049 train_acc_carts:0.263878 train_acc_orders:0.222608 lr:0.000461 grad_accum:5.000000 total_samples:4288224.000000'}\n",
      "[Train Epoch]1/2 [Time]10378.85 [Step]36928 [Batch]134500 [Speed]77.17ms/step [Loss]9.3049 [Metrics]{'train_loss:9.304934 train_acc_clicks:0.051134 train_acc_carts:0.264115 train_acc_orders:0.222903 lr:0.000460 grad_accum:5.000000 total_samples:4304224.000000'}\n",
      "[Train Epoch]1/2 [Time]10415.40 [Step]37028 [Batch]135000 [Speed]77.15ms/step [Loss]9.2998 [Metrics]{'train_loss:9.299821 train_acc_clicks:0.051213 train_acc_carts:0.264390 train_acc_orders:0.223209 lr:0.000459 grad_accum:5.000000 total_samples:4320224.000000'}\n",
      "[Train Epoch]1/2 [Time]10451.90 [Step]37128 [Batch]135500 [Speed]77.14ms/step [Loss]9.2944 [Metrics]{'train_loss:9.294449 train_acc_clicks:0.051290 train_acc_carts:0.264686 train_acc_orders:0.223541 lr:0.000459 grad_accum:5.000000 total_samples:4336224.000000'}\n",
      "[Train Epoch]1/2 [Time]10488.47 [Step]37228 [Batch]136000 [Speed]77.12ms/step [Loss]9.2894 [Metrics]{'train_loss:9.289396 train_acc_clicks:0.051362 train_acc_carts:0.265090 train_acc_orders:0.223861 lr:0.000458 grad_accum:5.000000 total_samples:4352224.000000'}\n",
      "[Train Epoch]1/2 [Time]10525.04 [Step]37328 [Batch]136500 [Speed]77.11ms/step [Loss]9.2845 [Metrics]{'train_loss:9.284472 train_acc_clicks:0.051433 train_acc_carts:0.265414 train_acc_orders:0.224158 lr:0.000457 grad_accum:5.000000 total_samples:4368224.000000'}\n",
      "[Train Epoch]1/2 [Time]10561.59 [Step]37428 [Batch]137000 [Speed]77.09ms/step [Loss]9.2793 [Metrics]{'train_loss:9.279319 train_acc_clicks:0.051512 train_acc_carts:0.265673 train_acc_orders:0.224443 lr:0.000457 grad_accum:5.000000 total_samples:4384224.000000'}\n",
      "[Train Epoch]1/2 [Time]10598.16 [Step]37528 [Batch]137500 [Speed]77.08ms/step [Loss]9.2743 [Metrics]{'train_loss:9.274294 train_acc_clicks:0.051586 train_acc_carts:0.265898 train_acc_orders:0.224662 lr:0.000456 grad_accum:5.000000 total_samples:4400224.000000'}\n",
      "[Train Epoch]1/2 [Time]10634.69 [Step]37628 [Batch]138000 [Speed]77.06ms/step [Loss]9.2692 [Metrics]{'train_loss:9.269173 train_acc_clicks:0.051663 train_acc_carts:0.266133 train_acc_orders:0.224942 lr:0.000456 grad_accum:5.000000 total_samples:4416224.000000'}\n",
      "[Train Epoch]1/2 [Time]10671.19 [Step]37728 [Batch]138500 [Speed]77.05ms/step [Loss]9.2642 [Metrics]{'train_loss:9.264184 train_acc_clicks:0.051739 train_acc_carts:0.266380 train_acc_orders:0.225240 lr:0.000455 grad_accum:5.000000 total_samples:4432224.000000'}\n",
      "[Train Epoch]1/2 [Time]10707.72 [Step]37828 [Batch]139000 [Speed]77.03ms/step [Loss]9.2590 [Metrics]{'train_loss:9.258986 train_acc_clicks:0.051821 train_acc_carts:0.266665 train_acc_orders:0.225632 lr:0.000454 grad_accum:5.000000 total_samples:4448224.000000'}\n",
      "[Train Epoch]1/2 [Time]10744.30 [Step]37928 [Batch]139500 [Speed]77.02ms/step [Loss]9.2538 [Metrics]{'train_loss:9.253848 train_acc_clicks:0.051893 train_acc_carts:0.267020 train_acc_orders:0.225865 lr:0.000454 grad_accum:5.000000 total_samples:4464224.000000'}\n",
      "[Train Epoch]1/2 [Time]10780.90 [Step]38028 [Batch]140000 [Speed]77.01ms/step [Loss]9.2488 [Metrics]{'train_loss:9.248839 train_acc_clicks:0.051974 train_acc_carts:0.267292 train_acc_orders:0.226043 lr:0.000453 grad_accum:5.000000 total_samples:4480224.000000'}\n",
      "[Train Epoch]1/2 [Time]10817.45 [Step]38128 [Batch]140500 [Speed]76.99ms/step [Loss]9.2438 [Metrics]{'train_loss:9.243798 train_acc_clicks:0.052052 train_acc_carts:0.267561 train_acc_orders:0.226370 lr:0.000453 grad_accum:5.000000 total_samples:4496224.000000'}\n",
      "[Train Epoch]1/2 [Time]10854.04 [Step]38228 [Batch]141000 [Speed]76.98ms/step [Loss]9.2388 [Metrics]{'train_loss:9.238762 train_acc_clicks:0.052127 train_acc_carts:0.267889 train_acc_orders:0.226604 lr:0.000452 grad_accum:5.000000 total_samples:4512224.000000'}\n",
      "[Train Epoch]1/2 [Time]10890.57 [Step]38328 [Batch]141500 [Speed]76.97ms/step [Loss]9.2341 [Metrics]{'train_loss:9.234130 train_acc_clicks:0.052193 train_acc_carts:0.268209 train_acc_orders:0.226723 lr:0.000451 grad_accum:5.000000 total_samples:4528224.000000'}\n",
      "[Train Epoch]1/2 [Time]10927.12 [Step]38428 [Batch]142000 [Speed]76.95ms/step [Loss]9.2293 [Metrics]{'train_loss:9.229336 train_acc_clicks:0.052267 train_acc_carts:0.268533 train_acc_orders:0.226930 lr:0.000451 grad_accum:5.000000 total_samples:4544224.000000'}\n",
      "[Train Epoch]1/2 [Time]10963.67 [Step]38528 [Batch]142500 [Speed]76.94ms/step [Loss]9.2244 [Metrics]{'train_loss:9.224398 train_acc_clicks:0.052341 train_acc_carts:0.268784 train_acc_orders:0.227179 lr:0.000450 grad_accum:5.000000 total_samples:4560224.000000'}\n",
      "[Train Epoch]1/2 [Time]11000.25 [Step]38628 [Batch]143000 [Speed]76.92ms/step [Loss]9.2195 [Metrics]{'train_loss:9.219512 train_acc_clicks:0.052421 train_acc_carts:0.269070 train_acc_orders:0.227436 lr:0.000450 grad_accum:5.000000 total_samples:4576224.000000'}\n",
      "[Train Epoch]1/2 [Time]11036.78 [Step]38728 [Batch]143500 [Speed]76.91ms/step [Loss]9.2148 [Metrics]{'train_loss:9.214773 train_acc_clicks:0.052496 train_acc_carts:0.269319 train_acc_orders:0.227576 lr:0.000449 grad_accum:5.000000 total_samples:4592224.000000'}\n",
      "[Train Epoch]1/2 [Time]11073.32 [Step]38828 [Batch]144000 [Speed]76.90ms/step [Loss]9.2100 [Metrics]{'train_loss:9.210036 train_acc_clicks:0.052572 train_acc_carts:0.269596 train_acc_orders:0.227914 lr:0.000449 grad_accum:5.000000 total_samples:4608224.000000'}\n",
      "[Train Epoch]1/2 [Time]11109.86 [Step]38928 [Batch]144500 [Speed]76.88ms/step [Loss]9.2053 [Metrics]{'train_loss:9.205271 train_acc_clicks:0.052649 train_acc_carts:0.269894 train_acc_orders:0.228165 lr:0.000448 grad_accum:5.000000 total_samples:4624224.000000'}\n",
      "[Train Epoch]1/2 [Time]11146.41 [Step]39028 [Batch]145000 [Speed]76.87ms/step [Loss]9.2007 [Metrics]{'train_loss:9.200692 train_acc_clicks:0.052719 train_acc_carts:0.270251 train_acc_orders:0.228384 lr:0.000447 grad_accum:5.000000 total_samples:4640224.000000'}\n",
      "[Train Epoch]1/2 [Time]11182.97 [Step]39128 [Batch]145500 [Speed]76.86ms/step [Loss]9.1958 [Metrics]{'train_loss:9.195813 train_acc_clicks:0.052782 train_acc_carts:0.270630 train_acc_orders:0.228752 lr:0.000447 grad_accum:5.000000 total_samples:4656224.000000'}\n",
      "[Train Epoch]1/2 [Time]11219.54 [Step]39228 [Batch]146000 [Speed]76.85ms/step [Loss]9.1913 [Metrics]{'train_loss:9.191267 train_acc_clicks:0.052855 train_acc_carts:0.270995 train_acc_orders:0.228948 lr:0.000446 grad_accum:5.000000 total_samples:4672224.000000'}\n",
      "[Train Epoch]1/2 [Time]11256.08 [Step]39328 [Batch]146500 [Speed]76.83ms/step [Loss]9.1867 [Metrics]{'train_loss:9.186730 train_acc_clicks:0.052926 train_acc_carts:0.271324 train_acc_orders:0.229301 lr:0.000446 grad_accum:5.000000 total_samples:4688224.000000'}\n",
      "[Train Epoch]1/2 [Time]11292.64 [Step]39428 [Batch]147000 [Speed]76.82ms/step [Loss]9.1824 [Metrics]{'train_loss:9.182350 train_acc_clicks:0.052997 train_acc_carts:0.271562 train_acc_orders:0.229529 lr:0.000445 grad_accum:5.000000 total_samples:4704224.000000'}\n",
      "[Train Epoch]1/2 [Time]11329.21 [Step]39528 [Batch]147500 [Speed]76.81ms/step [Loss]9.1778 [Metrics]{'train_loss:9.177799 train_acc_clicks:0.053065 train_acc_carts:0.271854 train_acc_orders:0.229846 lr:0.000445 grad_accum:5.000000 total_samples:4720224.000000'}\n",
      "[Train Epoch]1/2 [Time]11365.76 [Step]39628 [Batch]148000 [Speed]76.80ms/step [Loss]9.1733 [Metrics]{'train_loss:9.173297 train_acc_clicks:0.053126 train_acc_carts:0.272200 train_acc_orders:0.230118 lr:0.000444 grad_accum:5.000000 total_samples:4736224.000000'}\n",
      "[Train Epoch]1/2 [Time]11402.32 [Step]39728 [Batch]148500 [Speed]76.78ms/step [Loss]9.1689 [Metrics]{'train_loss:9.168877 train_acc_clicks:0.053200 train_acc_carts:0.272494 train_acc_orders:0.230323 lr:0.000443 grad_accum:5.000000 total_samples:4752224.000000'}\n",
      "[Train Epoch]1/2 [Time]11438.90 [Step]39828 [Batch]149000 [Speed]76.77ms/step [Loss]9.1645 [Metrics]{'train_loss:9.164470 train_acc_clicks:0.053265 train_acc_carts:0.272769 train_acc_orders:0.230514 lr:0.000443 grad_accum:5.000000 total_samples:4768224.000000'}\n",
      "[Train Epoch]1/2 [Time]11475.43 [Step]39928 [Batch]149500 [Speed]76.76ms/step [Loss]9.1598 [Metrics]{'train_loss:9.159830 train_acc_clicks:0.053339 train_acc_carts:0.273055 train_acc_orders:0.230678 lr:0.000442 grad_accum:5.000000 total_samples:4784224.000000'}\n",
      "[Train Epoch]1/2 [Time]11511.95 [Step]40028 [Batch]150000 [Speed]76.75ms/step [Loss]9.1556 [Metrics]{'train_loss:9.155552 train_acc_clicks:0.053407 train_acc_carts:0.273368 train_acc_orders:0.230854 lr:0.000442 grad_accum:5.000000 total_samples:4800224.000000'}\n",
      "Saving checkpoint for epoch 1 at step 40028 on path model_bert4rec_complete_0.9\n",
      "[Train Epoch]1/2 [Time]11552.58 [Step]40128 [Batch]150500 [Speed]76.76ms/step [Loss]9.1511 [Metrics]{'train_loss:9.151065 train_acc_clicks:0.053478 train_acc_carts:0.273696 train_acc_orders:0.231145 lr:0.000441 grad_accum:5.000000 total_samples:4816224.000000'}\n",
      "[Train Epoch]1/2 [Time]11589.15 [Step]40228 [Batch]151000 [Speed]76.75ms/step [Loss]9.1465 [Metrics]{'train_loss:9.146453 train_acc_clicks:0.053544 train_acc_carts:0.274049 train_acc_orders:0.231283 lr:0.000441 grad_accum:5.000000 total_samples:4832224.000000'}\n",
      "[Train Epoch]1/2 [Time]11627.52 [Step]40328 [Batch]151500 [Speed]76.75ms/step [Loss]9.1419 [Metrics]{'train_loss:9.141940 train_acc_clicks:0.053608 train_acc_carts:0.274275 train_acc_orders:0.231504 lr:0.000440 grad_accum:5.000000 total_samples:4848224.000000'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 126\u001b[0m\n\u001b[1;32m    121\u001b[0m grad_accum \u001b[39m=\u001b[39m grad_accum_scheduler(total_samples,\n\u001b[1;32m    122\u001b[0m                                   list_scheduler\u001b[39m=\u001b[39mlist_scheduler, \n\u001b[1;32m    123\u001b[0m                                   max_grad_accum\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mtup_scheduler_grad_accum[\u001b[39m1\u001b[39m])                                                             \n\u001b[1;32m    124\u001b[0m step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39mtarget, model\u001b[39m=\u001b[39mmodel, optimizer\u001b[39m=\u001b[39moptimizer, num_accum_steps\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconstant(grad_accum, tf\u001b[39m.\u001b[39mfloat32), \n\u001b[1;32m    125\u001b[0m                             loss\u001b[39m=\u001b[39mtrain_loss, acc_clicks\u001b[39m=\u001b[39mtrain_acc_clicks, acc_carts\u001b[39m=\u001b[39mtrain_acc_carts, acc_orders\u001b[39m=\u001b[39mtrain_acc_orders, seq_type\u001b[39m=\u001b[39minputs[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 126\u001b[0m global_gradients, total_step \u001b[39m=\u001b[39m backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    128\u001b[0m     train_dict_metrics \u001b[39m=\u001b[39m {x\u001b[39m.\u001b[39mname : x\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
      "Cell \u001b[0;32mIn [8], line 20\u001b[0m, in \u001b[0;36mbackward_optimization\u001b[0;34m(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[39mfor\u001b[39;00m i, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(step_gradients):\n\u001b[0;32m---> 20\u001b[0m         global_gradients[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_gradients(g)\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m num_grad_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(global_gradients, model\u001b[39m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn [8], line 8\u001b[0m, in \u001b[0;36mflat_gradients\u001b[0;34m(grads_or_idx_slices)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m'''Convert gradients if it's tf.IndexedSlices.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mWhen computing gradients for operation concerning `tf.gather`, the type of gradients \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(grads_or_idx_slices) \u001b[39m==\u001b[39m tf\u001b[39m.\u001b[39mIndexedSlices:\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mscatter_nd(\n\u001b[1;32m      9\u001b[0m         tf\u001b[39m.\u001b[39;49mexpand_dims(grads_or_idx_slices\u001b[39m.\u001b[39;49mindices, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m     10\u001b[0m         grads_or_idx_slices\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     11\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(grads_or_idx_slices\u001b[39m.\u001b[39;49mdense_shape, tf\u001b[39m.\u001b[39;49mint64)\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m grads_or_idx_slices\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:9162\u001b[0m, in \u001b[0;36mscatter_nd\u001b[0;34m(indices, updates, shape, name)\u001b[0m\n\u001b[1;32m   9160\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   9161\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 9162\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   9163\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mScatterNd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, indices, updates, shape)\n\u001b[1;32m   9164\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   9165\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '1_Model_v0.4.ipynb'\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    seed = 12 #42\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.4/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.8.8_v1/checkpoints/', 'ckpt-17')\n",
    "    model_name = 'model_bert4rec_complete_0.9'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 10_000_000\n",
    "    batch_size = 32\n",
    "    tup_scheduler_grad_accum = (1, 5, 1_000_000) #(start_grad_accum, max_grad_accum, ramp_up_samples)\n",
    "    seq_len = 30\n",
    "    mask_prob = 0.3\n",
    "    reverse_prob = 0.5\n",
    "    emb_dim = 128\n",
    "    trf_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 2\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 250\n",
    "    clipnorm = 1.0\n",
    "    num_iters_save_checkpoint = 25_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    weight_decay = 1e-1\n",
    "    log_wandb = True\n",
    "\n",
    "set_seed(BERT4REC_CONFIG.seed)\n",
    "\n",
    "list_scheduler = np.linspace(BERT4REC_CONFIG.tup_scheduler_grad_accum[0], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[1], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[2]).astype(np.uint8).tolist()\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}', dict_config=dict_config)\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')] + \\\n",
    "                   [f'{BERT4REC_CONFIG.path_tfrecords}na_split=test_aug/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=test_aug')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "                            # weight_decay=BERT4REC_CONFIG.weight_decay)                  \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = weighted_loss_bert4rec(apply_weights=True)\n",
    "acc_function = custom_accuracy()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "train_acc_clicks = tf.keras.metrics.Mean(name='train_acc_clicks')\n",
    "train_acc_carts = tf.keras.metrics.Mean(name='train_acc_carts')\n",
    "train_acc_orders = tf.keras.metrics.Mean(name='train_acc_orders')\n",
    "val_acc_clicks = tf.keras.metrics.Mean(name='val_acc_clicks')\n",
    "val_acc_carts = tf.keras.metrics.Mean(name='val_acc_carts')\n",
    "val_acc_orders = tf.keras.metrics.Mean(name='val_acc_orders')\n",
    "\n",
    "##############################################\n",
    "\n",
    "global_gradients = []\n",
    "total_step, val_step, total_samples = 0, 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders, val_acc_clicks, val_acc_carts, val_acc_orders)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        grad_accum = grad_accum_scheduler(total_samples,\n",
    "                                          list_scheduler=list_scheduler, \n",
    "                                          max_grad_accum=BERT4REC_CONFIG.tup_scheduler_grad_accum[1])                                                             \n",
    "        step_gradients = train_step(inputs, target=target, model=model, optimizer=optimizer, num_accum_steps=tf.constant(grad_accum, tf.float32), \n",
    "                                    loss=train_loss, acc_clicks=train_acc_clicks, acc_carts=train_acc_carts, acc_orders=train_acc_orders, seq_type=inputs[1])\n",
    "        global_gradients, total_step = backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "            train_dict_metrics.update({'lr' : optimizer.lr(total_step).numpy().astype(np.float32), 'grad_accum' : grad_accum, 'total_samples' : total_samples})\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                train_dict_metrics.update({'step_grad' : total_step, 'step' : total_step})\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics)     \n",
    "        total_samples += BERT4REC_CONFIG.batch_size * grad_accum if (batch_num+1) % grad_accum==0 else 0\n",
    "        if batch_num % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')\n",
    "     \n",
    "#     for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "#         inputs, target = val_batch_data\n",
    "#         predictions = test_step(inputs, target=target, loss=val_loss, acc_clicks=val_acc_clicks, acc_carts=val_acc_carts, acc_orders=val_acc_orders, seq_type=inputs[1])\n",
    "#         val_step += 1\n",
    "#         if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "#             val_dict_metrics = {x.name : x.result() for x in [val_loss, val_acc_clicks, val_acc_carts, val_acc_orders]}\n",
    "#             fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "#             if BERT4REC_CONFIG.log_wandb:\n",
    "#                 log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "#                 # if val_batch_num==0:\n",
    "#                 #     log_wandb_metrics(step=None, plot_image=True, \n",
    "#                 #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "    \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', num_step=epoch, dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:49, 10.02it/s]\n",
      "100%|██████████| 48096/48096 [00:00<00:00, 234685.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.809600e+04</td>\n",
       "      <td>20109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.409855e+06</td>\n",
       "      <td>0.318577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.715819e+06</td>\n",
       "      <td>0.455809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.630000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.190015e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.383588e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.627672e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289967e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session         score\n",
       "count  4.809600e+04  20109.000000\n",
       "mean   6.409855e+06      0.318577\n",
       "std    3.715819e+06      0.455809\n",
       "min    9.630000e+02      0.000000\n",
       "25%    3.190015e+06      0.000000\n",
       "50%    6.383588e+06      0.000000\n",
       "75%    9.627672e+06      1.000000\n",
       "max    1.289967e+07      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.35689285965918816,\n",
       " 'clicks': 0.2929286447638604,\n",
       " 'orders': 0.5219661184103197}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.4495\n"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0 \n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# ckpt = tf.train.Checkpoint(model=model)\n",
    "# ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.8.4/checkpoints'))\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.5/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=30, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_past_items, list_predictions, list_trues, list_types = [], [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target, idx_mask = targets\n",
    "    idxs = idx_mask.numpy() #tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "        list_past_items.append(seq_items.numpy()[:, :, 0])\n",
    "    if num_batch==500:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'past_items' : np.concatenate(list_past_items).tolist(),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.8.4 - ckpt10\n",
    "# {'carts': 0.3504520904714635,\n",
    "#  'clicks': 0.22126267582597317,\n",
    "#  'orders': 0.5380787421674682}\n",
    "# Kaggle Metric: 0.4501\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.8.4 - ckpt18\n",
    "# 'carts': 0.3685273404345569,\n",
    "#  'clicks': 0.23584843923826976,\n",
    "#  'orders': 0.5460814923612543}\n",
    "# Kaggle Metric: 0.4618\n",
    "\n",
    "# import wandb\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"<path to run>\")\n",
    "# run.summary[\"kaggle_metric\"] = kaggle_metric\n",
    "# run.update()\n",
    "\n",
    "# {'carts': 0.38179916427339106,\n",
    "#  'clicks': 0.24199986911851318,\n",
    "#  'orders': 0.5271463692098612}\n",
    "# Kaggle Metric: 0.4550"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2azkkync) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96aff4a8bf8940a29c3471a931b49af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.018 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.240576…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">model_bert4rec_complete_0.8_finetune_fold_0</strong>: <a href=\"https://wandb.ai/enric1296/otto-recsys/runs/2azkkync\" target=\"_blank\">https://wandb.ai/enric1296/otto-recsys/runs/2azkkync</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221122_114558-2azkkync/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2azkkync). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e74e0d3acf4cf0b53a2d666f6c51de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668100016666663, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/enric/SSD1TB/KAGGLE/025_Kaggle-OTTO Recsys-2022/1_Scripts/wandb/run-20221122_114635-32p0b058</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/32p0b058\" target=\"_blank\">model_bert4rec_complete_0.8_finetune_fold_0</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Fold: 0\n",
      "========================================================================================================================\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 11:46:42.819523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:436: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2022-11-22 11:46:46.800646: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14149/Unknown - 4639s 328ms/step - loss: 8.2624 - seq_acc: 0.0945"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 50\u001b[0m\n\u001b[1;32m     45\u001b[0m ckpt\u001b[39m.\u001b[39mrestore(tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mlatest_checkpoint(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/model_bert4rec_complete_0.8/checkpoints\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     46\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m4e-5\u001b[39m, clipnorm\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m),\n\u001b[1;32m     47\u001b[0m               loss\u001b[39m=\u001b[39mloss_function,\n\u001b[1;32m     48\u001b[0m               metrics\u001b[39m=\u001b[39m[acc_function])\n\u001b[0;32m---> 50\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataloader,\n\u001b[1;32m     51\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m     52\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     53\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[WandbCallback()],\n\u001b[1;32m     54\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     55\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     57\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/model_bert4rec_complete_0.7_finetuned_fold_\u001b[39m\u001b[39m{\u001b[39;00mnum_fold\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)                   \n\u001b[1;32m     58\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/utils/tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/utils/tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "list_paths = ['../tfrecords/tfrecords_v0.4/na_split=test_aug/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=test_aug')]# + \\\n",
    "            #  ['../tfrecords/tfrecords_v0.4/na_split=val_aug/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=val_aug')] \n",
    "np.random.shuffle(list_paths)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for num_fold, (train_idxs, val_idxs) in enumerate(kfold.split(list_paths)):\n",
    "    train_paths = np.asarray(list_paths)[train_idxs]\n",
    "    val_paths = np.asarray(list_paths)[val_idxs]\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        time_suffix = datetime.now().__str__().split('.')[0]\n",
    "        dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "        init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_finetune_fold_{num_fold}', dict_config=dict_config)\n",
    "    print('===='*30)\n",
    "    print(f'Fold: {num_fold}')\n",
    "    print('===='*30)\n",
    "\n",
    "    train_dataloader = Bert4RecDataLoader(train_paths, \n",
    "                                         num_items=NUM_ITEMS, \n",
    "                                        seq_len=20,  \n",
    "                                        batch_size=32, \n",
    "                                        mask_prob=0.4, \n",
    "                                        reverse_prob=0.25,  \n",
    "                                        is_val=False,\n",
    "                                        is_test=False,\n",
    "                                        get_session=False,\n",
    "                                        shuffle=True).get_generator()\n",
    "\n",
    "    val_dataloader = Bert4RecDataLoader(val_paths, \n",
    "                                        num_items=NUM_ITEMS, \n",
    "                                        seq_len=20,  \n",
    "                                        batch_size=32, \n",
    "                                        mask_prob=0.4, \n",
    "                                        reverse_prob=0.25,  \n",
    "                                        is_val=True,\n",
    "                                        is_test=False,\n",
    "                                        get_session=False,\n",
    "                                        shuffle=False).get_generator()\n",
    "\n",
    "    loss_function = custom_loss_bert4rec()\n",
    "    acc_function = custom_accuracy()\n",
    "    model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "    ckpt = tf.train.Checkpoint(model=model)\n",
    "    ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.8/checkpoints'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=4e-5, clipnorm=1.0),\n",
    "                  loss=loss_function,\n",
    "                  metrics=[acc_function])\n",
    "\n",
    "    history = model.fit(train_dataloader,\n",
    "                        validation_data=val_dataloader,\n",
    "                        batch_size=32,\n",
    "                        callbacks=[WandbCallback()],\n",
    "                        epochs=1,\n",
    "                        verbose=1)\n",
    "\n",
    "    model.save(f'../2_Models/model_bert4rec_complete_0.7_finetuned_fold_{num_fold}/')                   \n",
    "    wandb.finish()\n",
    "\n",
    "# 173/Unknown - 22s 113ms/step - loss: 7.9368 - recall_20: 0.3452\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 19:15:23.433225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "0it [00:00, ?it/s]2022-11-20 19:15:24.337587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "26122it [55:08,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.7/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.4/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, idxs, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    idxs = idxs.numpy()\n",
    "    # idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 26122it [54:28,  7.99it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")\n",
    "\n",
    "import gzip\n",
    "with open(f'../3_Submissions/{name_submission}.csv', 'rb') as f_in, gzip.open(f'../3_Submissions/{name_submission}.csv.gz', 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0432fa0070c5c9f7d9e158f590013ccc765eb84f02e6f69521746370c3bf6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
