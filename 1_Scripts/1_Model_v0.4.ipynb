{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 3337362.55it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "SEED = 12\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.4/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False, drop_remainder=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "        self.drop_remainder = drop_remainder\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*50, reshuffle_each_iteration=True)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=self.drop_remainder).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                # \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                # \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_time_encoding, seq_time_encoding_target = seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding), (seq_items_target_all[:, 0], seq_type_target_all[:, 0]), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "\n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items)), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items))\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_target[:, 0]\n",
    "  \n",
    "  \n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 20, 1]), TensorShape([32, 20, 1]), TensorShape([32, 20, 8])]\n",
      "[ 419353       0 1069524   40508       0       0       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0]\n",
      "[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[      0 1222831       0       0       0       0       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5212"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.4/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=train')]\n",
    "\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.4, \n",
    "                                     reverse_prob=0.25, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# # Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    break\n",
    "\n",
    "# # # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     target, type_target = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 6\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(\n",
    "            3+1, \n",
    "            model_cfg.emb_dim,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.mlp_proj_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_encoding(x_seq_encoding, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_time_encoding + x_seq_past_type)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        ones = tf.ones(tf.shape(y_true))\n",
    "        y_pred = y_pred\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "def recall_top_k(top_k=1):\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_true)[0]\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.float32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.float32)\n",
    "        cum_sum = tf.zeros(n_samples)\n",
    "        for i in tf.range(top_k):\n",
    "            indexes_i = top_index[:, :, i]\n",
    "            is_true = tf.reduce_sum(tf.cast(tf.equal(y_true, indexes_i), tf.float32), axis=-1)/tf.reduce_sum(mask, -1)\n",
    "            cum_sum += (is_true/tf.cast(i+1, tf.float32))\n",
    "        return tf.reduce_mean(cum_sum)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "# plt.plot(tmp_lr(tf.range(12_000_000 // (32 * 4), dtype=tf.float32)))\n",
    "plt.plot(tmp_lr(tf.range(12_000_000 // (8 * 20), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g)\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        global_gradients = zip(global_gradients, model.trainable_variables)\n",
    "        optimizer.apply_gradients(global_gradients)\n",
    "        global_gradients = []\n",
    "    return global_gradients\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    num_accum_steps = tf.cast(kwargs['num_accum_steps'], tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss / num_accum_steps)\n",
    "\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    # gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions)\n",
    "    l_loss(loss)\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.4f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, num_batch=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({f'step_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "        wandb.log({f'batch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name=''):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"))\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n",
      "Latest checkpoint restored!!\n",
      "================================================================================\n",
      "Epoch 1\n",
      "[Train Epoch]1/5 [Time]24.84 [Step]0 [Batch]0 [Speed]24840.04ms/step [Loss]9.0752 [Metrics]{'train_loss:9.0752'}\n",
      "[Train Epoch]1/5 [Time]51.42 [Step]31 [Batch]500 [Speed]102.83ms/step [Loss]9.1409 [Metrics]{'train_loss:9.1409'}\n",
      "[Train Epoch]1/5 [Time]76.22 [Step]62 [Batch]1000 [Speed]76.22ms/step [Loss]9.1579 [Metrics]{'train_loss:9.1579'}\n",
      "[Train Epoch]1/5 [Time]100.82 [Step]93 [Batch]1500 [Speed]67.22ms/step [Loss]9.1807 [Metrics]{'train_loss:9.1807'}\n",
      "[Train Epoch]1/5 [Time]125.94 [Step]125 [Batch]2000 [Speed]62.97ms/step [Loss]9.2071 [Metrics]{'train_loss:9.2071'}\n",
      "[Train Epoch]1/5 [Time]150.93 [Step]156 [Batch]2500 [Speed]60.37ms/step [Loss]9.2079 [Metrics]{'train_loss:9.2079'}\n",
      "[Train Epoch]1/5 [Time]175.44 [Step]187 [Batch]3000 [Speed]58.48ms/step [Loss]9.2151 [Metrics]{'train_loss:9.2151'}\n",
      "[Train Epoch]1/5 [Time]199.87 [Step]218 [Batch]3500 [Speed]57.11ms/step [Loss]9.2086 [Metrics]{'train_loss:9.2086'}\n",
      "[Train Epoch]1/5 [Time]225.01 [Step]250 [Batch]4000 [Speed]56.25ms/step [Loss]9.2081 [Metrics]{'train_loss:9.2081'}\n",
      "[Train Epoch]1/5 [Time]249.49 [Step]281 [Batch]4500 [Speed]55.44ms/step [Loss]9.2029 [Metrics]{'train_loss:9.2029'}\n",
      "[Train Epoch]1/5 [Time]273.95 [Step]312 [Batch]5000 [Speed]54.79ms/step [Loss]9.1958 [Metrics]{'train_loss:9.1958'}\n",
      "[Train Epoch]1/5 [Time]298.46 [Step]343 [Batch]5500 [Speed]54.27ms/step [Loss]9.1955 [Metrics]{'train_loss:9.1955'}\n",
      "[Train Epoch]1/5 [Time]322.21 [Step]375 [Batch]6000 [Speed]53.70ms/step [Loss]9.1922 [Metrics]{'train_loss:9.1922'}\n",
      "[Train Epoch]1/5 [Time]345.08 [Step]406 [Batch]6500 [Speed]53.09ms/step [Loss]9.1931 [Metrics]{'train_loss:9.1931'}\n",
      "[Train Epoch]1/5 [Time]368.04 [Step]437 [Batch]7000 [Speed]52.58ms/step [Loss]9.1915 [Metrics]{'train_loss:9.1915'}\n",
      "[Train Epoch]1/5 [Time]391.23 [Step]468 [Batch]7500 [Speed]52.16ms/step [Loss]9.1897 [Metrics]{'train_loss:9.1897'}\n",
      "[Train Epoch]1/5 [Time]415.61 [Step]500 [Batch]8000 [Speed]51.95ms/step [Loss]9.1891 [Metrics]{'train_loss:9.1891'}\n",
      "[Train Epoch]1/5 [Time]440.23 [Step]531 [Batch]8500 [Speed]51.79ms/step [Loss]9.1894 [Metrics]{'train_loss:9.1894'}\n",
      "[Train Epoch]1/5 [Time]464.97 [Step]562 [Batch]9000 [Speed]51.66ms/step [Loss]9.1876 [Metrics]{'train_loss:9.1876'}\n",
      "[Train Epoch]1/5 [Time]489.63 [Step]593 [Batch]9500 [Speed]51.54ms/step [Loss]9.1838 [Metrics]{'train_loss:9.1838'}\n",
      "[Train Epoch]1/5 [Time]514.20 [Step]625 [Batch]10000 [Speed]51.42ms/step [Loss]9.1869 [Metrics]{'train_loss:9.1869'}\n",
      "[Train Epoch]1/5 [Time]537.91 [Step]656 [Batch]10500 [Speed]51.23ms/step [Loss]9.1846 [Metrics]{'train_loss:9.1846'}\n",
      "[Train Epoch]1/5 [Time]560.86 [Step]687 [Batch]11000 [Speed]50.99ms/step [Loss]9.1786 [Metrics]{'train_loss:9.1786'}\n",
      "[Train Epoch]1/5 [Time]583.93 [Step]718 [Batch]11500 [Speed]50.78ms/step [Loss]9.1747 [Metrics]{'train_loss:9.1747'}\n",
      "[Train Epoch]1/5 [Time]607.27 [Step]750 [Batch]12000 [Speed]50.61ms/step [Loss]9.1706 [Metrics]{'train_loss:9.1706'}\n",
      "[Train Epoch]1/5 [Time]630.40 [Step]781 [Batch]12500 [Speed]50.43ms/step [Loss]9.1704 [Metrics]{'train_loss:9.1704'}\n",
      "[Train Epoch]1/5 [Time]653.53 [Step]812 [Batch]13000 [Speed]50.27ms/step [Loss]9.1660 [Metrics]{'train_loss:9.1660'}\n",
      "[Train Epoch]1/5 [Time]676.71 [Step]843 [Batch]13500 [Speed]50.13ms/step [Loss]9.1663 [Metrics]{'train_loss:9.1663'}\n",
      "[Train Epoch]1/5 [Time]699.88 [Step]875 [Batch]14000 [Speed]49.99ms/step [Loss]9.1685 [Metrics]{'train_loss:9.1685'}\n",
      "[Train Epoch]1/5 [Time]723.05 [Step]906 [Batch]14500 [Speed]49.87ms/step [Loss]9.1693 [Metrics]{'train_loss:9.1693'}\n",
      "[Train Epoch]1/5 [Time]746.17 [Step]937 [Batch]15000 [Speed]49.74ms/step [Loss]9.1674 [Metrics]{'train_loss:9.1674'}\n",
      "[Train Epoch]1/5 [Time]769.28 [Step]968 [Batch]15500 [Speed]49.63ms/step [Loss]9.1672 [Metrics]{'train_loss:9.1672'}\n",
      "[Train Epoch]1/5 [Time]792.45 [Step]1000 [Batch]16000 [Speed]49.53ms/step [Loss]9.1685 [Metrics]{'train_loss:9.1685'}\n",
      "[Train Epoch]1/5 [Time]815.77 [Step]1031 [Batch]16500 [Speed]49.44ms/step [Loss]9.1684 [Metrics]{'train_loss:9.1684'}\n",
      "[Train Epoch]1/5 [Time]839.00 [Step]1062 [Batch]17000 [Speed]49.35ms/step [Loss]9.1678 [Metrics]{'train_loss:9.1678'}\n",
      "[Train Epoch]1/5 [Time]862.16 [Step]1093 [Batch]17500 [Speed]49.27ms/step [Loss]9.1673 [Metrics]{'train_loss:9.1673'}\n",
      "[Train Epoch]1/5 [Time]885.11 [Step]1125 [Batch]18000 [Speed]49.17ms/step [Loss]9.1652 [Metrics]{'train_loss:9.1652'}\n",
      "[Train Epoch]1/5 [Time]908.17 [Step]1156 [Batch]18500 [Speed]49.09ms/step [Loss]9.1623 [Metrics]{'train_loss:9.1623'}\n",
      "[Train Epoch]1/5 [Time]931.23 [Step]1187 [Batch]19000 [Speed]49.01ms/step [Loss]9.1625 [Metrics]{'train_loss:9.1625'}\n",
      "[Train Epoch]1/5 [Time]954.42 [Step]1218 [Batch]19500 [Speed]48.94ms/step [Loss]9.1602 [Metrics]{'train_loss:9.1602'}\n",
      "[Train Epoch]1/5 [Time]977.50 [Step]1250 [Batch]20000 [Speed]48.87ms/step [Loss]9.1589 [Metrics]{'train_loss:9.1589'}\n",
      "[Train Epoch]1/5 [Time]1000.65 [Step]1281 [Batch]20500 [Speed]48.81ms/step [Loss]9.1585 [Metrics]{'train_loss:9.1585'}\n",
      "[Train Epoch]1/5 [Time]1023.70 [Step]1312 [Batch]21000 [Speed]48.75ms/step [Loss]9.1594 [Metrics]{'train_loss:9.1594'}\n",
      "[Train Epoch]1/5 [Time]1046.85 [Step]1343 [Batch]21500 [Speed]48.69ms/step [Loss]9.1591 [Metrics]{'train_loss:9.1591'}\n",
      "[Train Epoch]1/5 [Time]1070.05 [Step]1375 [Batch]22000 [Speed]48.64ms/step [Loss]9.1596 [Metrics]{'train_loss:9.1596'}\n",
      "[Train Epoch]1/5 [Time]1093.27 [Step]1406 [Batch]22500 [Speed]48.59ms/step [Loss]9.1590 [Metrics]{'train_loss:9.1590'}\n",
      "[Train Epoch]1/5 [Time]1116.39 [Step]1437 [Batch]23000 [Speed]48.54ms/step [Loss]9.1604 [Metrics]{'train_loss:9.1604'}\n",
      "[Train Epoch]1/5 [Time]1139.64 [Step]1468 [Batch]23500 [Speed]48.50ms/step [Loss]9.1610 [Metrics]{'train_loss:9.1610'}\n",
      "[Train Epoch]1/5 [Time]1162.71 [Step]1500 [Batch]24000 [Speed]48.45ms/step [Loss]9.1605 [Metrics]{'train_loss:9.1605'}\n",
      "[Train Epoch]1/5 [Time]1185.97 [Step]1531 [Batch]24500 [Speed]48.41ms/step [Loss]9.1615 [Metrics]{'train_loss:9.1615'}\n",
      "[Train Epoch]1/5 [Time]1209.29 [Step]1562 [Batch]25000 [Speed]48.37ms/step [Loss]9.1617 [Metrics]{'train_loss:9.1617'}\n",
      "[Train Epoch]1/5 [Time]1232.61 [Step]1593 [Batch]25500 [Speed]48.34ms/step [Loss]9.1616 [Metrics]{'train_loss:9.1616'}\n",
      "[Train Epoch]1/5 [Time]1255.93 [Step]1625 [Batch]26000 [Speed]48.30ms/step [Loss]9.1610 [Metrics]{'train_loss:9.1610'}\n",
      "[Train Epoch]1/5 [Time]1279.18 [Step]1656 [Batch]26500 [Speed]48.27ms/step [Loss]9.1612 [Metrics]{'train_loss:9.1612'}\n",
      "[Train Epoch]1/5 [Time]1302.41 [Step]1687 [Batch]27000 [Speed]48.24ms/step [Loss]9.1603 [Metrics]{'train_loss:9.1603'}\n",
      "[Train Epoch]1/5 [Time]1325.61 [Step]1718 [Batch]27500 [Speed]48.20ms/step [Loss]9.1596 [Metrics]{'train_loss:9.1596'}\n",
      "[Train Epoch]1/5 [Time]1348.76 [Step]1750 [Batch]28000 [Speed]48.17ms/step [Loss]9.1582 [Metrics]{'train_loss:9.1582'}\n",
      "[Train Epoch]1/5 [Time]1371.86 [Step]1781 [Batch]28500 [Speed]48.14ms/step [Loss]9.1579 [Metrics]{'train_loss:9.1579'}\n",
      "[Train Epoch]1/5 [Time]1395.03 [Step]1812 [Batch]29000 [Speed]48.10ms/step [Loss]9.1585 [Metrics]{'train_loss:9.1585'}\n",
      "[Train Epoch]1/5 [Time]1418.38 [Step]1843 [Batch]29500 [Speed]48.08ms/step [Loss]9.1590 [Metrics]{'train_loss:9.1590'}\n",
      "[Train Epoch]1/5 [Time]1441.71 [Step]1875 [Batch]30000 [Speed]48.06ms/step [Loss]9.1600 [Metrics]{'train_loss:9.1600'}\n",
      "[Train Epoch]1/5 [Time]1464.90 [Step]1906 [Batch]30500 [Speed]48.03ms/step [Loss]9.1599 [Metrics]{'train_loss:9.1599'}\n",
      "[Train Epoch]1/5 [Time]1488.09 [Step]1937 [Batch]31000 [Speed]48.00ms/step [Loss]9.1586 [Metrics]{'train_loss:9.1586'}\n",
      "[Train Epoch]1/5 [Time]1511.25 [Step]1968 [Batch]31500 [Speed]47.98ms/step [Loss]9.1588 [Metrics]{'train_loss:9.1588'}\n",
      "[Train Epoch]1/5 [Time]1534.43 [Step]2000 [Batch]32000 [Speed]47.95ms/step [Loss]9.1576 [Metrics]{'train_loss:9.1576'}\n",
      "[Train Epoch]1/5 [Time]1557.73 [Step]2031 [Batch]32500 [Speed]47.93ms/step [Loss]9.1572 [Metrics]{'train_loss:9.1572'}\n",
      "[Train Epoch]1/5 [Time]1580.98 [Step]2062 [Batch]33000 [Speed]47.91ms/step [Loss]9.1568 [Metrics]{'train_loss:9.1568'}\n",
      "[Train Epoch]1/5 [Time]1604.14 [Step]2093 [Batch]33500 [Speed]47.88ms/step [Loss]9.1578 [Metrics]{'train_loss:9.1578'}\n",
      "[Train Epoch]1/5 [Time]1627.34 [Step]2125 [Batch]34000 [Speed]47.86ms/step [Loss]9.1587 [Metrics]{'train_loss:9.1587'}\n",
      "[Train Epoch]1/5 [Time]1650.47 [Step]2156 [Batch]34500 [Speed]47.84ms/step [Loss]9.1575 [Metrics]{'train_loss:9.1575'}\n",
      "[Train Epoch]1/5 [Time]1673.72 [Step]2187 [Batch]35000 [Speed]47.82ms/step [Loss]9.1563 [Metrics]{'train_loss:9.1563'}\n",
      "[Train Epoch]1/5 [Time]1696.93 [Step]2218 [Batch]35500 [Speed]47.80ms/step [Loss]9.1556 [Metrics]{'train_loss:9.1556'}\n",
      "[Train Epoch]1/5 [Time]1720.19 [Step]2250 [Batch]36000 [Speed]47.78ms/step [Loss]9.1554 [Metrics]{'train_loss:9.1554'}\n",
      "[Train Epoch]1/5 [Time]1743.42 [Step]2281 [Batch]36500 [Speed]47.76ms/step [Loss]9.1554 [Metrics]{'train_loss:9.1554'}\n",
      "[Train Epoch]1/5 [Time]1766.57 [Step]2312 [Batch]37000 [Speed]47.75ms/step [Loss]9.1551 [Metrics]{'train_loss:9.1551'}\n",
      "[Train Epoch]1/5 [Time]1789.71 [Step]2343 [Batch]37500 [Speed]47.73ms/step [Loss]9.1553 [Metrics]{'train_loss:9.1553'}\n",
      "[Train Epoch]1/5 [Time]1812.93 [Step]2375 [Batch]38000 [Speed]47.71ms/step [Loss]9.1553 [Metrics]{'train_loss:9.1553'}\n",
      "[Train Epoch]1/5 [Time]1836.07 [Step]2406 [Batch]38500 [Speed]47.69ms/step [Loss]9.1557 [Metrics]{'train_loss:9.1557'}\n",
      "[Train Epoch]1/5 [Time]1859.29 [Step]2437 [Batch]39000 [Speed]47.67ms/step [Loss]9.1559 [Metrics]{'train_loss:9.1559'}\n",
      "[Train Epoch]1/5 [Time]1882.42 [Step]2468 [Batch]39500 [Speed]47.66ms/step [Loss]9.1554 [Metrics]{'train_loss:9.1554'}\n",
      "[Train Epoch]1/5 [Time]1905.56 [Step]2500 [Batch]40000 [Speed]47.64ms/step [Loss]9.1552 [Metrics]{'train_loss:9.1552'}\n",
      "[Train Epoch]1/5 [Time]1928.66 [Step]2531 [Batch]40500 [Speed]47.62ms/step [Loss]9.1551 [Metrics]{'train_loss:9.1551'}\n",
      "[Train Epoch]1/5 [Time]1951.80 [Step]2562 [Batch]41000 [Speed]47.60ms/step [Loss]9.1554 [Metrics]{'train_loss:9.1554'}\n",
      "[Train Epoch]1/5 [Time]1974.87 [Step]2593 [Batch]41500 [Speed]47.59ms/step [Loss]9.1556 [Metrics]{'train_loss:9.1556'}\n",
      "[Train Epoch]1/5 [Time]1998.24 [Step]2625 [Batch]42000 [Speed]47.58ms/step [Loss]9.1566 [Metrics]{'train_loss:9.1566'}\n",
      "[Train Epoch]1/5 [Time]2021.46 [Step]2656 [Batch]42500 [Speed]47.56ms/step [Loss]9.1560 [Metrics]{'train_loss:9.1560'}\n",
      "[Train Epoch]1/5 [Time]2044.70 [Step]2687 [Batch]43000 [Speed]47.55ms/step [Loss]9.1561 [Metrics]{'train_loss:9.1561'}\n",
      "[Train Epoch]1/5 [Time]2067.80 [Step]2718 [Batch]43500 [Speed]47.54ms/step [Loss]9.1554 [Metrics]{'train_loss:9.1554'}\n",
      "[Train Epoch]1/5 [Time]2090.87 [Step]2750 [Batch]44000 [Speed]47.52ms/step [Loss]9.1564 [Metrics]{'train_loss:9.1564'}\n",
      "[Train Epoch]1/5 [Time]2114.10 [Step]2781 [Batch]44500 [Speed]47.51ms/step [Loss]9.1559 [Metrics]{'train_loss:9.1559'}\n",
      "[Train Epoch]1/5 [Time]2137.30 [Step]2812 [Batch]45000 [Speed]47.50ms/step [Loss]9.1550 [Metrics]{'train_loss:9.1550'}\n",
      "[Train Epoch]1/5 [Time]2160.41 [Step]2843 [Batch]45500 [Speed]47.48ms/step [Loss]9.1542 [Metrics]{'train_loss:9.1542'}\n",
      "[Train Epoch]1/5 [Time]2183.62 [Step]2875 [Batch]46000 [Speed]47.47ms/step [Loss]9.1545 [Metrics]{'train_loss:9.1545'}\n",
      "[Train Epoch]1/5 [Time]2206.66 [Step]2906 [Batch]46500 [Speed]47.46ms/step [Loss]9.1542 [Metrics]{'train_loss:9.1542'}\n",
      "[Train Epoch]1/5 [Time]2229.87 [Step]2937 [Batch]47000 [Speed]47.44ms/step [Loss]9.1545 [Metrics]{'train_loss:9.1545'}\n",
      "[Train Epoch]1/5 [Time]2253.05 [Step]2968 [Batch]47500 [Speed]47.43ms/step [Loss]9.1534 [Metrics]{'train_loss:9.1534'}\n",
      "[Train Epoch]1/5 [Time]2276.37 [Step]3000 [Batch]48000 [Speed]47.42ms/step [Loss]9.1528 [Metrics]{'train_loss:9.1528'}\n",
      "[Train Epoch]1/5 [Time]2299.54 [Step]3031 [Batch]48500 [Speed]47.41ms/step [Loss]9.1536 [Metrics]{'train_loss:9.1536'}\n",
      "[Train Epoch]1/5 [Time]2322.68 [Step]3062 [Batch]49000 [Speed]47.40ms/step [Loss]9.1537 [Metrics]{'train_loss:9.1537'}\n",
      "[Train Epoch]1/5 [Time]2345.91 [Step]3093 [Batch]49500 [Speed]47.39ms/step [Loss]9.1536 [Metrics]{'train_loss:9.1536'}\n",
      "[Train Epoch]1/5 [Time]2369.01 [Step]3125 [Batch]50000 [Speed]47.38ms/step [Loss]9.1536 [Metrics]{'train_loss:9.1536'}\n",
      "[Train Epoch]1/5 [Time]2392.20 [Step]3156 [Batch]50500 [Speed]47.37ms/step [Loss]9.1537 [Metrics]{'train_loss:9.1537'}\n",
      "[Train Epoch]1/5 [Time]2415.27 [Step]3187 [Batch]51000 [Speed]47.36ms/step [Loss]9.1536 [Metrics]{'train_loss:9.1536'}\n",
      "[Train Epoch]1/5 [Time]2438.43 [Step]3218 [Batch]51500 [Speed]47.35ms/step [Loss]9.1535 [Metrics]{'train_loss:9.1535'}\n",
      "[Train Epoch]1/5 [Time]2461.74 [Step]3250 [Batch]52000 [Speed]47.34ms/step [Loss]9.1540 [Metrics]{'train_loss:9.1540'}\n",
      "[Train Epoch]1/5 [Time]2484.91 [Step]3281 [Batch]52500 [Speed]47.33ms/step [Loss]9.1542 [Metrics]{'train_loss:9.1542'}\n",
      "[Train Epoch]1/5 [Time]2508.12 [Step]3312 [Batch]53000 [Speed]47.32ms/step [Loss]9.1536 [Metrics]{'train_loss:9.1536'}\n",
      "[Train Epoch]1/5 [Time]2531.34 [Step]3343 [Batch]53500 [Speed]47.31ms/step [Loss]9.1531 [Metrics]{'train_loss:9.1531'}\n",
      "[Train Epoch]1/5 [Time]2554.42 [Step]3375 [Batch]54000 [Speed]47.30ms/step [Loss]9.1536 [Metrics]{'train_loss:9.1536'}\n",
      "[Train Epoch]1/5 [Time]2577.75 [Step]3406 [Batch]54500 [Speed]47.30ms/step [Loss]9.1537 [Metrics]{'train_loss:9.1537'}\n",
      "[Train Epoch]1/5 [Time]2600.95 [Step]3437 [Batch]55000 [Speed]47.29ms/step [Loss]9.1533 [Metrics]{'train_loss:9.1533'}\n",
      "[Train Epoch]1/5 [Time]2624.21 [Step]3468 [Batch]55500 [Speed]47.28ms/step [Loss]9.1539 [Metrics]{'train_loss:9.1539'}\n",
      "[Train Epoch]1/5 [Time]2647.51 [Step]3500 [Batch]56000 [Speed]47.28ms/step [Loss]9.1537 [Metrics]{'train_loss:9.1537'}\n",
      "[Train Epoch]1/5 [Time]2670.69 [Step]3531 [Batch]56500 [Speed]47.27ms/step [Loss]9.1535 [Metrics]{'train_loss:9.1535'}\n",
      "[Train Epoch]1/5 [Time]2693.97 [Step]3562 [Batch]57000 [Speed]47.26ms/step [Loss]9.1526 [Metrics]{'train_loss:9.1526'}\n",
      "[Train Epoch]1/5 [Time]2717.16 [Step]3593 [Batch]57500 [Speed]47.26ms/step [Loss]9.1528 [Metrics]{'train_loss:9.1528'}\n",
      "[Train Epoch]1/5 [Time]2740.36 [Step]3625 [Batch]58000 [Speed]47.25ms/step [Loss]9.1530 [Metrics]{'train_loss:9.1530'}\n",
      "[Train Epoch]1/5 [Time]2763.63 [Step]3656 [Batch]58500 [Speed]47.24ms/step [Loss]9.1530 [Metrics]{'train_loss:9.1530'}\n",
      "[Train Epoch]1/5 [Time]2786.78 [Step]3687 [Batch]59000 [Speed]47.23ms/step [Loss]9.1532 [Metrics]{'train_loss:9.1532'}\n",
      "[Train Epoch]1/5 [Time]2810.02 [Step]3718 [Batch]59500 [Speed]47.23ms/step [Loss]9.1531 [Metrics]{'train_loss:9.1531'}\n",
      "[Train Epoch]1/5 [Time]2833.19 [Step]3750 [Batch]60000 [Speed]47.22ms/step [Loss]9.1529 [Metrics]{'train_loss:9.1529'}\n",
      "[Train Epoch]1/5 [Time]2856.48 [Step]3781 [Batch]60500 [Speed]47.21ms/step [Loss]9.1533 [Metrics]{'train_loss:9.1533'}\n",
      "[Train Epoch]1/5 [Time]2879.61 [Step]3812 [Batch]61000 [Speed]47.21ms/step [Loss]9.1532 [Metrics]{'train_loss:9.1532'}\n",
      "[Train Epoch]1/5 [Time]2902.76 [Step]3843 [Batch]61500 [Speed]47.20ms/step [Loss]9.1535 [Metrics]{'train_loss:9.1535'}\n",
      "[Train Epoch]1/5 [Time]2926.10 [Step]3875 [Batch]62000 [Speed]47.20ms/step [Loss]9.1531 [Metrics]{'train_loss:9.1531'}\n",
      "[Train Epoch]1/5 [Time]2949.31 [Step]3906 [Batch]62500 [Speed]47.19ms/step [Loss]9.1531 [Metrics]{'train_loss:9.1531'}\n",
      "[Train Epoch]1/5 [Time]2972.56 [Step]3937 [Batch]63000 [Speed]47.18ms/step [Loss]9.1525 [Metrics]{'train_loss:9.1525'}\n",
      "[Train Epoch]1/5 [Time]2995.80 [Step]3968 [Batch]63500 [Speed]47.18ms/step [Loss]9.1525 [Metrics]{'train_loss:9.1525'}\n",
      "[Train Epoch]1/5 [Time]3019.09 [Step]4000 [Batch]64000 [Speed]47.17ms/step [Loss]9.1527 [Metrics]{'train_loss:9.1527'}\n",
      "[Train Epoch]1/5 [Time]3042.47 [Step]4031 [Batch]64500 [Speed]47.17ms/step [Loss]9.1528 [Metrics]{'train_loss:9.1528'}\n",
      "[Train Epoch]1/5 [Time]3065.73 [Step]4062 [Batch]65000 [Speed]47.17ms/step [Loss]9.1520 [Metrics]{'train_loss:9.1520'}\n",
      "[Train Epoch]1/5 [Time]3088.88 [Step]4093 [Batch]65500 [Speed]47.16ms/step [Loss]9.1517 [Metrics]{'train_loss:9.1517'}\n",
      "[Train Epoch]1/5 [Time]3112.13 [Step]4125 [Batch]66000 [Speed]47.15ms/step [Loss]9.1522 [Metrics]{'train_loss:9.1522'}\n",
      "[Train Epoch]1/5 [Time]3135.43 [Step]4156 [Batch]66500 [Speed]47.15ms/step [Loss]9.1520 [Metrics]{'train_loss:9.1520'}\n",
      "[Train Epoch]1/5 [Time]3158.52 [Step]4187 [Batch]67000 [Speed]47.14ms/step [Loss]9.1521 [Metrics]{'train_loss:9.1521'}\n",
      "[Train Epoch]1/5 [Time]3181.66 [Step]4218 [Batch]67500 [Speed]47.14ms/step [Loss]9.1516 [Metrics]{'train_loss:9.1516'}\n",
      "[Train Epoch]1/5 [Time]3204.92 [Step]4250 [Batch]68000 [Speed]47.13ms/step [Loss]9.1521 [Metrics]{'train_loss:9.1521'}\n",
      "[Train Epoch]1/5 [Time]3227.98 [Step]4281 [Batch]68500 [Speed]47.12ms/step [Loss]9.1522 [Metrics]{'train_loss:9.1522'}\n",
      "[Train Epoch]1/5 [Time]3251.22 [Step]4312 [Batch]69000 [Speed]47.12ms/step [Loss]9.1521 [Metrics]{'train_loss:9.1521'}\n",
      "[Train Epoch]1/5 [Time]3274.31 [Step]4343 [Batch]69500 [Speed]47.11ms/step [Loss]9.1523 [Metrics]{'train_loss:9.1523'}\n",
      "[Train Epoch]1/5 [Time]3297.62 [Step]4375 [Batch]70000 [Speed]47.11ms/step [Loss]9.1517 [Metrics]{'train_loss:9.1517'}\n",
      "[Train Epoch]1/5 [Time]3320.87 [Step]4406 [Batch]70500 [Speed]47.10ms/step [Loss]9.1520 [Metrics]{'train_loss:9.1520'}\n",
      "[Train Epoch]1/5 [Time]3344.06 [Step]4437 [Batch]71000 [Speed]47.10ms/step [Loss]9.1520 [Metrics]{'train_loss:9.1520'}\n",
      "[Train Epoch]1/5 [Time]3367.18 [Step]4468 [Batch]71500 [Speed]47.09ms/step [Loss]9.1520 [Metrics]{'train_loss:9.1520'}\n",
      "[Train Epoch]1/5 [Time]3390.49 [Step]4500 [Batch]72000 [Speed]47.09ms/step [Loss]9.1517 [Metrics]{'train_loss:9.1517'}\n",
      "[Train Epoch]1/5 [Time]3413.94 [Step]4531 [Batch]72500 [Speed]47.09ms/step [Loss]9.1521 [Metrics]{'train_loss:9.1521'}\n",
      "[Train Epoch]1/5 [Time]3437.30 [Step]4562 [Batch]73000 [Speed]47.09ms/step [Loss]9.1515 [Metrics]{'train_loss:9.1515'}\n",
      "[Train Epoch]1/5 [Time]3460.49 [Step]4593 [Batch]73500 [Speed]47.08ms/step [Loss]9.1514 [Metrics]{'train_loss:9.1514'}\n",
      "[Train Epoch]1/5 [Time]3483.87 [Step]4625 [Batch]74000 [Speed]47.08ms/step [Loss]9.1513 [Metrics]{'train_loss:9.1513'}\n",
      "[Train Epoch]1/5 [Time]3507.14 [Step]4656 [Batch]74500 [Speed]47.08ms/step [Loss]9.1514 [Metrics]{'train_loss:9.1514'}\n",
      "[Train Epoch]1/5 [Time]3530.34 [Step]4687 [Batch]75000 [Speed]47.07ms/step [Loss]9.1512 [Metrics]{'train_loss:9.1512'}\n",
      "[Train Epoch]1/5 [Time]3553.49 [Step]4718 [Batch]75500 [Speed]47.07ms/step [Loss]9.1508 [Metrics]{'train_loss:9.1508'}\n",
      "[Train Epoch]1/5 [Time]3576.85 [Step]4750 [Batch]76000 [Speed]47.06ms/step [Loss]9.1504 [Metrics]{'train_loss:9.1504'}\n",
      "[Train Epoch]1/5 [Time]3600.04 [Step]4781 [Batch]76500 [Speed]47.06ms/step [Loss]9.1507 [Metrics]{'train_loss:9.1507'}\n",
      "[Train Epoch]1/5 [Time]3623.25 [Step]4812 [Batch]77000 [Speed]47.06ms/step [Loss]9.1511 [Metrics]{'train_loss:9.1511'}\n",
      "[Train Epoch]1/5 [Time]3646.38 [Step]4843 [Batch]77500 [Speed]47.05ms/step [Loss]9.1511 [Metrics]{'train_loss:9.1511'}\n",
      "[Train Epoch]1/5 [Time]3669.65 [Step]4875 [Batch]78000 [Speed]47.05ms/step [Loss]9.1515 [Metrics]{'train_loss:9.1515'}\n",
      "[Train Epoch]1/5 [Time]3692.91 [Step]4906 [Batch]78500 [Speed]47.04ms/step [Loss]9.1513 [Metrics]{'train_loss:9.1513'}\n",
      "[Train Epoch]1/5 [Time]3716.21 [Step]4937 [Batch]79000 [Speed]47.04ms/step [Loss]9.1515 [Metrics]{'train_loss:9.1515'}\n",
      "[Train Epoch]1/5 [Time]3739.53 [Step]4968 [Batch]79500 [Speed]47.04ms/step [Loss]9.1508 [Metrics]{'train_loss:9.1508'}\n",
      "Saving checkpoint for epoch 1 at step 80000 on path ../2_Models/model_bert4rec_complete_0.5/checkpoints/\n",
      "[Train Epoch]1/5 [Time]3764.71 [Step]5000 [Batch]80000 [Speed]47.06ms/step [Loss]9.1506 [Metrics]{'train_loss:9.1506'}\n",
      "[Train Epoch]1/5 [Time]3788.02 [Step]5031 [Batch]80500 [Speed]47.06ms/step [Loss]9.1502 [Metrics]{'train_loss:9.1502'}\n",
      "[Train Epoch]1/5 [Time]3811.31 [Step]5062 [Batch]81000 [Speed]47.05ms/step [Loss]9.1503 [Metrics]{'train_loss:9.1503'}\n",
      "[Train Epoch]1/5 [Time]3834.50 [Step]5093 [Batch]81500 [Speed]47.05ms/step [Loss]9.1499 [Metrics]{'train_loss:9.1499'}\n",
      "[Train Epoch]1/5 [Time]3857.74 [Step]5125 [Batch]82000 [Speed]47.05ms/step [Loss]9.1495 [Metrics]{'train_loss:9.1495'}\n",
      "[Train Epoch]1/5 [Time]3880.94 [Step]5156 [Batch]82500 [Speed]47.04ms/step [Loss]9.1495 [Metrics]{'train_loss:9.1495'}\n",
      "[Train Epoch]1/5 [Time]3904.42 [Step]5187 [Batch]83000 [Speed]47.04ms/step [Loss]9.1497 [Metrics]{'train_loss:9.1497'}\n",
      "[Train Epoch]1/5 [Time]3927.62 [Step]5218 [Batch]83500 [Speed]47.04ms/step [Loss]9.1495 [Metrics]{'train_loss:9.1495'}\n",
      "[Train Epoch]1/5 [Time]3950.84 [Step]5250 [Batch]84000 [Speed]47.03ms/step [Loss]9.1498 [Metrics]{'train_loss:9.1498'}\n",
      "[Train Epoch]1/5 [Time]3974.05 [Step]5281 [Batch]84500 [Speed]47.03ms/step [Loss]9.1498 [Metrics]{'train_loss:9.1498'}\n",
      "[Train Epoch]1/5 [Time]3997.31 [Step]5312 [Batch]85000 [Speed]47.03ms/step [Loss]9.1497 [Metrics]{'train_loss:9.1497'}\n",
      "[Train Epoch]1/5 [Time]4020.55 [Step]5343 [Batch]85500 [Speed]47.02ms/step [Loss]9.1496 [Metrics]{'train_loss:9.1496'}\n",
      "[Train Epoch]1/5 [Time]4043.87 [Step]5375 [Batch]86000 [Speed]47.02ms/step [Loss]9.1493 [Metrics]{'train_loss:9.1493'}\n",
      "[Train Epoch]1/5 [Time]4066.99 [Step]5406 [Batch]86500 [Speed]47.02ms/step [Loss]9.1496 [Metrics]{'train_loss:9.1496'}\n",
      "[Train Epoch]1/5 [Time]4090.25 [Step]5437 [Batch]87000 [Speed]47.01ms/step [Loss]9.1499 [Metrics]{'train_loss:9.1499'}\n",
      "[Train Epoch]1/5 [Time]4113.66 [Step]5468 [Batch]87500 [Speed]47.01ms/step [Loss]9.1499 [Metrics]{'train_loss:9.1499'}\n",
      "[Train Epoch]1/5 [Time]4136.91 [Step]5500 [Batch]88000 [Speed]47.01ms/step [Loss]9.1497 [Metrics]{'train_loss:9.1497'}\n",
      "[Train Epoch]1/5 [Time]4160.22 [Step]5531 [Batch]88500 [Speed]47.01ms/step [Loss]9.1501 [Metrics]{'train_loss:9.1501'}\n",
      "[Train Epoch]1/5 [Time]4183.39 [Step]5562 [Batch]89000 [Speed]47.00ms/step [Loss]9.1500 [Metrics]{'train_loss:9.1500'}\n",
      "[Train Epoch]1/5 [Time]4206.71 [Step]5593 [Batch]89500 [Speed]47.00ms/step [Loss]9.1502 [Metrics]{'train_loss:9.1502'}\n",
      "[Train Epoch]1/5 [Time]4229.97 [Step]5625 [Batch]90000 [Speed]47.00ms/step [Loss]9.1504 [Metrics]{'train_loss:9.1504'}\n",
      "[Train Epoch]1/5 [Time]4253.23 [Step]5656 [Batch]90500 [Speed]47.00ms/step [Loss]9.1501 [Metrics]{'train_loss:9.1501'}\n",
      "[Train Epoch]1/5 [Time]4276.65 [Step]5687 [Batch]91000 [Speed]47.00ms/step [Loss]9.1506 [Metrics]{'train_loss:9.1506'}\n",
      "[Train Epoch]1/5 [Time]4299.64 [Step]5718 [Batch]91500 [Speed]46.99ms/step [Loss]9.1505 [Metrics]{'train_loss:9.1505'}\n",
      "[Train Epoch]1/5 [Time]4322.93 [Step]5750 [Batch]92000 [Speed]46.99ms/step [Loss]9.1501 [Metrics]{'train_loss:9.1501'}\n",
      "[Train Epoch]1/5 [Time]4348.67 [Step]5781 [Batch]92500 [Speed]47.01ms/step [Loss]9.1503 [Metrics]{'train_loss:9.1503'}\n",
      "[Train Epoch]1/5 [Time]4373.18 [Step]5812 [Batch]93000 [Speed]47.02ms/step [Loss]9.1503 [Metrics]{'train_loss:9.1503'}\n",
      "[Train Epoch]1/5 [Time]4397.91 [Step]5843 [Batch]93500 [Speed]47.04ms/step [Loss]9.1504 [Metrics]{'train_loss:9.1504'}\n",
      "[Train Epoch]1/5 [Time]4422.55 [Step]5875 [Batch]94000 [Speed]47.05ms/step [Loss]9.1505 [Metrics]{'train_loss:9.1505'}\n",
      "[Train Epoch]1/5 [Time]4447.09 [Step]5906 [Batch]94500 [Speed]47.06ms/step [Loss]9.1505 [Metrics]{'train_loss:9.1505'}\n",
      "[Train Epoch]1/5 [Time]4471.61 [Step]5937 [Batch]95000 [Speed]47.07ms/step [Loss]9.1504 [Metrics]{'train_loss:9.1504'}\n",
      "[Train Epoch]1/5 [Time]4496.00 [Step]5968 [Batch]95500 [Speed]47.08ms/step [Loss]9.1504 [Metrics]{'train_loss:9.1504'}\n",
      "[Train Epoch]1/5 [Time]4520.49 [Step]6000 [Batch]96000 [Speed]47.09ms/step [Loss]9.1503 [Metrics]{'train_loss:9.1503'}\n",
      "[Train Epoch]1/5 [Time]4544.70 [Step]6031 [Batch]96500 [Speed]47.10ms/step [Loss]9.1501 [Metrics]{'train_loss:9.1501'}\n",
      "[Train Epoch]1/5 [Time]4569.53 [Step]6062 [Batch]97000 [Speed]47.11ms/step [Loss]9.1506 [Metrics]{'train_loss:9.1506'}\n",
      "[Train Epoch]1/5 [Time]4594.15 [Step]6093 [Batch]97500 [Speed]47.12ms/step [Loss]9.1503 [Metrics]{'train_loss:9.1503'}\n",
      "[Train Epoch]1/5 [Time]4618.43 [Step]6125 [Batch]98000 [Speed]47.13ms/step [Loss]9.1506 [Metrics]{'train_loss:9.1506'}\n",
      "[Train Epoch]1/5 [Time]4643.19 [Step]6156 [Batch]98500 [Speed]47.14ms/step [Loss]9.1505 [Metrics]{'train_loss:9.1505'}\n",
      "[Train Epoch]1/5 [Time]4667.87 [Step]6187 [Batch]99000 [Speed]47.15ms/step [Loss]9.1500 [Metrics]{'train_loss:9.1500'}\n",
      "[Train Epoch]1/5 [Time]4692.28 [Step]6218 [Batch]99500 [Speed]47.16ms/step [Loss]9.1500 [Metrics]{'train_loss:9.1500'}\n",
      "[Train Epoch]1/5 [Time]4716.74 [Step]6250 [Batch]100000 [Speed]47.17ms/step [Loss]9.1499 [Metrics]{'train_loss:9.1499'}\n",
      "[Train Epoch]1/5 [Time]4742.44 [Step]6281 [Batch]100500 [Speed]47.19ms/step [Loss]9.1497 [Metrics]{'train_loss:9.1497'}\n",
      "[Train Epoch]1/5 [Time]4767.06 [Step]6312 [Batch]101000 [Speed]47.20ms/step [Loss]9.1494 [Metrics]{'train_loss:9.1494'}\n",
      "[Train Epoch]1/5 [Time]4791.52 [Step]6343 [Batch]101500 [Speed]47.21ms/step [Loss]9.1493 [Metrics]{'train_loss:9.1493'}\n",
      "[Train Epoch]1/5 [Time]4816.19 [Step]6375 [Batch]102000 [Speed]47.22ms/step [Loss]9.1489 [Metrics]{'train_loss:9.1489'}\n",
      "[Train Epoch]1/5 [Time]4841.00 [Step]6406 [Batch]102500 [Speed]47.23ms/step [Loss]9.1490 [Metrics]{'train_loss:9.1490'}\n",
      "[Train Epoch]1/5 [Time]4865.71 [Step]6437 [Batch]103000 [Speed]47.24ms/step [Loss]9.1493 [Metrics]{'train_loss:9.1493'}\n",
      "[Train Epoch]1/5 [Time]4890.35 [Step]6468 [Batch]103500 [Speed]47.25ms/step [Loss]9.1494 [Metrics]{'train_loss:9.1494'}\n",
      "[Train Epoch]1/5 [Time]4915.01 [Step]6500 [Batch]104000 [Speed]47.26ms/step [Loss]9.1495 [Metrics]{'train_loss:9.1495'}\n",
      "[Train Epoch]1/5 [Time]4939.70 [Step]6531 [Batch]104500 [Speed]47.27ms/step [Loss]9.1491 [Metrics]{'train_loss:9.1491'}\n",
      "[Train Epoch]1/5 [Time]4964.24 [Step]6562 [Batch]105000 [Speed]47.28ms/step [Loss]9.1493 [Metrics]{'train_loss:9.1493'}\n",
      "[Train Epoch]1/5 [Time]4988.64 [Step]6593 [Batch]105500 [Speed]47.29ms/step [Loss]9.1493 [Metrics]{'train_loss:9.1493'}\n",
      "[Train Epoch]1/5 [Time]5013.14 [Step]6625 [Batch]106000 [Speed]47.29ms/step [Loss]9.1493 [Metrics]{'train_loss:9.1493'}\n",
      "[Train Epoch]1/5 [Time]5037.64 [Step]6656 [Batch]106500 [Speed]47.30ms/step [Loss]9.1490 [Metrics]{'train_loss:9.1490'}\n",
      "[Train Epoch]1/5 [Time]5062.04 [Step]6687 [Batch]107000 [Speed]47.31ms/step [Loss]9.1488 [Metrics]{'train_loss:9.1488'}\n",
      "[Train Epoch]1/5 [Time]5086.43 [Step]6718 [Batch]107500 [Speed]47.32ms/step [Loss]9.1485 [Metrics]{'train_loss:9.1485'}\n",
      "[Train Epoch]1/5 [Time]5110.92 [Step]6750 [Batch]108000 [Speed]47.32ms/step [Loss]9.1484 [Metrics]{'train_loss:9.1484'}\n",
      "[Train Epoch]1/5 [Time]5135.46 [Step]6781 [Batch]108500 [Speed]47.33ms/step [Loss]9.1482 [Metrics]{'train_loss:9.1482'}\n",
      "[Train Epoch]1/5 [Time]5160.01 [Step]6812 [Batch]109000 [Speed]47.34ms/step [Loss]9.1485 [Metrics]{'train_loss:9.1485'}\n",
      "[Train Epoch]1/5 [Time]5184.55 [Step]6843 [Batch]109500 [Speed]47.35ms/step [Loss]9.1486 [Metrics]{'train_loss:9.1486'}\n",
      "[Train Epoch]1/5 [Time]5209.09 [Step]6875 [Batch]110000 [Speed]47.36ms/step [Loss]9.1488 [Metrics]{'train_loss:9.1488'}\n",
      "[Train Epoch]1/5 [Time]5233.90 [Step]6906 [Batch]110500 [Speed]47.37ms/step [Loss]9.1487 [Metrics]{'train_loss:9.1487'}\n",
      "[Train Epoch]1/5 [Time]5258.90 [Step]6937 [Batch]111000 [Speed]47.38ms/step [Loss]9.1483 [Metrics]{'train_loss:9.1483'}\n",
      "[Train Epoch]1/5 [Time]5283.72 [Step]6968 [Batch]111500 [Speed]47.39ms/step [Loss]9.1487 [Metrics]{'train_loss:9.1487'}\n",
      "[Train Epoch]1/5 [Time]5308.23 [Step]7000 [Batch]112000 [Speed]47.39ms/step [Loss]9.1484 [Metrics]{'train_loss:9.1484'}\n",
      "[Train Epoch]1/5 [Time]5332.86 [Step]7031 [Batch]112500 [Speed]47.40ms/step [Loss]9.1482 [Metrics]{'train_loss:9.1482'}\n",
      "[Train Epoch]1/5 [Time]5358.21 [Step]7062 [Batch]113000 [Speed]47.42ms/step [Loss]9.1485 [Metrics]{'train_loss:9.1485'}\n",
      "[Train Epoch]1/5 [Time]5382.10 [Step]7093 [Batch]113500 [Speed]47.42ms/step [Loss]9.1481 [Metrics]{'train_loss:9.1481'}\n",
      "[Train Epoch]1/5 [Time]5406.90 [Step]7125 [Batch]114000 [Speed]47.43ms/step [Loss]9.1474 [Metrics]{'train_loss:9.1474'}\n",
      "[Train Epoch]1/5 [Time]5431.13 [Step]7156 [Batch]114500 [Speed]47.43ms/step [Loss]9.1474 [Metrics]{'train_loss:9.1474'}\n",
      "[Train Epoch]1/5 [Time]5455.39 [Step]7187 [Batch]115000 [Speed]47.44ms/step [Loss]9.1472 [Metrics]{'train_loss:9.1472'}\n",
      "[Train Epoch]1/5 [Time]5479.92 [Step]7218 [Batch]115500 [Speed]47.45ms/step [Loss]9.1472 [Metrics]{'train_loss:9.1472'}\n",
      "[Train Epoch]1/5 [Time]5504.54 [Step]7250 [Batch]116000 [Speed]47.45ms/step [Loss]9.1476 [Metrics]{'train_loss:9.1476'}\n",
      "[Train Epoch]1/5 [Time]5529.06 [Step]7281 [Batch]116500 [Speed]47.46ms/step [Loss]9.1478 [Metrics]{'train_loss:9.1478'}\n",
      "[Train Epoch]1/5 [Time]5553.31 [Step]7312 [Batch]117000 [Speed]47.46ms/step [Loss]9.1475 [Metrics]{'train_loss:9.1475'}\n",
      "[Train Epoch]1/5 [Time]5576.44 [Step]7343 [Batch]117500 [Speed]47.46ms/step [Loss]9.1475 [Metrics]{'train_loss:9.1475'}\n",
      "[Train Epoch]1/5 [Time]5599.64 [Step]7375 [Batch]118000 [Speed]47.45ms/step [Loss]9.1477 [Metrics]{'train_loss:9.1477'}\n",
      "[Train Epoch]1/5 [Time]5622.79 [Step]7406 [Batch]118500 [Speed]47.45ms/step [Loss]9.1476 [Metrics]{'train_loss:9.1476'}\n",
      "[Train Epoch]1/5 [Time]5645.81 [Step]7437 [Batch]119000 [Speed]47.44ms/step [Loss]9.1472 [Metrics]{'train_loss:9.1472'}\n",
      "[Train Epoch]1/5 [Time]5669.09 [Step]7468 [Batch]119500 [Speed]47.44ms/step [Loss]9.1471 [Metrics]{'train_loss:9.1471'}\n",
      "[Train Epoch]1/5 [Time]5692.25 [Step]7500 [Batch]120000 [Speed]47.44ms/step [Loss]9.1468 [Metrics]{'train_loss:9.1468'}\n",
      "[Train Epoch]1/5 [Time]5715.36 [Step]7531 [Batch]120500 [Speed]47.43ms/step [Loss]9.1469 [Metrics]{'train_loss:9.1469'}\n",
      "[Train Epoch]1/5 [Time]5738.54 [Step]7562 [Batch]121000 [Speed]47.43ms/step [Loss]9.1466 [Metrics]{'train_loss:9.1466'}\n",
      "[Train Epoch]1/5 [Time]5761.76 [Step]7593 [Batch]121500 [Speed]47.42ms/step [Loss]9.1462 [Metrics]{'train_loss:9.1462'}\n",
      "[Train Epoch]1/5 [Time]5785.04 [Step]7625 [Batch]122000 [Speed]47.42ms/step [Loss]9.1467 [Metrics]{'train_loss:9.1467'}\n",
      "[Train Epoch]1/5 [Time]5808.27 [Step]7656 [Batch]122500 [Speed]47.41ms/step [Loss]9.1464 [Metrics]{'train_loss:9.1464'}\n",
      "[Train Epoch]1/5 [Time]5831.45 [Step]7687 [Batch]123000 [Speed]47.41ms/step [Loss]9.1465 [Metrics]{'train_loss:9.1465'}\n",
      "[Train Epoch]1/5 [Time]5854.70 [Step]7718 [Batch]123500 [Speed]47.41ms/step [Loss]9.1466 [Metrics]{'train_loss:9.1466'}\n",
      "[Train Epoch]1/5 [Time]5877.88 [Step]7750 [Batch]124000 [Speed]47.40ms/step [Loss]9.1467 [Metrics]{'train_loss:9.1467'}\n",
      "[Train Epoch]1/5 [Time]5901.15 [Step]7781 [Batch]124500 [Speed]47.40ms/step [Loss]9.1467 [Metrics]{'train_loss:9.1467'}\n",
      "[Train Epoch]1/5 [Time]5924.28 [Step]7812 [Batch]125000 [Speed]47.39ms/step [Loss]9.1467 [Metrics]{'train_loss:9.1467'}\n",
      "[Train Epoch]1/5 [Time]5947.60 [Step]7843 [Batch]125500 [Speed]47.39ms/step [Loss]9.1465 [Metrics]{'train_loss:9.1465'}\n",
      "[Train Epoch]1/5 [Time]5970.80 [Step]7875 [Batch]126000 [Speed]47.39ms/step [Loss]9.1464 [Metrics]{'train_loss:9.1464'}\n",
      "[Train Epoch]1/5 [Time]5993.93 [Step]7906 [Batch]126500 [Speed]47.38ms/step [Loss]9.1462 [Metrics]{'train_loss:9.1462'}\n",
      "[Train Epoch]1/5 [Time]6016.96 [Step]7937 [Batch]127000 [Speed]47.38ms/step [Loss]9.1462 [Metrics]{'train_loss:9.1462'}\n",
      "[Train Epoch]1/5 [Time]6040.13 [Step]7968 [Batch]127500 [Speed]47.37ms/step [Loss]9.1460 [Metrics]{'train_loss:9.1460'}\n",
      "[Train Epoch]1/5 [Time]6063.30 [Step]8000 [Batch]128000 [Speed]47.37ms/step [Loss]9.1461 [Metrics]{'train_loss:9.1461'}\n",
      "[Train Epoch]1/5 [Time]6086.47 [Step]8031 [Batch]128500 [Speed]47.37ms/step [Loss]9.1460 [Metrics]{'train_loss:9.1460'}\n",
      "[Train Epoch]1/5 [Time]6109.63 [Step]8062 [Batch]129000 [Speed]47.36ms/step [Loss]9.1459 [Metrics]{'train_loss:9.1459'}\n",
      "[Train Epoch]1/5 [Time]6132.74 [Step]8093 [Batch]129500 [Speed]47.36ms/step [Loss]9.1458 [Metrics]{'train_loss:9.1458'}\n",
      "[Train Epoch]1/5 [Time]6155.94 [Step]8125 [Batch]130000 [Speed]47.35ms/step [Loss]9.1454 [Metrics]{'train_loss:9.1454'}\n",
      "[Train Epoch]1/5 [Time]6179.25 [Step]8156 [Batch]130500 [Speed]47.35ms/step [Loss]9.1452 [Metrics]{'train_loss:9.1452'}\n",
      "[Train Epoch]1/5 [Time]6202.27 [Step]8187 [Batch]131000 [Speed]47.35ms/step [Loss]9.1448 [Metrics]{'train_loss:9.1448'}\n",
      "[Train Epoch]1/5 [Time]6225.43 [Step]8218 [Batch]131500 [Speed]47.34ms/step [Loss]9.1443 [Metrics]{'train_loss:9.1443'}\n",
      "[Train Epoch]1/5 [Time]6248.56 [Step]8250 [Batch]132000 [Speed]47.34ms/step [Loss]9.1438 [Metrics]{'train_loss:9.1438'}\n",
      "[Train Epoch]1/5 [Time]6271.79 [Step]8281 [Batch]132500 [Speed]47.33ms/step [Loss]9.1433 [Metrics]{'train_loss:9.1433'}\n",
      "[Train Epoch]1/5 [Time]6294.97 [Step]8312 [Batch]133000 [Speed]47.33ms/step [Loss]9.1436 [Metrics]{'train_loss:9.1436'}\n",
      "[Train Epoch]1/5 [Time]6318.09 [Step]8343 [Batch]133500 [Speed]47.33ms/step [Loss]9.1432 [Metrics]{'train_loss:9.1432'}\n",
      "[Train Epoch]1/5 [Time]6341.32 [Step]8375 [Batch]134000 [Speed]47.32ms/step [Loss]9.1431 [Metrics]{'train_loss:9.1431'}\n",
      "[Train Epoch]1/5 [Time]6364.66 [Step]8406 [Batch]134500 [Speed]47.32ms/step [Loss]9.1429 [Metrics]{'train_loss:9.1429'}\n",
      "[Train Epoch]1/5 [Time]6387.64 [Step]8437 [Batch]135000 [Speed]47.32ms/step [Loss]9.1427 [Metrics]{'train_loss:9.1427'}\n",
      "[Train Epoch]1/5 [Time]6410.75 [Step]8468 [Batch]135500 [Speed]47.31ms/step [Loss]9.1430 [Metrics]{'train_loss:9.1430'}\n",
      "[Train Epoch]1/5 [Time]6433.85 [Step]8500 [Batch]136000 [Speed]47.31ms/step [Loss]9.1429 [Metrics]{'train_loss:9.1429'}\n",
      "[Train Epoch]1/5 [Time]6457.07 [Step]8531 [Batch]136500 [Speed]47.30ms/step [Loss]9.1427 [Metrics]{'train_loss:9.1427'}\n",
      "[Train Epoch]1/5 [Time]6480.16 [Step]8562 [Batch]137000 [Speed]47.30ms/step [Loss]9.1426 [Metrics]{'train_loss:9.1426'}\n",
      "[Train Epoch]1/5 [Time]6503.41 [Step]8593 [Batch]137500 [Speed]47.30ms/step [Loss]9.1428 [Metrics]{'train_loss:9.1428'}\n",
      "[Train Epoch]1/5 [Time]6526.65 [Step]8625 [Batch]138000 [Speed]47.29ms/step [Loss]9.1429 [Metrics]{'train_loss:9.1429'}\n",
      "[Train Epoch]1/5 [Time]6549.80 [Step]8656 [Batch]138500 [Speed]47.29ms/step [Loss]9.1427 [Metrics]{'train_loss:9.1427'}\n",
      "[Train Epoch]1/5 [Time]6573.00 [Step]8687 [Batch]139000 [Speed]47.29ms/step [Loss]9.1422 [Metrics]{'train_loss:9.1422'}\n",
      "[Train Epoch]1/5 [Time]6596.19 [Step]8718 [Batch]139500 [Speed]47.28ms/step [Loss]9.1426 [Metrics]{'train_loss:9.1426'}\n",
      "[Train Epoch]1/5 [Time]6619.28 [Step]8750 [Batch]140000 [Speed]47.28ms/step [Loss]9.1425 [Metrics]{'train_loss:9.1425'}\n",
      "[Train Epoch]1/5 [Time]6642.48 [Step]8781 [Batch]140500 [Speed]47.28ms/step [Loss]9.1421 [Metrics]{'train_loss:9.1421'}\n",
      "[Train Epoch]1/5 [Time]6665.67 [Step]8812 [Batch]141000 [Speed]47.27ms/step [Loss]9.1419 [Metrics]{'train_loss:9.1419'}\n",
      "[Train Epoch]1/5 [Time]6688.84 [Step]8843 [Batch]141500 [Speed]47.27ms/step [Loss]9.1416 [Metrics]{'train_loss:9.1416'}\n",
      "[Train Epoch]1/5 [Time]6712.08 [Step]8875 [Batch]142000 [Speed]47.27ms/step [Loss]9.1417 [Metrics]{'train_loss:9.1417'}\n",
      "[Train Epoch]1/5 [Time]6735.20 [Step]8906 [Batch]142500 [Speed]47.26ms/step [Loss]9.1416 [Metrics]{'train_loss:9.1416'}\n",
      "[Train Epoch]1/5 [Time]6758.36 [Step]8937 [Batch]143000 [Speed]47.26ms/step [Loss]9.1415 [Metrics]{'train_loss:9.1415'}\n",
      "[Train Epoch]1/5 [Time]6781.55 [Step]8968 [Batch]143500 [Speed]47.26ms/step [Loss]9.1413 [Metrics]{'train_loss:9.1413'}\n",
      "[Train Epoch]1/5 [Time]6804.77 [Step]9000 [Batch]144000 [Speed]47.26ms/step [Loss]9.1412 [Metrics]{'train_loss:9.1412'}\n",
      "[Train Epoch]1/5 [Time]6828.02 [Step]9031 [Batch]144500 [Speed]47.25ms/step [Loss]9.1410 [Metrics]{'train_loss:9.1410'}\n",
      "[Train Epoch]1/5 [Time]6851.23 [Step]9062 [Batch]145000 [Speed]47.25ms/step [Loss]9.1409 [Metrics]{'train_loss:9.1409'}\n",
      "[Train Epoch]1/5 [Time]6874.32 [Step]9093 [Batch]145500 [Speed]47.25ms/step [Loss]9.1408 [Metrics]{'train_loss:9.1408'}\n",
      "[Train Epoch]1/5 [Time]6897.50 [Step]9125 [Batch]146000 [Speed]47.24ms/step [Loss]9.1410 [Metrics]{'train_loss:9.1410'}\n",
      "[Train Epoch]1/5 [Time]6920.64 [Step]9156 [Batch]146500 [Speed]47.24ms/step [Loss]9.1406 [Metrics]{'train_loss:9.1406'}\n",
      "[Train Epoch]1/5 [Time]6943.95 [Step]9187 [Batch]147000 [Speed]47.24ms/step [Loss]9.1403 [Metrics]{'train_loss:9.1403'}\n",
      "[Train Epoch]1/5 [Time]6967.16 [Step]9218 [Batch]147500 [Speed]47.24ms/step [Loss]9.1401 [Metrics]{'train_loss:9.1401'}\n",
      "[Train Epoch]1/5 [Time]6990.39 [Step]9250 [Batch]148000 [Speed]47.23ms/step [Loss]9.1400 [Metrics]{'train_loss:9.1400'}\n",
      "[Train Epoch]1/5 [Time]7013.70 [Step]9281 [Batch]148500 [Speed]47.23ms/step [Loss]9.1399 [Metrics]{'train_loss:9.1399'}\n",
      "[Train Epoch]1/5 [Time]7036.91 [Step]9312 [Batch]149000 [Speed]47.23ms/step [Loss]9.1398 [Metrics]{'train_loss:9.1398'}\n",
      "[Train Epoch]1/5 [Time]7060.09 [Step]9343 [Batch]149500 [Speed]47.22ms/step [Loss]9.1395 [Metrics]{'train_loss:9.1395'}\n",
      "[Train Epoch]1/5 [Time]7083.33 [Step]9375 [Batch]150000 [Speed]47.22ms/step [Loss]9.1394 [Metrics]{'train_loss:9.1394'}\n",
      "[Train Epoch]1/5 [Time]7106.54 [Step]9406 [Batch]150500 [Speed]47.22ms/step [Loss]9.1390 [Metrics]{'train_loss:9.1390'}\n",
      "[Train Epoch]1/5 [Time]7129.70 [Step]9437 [Batch]151000 [Speed]47.22ms/step [Loss]9.1387 [Metrics]{'train_loss:9.1387'}\n",
      "[Train Epoch]1/5 [Time]7152.90 [Step]9468 [Batch]151500 [Speed]47.21ms/step [Loss]9.1382 [Metrics]{'train_loss:9.1382'}\n",
      "[Train Epoch]1/5 [Time]7176.22 [Step]9500 [Batch]152000 [Speed]47.21ms/step [Loss]9.1381 [Metrics]{'train_loss:9.1381'}\n",
      "[Train Epoch]1/5 [Time]7199.47 [Step]9531 [Batch]152500 [Speed]47.21ms/step [Loss]9.1377 [Metrics]{'train_loss:9.1377'}\n",
      "[Train Epoch]1/5 [Time]7222.57 [Step]9562 [Batch]153000 [Speed]47.21ms/step [Loss]9.1373 [Metrics]{'train_loss:9.1373'}\n",
      "[Train Epoch]1/5 [Time]7245.88 [Step]9593 [Batch]153500 [Speed]47.20ms/step [Loss]9.1373 [Metrics]{'train_loss:9.1373'}\n",
      "[Train Epoch]1/5 [Time]7269.13 [Step]9625 [Batch]154000 [Speed]47.20ms/step [Loss]9.1371 [Metrics]{'train_loss:9.1371'}\n",
      "[Train Epoch]1/5 [Time]7292.26 [Step]9656 [Batch]154500 [Speed]47.20ms/step [Loss]9.1371 [Metrics]{'train_loss:9.1371'}\n",
      "[Train Epoch]1/5 [Time]7315.57 [Step]9687 [Batch]155000 [Speed]47.20ms/step [Loss]9.1372 [Metrics]{'train_loss:9.1372'}\n",
      "[Train Epoch]1/5 [Time]7338.79 [Step]9718 [Batch]155500 [Speed]47.19ms/step [Loss]9.1366 [Metrics]{'train_loss:9.1366'}\n",
      "[Train Epoch]1/5 [Time]7361.96 [Step]9750 [Batch]156000 [Speed]47.19ms/step [Loss]9.1362 [Metrics]{'train_loss:9.1362'}\n",
      "[Train Epoch]1/5 [Time]7385.16 [Step]9781 [Batch]156500 [Speed]47.19ms/step [Loss]9.1359 [Metrics]{'train_loss:9.1359'}\n",
      "[Train Epoch]1/5 [Time]7408.39 [Step]9812 [Batch]157000 [Speed]47.19ms/step [Loss]9.1358 [Metrics]{'train_loss:9.1358'}\n",
      "[Train Epoch]1/5 [Time]7431.57 [Step]9843 [Batch]157500 [Speed]47.18ms/step [Loss]9.1355 [Metrics]{'train_loss:9.1355'}\n",
      "[Train Epoch]1/5 [Time]7454.83 [Step]9875 [Batch]158000 [Speed]47.18ms/step [Loss]9.1352 [Metrics]{'train_loss:9.1352'}\n",
      "[Train Epoch]1/5 [Time]7478.16 [Step]9906 [Batch]158500 [Speed]47.18ms/step [Loss]9.1347 [Metrics]{'train_loss:9.1347'}\n",
      "[Train Epoch]1/5 [Time]7501.30 [Step]9937 [Batch]159000 [Speed]47.18ms/step [Loss]9.1347 [Metrics]{'train_loss:9.1347'}\n",
      "[Train Epoch]1/5 [Time]7524.52 [Step]9968 [Batch]159500 [Speed]47.18ms/step [Loss]9.1344 [Metrics]{'train_loss:9.1344'}\n",
      "Saving checkpoint for epoch 1 at step 160000 on path ../2_Models/model_bert4rec_complete_0.5/checkpoints/\n",
      "[Train Epoch]1/5 [Time]7549.56 [Step]10000 [Batch]160000 [Speed]47.18ms/step [Loss]9.1340 [Metrics]{'train_loss:9.1340'}\n",
      "[Train Epoch]1/5 [Time]7572.80 [Step]10031 [Batch]160500 [Speed]47.18ms/step [Loss]9.1340 [Metrics]{'train_loss:9.1340'}\n",
      "[Train Epoch]1/5 [Time]7596.09 [Step]10062 [Batch]161000 [Speed]47.18ms/step [Loss]9.1342 [Metrics]{'train_loss:9.1342'}\n",
      "[Train Epoch]1/5 [Time]7619.35 [Step]10093 [Batch]161500 [Speed]47.18ms/step [Loss]9.1340 [Metrics]{'train_loss:9.1340'}\n",
      "[Train Epoch]1/5 [Time]7642.56 [Step]10125 [Batch]162000 [Speed]47.18ms/step [Loss]9.1339 [Metrics]{'train_loss:9.1339'}\n",
      "[Train Epoch]1/5 [Time]7665.70 [Step]10156 [Batch]162500 [Speed]47.17ms/step [Loss]9.1341 [Metrics]{'train_loss:9.1341'}\n",
      "[Train Epoch]1/5 [Time]7688.92 [Step]10187 [Batch]163000 [Speed]47.17ms/step [Loss]9.1339 [Metrics]{'train_loss:9.1339'}\n",
      "[Train Epoch]1/5 [Time]7712.22 [Step]10218 [Batch]163500 [Speed]47.17ms/step [Loss]9.1337 [Metrics]{'train_loss:9.1337'}\n",
      "[Train Epoch]1/5 [Time]7735.44 [Step]10250 [Batch]164000 [Speed]47.17ms/step [Loss]9.1337 [Metrics]{'train_loss:9.1337'}\n",
      "[Train Epoch]1/5 [Time]7758.73 [Step]10281 [Batch]164500 [Speed]47.17ms/step [Loss]9.1336 [Metrics]{'train_loss:9.1336'}\n",
      "[Train Epoch]1/5 [Time]7781.86 [Step]10312 [Batch]165000 [Speed]47.16ms/step [Loss]9.1333 [Metrics]{'train_loss:9.1333'}\n",
      "[Train Epoch]1/5 [Time]7805.07 [Step]10343 [Batch]165500 [Speed]47.16ms/step [Loss]9.1329 [Metrics]{'train_loss:9.1329'}\n",
      "[Train Epoch]1/5 [Time]7828.40 [Step]10375 [Batch]166000 [Speed]47.16ms/step [Loss]9.1328 [Metrics]{'train_loss:9.1328'}\n",
      "[Train Epoch]1/5 [Time]7851.64 [Step]10406 [Batch]166500 [Speed]47.16ms/step [Loss]9.1330 [Metrics]{'train_loss:9.1330'}\n",
      "[Train Epoch]1/5 [Time]7875.76 [Step]10437 [Batch]167000 [Speed]47.16ms/step [Loss]9.1330 [Metrics]{'train_loss:9.1330'}\n",
      "[Train Epoch]1/5 [Time]7901.04 [Step]10468 [Batch]167500 [Speed]47.17ms/step [Loss]9.1328 [Metrics]{'train_loss:9.1328'}\n",
      "[Train Epoch]1/5 [Time]7925.98 [Step]10500 [Batch]168000 [Speed]47.18ms/step [Loss]9.1328 [Metrics]{'train_loss:9.1328'}\n",
      "[Train Epoch]1/5 [Time]7950.59 [Step]10531 [Batch]168500 [Speed]47.18ms/step [Loss]9.1328 [Metrics]{'train_loss:9.1328'}\n",
      "[Train Epoch]1/5 [Time]7975.17 [Step]10562 [Batch]169000 [Speed]47.19ms/step [Loss]9.1327 [Metrics]{'train_loss:9.1327'}\n",
      "[Train Epoch]1/5 [Time]8000.02 [Step]10593 [Batch]169500 [Speed]47.20ms/step [Loss]9.1324 [Metrics]{'train_loss:9.1324'}\n",
      "[Train Epoch]1/5 [Time]8024.79 [Step]10625 [Batch]170000 [Speed]47.20ms/step [Loss]9.1323 [Metrics]{'train_loss:9.1323'}\n",
      "[Train Epoch]1/5 [Time]8049.43 [Step]10656 [Batch]170500 [Speed]47.21ms/step [Loss]9.1322 [Metrics]{'train_loss:9.1322'}\n",
      "[Train Epoch]1/5 [Time]8074.33 [Step]10687 [Batch]171000 [Speed]47.22ms/step [Loss]9.1321 [Metrics]{'train_loss:9.1321'}\n",
      "[Train Epoch]1/5 [Time]8099.13 [Step]10718 [Batch]171500 [Speed]47.23ms/step [Loss]9.1321 [Metrics]{'train_loss:9.1321'}\n",
      "[Train Epoch]1/5 [Time]8123.93 [Step]10750 [Batch]172000 [Speed]47.23ms/step [Loss]9.1320 [Metrics]{'train_loss:9.1320'}\n",
      "[Train Epoch]1/5 [Time]8148.67 [Step]10781 [Batch]172500 [Speed]47.24ms/step [Loss]9.1319 [Metrics]{'train_loss:9.1319'}\n",
      "[Train Epoch]1/5 [Time]8173.71 [Step]10812 [Batch]173000 [Speed]47.25ms/step [Loss]9.1318 [Metrics]{'train_loss:9.1318'}\n",
      "[Train Epoch]1/5 [Time]8198.07 [Step]10843 [Batch]173500 [Speed]47.25ms/step [Loss]9.1315 [Metrics]{'train_loss:9.1315'}\n",
      "[Train Epoch]1/5 [Time]8222.43 [Step]10875 [Batch]174000 [Speed]47.26ms/step [Loss]9.1314 [Metrics]{'train_loss:9.1314'}\n",
      "[Train Epoch]1/5 [Time]8246.28 [Step]10906 [Batch]174500 [Speed]47.26ms/step [Loss]9.1312 [Metrics]{'train_loss:9.1312'}\n",
      "[Train Epoch]1/5 [Time]8270.71 [Step]10937 [Batch]175000 [Speed]47.26ms/step [Loss]9.1313 [Metrics]{'train_loss:9.1313'}\n",
      "[Train Epoch]1/5 [Time]8295.55 [Step]10968 [Batch]175500 [Speed]47.27ms/step [Loss]9.1312 [Metrics]{'train_loss:9.1312'}\n",
      "[Train Epoch]1/5 [Time]8318.68 [Step]11000 [Batch]176000 [Speed]47.27ms/step [Loss]9.1310 [Metrics]{'train_loss:9.1310'}\n",
      "[Train Epoch]1/5 [Time]8341.68 [Step]11031 [Batch]176500 [Speed]47.26ms/step [Loss]9.1307 [Metrics]{'train_loss:9.1307'}\n",
      "[Train Epoch]1/5 [Time]8364.90 [Step]11062 [Batch]177000 [Speed]47.26ms/step [Loss]9.1305 [Metrics]{'train_loss:9.1305'}\n",
      "[Train Epoch]1/5 [Time]8388.15 [Step]11093 [Batch]177500 [Speed]47.26ms/step [Loss]9.1307 [Metrics]{'train_loss:9.1307'}\n",
      "[Train Epoch]1/5 [Time]8412.99 [Step]11125 [Batch]178000 [Speed]47.26ms/step [Loss]9.1306 [Metrics]{'train_loss:9.1306'}\n",
      "[Train Epoch]1/5 [Time]8437.26 [Step]11156 [Batch]178500 [Speed]47.27ms/step [Loss]9.1305 [Metrics]{'train_loss:9.1305'}\n",
      "[Train Epoch]1/5 [Time]8460.29 [Step]11187 [Batch]179000 [Speed]47.26ms/step [Loss]9.1305 [Metrics]{'train_loss:9.1305'}\n",
      "[Train Epoch]1/5 [Time]8483.41 [Step]11218 [Batch]179500 [Speed]47.26ms/step [Loss]9.1303 [Metrics]{'train_loss:9.1303'}\n",
      "[Train Epoch]1/5 [Time]8506.54 [Step]11250 [Batch]180000 [Speed]47.26ms/step [Loss]9.1304 [Metrics]{'train_loss:9.1304'}\n",
      "[Train Epoch]1/5 [Time]8529.69 [Step]11281 [Batch]180500 [Speed]47.26ms/step [Loss]9.1303 [Metrics]{'train_loss:9.1303'}\n",
      "[Train Epoch]1/5 [Time]8552.68 [Step]11312 [Batch]181000 [Speed]47.25ms/step [Loss]9.1301 [Metrics]{'train_loss:9.1301'}\n",
      "[Train Epoch]1/5 [Time]8575.85 [Step]11343 [Batch]181500 [Speed]47.25ms/step [Loss]9.1301 [Metrics]{'train_loss:9.1301'}\n",
      "[Train Epoch]1/5 [Time]8599.05 [Step]11375 [Batch]182000 [Speed]47.25ms/step [Loss]9.1300 [Metrics]{'train_loss:9.1300'}\n",
      "[Train Epoch]1/5 [Time]8622.15 [Step]11406 [Batch]182500 [Speed]47.24ms/step [Loss]9.1299 [Metrics]{'train_loss:9.1299'}\n",
      "[Train Epoch]1/5 [Time]8645.46 [Step]11437 [Batch]183000 [Speed]47.24ms/step [Loss]9.1297 [Metrics]{'train_loss:9.1297'}\n",
      "[Train Epoch]1/5 [Time]8668.55 [Step]11468 [Batch]183500 [Speed]47.24ms/step [Loss]9.1296 [Metrics]{'train_loss:9.1296'}\n",
      "[Train Epoch]1/5 [Time]8692.22 [Step]11500 [Batch]184000 [Speed]47.24ms/step [Loss]9.1296 [Metrics]{'train_loss:9.1296'}\n",
      "[Train Epoch]1/5 [Time]8715.78 [Step]11531 [Batch]184500 [Speed]47.24ms/step [Loss]9.1293 [Metrics]{'train_loss:9.1293'}\n",
      "[Train Epoch]1/5 [Time]8739.31 [Step]11562 [Batch]185000 [Speed]47.24ms/step [Loss]9.1293 [Metrics]{'train_loss:9.1293'}\n",
      "[Train Epoch]1/5 [Time]8762.90 [Step]11593 [Batch]185500 [Speed]47.24ms/step [Loss]9.1291 [Metrics]{'train_loss:9.1291'}\n",
      "[Train Epoch]1/5 [Time]8786.12 [Step]11625 [Batch]186000 [Speed]47.24ms/step [Loss]9.1289 [Metrics]{'train_loss:9.1289'}\n",
      "[Train Epoch]1/5 [Time]8809.25 [Step]11656 [Batch]186500 [Speed]47.23ms/step [Loss]9.1286 [Metrics]{'train_loss:9.1286'}\n",
      "[Train Epoch]1/5 [Time]8832.16 [Step]11687 [Batch]187000 [Speed]47.23ms/step [Loss]9.1282 [Metrics]{'train_loss:9.1282'}\n",
      "[Train Epoch]1/5 [Time]8856.12 [Step]11718 [Batch]187500 [Speed]47.23ms/step [Loss]9.1283 [Metrics]{'train_loss:9.1283'}\n",
      "[Train Epoch]1/5 [Time]8879.36 [Step]11750 [Batch]188000 [Speed]47.23ms/step [Loss]9.1280 [Metrics]{'train_loss:9.1280'}\n",
      "[Train Epoch]1/5 [Time]8902.77 [Step]11781 [Batch]188500 [Speed]47.23ms/step [Loss]9.1280 [Metrics]{'train_loss:9.1280'}\n",
      "[Train Epoch]1/5 [Time]8925.90 [Step]11812 [Batch]189000 [Speed]47.23ms/step [Loss]9.1281 [Metrics]{'train_loss:9.1281'}\n",
      "[Train Epoch]1/5 [Time]8949.64 [Step]11843 [Batch]189500 [Speed]47.23ms/step [Loss]9.1279 [Metrics]{'train_loss:9.1279'}\n",
      "[Train Epoch]1/5 [Time]8972.75 [Step]11875 [Batch]190000 [Speed]47.22ms/step [Loss]9.1276 [Metrics]{'train_loss:9.1276'}\n",
      "[Train Epoch]1/5 [Time]8996.02 [Step]11906 [Batch]190500 [Speed]47.22ms/step [Loss]9.1273 [Metrics]{'train_loss:9.1273'}\n",
      "[Train Epoch]1/5 [Time]9019.15 [Step]11937 [Batch]191000 [Speed]47.22ms/step [Loss]9.1272 [Metrics]{'train_loss:9.1272'}\n",
      "[Train Epoch]1/5 [Time]9042.39 [Step]11968 [Batch]191500 [Speed]47.22ms/step [Loss]9.1272 [Metrics]{'train_loss:9.1272'}\n",
      "[Train Epoch]1/5 [Time]9065.44 [Step]12000 [Batch]192000 [Speed]47.22ms/step [Loss]9.1271 [Metrics]{'train_loss:9.1271'}\n",
      "[Train Epoch]1/5 [Time]9088.77 [Step]12031 [Batch]192500 [Speed]47.21ms/step [Loss]9.1271 [Metrics]{'train_loss:9.1271'}\n",
      "[Train Epoch]1/5 [Time]9112.32 [Step]12062 [Batch]193000 [Speed]47.21ms/step [Loss]9.1270 [Metrics]{'train_loss:9.1270'}\n",
      "[Train Epoch]1/5 [Time]9135.30 [Step]12093 [Batch]193500 [Speed]47.21ms/step [Loss]9.1269 [Metrics]{'train_loss:9.1269'}\n",
      "[Train Epoch]1/5 [Time]9158.46 [Step]12125 [Batch]194000 [Speed]47.21ms/step [Loss]9.1269 [Metrics]{'train_loss:9.1269'}\n",
      "[Train Epoch]1/5 [Time]9181.77 [Step]12156 [Batch]194500 [Speed]47.21ms/step [Loss]9.1268 [Metrics]{'train_loss:9.1268'}\n",
      "[Train Epoch]1/5 [Time]9204.95 [Step]12187 [Batch]195000 [Speed]47.20ms/step [Loss]9.1266 [Metrics]{'train_loss:9.1266'}\n",
      "[Train Epoch]1/5 [Time]9229.35 [Step]12218 [Batch]195500 [Speed]47.21ms/step [Loss]9.1267 [Metrics]{'train_loss:9.1267'}\n",
      "[Train Epoch]1/5 [Time]9252.58 [Step]12250 [Batch]196000 [Speed]47.21ms/step [Loss]9.1266 [Metrics]{'train_loss:9.1266'}\n",
      "[Train Epoch]1/5 [Time]9275.74 [Step]12281 [Batch]196500 [Speed]47.20ms/step [Loss]9.1267 [Metrics]{'train_loss:9.1267'}\n",
      "[Train Epoch]1/5 [Time]9298.88 [Step]12312 [Batch]197000 [Speed]47.20ms/step [Loss]9.1269 [Metrics]{'train_loss:9.1269'}\n",
      "[Train Epoch]1/5 [Time]9321.91 [Step]12343 [Batch]197500 [Speed]47.20ms/step [Loss]9.1270 [Metrics]{'train_loss:9.1270'}\n",
      "[Train Epoch]1/5 [Time]9345.04 [Step]12375 [Batch]198000 [Speed]47.20ms/step [Loss]9.1268 [Metrics]{'train_loss:9.1268'}\n",
      "[Train Epoch]1/5 [Time]9368.15 [Step]12406 [Batch]198500 [Speed]47.19ms/step [Loss]9.1266 [Metrics]{'train_loss:9.1266'}\n",
      "[Train Epoch]1/5 [Time]9391.36 [Step]12437 [Batch]199000 [Speed]47.19ms/step [Loss]9.1266 [Metrics]{'train_loss:9.1266'}\n",
      "[Train Epoch]1/5 [Time]9414.47 [Step]12468 [Batch]199500 [Speed]47.19ms/step [Loss]9.1265 [Metrics]{'train_loss:9.1265'}\n",
      "[Train Epoch]1/5 [Time]9437.92 [Step]12500 [Batch]200000 [Speed]47.19ms/step [Loss]9.1262 [Metrics]{'train_loss:9.1262'}\n",
      "[Train Epoch]1/5 [Time]9461.19 [Step]12531 [Batch]200500 [Speed]47.19ms/step [Loss]9.1260 [Metrics]{'train_loss:9.1260'}\n",
      "[Train Epoch]1/5 [Time]9484.58 [Step]12562 [Batch]201000 [Speed]47.19ms/step [Loss]9.1260 [Metrics]{'train_loss:9.1260'}\n",
      "[Train Epoch]1/5 [Time]9507.78 [Step]12593 [Batch]201500 [Speed]47.19ms/step [Loss]9.1259 [Metrics]{'train_loss:9.1259'}\n",
      "[Train Epoch]1/5 [Time]9531.89 [Step]12625 [Batch]202000 [Speed]47.19ms/step [Loss]9.1257 [Metrics]{'train_loss:9.1257'}\n",
      "[Train Epoch]1/5 [Time]9555.95 [Step]12656 [Batch]202500 [Speed]47.19ms/step [Loss]9.1256 [Metrics]{'train_loss:9.1256'}\n",
      "[Train Epoch]1/5 [Time]9579.23 [Step]12687 [Batch]203000 [Speed]47.19ms/step [Loss]9.1253 [Metrics]{'train_loss:9.1253'}\n",
      "[Train Epoch]1/5 [Time]9602.51 [Step]12718 [Batch]203500 [Speed]47.19ms/step [Loss]9.1252 [Metrics]{'train_loss:9.1252'}\n",
      "[Train Epoch]1/5 [Time]9625.74 [Step]12750 [Batch]204000 [Speed]47.18ms/step [Loss]9.1251 [Metrics]{'train_loss:9.1251'}\n",
      "[Train Epoch]1/5 [Time]9649.18 [Step]12781 [Batch]204500 [Speed]47.18ms/step [Loss]9.1251 [Metrics]{'train_loss:9.1251'}\n",
      "[Train Epoch]1/5 [Time]9673.10 [Step]12812 [Batch]205000 [Speed]47.19ms/step [Loss]9.1250 [Metrics]{'train_loss:9.1250'}\n",
      "[Train Epoch]1/5 [Time]9697.64 [Step]12843 [Batch]205500 [Speed]47.19ms/step [Loss]9.1250 [Metrics]{'train_loss:9.1250'}\n",
      "[Train Epoch]1/5 [Time]9721.66 [Step]12875 [Batch]206000 [Speed]47.19ms/step [Loss]9.1249 [Metrics]{'train_loss:9.1249'}\n",
      "[Train Epoch]1/5 [Time]9744.97 [Step]12906 [Batch]206500 [Speed]47.19ms/step [Loss]9.1249 [Metrics]{'train_loss:9.1249'}\n",
      "[Train Epoch]1/5 [Time]9768.21 [Step]12937 [Batch]207000 [Speed]47.19ms/step [Loss]9.1248 [Metrics]{'train_loss:9.1248'}\n",
      "[Train Epoch]1/5 [Time]9791.71 [Step]12968 [Batch]207500 [Speed]47.19ms/step [Loss]9.1247 [Metrics]{'train_loss:9.1247'}\n",
      "[Train Epoch]1/5 [Time]9815.06 [Step]13000 [Batch]208000 [Speed]47.19ms/step [Loss]9.1248 [Metrics]{'train_loss:9.1248'}\n",
      "[Train Epoch]1/5 [Time]9838.44 [Step]13031 [Batch]208500 [Speed]47.19ms/step [Loss]9.1245 [Metrics]{'train_loss:9.1245'}\n",
      "[Train Epoch]1/5 [Time]9861.78 [Step]13062 [Batch]209000 [Speed]47.19ms/step [Loss]9.1244 [Metrics]{'train_loss:9.1244'}\n",
      "[Train Epoch]1/5 [Time]9884.93 [Step]13093 [Batch]209500 [Speed]47.18ms/step [Loss]9.1244 [Metrics]{'train_loss:9.1244'}\n",
      "[Train Epoch]1/5 [Time]9908.07 [Step]13125 [Batch]210000 [Speed]47.18ms/step [Loss]9.1241 [Metrics]{'train_loss:9.1241'}\n",
      "[Train Epoch]1/5 [Time]9931.12 [Step]13156 [Batch]210500 [Speed]47.18ms/step [Loss]9.1240 [Metrics]{'train_loss:9.1240'}\n",
      "[Train Epoch]1/5 [Time]9955.22 [Step]13187 [Batch]211000 [Speed]47.18ms/step [Loss]9.1240 [Metrics]{'train_loss:9.1240'}\n",
      "[Train Epoch]1/5 [Time]9978.57 [Step]13218 [Batch]211500 [Speed]47.18ms/step [Loss]9.1239 [Metrics]{'train_loss:9.1239'}\n",
      "[Train Epoch]1/5 [Time]10001.78 [Step]13250 [Batch]212000 [Speed]47.18ms/step [Loss]9.1237 [Metrics]{'train_loss:9.1237'}\n",
      "[Train Epoch]1/5 [Time]10025.21 [Step]13281 [Batch]212500 [Speed]47.18ms/step [Loss]9.1237 [Metrics]{'train_loss:9.1237'}\n",
      "[Train Epoch]1/5 [Time]10049.32 [Step]13312 [Batch]213000 [Speed]47.18ms/step [Loss]9.1237 [Metrics]{'train_loss:9.1237'}\n",
      "[Train Epoch]1/5 [Time]10073.79 [Step]13343 [Batch]213500 [Speed]47.18ms/step [Loss]9.1236 [Metrics]{'train_loss:9.1236'}\n",
      "[Train Epoch]1/5 [Time]10098.70 [Step]13375 [Batch]214000 [Speed]47.19ms/step [Loss]9.1233 [Metrics]{'train_loss:9.1233'}\n",
      "[Train Epoch]1/5 [Time]10123.44 [Step]13406 [Batch]214500 [Speed]47.20ms/step [Loss]9.1233 [Metrics]{'train_loss:9.1233'}\n",
      "[Train Epoch]1/5 [Time]10147.36 [Step]13437 [Batch]215000 [Speed]47.20ms/step [Loss]9.1233 [Metrics]{'train_loss:9.1233'}\n",
      "[Train Epoch]1/5 [Time]10171.13 [Step]13468 [Batch]215500 [Speed]47.20ms/step [Loss]9.1234 [Metrics]{'train_loss:9.1234'}\n",
      "[Train Epoch]1/5 [Time]10195.10 [Step]13500 [Batch]216000 [Speed]47.20ms/step [Loss]9.1232 [Metrics]{'train_loss:9.1232'}\n",
      "[Train Epoch]1/5 [Time]10218.89 [Step]13531 [Batch]216500 [Speed]47.20ms/step [Loss]9.1230 [Metrics]{'train_loss:9.1230'}\n",
      "[Train Epoch]1/5 [Time]10242.82 [Step]13562 [Batch]217000 [Speed]47.20ms/step [Loss]9.1231 [Metrics]{'train_loss:9.1231'}\n",
      "[Train Epoch]1/5 [Time]10266.69 [Step]13593 [Batch]217500 [Speed]47.20ms/step [Loss]9.1230 [Metrics]{'train_loss:9.1230'}\n",
      "[Train Epoch]1/5 [Time]10290.61 [Step]13625 [Batch]218000 [Speed]47.20ms/step [Loss]9.1229 [Metrics]{'train_loss:9.1229'}\n",
      "[Train Epoch]1/5 [Time]10314.54 [Step]13656 [Batch]218500 [Speed]47.21ms/step [Loss]9.1229 [Metrics]{'train_loss:9.1229'}\n",
      "[Train Epoch]1/5 [Time]10338.39 [Step]13687 [Batch]219000 [Speed]47.21ms/step [Loss]9.1230 [Metrics]{'train_loss:9.1230'}\n",
      "[Train Epoch]1/5 [Time]10362.36 [Step]13718 [Batch]219500 [Speed]47.21ms/step [Loss]9.1229 [Metrics]{'train_loss:9.1229'}\n",
      "[Train Epoch]1/5 [Time]10386.25 [Step]13750 [Batch]220000 [Speed]47.21ms/step [Loss]9.1227 [Metrics]{'train_loss:9.1227'}\n",
      "[Train Epoch]1/5 [Time]10410.11 [Step]13781 [Batch]220500 [Speed]47.21ms/step [Loss]9.1223 [Metrics]{'train_loss:9.1223'}\n",
      "[Train Epoch]1/5 [Time]10434.06 [Step]13812 [Batch]221000 [Speed]47.21ms/step [Loss]9.1223 [Metrics]{'train_loss:9.1223'}\n",
      "[Train Epoch]1/5 [Time]10457.89 [Step]13843 [Batch]221500 [Speed]47.21ms/step [Loss]9.1223 [Metrics]{'train_loss:9.1223'}\n",
      "[Train Epoch]1/5 [Time]10481.86 [Step]13875 [Batch]222000 [Speed]47.22ms/step [Loss]9.1223 [Metrics]{'train_loss:9.1223'}\n",
      "[Train Epoch]1/5 [Time]10506.37 [Step]13906 [Batch]222500 [Speed]47.22ms/step [Loss]9.1222 [Metrics]{'train_loss:9.1222'}\n",
      "[Train Epoch]1/5 [Time]10531.02 [Step]13937 [Batch]223000 [Speed]47.22ms/step [Loss]9.1222 [Metrics]{'train_loss:9.1222'}\n",
      "[Train Epoch]1/5 [Time]10555.69 [Step]13968 [Batch]223500 [Speed]47.23ms/step [Loss]9.1222 [Metrics]{'train_loss:9.1222'}\n",
      "[Train Epoch]1/5 [Time]10580.33 [Step]14000 [Batch]224000 [Speed]47.23ms/step [Loss]9.1222 [Metrics]{'train_loss:9.1222'}\n",
      "[Train Epoch]1/5 [Time]10605.00 [Step]14031 [Batch]224500 [Speed]47.24ms/step [Loss]9.1223 [Metrics]{'train_loss:9.1223'}\n",
      "[Train Epoch]1/5 [Time]10630.00 [Step]14062 [Batch]225000 [Speed]47.24ms/step [Loss]9.1222 [Metrics]{'train_loss:9.1222'}\n",
      "[Train Epoch]1/5 [Time]10654.94 [Step]14093 [Batch]225500 [Speed]47.25ms/step [Loss]9.1220 [Metrics]{'train_loss:9.1220'}\n",
      "[Train Epoch]1/5 [Time]10679.83 [Step]14125 [Batch]226000 [Speed]47.26ms/step [Loss]9.1220 [Metrics]{'train_loss:9.1220'}\n",
      "[Train Epoch]1/5 [Time]10704.62 [Step]14156 [Batch]226500 [Speed]47.26ms/step [Loss]9.1220 [Metrics]{'train_loss:9.1220'}\n",
      "[Train Epoch]1/5 [Time]10729.22 [Step]14187 [Batch]227000 [Speed]47.27ms/step [Loss]9.1218 [Metrics]{'train_loss:9.1218'}\n",
      "[Train Epoch]1/5 [Time]10753.93 [Step]14218 [Batch]227500 [Speed]47.27ms/step [Loss]9.1217 [Metrics]{'train_loss:9.1217'}\n",
      "[Train Epoch]1/5 [Time]10778.76 [Step]14250 [Batch]228000 [Speed]47.28ms/step [Loss]9.1216 [Metrics]{'train_loss:9.1216'}\n",
      "[Train Epoch]1/5 [Time]10803.59 [Step]14281 [Batch]228500 [Speed]47.28ms/step [Loss]9.1215 [Metrics]{'train_loss:9.1215'}\n",
      "[Train Epoch]1/5 [Time]10827.99 [Step]14312 [Batch]229000 [Speed]47.28ms/step [Loss]9.1217 [Metrics]{'train_loss:9.1217'}\n",
      "[Train Epoch]1/5 [Time]10851.89 [Step]14343 [Batch]229500 [Speed]47.28ms/step [Loss]9.1217 [Metrics]{'train_loss:9.1217'}\n",
      "[Train Epoch]1/5 [Time]10875.90 [Step]14375 [Batch]230000 [Speed]47.29ms/step [Loss]9.1214 [Metrics]{'train_loss:9.1214'}\n",
      "[Train Epoch]1/5 [Time]10899.74 [Step]14406 [Batch]230500 [Speed]47.29ms/step [Loss]9.1214 [Metrics]{'train_loss:9.1214'}\n",
      "[Train Epoch]1/5 [Time]10922.78 [Step]14437 [Batch]231000 [Speed]47.28ms/step [Loss]9.1213 [Metrics]{'train_loss:9.1213'}\n",
      "[Train Epoch]1/5 [Time]10946.32 [Step]14468 [Batch]231500 [Speed]47.28ms/step [Loss]9.1210 [Metrics]{'train_loss:9.1210'}\n",
      "[Train Epoch]1/5 [Time]10969.67 [Step]14500 [Batch]232000 [Speed]47.28ms/step [Loss]9.1209 [Metrics]{'train_loss:9.1209'}\n",
      "[Train Epoch]1/5 [Time]10993.34 [Step]14531 [Batch]232500 [Speed]47.28ms/step [Loss]9.1207 [Metrics]{'train_loss:9.1207'}\n",
      "[Train Epoch]1/5 [Time]11017.14 [Step]14562 [Batch]233000 [Speed]47.28ms/step [Loss]9.1207 [Metrics]{'train_loss:9.1207'}\n",
      "[Train Epoch]1/5 [Time]11041.24 [Step]14593 [Batch]233500 [Speed]47.29ms/step [Loss]9.1206 [Metrics]{'train_loss:9.1206'}\n",
      "[Train Epoch]1/5 [Time]11065.05 [Step]14625 [Batch]234000 [Speed]47.29ms/step [Loss]9.1204 [Metrics]{'train_loss:9.1204'}\n",
      "[Train Epoch]1/5 [Time]11088.94 [Step]14656 [Batch]234500 [Speed]47.29ms/step [Loss]9.1204 [Metrics]{'train_loss:9.1204'}\n",
      "[Train Epoch]1/5 [Time]11112.13 [Step]14687 [Batch]235000 [Speed]47.29ms/step [Loss]9.1203 [Metrics]{'train_loss:9.1203'}\n",
      "[Train Epoch]1/5 [Time]11135.32 [Step]14718 [Batch]235500 [Speed]47.28ms/step [Loss]9.1203 [Metrics]{'train_loss:9.1203'}\n",
      "[Train Epoch]1/5 [Time]11158.52 [Step]14750 [Batch]236000 [Speed]47.28ms/step [Loss]9.1204 [Metrics]{'train_loss:9.1204'}\n",
      "[Train Epoch]1/5 [Time]11181.61 [Step]14781 [Batch]236500 [Speed]47.28ms/step [Loss]9.1203 [Metrics]{'train_loss:9.1203'}\n",
      "[Train Epoch]1/5 [Time]11204.74 [Step]14812 [Batch]237000 [Speed]47.28ms/step [Loss]9.1202 [Metrics]{'train_loss:9.1202'}\n",
      "[Train Epoch]1/5 [Time]11227.95 [Step]14843 [Batch]237500 [Speed]47.28ms/step [Loss]9.1202 [Metrics]{'train_loss:9.1202'}\n",
      "[Train Epoch]1/5 [Time]11252.83 [Step]14875 [Batch]238000 [Speed]47.28ms/step [Loss]9.1203 [Metrics]{'train_loss:9.1203'}\n",
      "[Train Epoch]1/5 [Time]11277.38 [Step]14906 [Batch]238500 [Speed]47.28ms/step [Loss]9.1202 [Metrics]{'train_loss:9.1202'}\n",
      "[Train Epoch]1/5 [Time]11301.25 [Step]14937 [Batch]239000 [Speed]47.29ms/step [Loss]9.1200 [Metrics]{'train_loss:9.1200'}\n",
      "[Train Epoch]1/5 [Time]11326.62 [Step]14968 [Batch]239500 [Speed]47.29ms/step [Loss]9.1199 [Metrics]{'train_loss:9.1199'}\n",
      "Saving checkpoint for epoch 1 at step 240000 on path ../2_Models/model_bert4rec_complete_0.5/checkpoints/\n",
      "[Train Epoch]1/5 [Time]11353.26 [Step]15000 [Batch]240000 [Speed]47.31ms/step [Loss]9.1198 [Metrics]{'train_loss:9.1198'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 108\u001b[0m\n\u001b[0;32m    106\u001b[0m inputs, target \u001b[39m=\u001b[39m batch_data\n\u001b[0;32m    107\u001b[0m step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39mtarget, loss\u001b[39m=\u001b[39mtrain_loss, num_accum_steps\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mnum_grad_accum_steps)\n\u001b[1;32m--> 108\u001b[0m global_gradients \u001b[39m=\u001b[39m backward_optimization(BERT4REC_CONFIG\u001b[39m.\u001b[39;49mnum_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    110\u001b[0m     train_dict_metrics \u001b[39m=\u001b[39m {x\u001b[39m.\u001b[39mname : x\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [train_loss]}\n",
      "Cell \u001b[1;32mIn [8], line 20\u001b[0m, in \u001b[0;36mbackward_optimization\u001b[1;34m(num_grad_steps, global_gradients, step_gradients, step, model, optimizer)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[39mfor\u001b[39;00m i, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(step_gradients):\n\u001b[1;32m---> 20\u001b[0m         global_gradients[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_gradients(g)\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m num_grad_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     22\u001b[0m     global_gradients \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(global_gradients, model\u001b[39m.\u001b[39mtrainable_variables)\n",
      "Cell \u001b[1;32mIn [8], line 8\u001b[0m, in \u001b[0;36mflat_gradients\u001b[1;34m(grads_or_idx_slices)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m'''Convert gradients if it's tf.IndexedSlices.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mWhen computing gradients for operation concerning `tf.gather`, the type of gradients \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(grads_or_idx_slices) \u001b[39m==\u001b[39m tf\u001b[39m.\u001b[39mIndexedSlices:\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mscatter_nd(\n\u001b[0;32m      9\u001b[0m         tf\u001b[39m.\u001b[39;49mexpand_dims(grads_or_idx_slices\u001b[39m.\u001b[39;49mindices, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m     10\u001b[0m         grads_or_idx_slices\u001b[39m.\u001b[39;49mvalues,\n\u001b[0;32m     11\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(grads_or_idx_slices\u001b[39m.\u001b[39;49mdense_shape, tf\u001b[39m.\u001b[39;49mint64)\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m grads_or_idx_slices\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:9154\u001b[0m, in \u001b[0;36mscatter_nd\u001b[1;34m(indices, updates, shape, name)\u001b[0m\n\u001b[0;32m   9152\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   9153\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 9154\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   9155\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mScatterNd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, indices, updates, shape)\n\u001b[0;32m   9156\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   9157\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.3/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.5/checkpoints/', 'ckpt-7')\n",
    "    model_name = 'model_bert4rec_complete_0.6'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 12_000_000\n",
    "    batch_size = 10\n",
    "    num_grad_accum_steps = 16\n",
    "    seq_len = 20\n",
    "    mask_prob = 0.4\n",
    "    reverse_prob = 0.25\n",
    "    emb_dim = 32\n",
    "    trf_dim = 32\n",
    "    num_heads = 2\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 5\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 200\n",
    "    clipnorm = 1\n",
    "    num_iters_save_checkpoint = 5_000 * num_grad_accum_steps\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    log_wandb = False\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}')\n",
    "\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.restore_last_chekpoint[1]}/', compile=False)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "                            warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "# optimizer = AdamW(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "#                     warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "#                     clipnorm=BERT4REC_CONFIG.clipnorm,\n",
    "#                     weight_decay=1e-4)                            \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = custom_loss_bert4rec()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "##############################################\n",
    "\n",
    "total_step, val_step = 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        step_gradients = train_step(inputs, target=target, loss=train_loss, num_accum_steps=BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "        global_gradients = backward_optimization(BERT4REC_CONFIG.num_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss]}\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step // BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='train', num_step=total_step // BERT4REC_CONFIG.num_grad_accum_steps, num_batch=total_step,\n",
    "                                  gradients=global_gradients, dict_metrics=train_dict_metrics) \n",
    "        \n",
    "        total_step += 1  \n",
    "\n",
    "        if total_step % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')        \n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            \n",
    "    for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "        inputs, target = val_batch_data\n",
    "        test_step(inputs, target=target, loss=val_loss)\n",
    "        val_step += 1\n",
    "        if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "            val_dict_metrics = {x.name : x.result() for x in [val_loss]}\n",
    "            fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "                # if val_batch_num==0:\n",
    "                #     log_wandb_metrics(step=None, plot_image=True, \n",
    "                #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m features \u001b[39m=\u001b[39m (seq_items, tf\u001b[39m.\u001b[39mstack(seq_type_new, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), seq_time)\n\u001b[0;32m     46\u001b[0m preds \u001b[39m=\u001b[39m model(features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 47\u001b[0m preds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mgather(preds, indices\u001b[39m=\u001b[39;49midxs, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_dims\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     48\u001b[0m topk_scores, topk_idxs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mtop_k(preds, k\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m     49\u001b[0m topk_idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray([[x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m topk_idxs\u001b[39m.\u001b[39mnumpy()[i, :]] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(topk_idxs\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])])\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5238\u001b[0m, in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, validate_indices, axis, batch_dims, name)\u001b[0m\n\u001b[0;32m   5230\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mgather\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   5231\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   5232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgather_v2\u001b[39m(params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5236\u001b[0m               batch_dims\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   5237\u001b[0m               name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 5238\u001b[0m   \u001b[39mreturn\u001b[39;00m gather(\n\u001b[0;32m   5239\u001b[0m       params,\n\u001b[0;32m   5240\u001b[0m       indices,\n\u001b[0;32m   5241\u001b[0m       validate_indices\u001b[39m=\u001b[39;49mvalidate_indices,\n\u001b[0;32m   5242\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   5243\u001b[0m       axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5244\u001b[0m       batch_dims\u001b[39m=\u001b[39;49mbatch_dims)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:548\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    541\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    542\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    543\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[0;32m    547\u001b[0m           instructions)\n\u001b[1;32m--> 548\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5220\u001b[0m, in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   5218\u001b[0m   axis \u001b[39m=\u001b[39m batch_dims\n\u001b[0;32m   5219\u001b[0m \u001b[39mif\u001b[39;00m tensor_util\u001b[39m.\u001b[39mconstant_value(axis) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 5220\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mgather_v2(\n\u001b[0;32m   5221\u001b[0m       params, indices, axis, batch_dims\u001b[39m=\u001b[39;49mbatch_dims, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   5222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   5223\u001b[0m   \u001b[39m# TODO(apassos) find a less bad way of detecting resource variables\u001b[39;00m\n\u001b[0;32m   5224\u001b[0m   \u001b[39m# without introducing a circular dependency.\u001b[39;00m\n\u001b[0;32m   5225\u001b[0m   \u001b[39mreturn\u001b[39;00m params\u001b[39m.\u001b[39msparse_read(indices, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3934\u001b[0m, in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, axis, batch_dims, name)\u001b[0m\n\u001b[0;32m   3932\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3933\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3934\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3935\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mGatherV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, params, indices, axis, \u001b[39m\"\u001b[39;49m\u001b[39mbatch_dims\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   3936\u001b[0m       batch_dims)\n\u001b[0;32m   3937\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3938\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0\n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.5/checkpoints'))\n",
    "# model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.4_finetuned/', compile=False)\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.3/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=16, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_predictions, list_trues, list_types = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    target, type_target = targets\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "    if num_batch==2_000:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# v0.4_finetuned seqlen=10\n",
    "# {'carts': 0.23272587826464677,\n",
    "#  'clicks': 0.16818629058707774,\n",
    "#  'orders': 0.31957377011651095}\n",
    "# Kaggle Metric: 0.2783808\n",
    "\n",
    "# model_bert4rec_complete_0.4.1 - ckpt42\n",
    "# mean = 0.202564\n",
    "# {'carts': 0.2417327288193879,\n",
    "#  'clicks': 0.18081338143653658,\n",
    "#  'orders': 0.33429939670611314}\n",
    "# Kaggle Metric: 0.2912\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.5 - ckpt10\n",
    "# {'carts': 0.2597342763878702,\n",
    "#  'clicks': 0.18694624926166567,\n",
    "#  'orders': 0.3624662713766583}\n",
    "# Kaggle Metric: 0.3141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.current_loss_scale\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.good_steps\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18995it [37:50,  8.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m type_ \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mclicks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcarts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morders\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m---> 26\u001b[0m     seq_type_new \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mconcat([\n\u001b[0;32m     27\u001b[0m                     seq_type[i, :ix],\n\u001b[0;32m     28\u001b[0m                     tf\u001b[39m.\u001b[39mconstant([[dict_map_type[type_]]], tf\u001b[39m.\u001b[39mint64),\n\u001b[0;32m     29\u001b[0m                     seq_type[i, ix\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m                 \u001b[39mfor\u001b[39;00m i, ix \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idxs)]\n\u001b[0;32m     31\u001b[0m     features \u001b[39m=\u001b[39m (seq_items, tf\u001b[39m.\u001b[39mstack(seq_type_new, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), seq_time)\n\u001b[0;32m     32\u001b[0m     preds \u001b[39m=\u001b[39m model(features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [11], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m type_ \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mclicks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcarts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morders\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     26\u001b[0m     seq_type_new \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mconcat([\n\u001b[1;32m---> 27\u001b[0m                     seq_type[i, :ix],\n\u001b[0;32m     28\u001b[0m                     tf\u001b[39m.\u001b[39mconstant([[dict_map_type[type_]]], tf\u001b[39m.\u001b[39mint64),\n\u001b[0;32m     29\u001b[0m                     seq_type[i, ix\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m                 \u001b[39mfor\u001b[39;00m i, ix \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idxs)]\n\u001b[0;32m     31\u001b[0m     features \u001b[39m=\u001b[39m (seq_items, tf\u001b[39m.\u001b[39mstack(seq_type_new, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), seq_time)\n\u001b[0;32m     32\u001b[0m     preds \u001b[39m=\u001b[39m model(features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1038\u001b[0m, in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\n\u001b[0;32m   1034\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1035\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstrided_slice\u001b[39m\u001b[39m\"\u001b[39m, [tensor] \u001b[39m+\u001b[39m begin \u001b[39m+\u001b[39m end \u001b[39m+\u001b[39m strides,\n\u001b[0;32m   1036\u001b[0m     skip_on_eager\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m name:\n\u001b[0;32m   1037\u001b[0m   \u001b[39mif\u001b[39;00m begin:\n\u001b[1;32m-> 1038\u001b[0m     packed_begin, packed_end, packed_strides \u001b[39m=\u001b[39m (stack(begin), stack(end),\n\u001b[0;32m   1039\u001b[0m                                                 stack(strides))\n\u001b[0;32m   1040\u001b[0m     \u001b[39mif\u001b[39;00m (packed_begin\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64 \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m         packed_end\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64 \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m         packed_strides\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64):\n\u001b[0;32m   1043\u001b[0m       \u001b[39mif\u001b[39;00m packed_begin\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtypes\u001b[39m.\u001b[39mint64:\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1424\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1422\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1423\u001b[0m     \u001b[39m# If the input is a constant list, it can be converted to a constant op\u001b[39;00m\n\u001b[1;32m-> 1424\u001b[0m     \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(values, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1425\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1426\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Input list contains non-constant tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1691\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1692\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   1694\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1695\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1697\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1698\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    342\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.5/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.3/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=16, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, target, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 52244it [2:47:45,  5.19it/s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c4b929e2472036a63dc2b4145b104daea13432f82a7dbc65e279332da4f8b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
