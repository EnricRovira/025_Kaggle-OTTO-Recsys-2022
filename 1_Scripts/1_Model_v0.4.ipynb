{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.3_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 3398540.27it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "SEED = 12\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.3/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False, drop_remainder=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "        self.drop_remainder = drop_remainder\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*50, reshuffle_each_iteration=True)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=self.drop_remainder).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_time_encoding, seq_time_encoding_target = seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding), (seq_items_target_all[:, 0], seq_type_target_all[:, 0]), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "\n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items)), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items))\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_target[:, 0]\n",
    "  \n",
    "  \n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 10, 1]), TensorShape([32, 10, 1]), TensorShape([32, 10, 8])]\n",
      "[ 863885       0       0  987942 1078084  432286       0       0       0\n",
      "       0]\n",
      "[1 1 1 1 1 1 0 0 0 0]\n",
      "[      0 1166894  591718       0       0       0       0       0       0\n",
      "       0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.3/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=train')]\n",
    "\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=10, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.4, \n",
    "                                     reverse_prob=0.2, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# # Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    break\n",
    "\n",
    "# # # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     target, type_target = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 15\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            # embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(3+1, model_cfg.emb_dim)\n",
    "        self.mlp_proj_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_encoding(x_seq_encoding, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_time_encoding + x_seq_past_type)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        ones = tf.ones(tf.shape(y_true))\n",
    "        y_pred = y_pred\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "def recall_top_k(top_k=1):\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_true)[0]\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.float32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.float32)\n",
    "        cum_sum = tf.zeros(n_samples)\n",
    "        for i in tf.range(top_k):\n",
    "            indexes_i = top_index[:, :, i]\n",
    "            is_true = tf.reduce_sum(tf.cast(tf.equal(y_true, indexes_i), tf.float32), axis=-1)/tf.reduce_sum(mask, -1)\n",
    "            cum_sum += (is_true/tf.cast(i+1, tf.float32))\n",
    "        return tf.reduce_mean(cum_sum)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "# plt.plot(tmp_lr(tf.range(12_000_000 // (32 * 4), dtype=tf.float32)))\n",
    "plt.plot(tmp_lr(tf.range(12_000_000 // (8 * 20), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g)\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        global_gradients = zip(global_gradients, model.trainable_variables)\n",
    "        optimizer.apply_gradients(global_gradients)\n",
    "        global_gradients = []\n",
    "    return global_gradients\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    num_accum_steps = tf.cast(kwargs['num_accum_steps'], tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss / num_accum_steps)\n",
    "\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    # gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions)\n",
    "    l_loss(loss)\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.4f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n",
      "Latest checkpoint restored!!\n",
      "================================================================================\n",
      "Epoch 1\n",
      "[Train Epoch]1/5 [Time]23.17 [Step]0 [Batch]0 [Speed]23172.08ms/step [Loss]9.5402 [Metrics]{'train_loss:9.5402'}\n",
      "[Train Epoch]1/5 [Time]47.68 [Step]31 [Batch]500 [Speed]95.36ms/step [Loss]9.6126 [Metrics]{'train_loss:9.6126'}\n",
      "[Train Epoch]1/5 [Time]71.59 [Step]62 [Batch]1000 [Speed]71.59ms/step [Loss]9.6323 [Metrics]{'train_loss:9.6323'}\n",
      "[Train Epoch]1/5 [Time]95.48 [Step]93 [Batch]1500 [Speed]63.65ms/step [Loss]9.6421 [Metrics]{'train_loss:9.6421'}\n",
      "[Train Epoch]1/5 [Time]117.80 [Step]125 [Batch]2000 [Speed]58.90ms/step [Loss]9.6672 [Metrics]{'train_loss:9.6672'}\n",
      "[Train Epoch]1/5 [Time]140.74 [Step]156 [Batch]2500 [Speed]56.29ms/step [Loss]9.6731 [Metrics]{'train_loss:9.6731'}\n",
      "[Train Epoch]1/5 [Time]163.53 [Step]187 [Batch]3000 [Speed]54.51ms/step [Loss]9.6717 [Metrics]{'train_loss:9.6717'}\n",
      "[Train Epoch]1/5 [Time]186.17 [Step]218 [Batch]3500 [Speed]53.19ms/step [Loss]9.6597 [Metrics]{'train_loss:9.6597'}\n",
      "[Train Epoch]1/5 [Time]208.90 [Step]250 [Batch]4000 [Speed]52.22ms/step [Loss]9.6564 [Metrics]{'train_loss:9.6564'}\n",
      "[Train Epoch]1/5 [Time]232.40 [Step]281 [Batch]4500 [Speed]51.64ms/step [Loss]9.6552 [Metrics]{'train_loss:9.6552'}\n",
      "[Train Epoch]1/5 [Time]256.01 [Step]312 [Batch]5000 [Speed]51.20ms/step [Loss]9.6488 [Metrics]{'train_loss:9.6488'}\n",
      "[Train Epoch]1/5 [Time]279.40 [Step]343 [Batch]5500 [Speed]50.80ms/step [Loss]9.6534 [Metrics]{'train_loss:9.6534'}\n",
      "[Train Epoch]1/5 [Time]301.76 [Step]375 [Batch]6000 [Speed]50.29ms/step [Loss]9.6509 [Metrics]{'train_loss:9.6509'}\n",
      "[Train Epoch]1/5 [Time]324.12 [Step]406 [Batch]6500 [Speed]49.86ms/step [Loss]9.6470 [Metrics]{'train_loss:9.6470'}\n",
      "[Train Epoch]1/5 [Time]346.50 [Step]437 [Batch]7000 [Speed]49.50ms/step [Loss]9.6485 [Metrics]{'train_loss:9.6485'}\n",
      "[Train Epoch]1/5 [Time]369.91 [Step]468 [Batch]7500 [Speed]49.32ms/step [Loss]9.6496 [Metrics]{'train_loss:9.6496'}\n",
      "[Train Epoch]1/5 [Time]392.99 [Step]500 [Batch]8000 [Speed]49.12ms/step [Loss]9.6471 [Metrics]{'train_loss:9.6471'}\n",
      "[Train Epoch]1/5 [Time]416.44 [Step]531 [Batch]8500 [Speed]48.99ms/step [Loss]9.6481 [Metrics]{'train_loss:9.6481'}\n",
      "[Train Epoch]1/5 [Time]439.97 [Step]562 [Batch]9000 [Speed]48.89ms/step [Loss]9.6456 [Metrics]{'train_loss:9.6456'}\n",
      "[Train Epoch]1/5 [Time]463.11 [Step]593 [Batch]9500 [Speed]48.75ms/step [Loss]9.6434 [Metrics]{'train_loss:9.6434'}\n",
      "[Train Epoch]1/5 [Time]486.36 [Step]625 [Batch]10000 [Speed]48.64ms/step [Loss]9.6443 [Metrics]{'train_loss:9.6443'}\n",
      "[Train Epoch]1/5 [Time]509.34 [Step]656 [Batch]10500 [Speed]48.51ms/step [Loss]9.6430 [Metrics]{'train_loss:9.6430'}\n",
      "[Train Epoch]1/5 [Time]532.34 [Step]687 [Batch]11000 [Speed]48.39ms/step [Loss]9.6377 [Metrics]{'train_loss:9.6377'}\n",
      "[Train Epoch]1/5 [Time]555.15 [Step]718 [Batch]11500 [Speed]48.27ms/step [Loss]9.6338 [Metrics]{'train_loss:9.6338'}\n",
      "[Train Epoch]1/5 [Time]578.08 [Step]750 [Batch]12000 [Speed]48.17ms/step [Loss]9.6332 [Metrics]{'train_loss:9.6332'}\n",
      "[Train Epoch]1/5 [Time]601.27 [Step]781 [Batch]12500 [Speed]48.10ms/step [Loss]9.6318 [Metrics]{'train_loss:9.6318'}\n",
      "[Train Epoch]1/5 [Time]624.63 [Step]812 [Batch]13000 [Speed]48.05ms/step [Loss]9.6289 [Metrics]{'train_loss:9.6289'}\n",
      "[Train Epoch]1/5 [Time]647.59 [Step]843 [Batch]13500 [Speed]47.97ms/step [Loss]9.6272 [Metrics]{'train_loss:9.6272'}\n",
      "[Train Epoch]1/5 [Time]670.15 [Step]875 [Batch]14000 [Speed]47.87ms/step [Loss]9.6292 [Metrics]{'train_loss:9.6292'}\n",
      "[Train Epoch]1/5 [Time]693.10 [Step]906 [Batch]14500 [Speed]47.80ms/step [Loss]9.6301 [Metrics]{'train_loss:9.6301'}\n",
      "[Train Epoch]1/5 [Time]715.46 [Step]937 [Batch]15000 [Speed]47.70ms/step [Loss]9.6289 [Metrics]{'train_loss:9.6289'}\n",
      "[Train Epoch]1/5 [Time]737.76 [Step]968 [Batch]15500 [Speed]47.60ms/step [Loss]9.6275 [Metrics]{'train_loss:9.6275'}\n",
      "[Train Epoch]1/5 [Time]760.11 [Step]1000 [Batch]16000 [Speed]47.51ms/step [Loss]9.6286 [Metrics]{'train_loss:9.6286'}\n",
      "[Train Epoch]1/5 [Time]783.05 [Step]1031 [Batch]16500 [Speed]47.46ms/step [Loss]9.6277 [Metrics]{'train_loss:9.6277'}\n",
      "[Train Epoch]1/5 [Time]805.99 [Step]1062 [Batch]17000 [Speed]47.41ms/step [Loss]9.6269 [Metrics]{'train_loss:9.6269'}\n",
      "[Train Epoch]1/5 [Time]828.89 [Step]1093 [Batch]17500 [Speed]47.37ms/step [Loss]9.6265 [Metrics]{'train_loss:9.6265'}\n",
      "[Train Epoch]1/5 [Time]852.28 [Step]1125 [Batch]18000 [Speed]47.35ms/step [Loss]9.6262 [Metrics]{'train_loss:9.6262'}\n",
      "[Train Epoch]1/5 [Time]875.11 [Step]1156 [Batch]18500 [Speed]47.30ms/step [Loss]9.6234 [Metrics]{'train_loss:9.6234'}\n",
      "[Train Epoch]1/5 [Time]898.01 [Step]1187 [Batch]19000 [Speed]47.26ms/step [Loss]9.6245 [Metrics]{'train_loss:9.6245'}\n",
      "[Train Epoch]1/5 [Time]920.97 [Step]1218 [Batch]19500 [Speed]47.23ms/step [Loss]9.6226 [Metrics]{'train_loss:9.6226'}\n",
      "[Train Epoch]1/5 [Time]943.90 [Step]1250 [Batch]20000 [Speed]47.20ms/step [Loss]9.6209 [Metrics]{'train_loss:9.6209'}\n",
      "[Train Epoch]1/5 [Time]966.94 [Step]1281 [Batch]20500 [Speed]47.17ms/step [Loss]9.6206 [Metrics]{'train_loss:9.6206'}\n",
      "[Train Epoch]1/5 [Time]989.69 [Step]1312 [Batch]21000 [Speed]47.13ms/step [Loss]9.6206 [Metrics]{'train_loss:9.6206'}\n",
      "[Train Epoch]1/5 [Time]1012.60 [Step]1343 [Batch]21500 [Speed]47.10ms/step [Loss]9.6205 [Metrics]{'train_loss:9.6205'}\n",
      "[Train Epoch]1/5 [Time]1035.96 [Step]1375 [Batch]22000 [Speed]47.09ms/step [Loss]9.6206 [Metrics]{'train_loss:9.6206'}\n",
      "[Train Epoch]1/5 [Time]1058.91 [Step]1406 [Batch]22500 [Speed]47.06ms/step [Loss]9.6192 [Metrics]{'train_loss:9.6192'}\n",
      "[Train Epoch]1/5 [Time]1081.69 [Step]1437 [Batch]23000 [Speed]47.03ms/step [Loss]9.6199 [Metrics]{'train_loss:9.6199'}\n",
      "[Train Epoch]1/5 [Time]1104.78 [Step]1468 [Batch]23500 [Speed]47.01ms/step [Loss]9.6199 [Metrics]{'train_loss:9.6199'}\n",
      "[Train Epoch]1/5 [Time]1127.79 [Step]1500 [Batch]24000 [Speed]46.99ms/step [Loss]9.6191 [Metrics]{'train_loss:9.6191'}\n",
      "[Train Epoch]1/5 [Time]1150.64 [Step]1531 [Batch]24500 [Speed]46.96ms/step [Loss]9.6201 [Metrics]{'train_loss:9.6201'}\n",
      "[Train Epoch]1/5 [Time]1173.70 [Step]1562 [Batch]25000 [Speed]46.95ms/step [Loss]9.6200 [Metrics]{'train_loss:9.6200'}\n",
      "[Train Epoch]1/5 [Time]1196.74 [Step]1593 [Batch]25500 [Speed]46.93ms/step [Loss]9.6196 [Metrics]{'train_loss:9.6196'}\n",
      "[Train Epoch]1/5 [Time]1219.78 [Step]1625 [Batch]26000 [Speed]46.91ms/step [Loss]9.6185 [Metrics]{'train_loss:9.6185'}\n",
      "[Train Epoch]1/5 [Time]1242.74 [Step]1656 [Batch]26500 [Speed]46.90ms/step [Loss]9.6192 [Metrics]{'train_loss:9.6192'}\n",
      "[Train Epoch]1/5 [Time]1265.57 [Step]1687 [Batch]27000 [Speed]46.87ms/step [Loss]9.6190 [Metrics]{'train_loss:9.6190'}\n",
      "[Train Epoch]1/5 [Time]1288.51 [Step]1718 [Batch]27500 [Speed]46.85ms/step [Loss]9.6185 [Metrics]{'train_loss:9.6185'}\n",
      "[Train Epoch]1/5 [Time]1311.58 [Step]1750 [Batch]28000 [Speed]46.84ms/step [Loss]9.6171 [Metrics]{'train_loss:9.6171'}\n",
      "[Train Epoch]1/5 [Time]1334.50 [Step]1781 [Batch]28500 [Speed]46.82ms/step [Loss]9.6163 [Metrics]{'train_loss:9.6163'}\n",
      "[Train Epoch]1/5 [Time]1357.46 [Step]1812 [Batch]29000 [Speed]46.81ms/step [Loss]9.6168 [Metrics]{'train_loss:9.6168'}\n",
      "[Train Epoch]1/5 [Time]1380.79 [Step]1843 [Batch]29500 [Speed]46.81ms/step [Loss]9.6169 [Metrics]{'train_loss:9.6169'}\n",
      "[Train Epoch]1/5 [Time]1404.50 [Step]1875 [Batch]30000 [Speed]46.82ms/step [Loss]9.6168 [Metrics]{'train_loss:9.6168'}\n",
      "[Train Epoch]1/5 [Time]1428.02 [Step]1906 [Batch]30500 [Speed]46.82ms/step [Loss]9.6156 [Metrics]{'train_loss:9.6156'}\n",
      "[Train Epoch]1/5 [Time]1451.88 [Step]1937 [Batch]31000 [Speed]46.83ms/step [Loss]9.6134 [Metrics]{'train_loss:9.6134'}\n",
      "[Train Epoch]1/5 [Time]1475.65 [Step]1968 [Batch]31500 [Speed]46.85ms/step [Loss]9.6134 [Metrics]{'train_loss:9.6134'}\n",
      "[Train Epoch]1/5 [Time]1499.32 [Step]2000 [Batch]32000 [Speed]46.85ms/step [Loss]9.6123 [Metrics]{'train_loss:9.6123'}\n",
      "[Train Epoch]1/5 [Time]1522.87 [Step]2031 [Batch]32500 [Speed]46.86ms/step [Loss]9.6118 [Metrics]{'train_loss:9.6118'}\n",
      "[Train Epoch]1/5 [Time]1546.44 [Step]2062 [Batch]33000 [Speed]46.86ms/step [Loss]9.6113 [Metrics]{'train_loss:9.6113'}\n",
      "[Train Epoch]1/5 [Time]1569.96 [Step]2093 [Batch]33500 [Speed]46.86ms/step [Loss]9.6111 [Metrics]{'train_loss:9.6111'}\n",
      "[Train Epoch]1/5 [Time]1593.60 [Step]2125 [Batch]34000 [Speed]46.87ms/step [Loss]9.6112 [Metrics]{'train_loss:9.6112'}\n",
      "[Train Epoch]1/5 [Time]1617.03 [Step]2156 [Batch]34500 [Speed]46.87ms/step [Loss]9.6101 [Metrics]{'train_loss:9.6101'}\n",
      "[Train Epoch]1/5 [Time]1640.59 [Step]2187 [Batch]35000 [Speed]46.87ms/step [Loss]9.6085 [Metrics]{'train_loss:9.6085'}\n",
      "[Train Epoch]1/5 [Time]1664.24 [Step]2218 [Batch]35500 [Speed]46.88ms/step [Loss]9.6080 [Metrics]{'train_loss:9.6080'}\n",
      "[Train Epoch]1/5 [Time]1687.80 [Step]2250 [Batch]36000 [Speed]46.88ms/step [Loss]9.6076 [Metrics]{'train_loss:9.6076'}\n",
      "[Train Epoch]1/5 [Time]1711.34 [Step]2281 [Batch]36500 [Speed]46.89ms/step [Loss]9.6077 [Metrics]{'train_loss:9.6077'}\n",
      "[Train Epoch]1/5 [Time]1734.95 [Step]2312 [Batch]37000 [Speed]46.89ms/step [Loss]9.6070 [Metrics]{'train_loss:9.6070'}\n",
      "[Train Epoch]1/5 [Time]1758.82 [Step]2343 [Batch]37500 [Speed]46.90ms/step [Loss]9.6066 [Metrics]{'train_loss:9.6066'}\n",
      "[Train Epoch]1/5 [Time]1781.87 [Step]2375 [Batch]38000 [Speed]46.89ms/step [Loss]9.6062 [Metrics]{'train_loss:9.6062'}\n",
      "[Train Epoch]1/5 [Time]1804.74 [Step]2406 [Batch]38500 [Speed]46.88ms/step [Loss]9.6061 [Metrics]{'train_loss:9.6061'}\n",
      "[Train Epoch]1/5 [Time]1827.51 [Step]2437 [Batch]39000 [Speed]46.86ms/step [Loss]9.6054 [Metrics]{'train_loss:9.6054'}\n",
      "[Train Epoch]1/5 [Time]1850.59 [Step]2468 [Batch]39500 [Speed]46.85ms/step [Loss]9.6044 [Metrics]{'train_loss:9.6044'}\n",
      "[Train Epoch]1/5 [Time]1874.84 [Step]2500 [Batch]40000 [Speed]46.87ms/step [Loss]9.6043 [Metrics]{'train_loss:9.6043'}\n",
      "[Train Epoch]1/5 [Time]1899.30 [Step]2531 [Batch]40500 [Speed]46.90ms/step [Loss]9.6032 [Metrics]{'train_loss:9.6032'}\n",
      "[Train Epoch]1/5 [Time]1923.62 [Step]2562 [Batch]41000 [Speed]46.92ms/step [Loss]9.6031 [Metrics]{'train_loss:9.6031'}\n",
      "[Train Epoch]1/5 [Time]1948.10 [Step]2593 [Batch]41500 [Speed]46.94ms/step [Loss]9.6032 [Metrics]{'train_loss:9.6032'}\n",
      "[Train Epoch]1/5 [Time]1972.54 [Step]2625 [Batch]42000 [Speed]46.97ms/step [Loss]9.6037 [Metrics]{'train_loss:9.6037'}\n",
      "[Train Epoch]1/5 [Time]1996.13 [Step]2656 [Batch]42500 [Speed]46.97ms/step [Loss]9.6021 [Metrics]{'train_loss:9.6021'}\n",
      "[Train Epoch]1/5 [Time]2020.00 [Step]2687 [Batch]43000 [Speed]46.98ms/step [Loss]9.6017 [Metrics]{'train_loss:9.6017'}\n",
      "[Train Epoch]1/5 [Time]2043.28 [Step]2718 [Batch]43500 [Speed]46.97ms/step [Loss]9.6003 [Metrics]{'train_loss:9.6003'}\n",
      "[Train Epoch]1/5 [Time]2066.24 [Step]2750 [Batch]44000 [Speed]46.96ms/step [Loss]9.6005 [Metrics]{'train_loss:9.6005'}\n",
      "[Train Epoch]1/5 [Time]2089.23 [Step]2781 [Batch]44500 [Speed]46.95ms/step [Loss]9.6001 [Metrics]{'train_loss:9.6001'}\n",
      "[Train Epoch]1/5 [Time]2112.43 [Step]2812 [Batch]45000 [Speed]46.94ms/step [Loss]9.5985 [Metrics]{'train_loss:9.5985'}\n",
      "[Train Epoch]1/5 [Time]2135.98 [Step]2843 [Batch]45500 [Speed]46.94ms/step [Loss]9.5975 [Metrics]{'train_loss:9.5975'}\n",
      "[Train Epoch]1/5 [Time]2159.55 [Step]2875 [Batch]46000 [Speed]46.95ms/step [Loss]9.5969 [Metrics]{'train_loss:9.5969'}\n",
      "[Train Epoch]1/5 [Time]2182.58 [Step]2906 [Batch]46500 [Speed]46.94ms/step [Loss]9.5962 [Metrics]{'train_loss:9.5962'}\n",
      "[Train Epoch]1/5 [Time]2205.65 [Step]2937 [Batch]47000 [Speed]46.93ms/step [Loss]9.5957 [Metrics]{'train_loss:9.5957'}\n",
      "[Train Epoch]1/5 [Time]2228.63 [Step]2968 [Batch]47500 [Speed]46.92ms/step [Loss]9.5948 [Metrics]{'train_loss:9.5948'}\n",
      "[Train Epoch]1/5 [Time]2251.64 [Step]3000 [Batch]48000 [Speed]46.91ms/step [Loss]9.5941 [Metrics]{'train_loss:9.5941'}\n",
      "[Train Epoch]1/5 [Time]2274.53 [Step]3031 [Batch]48500 [Speed]46.90ms/step [Loss]9.5945 [Metrics]{'train_loss:9.5945'}\n",
      "[Train Epoch]1/5 [Time]2297.95 [Step]3062 [Batch]49000 [Speed]46.90ms/step [Loss]9.5942 [Metrics]{'train_loss:9.5942'}\n",
      "[Train Epoch]1/5 [Time]2321.27 [Step]3093 [Batch]49500 [Speed]46.89ms/step [Loss]9.5935 [Metrics]{'train_loss:9.5935'}\n",
      "[Train Epoch]1/5 [Time]2344.76 [Step]3125 [Batch]50000 [Speed]46.90ms/step [Loss]9.5937 [Metrics]{'train_loss:9.5937'}\n",
      "[Train Epoch]1/5 [Time]2367.63 [Step]3156 [Batch]50500 [Speed]46.88ms/step [Loss]9.5932 [Metrics]{'train_loss:9.5932'}\n",
      "[Train Epoch]1/5 [Time]2390.73 [Step]3187 [Batch]51000 [Speed]46.88ms/step [Loss]9.5928 [Metrics]{'train_loss:9.5928'}\n",
      "[Train Epoch]1/5 [Time]2414.12 [Step]3218 [Batch]51500 [Speed]46.88ms/step [Loss]9.5922 [Metrics]{'train_loss:9.5922'}\n",
      "[Train Epoch]1/5 [Time]2437.27 [Step]3250 [Batch]52000 [Speed]46.87ms/step [Loss]9.5922 [Metrics]{'train_loss:9.5922'}\n",
      "[Train Epoch]1/5 [Time]2460.29 [Step]3281 [Batch]52500 [Speed]46.86ms/step [Loss]9.5925 [Metrics]{'train_loss:9.5925'}\n",
      "[Train Epoch]1/5 [Time]2483.24 [Step]3312 [Batch]53000 [Speed]46.85ms/step [Loss]9.5917 [Metrics]{'train_loss:9.5917'}\n",
      "[Train Epoch]1/5 [Time]2506.24 [Step]3343 [Batch]53500 [Speed]46.85ms/step [Loss]9.5905 [Metrics]{'train_loss:9.5905'}\n",
      "[Train Epoch]1/5 [Time]2529.20 [Step]3375 [Batch]54000 [Speed]46.84ms/step [Loss]9.5906 [Metrics]{'train_loss:9.5906'}\n",
      "[Train Epoch]1/5 [Time]2552.04 [Step]3406 [Batch]54500 [Speed]46.83ms/step [Loss]9.5904 [Metrics]{'train_loss:9.5904'}\n",
      "[Train Epoch]1/5 [Time]2575.39 [Step]3437 [Batch]55000 [Speed]46.83ms/step [Loss]9.5895 [Metrics]{'train_loss:9.5895'}\n",
      "[Train Epoch]1/5 [Time]2598.39 [Step]3468 [Batch]55500 [Speed]46.82ms/step [Loss]9.5897 [Metrics]{'train_loss:9.5897'}\n",
      "[Train Epoch]1/5 [Time]2621.34 [Step]3500 [Batch]56000 [Speed]46.81ms/step [Loss]9.5896 [Metrics]{'train_loss:9.5896'}\n",
      "[Train Epoch]1/5 [Time]2644.46 [Step]3531 [Batch]56500 [Speed]46.80ms/step [Loss]9.5889 [Metrics]{'train_loss:9.5889'}\n",
      "[Train Epoch]1/5 [Time]2667.50 [Step]3562 [Batch]57000 [Speed]46.80ms/step [Loss]9.5875 [Metrics]{'train_loss:9.5875'}\n",
      "[Train Epoch]1/5 [Time]2690.66 [Step]3593 [Batch]57500 [Speed]46.79ms/step [Loss]9.5867 [Metrics]{'train_loss:9.5867'}\n",
      "[Train Epoch]1/5 [Time]2713.53 [Step]3625 [Batch]58000 [Speed]46.78ms/step [Loss]9.5865 [Metrics]{'train_loss:9.5865'}\n",
      "[Train Epoch]1/5 [Time]2736.35 [Step]3656 [Batch]58500 [Speed]46.78ms/step [Loss]9.5863 [Metrics]{'train_loss:9.5863'}\n",
      "[Train Epoch]1/5 [Time]2759.34 [Step]3687 [Batch]59000 [Speed]46.77ms/step [Loss]9.5862 [Metrics]{'train_loss:9.5862'}\n",
      "[Train Epoch]1/5 [Time]2783.04 [Step]3718 [Batch]59500 [Speed]46.77ms/step [Loss]9.5857 [Metrics]{'train_loss:9.5857'}\n",
      "[Train Epoch]1/5 [Time]2806.88 [Step]3750 [Batch]60000 [Speed]46.78ms/step [Loss]9.5851 [Metrics]{'train_loss:9.5851'}\n",
      "[Train Epoch]1/5 [Time]2830.43 [Step]3781 [Batch]60500 [Speed]46.78ms/step [Loss]9.5849 [Metrics]{'train_loss:9.5849'}\n",
      "[Train Epoch]1/5 [Time]2853.92 [Step]3812 [Batch]61000 [Speed]46.79ms/step [Loss]9.5842 [Metrics]{'train_loss:9.5842'}\n",
      "[Train Epoch]1/5 [Time]2877.56 [Step]3843 [Batch]61500 [Speed]46.79ms/step [Loss]9.5840 [Metrics]{'train_loss:9.5840'}\n",
      "[Train Epoch]1/5 [Time]2901.21 [Step]3875 [Batch]62000 [Speed]46.79ms/step [Loss]9.5830 [Metrics]{'train_loss:9.5830'}\n",
      "[Train Epoch]1/5 [Time]2924.82 [Step]3906 [Batch]62500 [Speed]46.80ms/step [Loss]9.5827 [Metrics]{'train_loss:9.5827'}\n",
      "[Train Epoch]1/5 [Time]2948.58 [Step]3937 [Batch]63000 [Speed]46.80ms/step [Loss]9.5820 [Metrics]{'train_loss:9.5820'}\n",
      "[Train Epoch]1/5 [Time]2971.84 [Step]3968 [Batch]63500 [Speed]46.80ms/step [Loss]9.5816 [Metrics]{'train_loss:9.5816'}\n",
      "[Train Epoch]1/5 [Time]2995.26 [Step]4000 [Batch]64000 [Speed]46.80ms/step [Loss]9.5814 [Metrics]{'train_loss:9.5814'}\n",
      "[Train Epoch]1/5 [Time]3018.70 [Step]4031 [Batch]64500 [Speed]46.80ms/step [Loss]9.5812 [Metrics]{'train_loss:9.5812'}\n",
      "[Train Epoch]1/5 [Time]3042.24 [Step]4062 [Batch]65000 [Speed]46.80ms/step [Loss]9.5804 [Metrics]{'train_loss:9.5804'}\n",
      "[Train Epoch]1/5 [Time]3065.71 [Step]4093 [Batch]65500 [Speed]46.80ms/step [Loss]9.5797 [Metrics]{'train_loss:9.5797'}\n",
      "[Train Epoch]1/5 [Time]3089.35 [Step]4125 [Batch]66000 [Speed]46.81ms/step [Loss]9.5801 [Metrics]{'train_loss:9.5801'}\n",
      "[Train Epoch]1/5 [Time]3112.04 [Step]4156 [Batch]66500 [Speed]46.80ms/step [Loss]9.5795 [Metrics]{'train_loss:9.5795'}\n",
      "[Train Epoch]1/5 [Time]3134.99 [Step]4187 [Batch]67000 [Speed]46.79ms/step [Loss]9.5788 [Metrics]{'train_loss:9.5788'}\n",
      "[Train Epoch]1/5 [Time]3157.65 [Step]4218 [Batch]67500 [Speed]46.78ms/step [Loss]9.5782 [Metrics]{'train_loss:9.5782'}\n",
      "[Train Epoch]1/5 [Time]3179.94 [Step]4250 [Batch]68000 [Speed]46.76ms/step [Loss]9.5783 [Metrics]{'train_loss:9.5783'}\n",
      "[Train Epoch]1/5 [Time]3202.23 [Step]4281 [Batch]68500 [Speed]46.75ms/step [Loss]9.5781 [Metrics]{'train_loss:9.5781'}\n",
      "[Train Epoch]1/5 [Time]3224.57 [Step]4312 [Batch]69000 [Speed]46.73ms/step [Loss]9.5775 [Metrics]{'train_loss:9.5775'}\n",
      "[Train Epoch]1/5 [Time]3247.07 [Step]4343 [Batch]69500 [Speed]46.72ms/step [Loss]9.5773 [Metrics]{'train_loss:9.5773'}\n",
      "[Train Epoch]1/5 [Time]3269.70 [Step]4375 [Batch]70000 [Speed]46.71ms/step [Loss]9.5763 [Metrics]{'train_loss:9.5763'}\n",
      "[Train Epoch]1/5 [Time]3293.37 [Step]4406 [Batch]70500 [Speed]46.71ms/step [Loss]9.5761 [Metrics]{'train_loss:9.5761'}\n",
      "[Train Epoch]1/5 [Time]3316.96 [Step]4437 [Batch]71000 [Speed]46.72ms/step [Loss]9.5755 [Metrics]{'train_loss:9.5755'}\n",
      "[Train Epoch]1/5 [Time]3339.64 [Step]4468 [Batch]71500 [Speed]46.71ms/step [Loss]9.5751 [Metrics]{'train_loss:9.5751'}\n",
      "[Train Epoch]1/5 [Time]3363.60 [Step]4500 [Batch]72000 [Speed]46.72ms/step [Loss]9.5746 [Metrics]{'train_loss:9.5746'}\n",
      "[Train Epoch]1/5 [Time]3387.06 [Step]4531 [Batch]72500 [Speed]46.72ms/step [Loss]9.5747 [Metrics]{'train_loss:9.5747'}\n",
      "[Train Epoch]1/5 [Time]3409.96 [Step]4562 [Batch]73000 [Speed]46.71ms/step [Loss]9.5735 [Metrics]{'train_loss:9.5735'}\n",
      "[Train Epoch]1/5 [Time]3432.69 [Step]4593 [Batch]73500 [Speed]46.70ms/step [Loss]9.5730 [Metrics]{'train_loss:9.5730'}\n",
      "[Train Epoch]1/5 [Time]3455.03 [Step]4625 [Batch]74000 [Speed]46.69ms/step [Loss]9.5724 [Metrics]{'train_loss:9.5724'}\n",
      "[Train Epoch]1/5 [Time]3477.61 [Step]4656 [Batch]74500 [Speed]46.68ms/step [Loss]9.5720 [Metrics]{'train_loss:9.5720'}\n",
      "[Train Epoch]1/5 [Time]3500.19 [Step]4687 [Batch]75000 [Speed]46.67ms/step [Loss]9.5716 [Metrics]{'train_loss:9.5716'}\n",
      "[Train Epoch]1/5 [Time]3522.58 [Step]4718 [Batch]75500 [Speed]46.66ms/step [Loss]9.5713 [Metrics]{'train_loss:9.5713'}\n",
      "[Train Epoch]1/5 [Time]3545.62 [Step]4750 [Batch]76000 [Speed]46.65ms/step [Loss]9.5707 [Metrics]{'train_loss:9.5707'}\n",
      "[Train Epoch]1/5 [Time]3568.71 [Step]4781 [Batch]76500 [Speed]46.65ms/step [Loss]9.5703 [Metrics]{'train_loss:9.5703'}\n",
      "[Train Epoch]1/5 [Time]3591.09 [Step]4812 [Batch]77000 [Speed]46.64ms/step [Loss]9.5703 [Metrics]{'train_loss:9.5703'}\n",
      "[Train Epoch]1/5 [Time]3613.38 [Step]4843 [Batch]77500 [Speed]46.62ms/step [Loss]9.5699 [Metrics]{'train_loss:9.5699'}\n",
      "[Train Epoch]1/5 [Time]3635.81 [Step]4875 [Batch]78000 [Speed]46.61ms/step [Loss]9.5699 [Metrics]{'train_loss:9.5699'}\n",
      "[Train Epoch]1/5 [Time]3658.12 [Step]4906 [Batch]78500 [Speed]46.60ms/step [Loss]9.5694 [Metrics]{'train_loss:9.5694'}\n",
      "[Train Epoch]1/5 [Time]3681.14 [Step]4937 [Batch]79000 [Speed]46.60ms/step [Loss]9.5692 [Metrics]{'train_loss:9.5692'}\n",
      "[Train Epoch]1/5 [Time]3703.41 [Step]4968 [Batch]79500 [Speed]46.58ms/step [Loss]9.5683 [Metrics]{'train_loss:9.5683'}\n",
      "Saving checkpoint for epoch 1 at step 80000 on path ../2_Models/model_bert4rec_complete_0.5/checkpoints/\n",
      "[Train Epoch]1/5 [Time]3727.49 [Step]5000 [Batch]80000 [Speed]46.59ms/step [Loss]9.5678 [Metrics]{'train_loss:9.5678'}\n",
      "[Train Epoch]1/5 [Time]3749.90 [Step]5031 [Batch]80500 [Speed]46.58ms/step [Loss]9.5672 [Metrics]{'train_loss:9.5672'}\n",
      "[Train Epoch]1/5 [Time]3772.05 [Step]5062 [Batch]81000 [Speed]46.57ms/step [Loss]9.5669 [Metrics]{'train_loss:9.5669'}\n",
      "[Train Epoch]1/5 [Time]3794.20 [Step]5093 [Batch]81500 [Speed]46.55ms/step [Loss]9.5663 [Metrics]{'train_loss:9.5663'}\n",
      "[Train Epoch]1/5 [Time]3816.35 [Step]5125 [Batch]82000 [Speed]46.54ms/step [Loss]9.5656 [Metrics]{'train_loss:9.5656'}\n",
      "[Train Epoch]1/5 [Time]3838.49 [Step]5156 [Batch]82500 [Speed]46.53ms/step [Loss]9.5655 [Metrics]{'train_loss:9.5655'}\n",
      "[Train Epoch]1/5 [Time]3860.71 [Step]5187 [Batch]83000 [Speed]46.51ms/step [Loss]9.5653 [Metrics]{'train_loss:9.5653'}\n",
      "[Train Epoch]1/5 [Time]3882.91 [Step]5218 [Batch]83500 [Speed]46.50ms/step [Loss]9.5650 [Metrics]{'train_loss:9.5650'}\n",
      "[Train Epoch]1/5 [Time]3904.99 [Step]5250 [Batch]84000 [Speed]46.49ms/step [Loss]9.5650 [Metrics]{'train_loss:9.5650'}\n",
      "[Train Epoch]1/5 [Time]3927.17 [Step]5281 [Batch]84500 [Speed]46.48ms/step [Loss]9.5648 [Metrics]{'train_loss:9.5648'}\n",
      "[Train Epoch]1/5 [Time]3949.39 [Step]5312 [Batch]85000 [Speed]46.46ms/step [Loss]9.5644 [Metrics]{'train_loss:9.5644'}\n",
      "[Train Epoch]1/5 [Time]3971.52 [Step]5343 [Batch]85500 [Speed]46.45ms/step [Loss]9.5639 [Metrics]{'train_loss:9.5639'}\n",
      "[Train Epoch]1/5 [Time]3993.68 [Step]5375 [Batch]86000 [Speed]46.44ms/step [Loss]9.5630 [Metrics]{'train_loss:9.5630'}\n",
      "[Train Epoch]1/5 [Time]4015.92 [Step]5406 [Batch]86500 [Speed]46.43ms/step [Loss]9.5632 [Metrics]{'train_loss:9.5632'}\n",
      "[Train Epoch]1/5 [Time]4037.96 [Step]5437 [Batch]87000 [Speed]46.41ms/step [Loss]9.5629 [Metrics]{'train_loss:9.5629'}\n",
      "[Train Epoch]1/5 [Time]4060.15 [Step]5468 [Batch]87500 [Speed]46.40ms/step [Loss]9.5629 [Metrics]{'train_loss:9.5629'}\n",
      "[Train Epoch]1/5 [Time]4082.32 [Step]5500 [Batch]88000 [Speed]46.39ms/step [Loss]9.5623 [Metrics]{'train_loss:9.5623'}\n",
      "[Train Epoch]1/5 [Time]4104.52 [Step]5531 [Batch]88500 [Speed]46.38ms/step [Loss]9.5623 [Metrics]{'train_loss:9.5623'}\n",
      "[Train Epoch]1/5 [Time]4126.62 [Step]5562 [Batch]89000 [Speed]46.37ms/step [Loss]9.5619 [Metrics]{'train_loss:9.5619'}\n",
      "[Train Epoch]1/5 [Time]4148.71 [Step]5593 [Batch]89500 [Speed]46.35ms/step [Loss]9.5618 [Metrics]{'train_loss:9.5618'}\n",
      "[Train Epoch]1/5 [Time]4170.86 [Step]5625 [Batch]90000 [Speed]46.34ms/step [Loss]9.5616 [Metrics]{'train_loss:9.5616'}\n",
      "[Train Epoch]1/5 [Time]4193.01 [Step]5656 [Batch]90500 [Speed]46.33ms/step [Loss]9.5612 [Metrics]{'train_loss:9.5612'}\n",
      "[Train Epoch]1/5 [Time]4215.21 [Step]5687 [Batch]91000 [Speed]46.32ms/step [Loss]9.5608 [Metrics]{'train_loss:9.5608'}\n",
      "[Train Epoch]1/5 [Time]4237.44 [Step]5718 [Batch]91500 [Speed]46.31ms/step [Loss]9.5601 [Metrics]{'train_loss:9.5601'}\n",
      "[Train Epoch]1/5 [Time]4259.65 [Step]5750 [Batch]92000 [Speed]46.30ms/step [Loss]9.5593 [Metrics]{'train_loss:9.5593'}\n",
      "[Train Epoch]1/5 [Time]4281.81 [Step]5781 [Batch]92500 [Speed]46.29ms/step [Loss]9.5589 [Metrics]{'train_loss:9.5589'}\n",
      "[Train Epoch]1/5 [Time]4303.95 [Step]5812 [Batch]93000 [Speed]46.28ms/step [Loss]9.5586 [Metrics]{'train_loss:9.5586'}\n",
      "[Train Epoch]1/5 [Time]4326.14 [Step]5843 [Batch]93500 [Speed]46.27ms/step [Loss]9.5581 [Metrics]{'train_loss:9.5581'}\n",
      "[Train Epoch]1/5 [Time]4348.23 [Step]5875 [Batch]94000 [Speed]46.26ms/step [Loss]9.5575 [Metrics]{'train_loss:9.5575'}\n",
      "[Train Epoch]1/5 [Time]4370.45 [Step]5906 [Batch]94500 [Speed]46.25ms/step [Loss]9.5570 [Metrics]{'train_loss:9.5570'}\n",
      "[Train Epoch]1/5 [Time]4392.74 [Step]5937 [Batch]95000 [Speed]46.24ms/step [Loss]9.5564 [Metrics]{'train_loss:9.5564'}\n",
      "[Train Epoch]1/5 [Time]4415.04 [Step]5968 [Batch]95500 [Speed]46.23ms/step [Loss]9.5561 [Metrics]{'train_loss:9.5561'}\n",
      "[Train Epoch]1/5 [Time]4437.38 [Step]6000 [Batch]96000 [Speed]46.22ms/step [Loss]9.5556 [Metrics]{'train_loss:9.5556'}\n",
      "[Train Epoch]1/5 [Time]4459.51 [Step]6031 [Batch]96500 [Speed]46.21ms/step [Loss]9.5550 [Metrics]{'train_loss:9.5550'}\n",
      "[Train Epoch]1/5 [Time]4481.66 [Step]6062 [Batch]97000 [Speed]46.20ms/step [Loss]9.5550 [Metrics]{'train_loss:9.5550'}\n",
      "[Train Epoch]1/5 [Time]4503.83 [Step]6093 [Batch]97500 [Speed]46.19ms/step [Loss]9.5544 [Metrics]{'train_loss:9.5544'}\n",
      "[Train Epoch]1/5 [Time]4526.02 [Step]6125 [Batch]98000 [Speed]46.18ms/step [Loss]9.5543 [Metrics]{'train_loss:9.5543'}\n",
      "[Train Epoch]1/5 [Time]4548.19 [Step]6156 [Batch]98500 [Speed]46.17ms/step [Loss]9.5537 [Metrics]{'train_loss:9.5537'}\n",
      "[Train Epoch]1/5 [Time]4570.36 [Step]6187 [Batch]99000 [Speed]46.17ms/step [Loss]9.5530 [Metrics]{'train_loss:9.5530'}\n",
      "[Train Epoch]1/5 [Time]4592.49 [Step]6218 [Batch]99500 [Speed]46.16ms/step [Loss]9.5526 [Metrics]{'train_loss:9.5526'}\n",
      "[Train Epoch]1/5 [Time]4614.70 [Step]6250 [Batch]100000 [Speed]46.15ms/step [Loss]9.5522 [Metrics]{'train_loss:9.5522'}\n",
      "[Train Epoch]1/5 [Time]4636.87 [Step]6281 [Batch]100500 [Speed]46.14ms/step [Loss]9.5515 [Metrics]{'train_loss:9.5515'}\n",
      "[Train Epoch]1/5 [Time]4659.03 [Step]6312 [Batch]101000 [Speed]46.13ms/step [Loss]9.5509 [Metrics]{'train_loss:9.5509'}\n",
      "[Train Epoch]1/5 [Time]4681.30 [Step]6343 [Batch]101500 [Speed]46.12ms/step [Loss]9.5504 [Metrics]{'train_loss:9.5504'}\n",
      "[Train Epoch]1/5 [Time]4703.57 [Step]6375 [Batch]102000 [Speed]46.11ms/step [Loss]9.5497 [Metrics]{'train_loss:9.5497'}\n",
      "[Train Epoch]1/5 [Time]4725.71 [Step]6406 [Batch]102500 [Speed]46.10ms/step [Loss]9.5492 [Metrics]{'train_loss:9.5492'}\n",
      "[Train Epoch]1/5 [Time]4747.80 [Step]6437 [Batch]103000 [Speed]46.10ms/step [Loss]9.5491 [Metrics]{'train_loss:9.5491'}\n",
      "[Train Epoch]1/5 [Time]4770.02 [Step]6468 [Batch]103500 [Speed]46.09ms/step [Loss]9.5489 [Metrics]{'train_loss:9.5489'}\n",
      "[Train Epoch]1/5 [Time]4792.37 [Step]6500 [Batch]104000 [Speed]46.08ms/step [Loss]9.5485 [Metrics]{'train_loss:9.5485'}\n",
      "[Train Epoch]1/5 [Time]4814.67 [Step]6531 [Batch]104500 [Speed]46.07ms/step [Loss]9.5477 [Metrics]{'train_loss:9.5477'}\n",
      "[Train Epoch]1/5 [Time]4836.86 [Step]6562 [Batch]105000 [Speed]46.07ms/step [Loss]9.5474 [Metrics]{'train_loss:9.5474'}\n",
      "[Train Epoch]1/5 [Time]4859.06 [Step]6593 [Batch]105500 [Speed]46.06ms/step [Loss]9.5469 [Metrics]{'train_loss:9.5469'}\n",
      "[Train Epoch]1/5 [Time]4881.28 [Step]6625 [Batch]106000 [Speed]46.05ms/step [Loss]9.5464 [Metrics]{'train_loss:9.5464'}\n",
      "[Train Epoch]1/5 [Time]4903.34 [Step]6656 [Batch]106500 [Speed]46.04ms/step [Loss]9.5459 [Metrics]{'train_loss:9.5459'}\n",
      "[Train Epoch]1/5 [Time]4925.46 [Step]6687 [Batch]107000 [Speed]46.03ms/step [Loss]9.5455 [Metrics]{'train_loss:9.5455'}\n",
      "[Train Epoch]1/5 [Time]4947.65 [Step]6718 [Batch]107500 [Speed]46.02ms/step [Loss]9.5448 [Metrics]{'train_loss:9.5448'}\n",
      "[Train Epoch]1/5 [Time]4969.70 [Step]6750 [Batch]108000 [Speed]46.02ms/step [Loss]9.5443 [Metrics]{'train_loss:9.5443'}\n",
      "[Train Epoch]1/5 [Time]4991.87 [Step]6781 [Batch]108500 [Speed]46.01ms/step [Loss]9.5437 [Metrics]{'train_loss:9.5437'}\n",
      "[Train Epoch]1/5 [Time]5014.05 [Step]6812 [Batch]109000 [Speed]46.00ms/step [Loss]9.5435 [Metrics]{'train_loss:9.5435'}\n",
      "[Train Epoch]1/5 [Time]5036.15 [Step]6843 [Batch]109500 [Speed]45.99ms/step [Loss]9.5431 [Metrics]{'train_loss:9.5431'}\n",
      "[Train Epoch]1/5 [Time]5058.39 [Step]6875 [Batch]110000 [Speed]45.99ms/step [Loss]9.5429 [Metrics]{'train_loss:9.5429'}\n",
      "[Train Epoch]1/5 [Time]5080.54 [Step]6906 [Batch]110500 [Speed]45.98ms/step [Loss]9.5423 [Metrics]{'train_loss:9.5423'}\n",
      "[Train Epoch]1/5 [Time]5102.63 [Step]6937 [Batch]111000 [Speed]45.97ms/step [Loss]9.5415 [Metrics]{'train_loss:9.5415'}\n",
      "[Train Epoch]1/5 [Time]5124.78 [Step]6968 [Batch]111500 [Speed]45.96ms/step [Loss]9.5414 [Metrics]{'train_loss:9.5414'}\n",
      "[Train Epoch]1/5 [Time]5146.96 [Step]7000 [Batch]112000 [Speed]45.95ms/step [Loss]9.5408 [Metrics]{'train_loss:9.5408'}\n",
      "[Train Epoch]1/5 [Time]5169.02 [Step]7031 [Batch]112500 [Speed]45.95ms/step [Loss]9.5402 [Metrics]{'train_loss:9.5402'}\n",
      "[Train Epoch]1/5 [Time]5191.23 [Step]7062 [Batch]113000 [Speed]45.94ms/step [Loss]9.5403 [Metrics]{'train_loss:9.5403'}\n",
      "[Train Epoch]1/5 [Time]5213.42 [Step]7093 [Batch]113500 [Speed]45.93ms/step [Loss]9.5395 [Metrics]{'train_loss:9.5395'}\n",
      "[Train Epoch]1/5 [Time]5235.60 [Step]7125 [Batch]114000 [Speed]45.93ms/step [Loss]9.5384 [Metrics]{'train_loss:9.5384'}\n",
      "[Train Epoch]1/5 [Time]5257.79 [Step]7156 [Batch]114500 [Speed]45.92ms/step [Loss]9.5380 [Metrics]{'train_loss:9.5380'}\n",
      "[Train Epoch]1/5 [Time]5280.01 [Step]7187 [Batch]115000 [Speed]45.91ms/step [Loss]9.5375 [Metrics]{'train_loss:9.5375'}\n",
      "[Train Epoch]1/5 [Time]5302.14 [Step]7218 [Batch]115500 [Speed]45.91ms/step [Loss]9.5373 [Metrics]{'train_loss:9.5373'}\n",
      "[Train Epoch]1/5 [Time]5324.36 [Step]7250 [Batch]116000 [Speed]45.90ms/step [Loss]9.5372 [Metrics]{'train_loss:9.5372'}\n",
      "[Train Epoch]1/5 [Time]5346.52 [Step]7281 [Batch]116500 [Speed]45.89ms/step [Loss]9.5367 [Metrics]{'train_loss:9.5367'}\n",
      "[Train Epoch]1/5 [Time]5368.64 [Step]7312 [Batch]117000 [Speed]45.89ms/step [Loss]9.5359 [Metrics]{'train_loss:9.5359'}\n",
      "[Train Epoch]1/5 [Time]5390.88 [Step]7343 [Batch]117500 [Speed]45.88ms/step [Loss]9.5354 [Metrics]{'train_loss:9.5354'}\n",
      "[Train Epoch]1/5 [Time]5413.06 [Step]7375 [Batch]118000 [Speed]45.87ms/step [Loss]9.5352 [Metrics]{'train_loss:9.5352'}\n",
      "[Train Epoch]1/5 [Time]5435.09 [Step]7406 [Batch]118500 [Speed]45.87ms/step [Loss]9.5348 [Metrics]{'train_loss:9.5348'}\n",
      "[Train Epoch]1/5 [Time]5457.34 [Step]7437 [Batch]119000 [Speed]45.86ms/step [Loss]9.5340 [Metrics]{'train_loss:9.5340'}\n",
      "[Train Epoch]1/5 [Time]5479.53 [Step]7468 [Batch]119500 [Speed]45.85ms/step [Loss]9.5335 [Metrics]{'train_loss:9.5335'}\n",
      "[Train Epoch]1/5 [Time]5501.68 [Step]7500 [Batch]120000 [Speed]45.85ms/step [Loss]9.5330 [Metrics]{'train_loss:9.5330'}\n",
      "[Train Epoch]1/5 [Time]5523.87 [Step]7531 [Batch]120500 [Speed]45.84ms/step [Loss]9.5324 [Metrics]{'train_loss:9.5324'}\n",
      "[Train Epoch]1/5 [Time]5545.98 [Step]7562 [Batch]121000 [Speed]45.83ms/step [Loss]9.5315 [Metrics]{'train_loss:9.5315'}\n",
      "[Train Epoch]1/5 [Time]5568.10 [Step]7593 [Batch]121500 [Speed]45.83ms/step [Loss]9.5308 [Metrics]{'train_loss:9.5308'}\n",
      "[Train Epoch]1/5 [Time]5590.27 [Step]7625 [Batch]122000 [Speed]45.82ms/step [Loss]9.5309 [Metrics]{'train_loss:9.5309'}\n",
      "[Train Epoch]1/5 [Time]5612.45 [Step]7656 [Batch]122500 [Speed]45.82ms/step [Loss]9.5301 [Metrics]{'train_loss:9.5301'}\n",
      "[Train Epoch]1/5 [Time]5634.57 [Step]7687 [Batch]123000 [Speed]45.81ms/step [Loss]9.5297 [Metrics]{'train_loss:9.5297'}\n",
      "[Train Epoch]1/5 [Time]5656.76 [Step]7718 [Batch]123500 [Speed]45.80ms/step [Loss]9.5295 [Metrics]{'train_loss:9.5295'}\n",
      "[Train Epoch]1/5 [Time]5679.08 [Step]7750 [Batch]124000 [Speed]45.80ms/step [Loss]9.5292 [Metrics]{'train_loss:9.5292'}\n",
      "[Train Epoch]1/5 [Time]5701.15 [Step]7781 [Batch]124500 [Speed]45.79ms/step [Loss]9.5288 [Metrics]{'train_loss:9.5288'}\n",
      "[Train Epoch]1/5 [Time]5723.39 [Step]7812 [Batch]125000 [Speed]45.79ms/step [Loss]9.5283 [Metrics]{'train_loss:9.5283'}\n",
      "[Train Epoch]1/5 [Time]5745.63 [Step]7843 [Batch]125500 [Speed]45.78ms/step [Loss]9.5277 [Metrics]{'train_loss:9.5277'}\n",
      "[Train Epoch]1/5 [Time]5767.73 [Step]7875 [Batch]126000 [Speed]45.78ms/step [Loss]9.5272 [Metrics]{'train_loss:9.5272'}\n",
      "[Train Epoch]1/5 [Time]5790.02 [Step]7906 [Batch]126500 [Speed]45.77ms/step [Loss]9.5265 [Metrics]{'train_loss:9.5265'}\n",
      "[Train Epoch]1/5 [Time]5812.19 [Step]7937 [Batch]127000 [Speed]45.77ms/step [Loss]9.5260 [Metrics]{'train_loss:9.5260'}\n",
      "[Train Epoch]1/5 [Time]5834.40 [Step]7968 [Batch]127500 [Speed]45.76ms/step [Loss]9.5254 [Metrics]{'train_loss:9.5254'}\n",
      "[Train Epoch]1/5 [Time]5856.59 [Step]8000 [Batch]128000 [Speed]45.75ms/step [Loss]9.5252 [Metrics]{'train_loss:9.5252'}\n",
      "[Train Epoch]1/5 [Time]5878.79 [Step]8031 [Batch]128500 [Speed]45.75ms/step [Loss]9.5245 [Metrics]{'train_loss:9.5245'}\n",
      "[Train Epoch]1/5 [Time]5901.02 [Step]8062 [Batch]129000 [Speed]45.74ms/step [Loss]9.5240 [Metrics]{'train_loss:9.5240'}\n",
      "[Train Epoch]1/5 [Time]5923.15 [Step]8093 [Batch]129500 [Speed]45.74ms/step [Loss]9.5236 [Metrics]{'train_loss:9.5236'}\n",
      "[Train Epoch]1/5 [Time]5945.40 [Step]8125 [Batch]130000 [Speed]45.73ms/step [Loss]9.5229 [Metrics]{'train_loss:9.5229'}\n",
      "[Train Epoch]1/5 [Time]5967.60 [Step]8156 [Batch]130500 [Speed]45.73ms/step [Loss]9.5223 [Metrics]{'train_loss:9.5223'}\n",
      "[Train Epoch]1/5 [Time]5989.79 [Step]8187 [Batch]131000 [Speed]45.72ms/step [Loss]9.5216 [Metrics]{'train_loss:9.5216'}\n",
      "[Train Epoch]1/5 [Time]6011.94 [Step]8218 [Batch]131500 [Speed]45.72ms/step [Loss]9.5206 [Metrics]{'train_loss:9.5206'}\n",
      "[Train Epoch]1/5 [Time]6034.20 [Step]8250 [Batch]132000 [Speed]45.71ms/step [Loss]9.5197 [Metrics]{'train_loss:9.5197'}\n",
      "[Train Epoch]1/5 [Time]6056.37 [Step]8281 [Batch]132500 [Speed]45.71ms/step [Loss]9.5189 [Metrics]{'train_loss:9.5189'}\n",
      "[Train Epoch]1/5 [Time]6078.56 [Step]8312 [Batch]133000 [Speed]45.70ms/step [Loss]9.5186 [Metrics]{'train_loss:9.5186'}\n",
      "[Train Epoch]1/5 [Time]6100.76 [Step]8343 [Batch]133500 [Speed]45.70ms/step [Loss]9.5177 [Metrics]{'train_loss:9.5177'}\n",
      "[Train Epoch]1/5 [Time]6122.91 [Step]8375 [Batch]134000 [Speed]45.69ms/step [Loss]9.5172 [Metrics]{'train_loss:9.5172'}\n",
      "[Train Epoch]1/5 [Time]6145.11 [Step]8406 [Batch]134500 [Speed]45.69ms/step [Loss]9.5166 [Metrics]{'train_loss:9.5166'}\n",
      "[Train Epoch]1/5 [Time]6167.37 [Step]8437 [Batch]135000 [Speed]45.68ms/step [Loss]9.5160 [Metrics]{'train_loss:9.5160'}\n",
      "[Train Epoch]1/5 [Time]6189.47 [Step]8468 [Batch]135500 [Speed]45.68ms/step [Loss]9.5159 [Metrics]{'train_loss:9.5159'}\n",
      "[Train Epoch]1/5 [Time]6211.77 [Step]8500 [Batch]136000 [Speed]45.67ms/step [Loss]9.5155 [Metrics]{'train_loss:9.5155'}\n",
      "[Train Epoch]1/5 [Time]6234.08 [Step]8531 [Batch]136500 [Speed]45.67ms/step [Loss]9.5149 [Metrics]{'train_loss:9.5149'}\n",
      "[Train Epoch]1/5 [Time]6256.25 [Step]8562 [Batch]137000 [Speed]45.67ms/step [Loss]9.5146 [Metrics]{'train_loss:9.5146'}\n",
      "[Train Epoch]1/5 [Time]6278.45 [Step]8593 [Batch]137500 [Speed]45.66ms/step [Loss]9.5143 [Metrics]{'train_loss:9.5143'}\n",
      "[Train Epoch]1/5 [Time]6300.69 [Step]8625 [Batch]138000 [Speed]45.66ms/step [Loss]9.5138 [Metrics]{'train_loss:9.5138'}\n",
      "[Train Epoch]1/5 [Time]6322.99 [Step]8656 [Batch]138500 [Speed]45.65ms/step [Loss]9.5132 [Metrics]{'train_loss:9.5132'}\n",
      "[Train Epoch]1/5 [Time]6345.17 [Step]8687 [Batch]139000 [Speed]45.65ms/step [Loss]9.5124 [Metrics]{'train_loss:9.5124'}\n",
      "[Train Epoch]1/5 [Time]6367.39 [Step]8718 [Batch]139500 [Speed]45.64ms/step [Loss]9.5122 [Metrics]{'train_loss:9.5122'}\n",
      "[Train Epoch]1/5 [Time]6389.56 [Step]8750 [Batch]140000 [Speed]45.64ms/step [Loss]9.5116 [Metrics]{'train_loss:9.5116'}\n",
      "[Train Epoch]1/5 [Time]6411.70 [Step]8781 [Batch]140500 [Speed]45.63ms/step [Loss]9.5109 [Metrics]{'train_loss:9.5109'}\n",
      "[Train Epoch]1/5 [Time]6433.80 [Step]8812 [Batch]141000 [Speed]45.63ms/step [Loss]9.5102 [Metrics]{'train_loss:9.5102'}\n",
      "[Train Epoch]1/5 [Time]6455.94 [Step]8843 [Batch]141500 [Speed]45.63ms/step [Loss]9.5095 [Metrics]{'train_loss:9.5095'}\n",
      "[Train Epoch]1/5 [Time]6478.14 [Step]8875 [Batch]142000 [Speed]45.62ms/step [Loss]9.5092 [Metrics]{'train_loss:9.5092'}\n",
      "[Train Epoch]1/5 [Time]6500.38 [Step]8906 [Batch]142500 [Speed]45.62ms/step [Loss]9.5086 [Metrics]{'train_loss:9.5086'}\n",
      "[Train Epoch]1/5 [Time]6522.64 [Step]8937 [Batch]143000 [Speed]45.61ms/step [Loss]9.5081 [Metrics]{'train_loss:9.5081'}\n",
      "[Train Epoch]1/5 [Time]6544.75 [Step]8968 [Batch]143500 [Speed]45.61ms/step [Loss]9.5075 [Metrics]{'train_loss:9.5075'}\n",
      "[Train Epoch]1/5 [Time]6566.99 [Step]9000 [Batch]144000 [Speed]45.60ms/step [Loss]9.5069 [Metrics]{'train_loss:9.5069'}\n",
      "[Train Epoch]1/5 [Time]6589.28 [Step]9031 [Batch]144500 [Speed]45.60ms/step [Loss]9.5063 [Metrics]{'train_loss:9.5063'}\n",
      "[Train Epoch]1/5 [Time]6611.45 [Step]9062 [Batch]145000 [Speed]45.60ms/step [Loss]9.5058 [Metrics]{'train_loss:9.5058'}\n",
      "[Train Epoch]1/5 [Time]6633.72 [Step]9093 [Batch]145500 [Speed]45.59ms/step [Loss]9.5054 [Metrics]{'train_loss:9.5054'}\n",
      "[Train Epoch]1/5 [Time]6655.89 [Step]9125 [Batch]146000 [Speed]45.59ms/step [Loss]9.5049 [Metrics]{'train_loss:9.5049'}\n",
      "[Train Epoch]1/5 [Time]6678.06 [Step]9156 [Batch]146500 [Speed]45.58ms/step [Loss]9.5041 [Metrics]{'train_loss:9.5041'}\n",
      "[Train Epoch]1/5 [Time]6700.31 [Step]9187 [Batch]147000 [Speed]45.58ms/step [Loss]9.5035 [Metrics]{'train_loss:9.5035'}\n",
      "[Train Epoch]1/5 [Time]6722.64 [Step]9218 [Batch]147500 [Speed]45.58ms/step [Loss]9.5027 [Metrics]{'train_loss:9.5027'}\n",
      "[Train Epoch]1/5 [Time]6744.80 [Step]9250 [Batch]148000 [Speed]45.57ms/step [Loss]9.5021 [Metrics]{'train_loss:9.5021'}\n",
      "[Train Epoch]1/5 [Time]6767.00 [Step]9281 [Batch]148500 [Speed]45.57ms/step [Loss]9.5016 [Metrics]{'train_loss:9.5016'}\n",
      "[Train Epoch]1/5 [Time]6789.27 [Step]9312 [Batch]149000 [Speed]45.57ms/step [Loss]9.5010 [Metrics]{'train_loss:9.5010'}\n",
      "[Train Epoch]1/5 [Time]6811.45 [Step]9343 [Batch]149500 [Speed]45.56ms/step [Loss]9.5002 [Metrics]{'train_loss:9.5002'}\n",
      "[Train Epoch]1/5 [Time]6833.74 [Step]9375 [Batch]150000 [Speed]45.56ms/step [Loss]9.4996 [Metrics]{'train_loss:9.4996'}\n",
      "[Train Epoch]1/5 [Time]6856.02 [Step]9406 [Batch]150500 [Speed]45.55ms/step [Loss]9.4988 [Metrics]{'train_loss:9.4988'}\n",
      "[Train Epoch]1/5 [Time]6878.24 [Step]9437 [Batch]151000 [Speed]45.55ms/step [Loss]9.4982 [Metrics]{'train_loss:9.4982'}\n",
      "[Train Epoch]1/5 [Time]6900.51 [Step]9468 [Batch]151500 [Speed]45.55ms/step [Loss]9.4971 [Metrics]{'train_loss:9.4971'}\n",
      "[Train Epoch]1/5 [Time]6922.71 [Step]9500 [Batch]152000 [Speed]45.54ms/step [Loss]9.4964 [Metrics]{'train_loss:9.4964'}\n",
      "[Train Epoch]1/5 [Time]6944.93 [Step]9531 [Batch]152500 [Speed]45.54ms/step [Loss]9.4957 [Metrics]{'train_loss:9.4957'}\n",
      "[Train Epoch]1/5 [Time]6967.22 [Step]9562 [Batch]153000 [Speed]45.54ms/step [Loss]9.4947 [Metrics]{'train_loss:9.4947'}\n",
      "[Train Epoch]1/5 [Time]6989.46 [Step]9593 [Batch]153500 [Speed]45.53ms/step [Loss]9.4942 [Metrics]{'train_loss:9.4942'}\n",
      "[Train Epoch]1/5 [Time]7011.66 [Step]9625 [Batch]154000 [Speed]45.53ms/step [Loss]9.4935 [Metrics]{'train_loss:9.4935'}\n",
      "[Train Epoch]1/5 [Time]7033.93 [Step]9656 [Batch]154500 [Speed]45.53ms/step [Loss]9.4930 [Metrics]{'train_loss:9.4930'}\n",
      "[Train Epoch]1/5 [Time]7056.21 [Step]9687 [Batch]155000 [Speed]45.52ms/step [Loss]9.4925 [Metrics]{'train_loss:9.4925'}\n",
      "[Train Epoch]1/5 [Time]7078.42 [Step]9718 [Batch]155500 [Speed]45.52ms/step [Loss]9.4913 [Metrics]{'train_loss:9.4913'}\n",
      "[Train Epoch]1/5 [Time]7100.58 [Step]9750 [Batch]156000 [Speed]45.52ms/step [Loss]9.4902 [Metrics]{'train_loss:9.4902'}\n",
      "[Train Epoch]1/5 [Time]7122.82 [Step]9781 [Batch]156500 [Speed]45.51ms/step [Loss]9.4893 [Metrics]{'train_loss:9.4893'}\n",
      "[Train Epoch]1/5 [Time]7145.11 [Step]9812 [Batch]157000 [Speed]45.51ms/step [Loss]9.4887 [Metrics]{'train_loss:9.4887'}\n",
      "[Train Epoch]1/5 [Time]7167.27 [Step]9843 [Batch]157500 [Speed]45.51ms/step [Loss]9.4881 [Metrics]{'train_loss:9.4881'}\n",
      "[Train Epoch]1/5 [Time]7189.55 [Step]9875 [Batch]158000 [Speed]45.50ms/step [Loss]9.4873 [Metrics]{'train_loss:9.4873'}\n",
      "[Train Epoch]1/5 [Time]7211.87 [Step]9906 [Batch]158500 [Speed]45.50ms/step [Loss]9.4866 [Metrics]{'train_loss:9.4866'}\n",
      "[Train Epoch]1/5 [Time]7234.01 [Step]9937 [Batch]159000 [Speed]45.50ms/step [Loss]9.4859 [Metrics]{'train_loss:9.4859'}\n",
      "[Train Epoch]1/5 [Time]7256.29 [Step]9968 [Batch]159500 [Speed]45.49ms/step [Loss]9.4851 [Metrics]{'train_loss:9.4851'}\n",
      "Saving checkpoint for epoch 1 at step 160000 on path ../2_Models/model_bert4rec_complete_0.5/checkpoints/\n",
      "[Train Epoch]1/5 [Time]7280.43 [Step]10000 [Batch]160000 [Speed]45.50ms/step [Loss]9.4841 [Metrics]{'train_loss:9.4841'}\n",
      "[Train Epoch]1/5 [Time]7302.77 [Step]10031 [Batch]160500 [Speed]45.50ms/step [Loss]9.4837 [Metrics]{'train_loss:9.4837'}\n",
      "[Train Epoch]1/5 [Time]7325.08 [Step]10062 [Batch]161000 [Speed]45.50ms/step [Loss]9.4832 [Metrics]{'train_loss:9.4832'}\n",
      "[Train Epoch]1/5 [Time]7347.22 [Step]10093 [Batch]161500 [Speed]45.49ms/step [Loss]9.4825 [Metrics]{'train_loss:9.4825'}\n",
      "[Train Epoch]1/5 [Time]7369.48 [Step]10125 [Batch]162000 [Speed]45.49ms/step [Loss]9.4818 [Metrics]{'train_loss:9.4818'}\n",
      "[Train Epoch]1/5 [Time]7391.73 [Step]10156 [Batch]162500 [Speed]45.49ms/step [Loss]9.4814 [Metrics]{'train_loss:9.4814'}\n",
      "[Train Epoch]1/5 [Time]7414.01 [Step]10187 [Batch]163000 [Speed]45.48ms/step [Loss]9.4807 [Metrics]{'train_loss:9.4807'}\n",
      "[Train Epoch]1/5 [Time]7436.20 [Step]10218 [Batch]163500 [Speed]45.48ms/step [Loss]9.4801 [Metrics]{'train_loss:9.4801'}\n",
      "[Train Epoch]1/5 [Time]7458.40 [Step]10250 [Batch]164000 [Speed]45.48ms/step [Loss]9.4797 [Metrics]{'train_loss:9.4797'}\n",
      "[Train Epoch]1/5 [Time]7480.58 [Step]10281 [Batch]164500 [Speed]45.47ms/step [Loss]9.4792 [Metrics]{'train_loss:9.4792'}\n",
      "[Train Epoch]1/5 [Time]7502.81 [Step]10312 [Batch]165000 [Speed]45.47ms/step [Loss]9.4784 [Metrics]{'train_loss:9.4784'}\n",
      "[Train Epoch]1/5 [Time]7525.08 [Step]10343 [Batch]165500 [Speed]45.47ms/step [Loss]9.4775 [Metrics]{'train_loss:9.4775'}\n",
      "[Train Epoch]1/5 [Time]7547.33 [Step]10375 [Batch]166000 [Speed]45.47ms/step [Loss]9.4770 [Metrics]{'train_loss:9.4770'}\n",
      "[Train Epoch]1/5 [Time]7569.55 [Step]10406 [Batch]166500 [Speed]45.46ms/step [Loss]9.4765 [Metrics]{'train_loss:9.4765'}\n",
      "[Train Epoch]1/5 [Time]7591.75 [Step]10437 [Batch]167000 [Speed]45.46ms/step [Loss]9.4760 [Metrics]{'train_loss:9.4760'}\n",
      "[Train Epoch]1/5 [Time]7613.97 [Step]10468 [Batch]167500 [Speed]45.46ms/step [Loss]9.4753 [Metrics]{'train_loss:9.4753'}\n",
      "[Train Epoch]1/5 [Time]7636.34 [Step]10500 [Batch]168000 [Speed]45.45ms/step [Loss]9.4747 [Metrics]{'train_loss:9.4747'}\n",
      "[Train Epoch]1/5 [Time]7658.59 [Step]10531 [Batch]168500 [Speed]45.45ms/step [Loss]9.4742 [Metrics]{'train_loss:9.4742'}\n",
      "[Train Epoch]1/5 [Time]7680.78 [Step]10562 [Batch]169000 [Speed]45.45ms/step [Loss]9.4734 [Metrics]{'train_loss:9.4734'}\n",
      "[Train Epoch]1/5 [Time]7703.10 [Step]10593 [Batch]169500 [Speed]45.45ms/step [Loss]9.4727 [Metrics]{'train_loss:9.4727'}\n",
      "[Train Epoch]1/5 [Time]7725.39 [Step]10625 [Batch]170000 [Speed]45.44ms/step [Loss]9.4721 [Metrics]{'train_loss:9.4721'}\n",
      "[Train Epoch]1/5 [Time]7747.70 [Step]10656 [Batch]170500 [Speed]45.44ms/step [Loss]9.4714 [Metrics]{'train_loss:9.4714'}\n",
      "[Train Epoch]1/5 [Time]7769.99 [Step]10687 [Batch]171000 [Speed]45.44ms/step [Loss]9.4708 [Metrics]{'train_loss:9.4708'}\n",
      "[Train Epoch]1/5 [Time]7792.21 [Step]10718 [Batch]171500 [Speed]45.44ms/step [Loss]9.4704 [Metrics]{'train_loss:9.4704'}\n",
      "[Train Epoch]1/5 [Time]7814.41 [Step]10750 [Batch]172000 [Speed]45.43ms/step [Loss]9.4698 [Metrics]{'train_loss:9.4698'}\n",
      "[Train Epoch]1/5 [Time]7836.72 [Step]10781 [Batch]172500 [Speed]45.43ms/step [Loss]9.4692 [Metrics]{'train_loss:9.4692'}\n",
      "[Train Epoch]1/5 [Time]7858.96 [Step]10812 [Batch]173000 [Speed]45.43ms/step [Loss]9.4685 [Metrics]{'train_loss:9.4685'}\n",
      "[Train Epoch]1/5 [Time]7881.10 [Step]10843 [Batch]173500 [Speed]45.42ms/step [Loss]9.4677 [Metrics]{'train_loss:9.4677'}\n",
      "[Train Epoch]1/5 [Time]7903.34 [Step]10875 [Batch]174000 [Speed]45.42ms/step [Loss]9.4671 [Metrics]{'train_loss:9.4671'}\n",
      "[Train Epoch]1/5 [Time]7925.55 [Step]10906 [Batch]174500 [Speed]45.42ms/step [Loss]9.4665 [Metrics]{'train_loss:9.4665'}\n",
      "[Train Epoch]1/5 [Time]7947.76 [Step]10937 [Batch]175000 [Speed]45.42ms/step [Loss]9.4661 [Metrics]{'train_loss:9.4661'}\n",
      "[Train Epoch]1/5 [Time]7969.97 [Step]10968 [Batch]175500 [Speed]45.41ms/step [Loss]9.4654 [Metrics]{'train_loss:9.4654'}\n",
      "[Train Epoch]1/5 [Time]7992.30 [Step]11000 [Batch]176000 [Speed]45.41ms/step [Loss]9.4648 [Metrics]{'train_loss:9.4648'}\n",
      "[Train Epoch]1/5 [Time]8014.57 [Step]11031 [Batch]176500 [Speed]45.41ms/step [Loss]9.4641 [Metrics]{'train_loss:9.4641'}\n",
      "[Train Epoch]1/5 [Time]8036.83 [Step]11062 [Batch]177000 [Speed]45.41ms/step [Loss]9.4633 [Metrics]{'train_loss:9.4633'}\n",
      "[Train Epoch]1/5 [Time]8059.07 [Step]11093 [Batch]177500 [Speed]45.40ms/step [Loss]9.4629 [Metrics]{'train_loss:9.4629'}\n",
      "[Train Epoch]1/5 [Time]8081.28 [Step]11125 [Batch]178000 [Speed]45.40ms/step [Loss]9.4624 [Metrics]{'train_loss:9.4624'}\n",
      "[Train Epoch]1/5 [Time]8103.55 [Step]11156 [Batch]178500 [Speed]45.40ms/step [Loss]9.4619 [Metrics]{'train_loss:9.4619'}\n",
      "[Train Epoch]1/5 [Time]8125.84 [Step]11187 [Batch]179000 [Speed]45.40ms/step [Loss]9.4614 [Metrics]{'train_loss:9.4614'}\n",
      "[Train Epoch]1/5 [Time]8148.11 [Step]11218 [Batch]179500 [Speed]45.39ms/step [Loss]9.4608 [Metrics]{'train_loss:9.4608'}\n",
      "[Train Epoch]1/5 [Time]8170.37 [Step]11250 [Batch]180000 [Speed]45.39ms/step [Loss]9.4605 [Metrics]{'train_loss:9.4605'}\n",
      "[Train Epoch]1/5 [Time]8192.72 [Step]11281 [Batch]180500 [Speed]45.39ms/step [Loss]9.4601 [Metrics]{'train_loss:9.4601'}\n",
      "[Train Epoch]1/5 [Time]8215.03 [Step]11312 [Batch]181000 [Speed]45.39ms/step [Loss]9.4595 [Metrics]{'train_loss:9.4595'}\n",
      "[Train Epoch]1/5 [Time]8237.24 [Step]11343 [Batch]181500 [Speed]45.38ms/step [Loss]9.4591 [Metrics]{'train_loss:9.4591'}\n",
      "[Train Epoch]1/5 [Time]8259.46 [Step]11375 [Batch]182000 [Speed]45.38ms/step [Loss]9.4586 [Metrics]{'train_loss:9.4586'}\n",
      "[Train Epoch]1/5 [Time]8281.81 [Step]11406 [Batch]182500 [Speed]45.38ms/step [Loss]9.4581 [Metrics]{'train_loss:9.4581'}\n",
      "[Train Epoch]1/5 [Time]8304.01 [Step]11437 [Batch]183000 [Speed]45.38ms/step [Loss]9.4573 [Metrics]{'train_loss:9.4573'}\n",
      "[Train Epoch]1/5 [Time]8326.31 [Step]11468 [Batch]183500 [Speed]45.37ms/step [Loss]9.4570 [Metrics]{'train_loss:9.4570'}\n",
      "[Train Epoch]1/5 [Time]8348.60 [Step]11500 [Batch]184000 [Speed]45.37ms/step [Loss]9.4564 [Metrics]{'train_loss:9.4564'}\n",
      "[Train Epoch]1/5 [Time]8370.78 [Step]11531 [Batch]184500 [Speed]45.37ms/step [Loss]9.4557 [Metrics]{'train_loss:9.4557'}\n",
      "[Train Epoch]1/5 [Time]8393.05 [Step]11562 [Batch]185000 [Speed]45.37ms/step [Loss]9.4554 [Metrics]{'train_loss:9.4554'}\n",
      "[Train Epoch]1/5 [Time]8415.34 [Step]11593 [Batch]185500 [Speed]45.37ms/step [Loss]9.4548 [Metrics]{'train_loss:9.4548'}\n",
      "[Train Epoch]1/5 [Time]8437.48 [Step]11625 [Batch]186000 [Speed]45.36ms/step [Loss]9.4542 [Metrics]{'train_loss:9.4542'}\n",
      "[Train Epoch]1/5 [Time]8459.68 [Step]11656 [Batch]186500 [Speed]45.36ms/step [Loss]9.4535 [Metrics]{'train_loss:9.4535'}\n",
      "[Train Epoch]1/5 [Time]8484.16 [Step]11687 [Batch]187000 [Speed]45.37ms/step [Loss]9.4528 [Metrics]{'train_loss:9.4528'}\n",
      "[Train Epoch]1/5 [Time]8508.31 [Step]11718 [Batch]187500 [Speed]45.38ms/step [Loss]9.4523 [Metrics]{'train_loss:9.4523'}\n",
      "[Train Epoch]1/5 [Time]8532.06 [Step]11750 [Batch]188000 [Speed]45.38ms/step [Loss]9.4517 [Metrics]{'train_loss:9.4517'}\n",
      "[Train Epoch]1/5 [Time]8555.97 [Step]11781 [Batch]188500 [Speed]45.39ms/step [Loss]9.4515 [Metrics]{'train_loss:9.4515'}\n",
      "[Train Epoch]1/5 [Time]8579.63 [Step]11812 [Batch]189000 [Speed]45.39ms/step [Loss]9.4511 [Metrics]{'train_loss:9.4511'}\n",
      "[Train Epoch]1/5 [Time]8603.31 [Step]11843 [Batch]189500 [Speed]45.40ms/step [Loss]9.4505 [Metrics]{'train_loss:9.4505'}\n",
      "[Train Epoch]1/5 [Time]8626.97 [Step]11875 [Batch]190000 [Speed]45.41ms/step [Loss]9.4499 [Metrics]{'train_loss:9.4499'}\n",
      "[Train Epoch]1/5 [Time]8650.58 [Step]11906 [Batch]190500 [Speed]45.41ms/step [Loss]9.4491 [Metrics]{'train_loss:9.4491'}\n",
      "[Train Epoch]1/5 [Time]8674.21 [Step]11937 [Batch]191000 [Speed]45.41ms/step [Loss]9.4486 [Metrics]{'train_loss:9.4486'}\n",
      "[Train Epoch]1/5 [Time]8697.93 [Step]11968 [Batch]191500 [Speed]45.42ms/step [Loss]9.4482 [Metrics]{'train_loss:9.4482'}\n",
      "[Train Epoch]1/5 [Time]8721.66 [Step]12000 [Batch]192000 [Speed]45.43ms/step [Loss]9.4475 [Metrics]{'train_loss:9.4475'}\n",
      "[Train Epoch]1/5 [Time]8745.33 [Step]12031 [Batch]192500 [Speed]45.43ms/step [Loss]9.4471 [Metrics]{'train_loss:9.4471'}\n",
      "[Train Epoch]1/5 [Time]8769.08 [Step]12062 [Batch]193000 [Speed]45.44ms/step [Loss]9.4465 [Metrics]{'train_loss:9.4465'}\n",
      "[Train Epoch]1/5 [Time]8793.09 [Step]12093 [Batch]193500 [Speed]45.44ms/step [Loss]9.4460 [Metrics]{'train_loss:9.4460'}\n",
      "[Train Epoch]1/5 [Time]8817.14 [Step]12125 [Batch]194000 [Speed]45.45ms/step [Loss]9.4456 [Metrics]{'train_loss:9.4456'}\n",
      "[Train Epoch]1/5 [Time]8840.92 [Step]12156 [Batch]194500 [Speed]45.45ms/step [Loss]9.4450 [Metrics]{'train_loss:9.4450'}\n",
      "[Train Epoch]1/5 [Time]8864.66 [Step]12187 [Batch]195000 [Speed]45.46ms/step [Loss]9.4445 [Metrics]{'train_loss:9.4445'}\n",
      "[Train Epoch]1/5 [Time]8888.41 [Step]12218 [Batch]195500 [Speed]45.47ms/step [Loss]9.4442 [Metrics]{'train_loss:9.4442'}\n",
      "[Train Epoch]1/5 [Time]8912.22 [Step]12250 [Batch]196000 [Speed]45.47ms/step [Loss]9.4437 [Metrics]{'train_loss:9.4437'}\n",
      "[Train Epoch]1/5 [Time]8935.86 [Step]12281 [Batch]196500 [Speed]45.48ms/step [Loss]9.4434 [Metrics]{'train_loss:9.4434'}\n",
      "[Train Epoch]1/5 [Time]8959.82 [Step]12312 [Batch]197000 [Speed]45.48ms/step [Loss]9.4433 [Metrics]{'train_loss:9.4433'}\n",
      "[Train Epoch]1/5 [Time]8983.64 [Step]12343 [Batch]197500 [Speed]45.49ms/step [Loss]9.4430 [Metrics]{'train_loss:9.4430'}\n",
      "[Train Epoch]1/5 [Time]9007.34 [Step]12375 [Batch]198000 [Speed]45.49ms/step [Loss]9.4425 [Metrics]{'train_loss:9.4425'}\n",
      "[Train Epoch]1/5 [Time]9030.58 [Step]12406 [Batch]198500 [Speed]45.49ms/step [Loss]9.4420 [Metrics]{'train_loss:9.4420'}\n",
      "[Train Epoch]1/5 [Time]9053.94 [Step]12437 [Batch]199000 [Speed]45.50ms/step [Loss]9.4415 [Metrics]{'train_loss:9.4415'}\n",
      "[Train Epoch]1/5 [Time]9077.58 [Step]12468 [Batch]199500 [Speed]45.50ms/step [Loss]9.4412 [Metrics]{'train_loss:9.4412'}\n",
      "[Train Epoch]1/5 [Time]9100.56 [Step]12500 [Batch]200000 [Speed]45.50ms/step [Loss]9.4406 [Metrics]{'train_loss:9.4406'}\n",
      "[Train Epoch]1/5 [Time]9123.95 [Step]12531 [Batch]200500 [Speed]45.51ms/step [Loss]9.4400 [Metrics]{'train_loss:9.4400'}\n",
      "[Train Epoch]1/5 [Time]9146.60 [Step]12562 [Batch]201000 [Speed]45.51ms/step [Loss]9.4395 [Metrics]{'train_loss:9.4395'}\n",
      "[Train Epoch]1/5 [Time]9170.85 [Step]12593 [Batch]201500 [Speed]45.51ms/step [Loss]9.4391 [Metrics]{'train_loss:9.4391'}\n",
      "[Train Epoch]1/5 [Time]9195.18 [Step]12625 [Batch]202000 [Speed]45.52ms/step [Loss]9.4383 [Metrics]{'train_loss:9.4383'}\n",
      "[Train Epoch]1/5 [Time]9219.19 [Step]12656 [Batch]202500 [Speed]45.53ms/step [Loss]9.4378 [Metrics]{'train_loss:9.4378'}\n",
      "[Train Epoch]1/5 [Time]9243.30 [Step]12687 [Batch]203000 [Speed]45.53ms/step [Loss]9.4370 [Metrics]{'train_loss:9.4370'}\n",
      "[Train Epoch]1/5 [Time]9267.28 [Step]12718 [Batch]203500 [Speed]45.54ms/step [Loss]9.4365 [Metrics]{'train_loss:9.4365'}\n",
      "[Train Epoch]1/5 [Time]9291.75 [Step]12750 [Batch]204000 [Speed]45.55ms/step [Loss]9.4361 [Metrics]{'train_loss:9.4361'}\n",
      "[Train Epoch]1/5 [Time]9315.99 [Step]12781 [Batch]204500 [Speed]45.55ms/step [Loss]9.4357 [Metrics]{'train_loss:9.4357'}\n",
      "[Train Epoch]1/5 [Time]9340.13 [Step]12812 [Batch]205000 [Speed]45.56ms/step [Loss]9.4352 [Metrics]{'train_loss:9.4352'}\n",
      "[Train Epoch]1/5 [Time]9364.45 [Step]12843 [Batch]205500 [Speed]45.57ms/step [Loss]9.4347 [Metrics]{'train_loss:9.4347'}\n",
      "[Train Epoch]1/5 [Time]9388.67 [Step]12875 [Batch]206000 [Speed]45.58ms/step [Loss]9.4344 [Metrics]{'train_loss:9.4344'}\n",
      "[Train Epoch]1/5 [Time]9412.82 [Step]12906 [Batch]206500 [Speed]45.58ms/step [Loss]9.4340 [Metrics]{'train_loss:9.4340'}\n",
      "[Train Epoch]1/5 [Time]9436.93 [Step]12937 [Batch]207000 [Speed]45.59ms/step [Loss]9.4335 [Metrics]{'train_loss:9.4335'}\n",
      "[Train Epoch]1/5 [Time]9460.59 [Step]12968 [Batch]207500 [Speed]45.59ms/step [Loss]9.4330 [Metrics]{'train_loss:9.4330'}\n",
      "[Train Epoch]1/5 [Time]9483.13 [Step]13000 [Batch]208000 [Speed]45.59ms/step [Loss]9.4326 [Metrics]{'train_loss:9.4326'}\n",
      "[Train Epoch]1/5 [Time]9505.71 [Step]13031 [Batch]208500 [Speed]45.59ms/step [Loss]9.4320 [Metrics]{'train_loss:9.4320'}\n",
      "[Train Epoch]1/5 [Time]9528.23 [Step]13062 [Batch]209000 [Speed]45.59ms/step [Loss]9.4316 [Metrics]{'train_loss:9.4316'}\n",
      "[Train Epoch]1/5 [Time]9550.86 [Step]13093 [Batch]209500 [Speed]45.59ms/step [Loss]9.4313 [Metrics]{'train_loss:9.4313'}\n",
      "[Train Epoch]1/5 [Time]9573.44 [Step]13125 [Batch]210000 [Speed]45.59ms/step [Loss]9.4305 [Metrics]{'train_loss:9.4305'}\n",
      "[Train Epoch]1/5 [Time]9596.00 [Step]13156 [Batch]210500 [Speed]45.59ms/step [Loss]9.4302 [Metrics]{'train_loss:9.4302'}\n",
      "[Train Epoch]1/5 [Time]9618.55 [Step]13187 [Batch]211000 [Speed]45.59ms/step [Loss]9.4297 [Metrics]{'train_loss:9.4297'}\n",
      "[Train Epoch]1/5 [Time]9641.06 [Step]13218 [Batch]211500 [Speed]45.58ms/step [Loss]9.4293 [Metrics]{'train_loss:9.4293'}\n",
      "[Train Epoch]1/5 [Time]9663.66 [Step]13250 [Batch]212000 [Speed]45.58ms/step [Loss]9.4287 [Metrics]{'train_loss:9.4287'}\n",
      "[Train Epoch]1/5 [Time]9686.22 [Step]13281 [Batch]212500 [Speed]45.58ms/step [Loss]9.4284 [Metrics]{'train_loss:9.4284'}\n",
      "[Train Epoch]1/5 [Time]9708.84 [Step]13312 [Batch]213000 [Speed]45.58ms/step [Loss]9.4280 [Metrics]{'train_loss:9.4280'}\n",
      "[Train Epoch]1/5 [Time]9731.34 [Step]13343 [Batch]213500 [Speed]45.58ms/step [Loss]9.4275 [Metrics]{'train_loss:9.4275'}\n",
      "[Train Epoch]1/5 [Time]9753.93 [Step]13375 [Batch]214000 [Speed]45.58ms/step [Loss]9.4270 [Metrics]{'train_loss:9.4270'}\n",
      "[Train Epoch]1/5 [Time]9776.49 [Step]13406 [Batch]214500 [Speed]45.58ms/step [Loss]9.4266 [Metrics]{'train_loss:9.4266'}\n",
      "[Train Epoch]1/5 [Time]9798.98 [Step]13437 [Batch]215000 [Speed]45.58ms/step [Loss]9.4261 [Metrics]{'train_loss:9.4261'}\n",
      "[Train Epoch]1/5 [Time]9821.50 [Step]13468 [Batch]215500 [Speed]45.58ms/step [Loss]9.4258 [Metrics]{'train_loss:9.4258'}\n",
      "[Train Epoch]1/5 [Time]9844.11 [Step]13500 [Batch]216000 [Speed]45.57ms/step [Loss]9.4252 [Metrics]{'train_loss:9.4252'}\n",
      "[Train Epoch]1/5 [Time]9866.70 [Step]13531 [Batch]216500 [Speed]45.57ms/step [Loss]9.4248 [Metrics]{'train_loss:9.4248'}\n",
      "[Train Epoch]1/5 [Time]9889.31 [Step]13562 [Batch]217000 [Speed]45.57ms/step [Loss]9.4244 [Metrics]{'train_loss:9.4244'}\n",
      "[Train Epoch]1/5 [Time]9911.87 [Step]13593 [Batch]217500 [Speed]45.57ms/step [Loss]9.4240 [Metrics]{'train_loss:9.4240'}\n",
      "[Train Epoch]1/5 [Time]9934.48 [Step]13625 [Batch]218000 [Speed]45.57ms/step [Loss]9.4235 [Metrics]{'train_loss:9.4235'}\n",
      "[Train Epoch]1/5 [Time]9956.96 [Step]13656 [Batch]218500 [Speed]45.57ms/step [Loss]9.4232 [Metrics]{'train_loss:9.4232'}\n",
      "[Train Epoch]1/5 [Time]9979.52 [Step]13687 [Batch]219000 [Speed]45.57ms/step [Loss]9.4228 [Metrics]{'train_loss:9.4228'}\n",
      "[Train Epoch]1/5 [Time]10002.06 [Step]13718 [Batch]219500 [Speed]45.57ms/step [Loss]9.4224 [Metrics]{'train_loss:9.4224'}\n",
      "[Train Epoch]1/5 [Time]10024.63 [Step]13750 [Batch]220000 [Speed]45.57ms/step [Loss]9.4218 [Metrics]{'train_loss:9.4218'}\n",
      "[Train Epoch]1/5 [Time]10047.21 [Step]13781 [Batch]220500 [Speed]45.57ms/step [Loss]9.4211 [Metrics]{'train_loss:9.4211'}\n",
      "[Train Epoch]1/5 [Time]10069.79 [Step]13812 [Batch]221000 [Speed]45.56ms/step [Loss]9.4207 [Metrics]{'train_loss:9.4207'}\n",
      "[Train Epoch]1/5 [Time]10092.37 [Step]13843 [Batch]221500 [Speed]45.56ms/step [Loss]9.4204 [Metrics]{'train_loss:9.4204'}\n",
      "[Train Epoch]1/5 [Time]10114.87 [Step]13875 [Batch]222000 [Speed]45.56ms/step [Loss]9.4201 [Metrics]{'train_loss:9.4201'}\n",
      "[Train Epoch]1/5 [Time]10137.44 [Step]13906 [Batch]222500 [Speed]45.56ms/step [Loss]9.4196 [Metrics]{'train_loss:9.4196'}\n",
      "[Train Epoch]1/5 [Time]10160.02 [Step]13937 [Batch]223000 [Speed]45.56ms/step [Loss]9.4192 [Metrics]{'train_loss:9.4192'}\n",
      "[Train Epoch]1/5 [Time]10182.60 [Step]13968 [Batch]223500 [Speed]45.56ms/step [Loss]9.4189 [Metrics]{'train_loss:9.4189'}\n",
      "[Train Epoch]1/5 [Time]10205.21 [Step]14000 [Batch]224000 [Speed]45.56ms/step [Loss]9.4185 [Metrics]{'train_loss:9.4185'}\n",
      "[Train Epoch]1/5 [Time]10227.79 [Step]14031 [Batch]224500 [Speed]45.56ms/step [Loss]9.4182 [Metrics]{'train_loss:9.4182'}\n",
      "[Train Epoch]1/5 [Time]10250.40 [Step]14062 [Batch]225000 [Speed]45.56ms/step [Loss]9.4179 [Metrics]{'train_loss:9.4179'}\n",
      "[Train Epoch]1/5 [Time]10272.91 [Step]14093 [Batch]225500 [Speed]45.56ms/step [Loss]9.4173 [Metrics]{'train_loss:9.4173'}\n",
      "[Train Epoch]1/5 [Time]10295.55 [Step]14125 [Batch]226000 [Speed]45.56ms/step [Loss]9.4170 [Metrics]{'train_loss:9.4170'}\n",
      "[Train Epoch]1/5 [Time]10318.10 [Step]14156 [Batch]226500 [Speed]45.55ms/step [Loss]9.4166 [Metrics]{'train_loss:9.4166'}\n",
      "[Train Epoch]1/5 [Time]10340.66 [Step]14187 [Batch]227000 [Speed]45.55ms/step [Loss]9.4160 [Metrics]{'train_loss:9.4160'}\n",
      "[Train Epoch]1/5 [Time]10363.21 [Step]14218 [Batch]227500 [Speed]45.55ms/step [Loss]9.4155 [Metrics]{'train_loss:9.4155'}\n",
      "[Train Epoch]1/5 [Time]10385.81 [Step]14250 [Batch]228000 [Speed]45.55ms/step [Loss]9.4151 [Metrics]{'train_loss:9.4151'}\n",
      "[Train Epoch]1/5 [Time]10408.39 [Step]14281 [Batch]228500 [Speed]45.55ms/step [Loss]9.4147 [Metrics]{'train_loss:9.4147'}\n",
      "[Train Epoch]1/5 [Time]10430.95 [Step]14312 [Batch]229000 [Speed]45.55ms/step [Loss]9.4145 [Metrics]{'train_loss:9.4145'}\n",
      "[Train Epoch]1/5 [Time]10453.57 [Step]14343 [Batch]229500 [Speed]45.55ms/step [Loss]9.4142 [Metrics]{'train_loss:9.4142'}\n",
      "[Train Epoch]1/5 [Time]10476.20 [Step]14375 [Batch]230000 [Speed]45.55ms/step [Loss]9.4137 [Metrics]{'train_loss:9.4137'}\n",
      "[Train Epoch]1/5 [Time]10498.79 [Step]14406 [Batch]230500 [Speed]45.55ms/step [Loss]9.4134 [Metrics]{'train_loss:9.4134'}\n",
      "[Train Epoch]1/5 [Time]10521.35 [Step]14437 [Batch]231000 [Speed]45.55ms/step [Loss]9.4129 [Metrics]{'train_loss:9.4129'}\n",
      "[Train Epoch]1/5 [Time]10543.94 [Step]14468 [Batch]231500 [Speed]45.55ms/step [Loss]9.4124 [Metrics]{'train_loss:9.4124'}\n",
      "[Train Epoch]1/5 [Time]10566.60 [Step]14500 [Batch]232000 [Speed]45.55ms/step [Loss]9.4120 [Metrics]{'train_loss:9.4120'}\n",
      "[Train Epoch]1/5 [Time]10589.11 [Step]14531 [Batch]232500 [Speed]45.54ms/step [Loss]9.4114 [Metrics]{'train_loss:9.4114'}\n",
      "[Train Epoch]1/5 [Time]10611.64 [Step]14562 [Batch]233000 [Speed]45.54ms/step [Loss]9.4109 [Metrics]{'train_loss:9.4109'}\n",
      "[Train Epoch]1/5 [Time]10634.27 [Step]14593 [Batch]233500 [Speed]45.54ms/step [Loss]9.4106 [Metrics]{'train_loss:9.4106'}\n",
      "[Train Epoch]1/5 [Time]10658.89 [Step]14625 [Batch]234000 [Speed]45.55ms/step [Loss]9.4100 [Metrics]{'train_loss:9.4100'}\n",
      "[Train Epoch]1/5 [Time]10682.50 [Step]14656 [Batch]234500 [Speed]45.55ms/step [Loss]9.4096 [Metrics]{'train_loss:9.4096'}\n",
      "[Train Epoch]1/5 [Time]10706.28 [Step]14687 [Batch]235000 [Speed]45.56ms/step [Loss]9.4091 [Metrics]{'train_loss:9.4091'}\n",
      "[Train Epoch]1/5 [Time]10729.18 [Step]14718 [Batch]235500 [Speed]45.56ms/step [Loss]9.4088 [Metrics]{'train_loss:9.4088'}\n",
      "[Train Epoch]1/5 [Time]10753.59 [Step]14750 [Batch]236000 [Speed]45.57ms/step [Loss]9.4085 [Metrics]{'train_loss:9.4085'}\n",
      "[Train Epoch]1/5 [Time]10776.85 [Step]14781 [Batch]236500 [Speed]45.57ms/step [Loss]9.4083 [Metrics]{'train_loss:9.4083'}\n",
      "[Train Epoch]1/5 [Time]10800.21 [Step]14812 [Batch]237000 [Speed]45.57ms/step [Loss]9.4077 [Metrics]{'train_loss:9.4077'}\n",
      "[Train Epoch]1/5 [Time]10823.36 [Step]14843 [Batch]237500 [Speed]45.57ms/step [Loss]9.4073 [Metrics]{'train_loss:9.4073'}\n",
      "[Train Epoch]1/5 [Time]10846.11 [Step]14875 [Batch]238000 [Speed]45.57ms/step [Loss]9.4070 [Metrics]{'train_loss:9.4070'}\n",
      "[Train Epoch]1/5 [Time]10869.61 [Step]14906 [Batch]238500 [Speed]45.57ms/step [Loss]9.4066 [Metrics]{'train_loss:9.4066'}\n",
      "[Train Epoch]1/5 [Time]10892.59 [Step]14937 [Batch]239000 [Speed]45.58ms/step [Loss]9.4061 [Metrics]{'train_loss:9.4061'}\n",
      "[Train Epoch]1/5 [Time]10916.71 [Step]14968 [Batch]239500 [Speed]45.58ms/step [Loss]9.4057 [Metrics]{'train_loss:9.4057'}\n",
      "Saving checkpoint for epoch 1 at step 240000 on path ../2_Models/model_bert4rec_complete_0.5/checkpoints/\n",
      "[Train Epoch]1/5 [Time]10941.80 [Step]15000 [Batch]240000 [Speed]45.59ms/step [Loss]9.4053 [Metrics]{'train_loss:9.4053'}\n",
      "[Train Epoch]1/5 [Time]10965.02 [Step]15031 [Batch]240500 [Speed]45.59ms/step [Loss]9.4049 [Metrics]{'train_loss:9.4049'}\n",
      "[Train Epoch]1/5 [Time]10989.02 [Step]15062 [Batch]241000 [Speed]45.60ms/step [Loss]9.4045 [Metrics]{'train_loss:9.4045'}\n",
      "[Train Epoch]1/5 [Time]11012.75 [Step]15093 [Batch]241500 [Speed]45.60ms/step [Loss]9.4042 [Metrics]{'train_loss:9.4042'}\n",
      "[Train Epoch]1/5 [Time]11036.30 [Step]15125 [Batch]242000 [Speed]45.60ms/step [Loss]9.4039 [Metrics]{'train_loss:9.4039'}\n",
      "[Train Epoch]1/5 [Time]11059.77 [Step]15156 [Batch]242500 [Speed]45.61ms/step [Loss]9.4035 [Metrics]{'train_loss:9.4035'}\n",
      "[Train Epoch]1/5 [Time]11083.86 [Step]15187 [Batch]243000 [Speed]45.61ms/step [Loss]9.4031 [Metrics]{'train_loss:9.4031'}\n",
      "[Train Epoch]1/5 [Time]11108.28 [Step]15218 [Batch]243500 [Speed]45.62ms/step [Loss]9.4027 [Metrics]{'train_loss:9.4027'}\n",
      "[Train Epoch]1/5 [Time]11131.58 [Step]15250 [Batch]244000 [Speed]45.62ms/step [Loss]9.4024 [Metrics]{'train_loss:9.4024'}\n",
      "[Train Epoch]1/5 [Time]11155.38 [Step]15281 [Batch]244500 [Speed]45.63ms/step [Loss]9.4020 [Metrics]{'train_loss:9.4020'}\n",
      "[Train Epoch]1/5 [Time]11179.05 [Step]15312 [Batch]245000 [Speed]45.63ms/step [Loss]9.4015 [Metrics]{'train_loss:9.4015'}\n",
      "[Train Epoch]1/5 [Time]11201.82 [Step]15343 [Batch]245500 [Speed]45.63ms/step [Loss]9.4011 [Metrics]{'train_loss:9.4011'}\n",
      "[Train Epoch]1/5 [Time]11225.74 [Step]15375 [Batch]246000 [Speed]45.63ms/step [Loss]9.4009 [Metrics]{'train_loss:9.4009'}\n",
      "[Train Epoch]1/5 [Time]11249.56 [Step]15406 [Batch]246500 [Speed]45.64ms/step [Loss]9.4005 [Metrics]{'train_loss:9.4005'}\n",
      "[Train Epoch]1/5 [Time]11273.29 [Step]15437 [Batch]247000 [Speed]45.64ms/step [Loss]9.4002 [Metrics]{'train_loss:9.4002'}\n",
      "[Train Epoch]1/5 [Time]11296.55 [Step]15468 [Batch]247500 [Speed]45.64ms/step [Loss]9.3998 [Metrics]{'train_loss:9.3998'}\n",
      "[Train Epoch]1/5 [Time]11320.04 [Step]15500 [Batch]248000 [Speed]45.65ms/step [Loss]9.3993 [Metrics]{'train_loss:9.3993'}\n",
      "[Train Epoch]1/5 [Time]11343.27 [Step]15531 [Batch]248500 [Speed]45.65ms/step [Loss]9.3989 [Metrics]{'train_loss:9.3989'}\n",
      "[Train Epoch]1/5 [Time]11366.98 [Step]15562 [Batch]249000 [Speed]45.65ms/step [Loss]9.3986 [Metrics]{'train_loss:9.3986'}\n",
      "[Train Epoch]1/5 [Time]11390.24 [Step]15593 [Batch]249500 [Speed]45.65ms/step [Loss]9.3983 [Metrics]{'train_loss:9.3983'}\n",
      "[Train Epoch]1/5 [Time]11413.62 [Step]15625 [Batch]250000 [Speed]45.65ms/step [Loss]9.3979 [Metrics]{'train_loss:9.3979'}\n",
      "[Train Epoch]1/5 [Time]11436.91 [Step]15656 [Batch]250500 [Speed]45.66ms/step [Loss]9.3976 [Metrics]{'train_loss:9.3976'}\n",
      "[Train Epoch]1/5 [Time]11460.16 [Step]15687 [Batch]251000 [Speed]45.66ms/step [Loss]9.3973 [Metrics]{'train_loss:9.3973'}\n",
      "[Train Epoch]1/5 [Time]11484.00 [Step]15718 [Batch]251500 [Speed]45.66ms/step [Loss]9.3970 [Metrics]{'train_loss:9.3970'}\n",
      "[Train Epoch]1/5 [Time]11507.31 [Step]15750 [Batch]252000 [Speed]45.66ms/step [Loss]9.3966 [Metrics]{'train_loss:9.3966'}\n",
      "[Train Epoch]1/5 [Time]11530.94 [Step]15781 [Batch]252500 [Speed]45.67ms/step [Loss]9.3962 [Metrics]{'train_loss:9.3962'}\n",
      "[Train Epoch]1/5 [Time]11554.42 [Step]15812 [Batch]253000 [Speed]45.67ms/step [Loss]9.3961 [Metrics]{'train_loss:9.3961'}\n",
      "[Train Epoch]1/5 [Time]11577.70 [Step]15843 [Batch]253500 [Speed]45.67ms/step [Loss]9.3957 [Metrics]{'train_loss:9.3957'}\n",
      "[Train Epoch]1/5 [Time]11601.05 [Step]15875 [Batch]254000 [Speed]45.67ms/step [Loss]9.3953 [Metrics]{'train_loss:9.3953'}\n",
      "[Train Epoch]1/5 [Time]11624.30 [Step]15906 [Batch]254500 [Speed]45.68ms/step [Loss]9.3949 [Metrics]{'train_loss:9.3949'}\n",
      "[Train Epoch]1/5 [Time]11647.61 [Step]15937 [Batch]255000 [Speed]45.68ms/step [Loss]9.3946 [Metrics]{'train_loss:9.3946'}\n",
      "[Train Epoch]1/5 [Time]11670.97 [Step]15968 [Batch]255500 [Speed]45.68ms/step [Loss]9.3945 [Metrics]{'train_loss:9.3945'}\n",
      "[Train Epoch]1/5 [Time]11694.34 [Step]16000 [Batch]256000 [Speed]45.68ms/step [Loss]9.3942 [Metrics]{'train_loss:9.3942'}\n",
      "[Train Epoch]1/5 [Time]11717.50 [Step]16031 [Batch]256500 [Speed]45.68ms/step [Loss]9.3938 [Metrics]{'train_loss:9.3938'}\n",
      "[Train Epoch]1/5 [Time]11740.81 [Step]16062 [Batch]257000 [Speed]45.68ms/step [Loss]9.3935 [Metrics]{'train_loss:9.3935'}\n",
      "[Train Epoch]1/5 [Time]11764.05 [Step]16093 [Batch]257500 [Speed]45.69ms/step [Loss]9.3930 [Metrics]{'train_loss:9.3930'}\n",
      "[Train Epoch]1/5 [Time]11787.42 [Step]16125 [Batch]258000 [Speed]45.69ms/step [Loss]9.3927 [Metrics]{'train_loss:9.3927'}\n",
      "[Train Epoch]1/5 [Time]11810.71 [Step]16156 [Batch]258500 [Speed]45.69ms/step [Loss]9.3923 [Metrics]{'train_loss:9.3923'}\n",
      "[Train Epoch]1/5 [Time]11833.91 [Step]16187 [Batch]259000 [Speed]45.69ms/step [Loss]9.3919 [Metrics]{'train_loss:9.3919'}\n",
      "[Train Epoch]1/5 [Time]11857.22 [Step]16218 [Batch]259500 [Speed]45.69ms/step [Loss]9.3914 [Metrics]{'train_loss:9.3914'}\n",
      "[Train Epoch]1/5 [Time]11880.45 [Step]16250 [Batch]260000 [Speed]45.69ms/step [Loss]9.3911 [Metrics]{'train_loss:9.3911'}\n",
      "[Train Epoch]1/5 [Time]11903.82 [Step]16281 [Batch]260500 [Speed]45.70ms/step [Loss]9.3909 [Metrics]{'train_loss:9.3909'}\n",
      "[Train Epoch]1/5 [Time]11927.07 [Step]16312 [Batch]261000 [Speed]45.70ms/step [Loss]9.3905 [Metrics]{'train_loss:9.3905'}\n",
      "[Train Epoch]1/5 [Time]11950.34 [Step]16343 [Batch]261500 [Speed]45.70ms/step [Loss]9.3901 [Metrics]{'train_loss:9.3901'}\n",
      "[Train Epoch]1/5 [Time]11973.65 [Step]16375 [Batch]262000 [Speed]45.70ms/step [Loss]9.3900 [Metrics]{'train_loss:9.3900'}\n",
      "[Train Epoch]1/5 [Time]11996.84 [Step]16406 [Batch]262500 [Speed]45.70ms/step [Loss]9.3896 [Metrics]{'train_loss:9.3896'}\n",
      "[Train Epoch]1/5 [Time]12020.12 [Step]16437 [Batch]263000 [Speed]45.70ms/step [Loss]9.3892 [Metrics]{'train_loss:9.3892'}\n",
      "[Train Epoch]1/5 [Time]12043.31 [Step]16468 [Batch]263500 [Speed]45.71ms/step [Loss]9.3888 [Metrics]{'train_loss:9.3888'}\n",
      "[Train Epoch]1/5 [Time]12066.67 [Step]16500 [Batch]264000 [Speed]45.71ms/step [Loss]9.3885 [Metrics]{'train_loss:9.3885'}\n",
      "[Train Epoch]1/5 [Time]12089.91 [Step]16531 [Batch]264500 [Speed]45.71ms/step [Loss]9.3883 [Metrics]{'train_loss:9.3883'}\n",
      "[Train Epoch]1/5 [Time]12113.19 [Step]16562 [Batch]265000 [Speed]45.71ms/step [Loss]9.3880 [Metrics]{'train_loss:9.3880'}\n",
      "[Train Epoch]1/5 [Time]12136.45 [Step]16593 [Batch]265500 [Speed]45.71ms/step [Loss]9.3877 [Metrics]{'train_loss:9.3877'}\n",
      "[Train Epoch]1/5 [Time]12159.72 [Step]16625 [Batch]266000 [Speed]45.71ms/step [Loss]9.3875 [Metrics]{'train_loss:9.3875'}\n",
      "[Train Epoch]1/5 [Time]12182.90 [Step]16656 [Batch]266500 [Speed]45.71ms/step [Loss]9.3871 [Metrics]{'train_loss:9.3871'}\n",
      "[Train Epoch]1/5 [Time]12206.21 [Step]16687 [Batch]267000 [Speed]45.72ms/step [Loss]9.3869 [Metrics]{'train_loss:9.3869'}\n",
      "[Train Epoch]1/5 [Time]12229.43 [Step]16718 [Batch]267500 [Speed]45.72ms/step [Loss]9.3866 [Metrics]{'train_loss:9.3866'}\n",
      "[Train Epoch]1/5 [Time]12252.68 [Step]16750 [Batch]268000 [Speed]45.72ms/step [Loss]9.3863 [Metrics]{'train_loss:9.3863'}\n",
      "[Train Epoch]1/5 [Time]12275.98 [Step]16781 [Batch]268500 [Speed]45.72ms/step [Loss]9.3861 [Metrics]{'train_loss:9.3861'}\n",
      "[Train Epoch]1/5 [Time]12299.21 [Step]16812 [Batch]269000 [Speed]45.72ms/step [Loss]9.3857 [Metrics]{'train_loss:9.3857'}\n",
      "[Train Epoch]1/5 [Time]12322.42 [Step]16843 [Batch]269500 [Speed]45.72ms/step [Loss]9.3853 [Metrics]{'train_loss:9.3853'}\n",
      "[Train Epoch]1/5 [Time]12345.76 [Step]16875 [Batch]270000 [Speed]45.73ms/step [Loss]9.3851 [Metrics]{'train_loss:9.3851'}\n",
      "[Train Epoch]1/5 [Time]12369.02 [Step]16906 [Batch]270500 [Speed]45.73ms/step [Loss]9.3847 [Metrics]{'train_loss:9.3847'}\n",
      "[Train Epoch]1/5 [Time]12392.19 [Step]16937 [Batch]271000 [Speed]45.73ms/step [Loss]9.3844 [Metrics]{'train_loss:9.3844'}\n",
      "[Train Epoch]1/5 [Time]12415.19 [Step]16968 [Batch]271500 [Speed]45.73ms/step [Loss]9.3841 [Metrics]{'train_loss:9.3841'}\n",
      "[Train Epoch]1/5 [Time]12437.87 [Step]17000 [Batch]272000 [Speed]45.73ms/step [Loss]9.3836 [Metrics]{'train_loss:9.3836'}\n",
      "[Train Epoch]1/5 [Time]12460.52 [Step]17031 [Batch]272500 [Speed]45.73ms/step [Loss]9.3833 [Metrics]{'train_loss:9.3833'}\n",
      "[Train Epoch]1/5 [Time]12483.22 [Step]17062 [Batch]273000 [Speed]45.73ms/step [Loss]9.3828 [Metrics]{'train_loss:9.3828'}\n",
      "[Train Epoch]1/5 [Time]12505.86 [Step]17093 [Batch]273500 [Speed]45.73ms/step [Loss]9.3824 [Metrics]{'train_loss:9.3824'}\n",
      "[Train Epoch]1/5 [Time]12528.56 [Step]17125 [Batch]274000 [Speed]45.72ms/step [Loss]9.3822 [Metrics]{'train_loss:9.3822'}\n",
      "[Train Epoch]1/5 [Time]12551.17 [Step]17156 [Batch]274500 [Speed]45.72ms/step [Loss]9.3820 [Metrics]{'train_loss:9.3820'}\n",
      "[Train Epoch]1/5 [Time]12573.81 [Step]17187 [Batch]275000 [Speed]45.72ms/step [Loss]9.3816 [Metrics]{'train_loss:9.3816'}\n",
      "[Train Epoch]1/5 [Time]12596.50 [Step]17218 [Batch]275500 [Speed]45.72ms/step [Loss]9.3813 [Metrics]{'train_loss:9.3813'}\n",
      "[Train Epoch]1/5 [Time]12619.11 [Step]17250 [Batch]276000 [Speed]45.72ms/step [Loss]9.3809 [Metrics]{'train_loss:9.3809'}\n",
      "[Train Epoch]1/5 [Time]12641.76 [Step]17281 [Batch]276500 [Speed]45.72ms/step [Loss]9.3806 [Metrics]{'train_loss:9.3806'}\n",
      "[Train Epoch]1/5 [Time]12664.44 [Step]17312 [Batch]277000 [Speed]45.72ms/step [Loss]9.3804 [Metrics]{'train_loss:9.3804'}\n",
      "[Train Epoch]1/5 [Time]12687.01 [Step]17343 [Batch]277500 [Speed]45.72ms/step [Loss]9.3802 [Metrics]{'train_loss:9.3802'}\n",
      "[Train Epoch]1/5 [Time]12709.73 [Step]17375 [Batch]278000 [Speed]45.72ms/step [Loss]9.3800 [Metrics]{'train_loss:9.3800'}\n",
      "[Train Epoch]1/5 [Time]12732.40 [Step]17406 [Batch]278500 [Speed]45.72ms/step [Loss]9.3798 [Metrics]{'train_loss:9.3798'}\n",
      "[Train Epoch]1/5 [Time]12755.09 [Step]17437 [Batch]279000 [Speed]45.72ms/step [Loss]9.3794 [Metrics]{'train_loss:9.3794'}\n",
      "[Train Epoch]1/5 [Time]12777.81 [Step]17468 [Batch]279500 [Speed]45.72ms/step [Loss]9.3792 [Metrics]{'train_loss:9.3792'}\n",
      "[Train Epoch]1/5 [Time]12800.57 [Step]17500 [Batch]280000 [Speed]45.72ms/step [Loss]9.3791 [Metrics]{'train_loss:9.3791'}\n",
      "[Train Epoch]1/5 [Time]12824.04 [Step]17531 [Batch]280500 [Speed]45.72ms/step [Loss]9.3787 [Metrics]{'train_loss:9.3787'}\n",
      "[Train Epoch]1/5 [Time]12848.29 [Step]17562 [Batch]281000 [Speed]45.72ms/step [Loss]9.3785 [Metrics]{'train_loss:9.3785'}\n",
      "[Train Epoch]1/5 [Time]12872.11 [Step]17593 [Batch]281500 [Speed]45.73ms/step [Loss]9.3780 [Metrics]{'train_loss:9.3780'}\n",
      "[Train Epoch]1/5 [Time]12896.05 [Step]17625 [Batch]282000 [Speed]45.73ms/step [Loss]9.3776 [Metrics]{'train_loss:9.3776'}\n",
      "[Train Epoch]1/5 [Time]12918.67 [Step]17656 [Batch]282500 [Speed]45.73ms/step [Loss]9.3773 [Metrics]{'train_loss:9.3773'}\n",
      "[Train Epoch]1/5 [Time]12941.33 [Step]17687 [Batch]283000 [Speed]45.73ms/step [Loss]9.3770 [Metrics]{'train_loss:9.3770'}\n",
      "[Train Epoch]1/5 [Time]12964.00 [Step]17718 [Batch]283500 [Speed]45.73ms/step [Loss]9.3767 [Metrics]{'train_loss:9.3767'}\n",
      "[Train Epoch]1/5 [Time]12986.72 [Step]17750 [Batch]284000 [Speed]45.73ms/step [Loss]9.3764 [Metrics]{'train_loss:9.3764'}\n",
      "[Train Epoch]1/5 [Time]13009.38 [Step]17781 [Batch]284500 [Speed]45.73ms/step [Loss]9.3763 [Metrics]{'train_loss:9.3763'}\n",
      "[Train Epoch]1/5 [Time]13032.05 [Step]17812 [Batch]285000 [Speed]45.73ms/step [Loss]9.3761 [Metrics]{'train_loss:9.3761'}\n",
      "[Train Epoch]1/5 [Time]13054.71 [Step]17843 [Batch]285500 [Speed]45.73ms/step [Loss]9.3760 [Metrics]{'train_loss:9.3760'}\n",
      "[Train Epoch]1/5 [Time]13077.35 [Step]17875 [Batch]286000 [Speed]45.73ms/step [Loss]9.3756 [Metrics]{'train_loss:9.3756'}\n",
      "[Train Epoch]1/5 [Time]13100.04 [Step]17906 [Batch]286500 [Speed]45.72ms/step [Loss]9.3752 [Metrics]{'train_loss:9.3752'}\n",
      "[Train Epoch]1/5 [Time]13122.65 [Step]17937 [Batch]287000 [Speed]45.72ms/step [Loss]9.3750 [Metrics]{'train_loss:9.3750'}\n",
      "[Train Epoch]1/5 [Time]13145.36 [Step]17968 [Batch]287500 [Speed]45.72ms/step [Loss]9.3747 [Metrics]{'train_loss:9.3747'}\n",
      "[Train Epoch]1/5 [Time]13168.02 [Step]18000 [Batch]288000 [Speed]45.72ms/step [Loss]9.3744 [Metrics]{'train_loss:9.3744'}\n",
      "[Train Epoch]1/5 [Time]13190.69 [Step]18031 [Batch]288500 [Speed]45.72ms/step [Loss]9.3742 [Metrics]{'train_loss:9.3742'}\n",
      "[Train Epoch]1/5 [Time]13213.34 [Step]18062 [Batch]289000 [Speed]45.72ms/step [Loss]9.3738 [Metrics]{'train_loss:9.3738'}\n",
      "[Train Epoch]1/5 [Time]13235.89 [Step]18093 [Batch]289500 [Speed]45.72ms/step [Loss]9.3736 [Metrics]{'train_loss:9.3736'}\n",
      "[Train Epoch]1/5 [Time]13258.58 [Step]18125 [Batch]290000 [Speed]45.72ms/step [Loss]9.3733 [Metrics]{'train_loss:9.3733'}\n",
      "[Train Epoch]1/5 [Time]13281.25 [Step]18156 [Batch]290500 [Speed]45.72ms/step [Loss]9.3730 [Metrics]{'train_loss:9.3730'}\n",
      "[Train Epoch]1/5 [Time]13303.92 [Step]18187 [Batch]291000 [Speed]45.72ms/step [Loss]9.3728 [Metrics]{'train_loss:9.3728'}\n",
      "[Train Epoch]1/5 [Time]13326.57 [Step]18218 [Batch]291500 [Speed]45.72ms/step [Loss]9.3724 [Metrics]{'train_loss:9.3724'}\n",
      "[Train Epoch]1/5 [Time]13349.32 [Step]18250 [Batch]292000 [Speed]45.72ms/step [Loss]9.3721 [Metrics]{'train_loss:9.3721'}\n",
      "[Train Epoch]1/5 [Time]13371.98 [Step]18281 [Batch]292500 [Speed]45.72ms/step [Loss]9.3718 [Metrics]{'train_loss:9.3718'}\n",
      "[Train Epoch]1/5 [Time]13394.62 [Step]18312 [Batch]293000 [Speed]45.72ms/step [Loss]9.3716 [Metrics]{'train_loss:9.3716'}\n",
      "[Train Epoch]1/5 [Time]13417.30 [Step]18343 [Batch]293500 [Speed]45.71ms/step [Loss]9.3712 [Metrics]{'train_loss:9.3712'}\n",
      "[Train Epoch]1/5 [Time]13439.94 [Step]18375 [Batch]294000 [Speed]45.71ms/step [Loss]9.3708 [Metrics]{'train_loss:9.3708'}\n",
      "[Train Epoch]1/5 [Time]13462.60 [Step]18406 [Batch]294500 [Speed]45.71ms/step [Loss]9.3704 [Metrics]{'train_loss:9.3704'}\n",
      "[Train Epoch]1/5 [Time]13485.27 [Step]18437 [Batch]295000 [Speed]45.71ms/step [Loss]9.3700 [Metrics]{'train_loss:9.3700'}\n",
      "[Train Epoch]1/5 [Time]13507.94 [Step]18468 [Batch]295500 [Speed]45.71ms/step [Loss]9.3697 [Metrics]{'train_loss:9.3697'}\n",
      "[Train Epoch]1/5 [Time]13530.65 [Step]18500 [Batch]296000 [Speed]45.71ms/step [Loss]9.3693 [Metrics]{'train_loss:9.3693'}\n",
      "[Train Epoch]1/5 [Time]13553.22 [Step]18531 [Batch]296500 [Speed]45.71ms/step [Loss]9.3690 [Metrics]{'train_loss:9.3690'}\n",
      "[Train Epoch]1/5 [Time]13575.84 [Step]18562 [Batch]297000 [Speed]45.71ms/step [Loss]9.3688 [Metrics]{'train_loss:9.3688'}\n",
      "[Train Epoch]1/5 [Time]13598.50 [Step]18593 [Batch]297500 [Speed]45.71ms/step [Loss]9.3686 [Metrics]{'train_loss:9.3686'}\n",
      "[Train Epoch]1/5 [Time]13621.19 [Step]18625 [Batch]298000 [Speed]45.71ms/step [Loss]9.3683 [Metrics]{'train_loss:9.3683'}\n",
      "[Train Epoch]1/5 [Time]13643.91 [Step]18656 [Batch]298500 [Speed]45.71ms/step [Loss]9.3681 [Metrics]{'train_loss:9.3681'}\n",
      "[Train Epoch]1/5 [Time]13666.56 [Step]18687 [Batch]299000 [Speed]45.71ms/step [Loss]9.3678 [Metrics]{'train_loss:9.3678'}\n",
      "[Train Epoch]1/5 [Time]13689.21 [Step]18718 [Batch]299500 [Speed]45.71ms/step [Loss]9.3676 [Metrics]{'train_loss:9.3676'}\n",
      "[Train Epoch]1/5 [Time]13711.82 [Step]18750 [Batch]300000 [Speed]45.71ms/step [Loss]9.3674 [Metrics]{'train_loss:9.3674'}\n",
      "[Train Epoch]1/5 [Time]13734.52 [Step]18781 [Batch]300500 [Speed]45.71ms/step [Loss]9.3670 [Metrics]{'train_loss:9.3670'}\n",
      "[Train Epoch]1/5 [Time]13757.18 [Step]18812 [Batch]301000 [Speed]45.70ms/step [Loss]9.3669 [Metrics]{'train_loss:9.3669'}\n",
      "[Train Epoch]1/5 [Time]13779.88 [Step]18843 [Batch]301500 [Speed]45.70ms/step [Loss]9.3665 [Metrics]{'train_loss:9.3665'}\n",
      "[Train Epoch]1/5 [Time]13802.59 [Step]18875 [Batch]302000 [Speed]45.70ms/step [Loss]9.3662 [Metrics]{'train_loss:9.3662'}\n",
      "[Train Epoch]1/5 [Time]13825.30 [Step]18906 [Batch]302500 [Speed]45.70ms/step [Loss]9.3660 [Metrics]{'train_loss:9.3660'}\n",
      "[Train Epoch]1/5 [Time]13847.92 [Step]18937 [Batch]303000 [Speed]45.70ms/step [Loss]9.3656 [Metrics]{'train_loss:9.3656'}\n",
      "[Train Epoch]1/5 [Time]13870.53 [Step]18968 [Batch]303500 [Speed]45.70ms/step [Loss]9.3654 [Metrics]{'train_loss:9.3654'}\n",
      "[Train Epoch]1/5 [Time]13893.22 [Step]19000 [Batch]304000 [Speed]45.70ms/step [Loss]9.3650 [Metrics]{'train_loss:9.3650'}\n",
      "[Train Epoch]1/5 [Time]13915.87 [Step]19031 [Batch]304500 [Speed]45.70ms/step [Loss]9.3647 [Metrics]{'train_loss:9.3647'}\n",
      "[Train Epoch]1/5 [Time]13938.56 [Step]19062 [Batch]305000 [Speed]45.70ms/step [Loss]9.3644 [Metrics]{'train_loss:9.3644'}\n",
      "[Train Epoch]1/5 [Time]13961.28 [Step]19093 [Batch]305500 [Speed]45.70ms/step [Loss]9.3641 [Metrics]{'train_loss:9.3641'}\n",
      "[Train Epoch]1/5 [Time]13983.98 [Step]19125 [Batch]306000 [Speed]45.70ms/step [Loss]9.3638 [Metrics]{'train_loss:9.3638'}\n",
      "[Train Epoch]1/5 [Time]14006.63 [Step]19156 [Batch]306500 [Speed]45.70ms/step [Loss]9.3638 [Metrics]{'train_loss:9.3638'}\n",
      "[Train Epoch]1/5 [Time]14029.29 [Step]19187 [Batch]307000 [Speed]45.70ms/step [Loss]9.3636 [Metrics]{'train_loss:9.3636'}\n",
      "[Train Epoch]1/5 [Time]14051.96 [Step]19218 [Batch]307500 [Speed]45.70ms/step [Loss]9.3634 [Metrics]{'train_loss:9.3634'}\n",
      "[Train Epoch]1/5 [Time]14074.68 [Step]19250 [Batch]308000 [Speed]45.70ms/step [Loss]9.3631 [Metrics]{'train_loss:9.3631'}\n",
      "[Train Epoch]1/5 [Time]14097.39 [Step]19281 [Batch]308500 [Speed]45.70ms/step [Loss]9.3628 [Metrics]{'train_loss:9.3628'}\n",
      "[Train Epoch]1/5 [Time]14120.11 [Step]19312 [Batch]309000 [Speed]45.70ms/step [Loss]9.3626 [Metrics]{'train_loss:9.3626'}\n",
      "[Train Epoch]1/5 [Time]14142.80 [Step]19343 [Batch]309500 [Speed]45.70ms/step [Loss]9.3623 [Metrics]{'train_loss:9.3623'}\n",
      "[Train Epoch]1/5 [Time]14165.54 [Step]19375 [Batch]310000 [Speed]45.70ms/step [Loss]9.3619 [Metrics]{'train_loss:9.3619'}\n",
      "[Train Epoch]1/5 [Time]14188.16 [Step]19406 [Batch]310500 [Speed]45.69ms/step [Loss]9.3616 [Metrics]{'train_loss:9.3616'}\n",
      "[Train Epoch]1/5 [Time]14210.86 [Step]19437 [Batch]311000 [Speed]45.69ms/step [Loss]9.3614 [Metrics]{'train_loss:9.3614'}\n",
      "[Train Epoch]1/5 [Time]14233.61 [Step]19468 [Batch]311500 [Speed]45.69ms/step [Loss]9.3613 [Metrics]{'train_loss:9.3613'}\n",
      "[Train Epoch]1/5 [Time]14256.35 [Step]19500 [Batch]312000 [Speed]45.69ms/step [Loss]9.3610 [Metrics]{'train_loss:9.3610'}\n",
      "[Train Epoch]1/5 [Time]14279.04 [Step]19531 [Batch]312500 [Speed]45.69ms/step [Loss]9.3607 [Metrics]{'train_loss:9.3607'}\n",
      "[Train Epoch]1/5 [Time]14301.77 [Step]19562 [Batch]313000 [Speed]45.69ms/step [Loss]9.3603 [Metrics]{'train_loss:9.3603'}\n",
      "[Train Epoch]1/5 [Time]14324.48 [Step]19593 [Batch]313500 [Speed]45.69ms/step [Loss]9.3601 [Metrics]{'train_loss:9.3601'}\n",
      "[Train Epoch]1/5 [Time]14347.11 [Step]19625 [Batch]314000 [Speed]45.69ms/step [Loss]9.3599 [Metrics]{'train_loss:9.3599'}\n",
      "[Train Epoch]1/5 [Time]14369.87 [Step]19656 [Batch]314500 [Speed]45.69ms/step [Loss]9.3596 [Metrics]{'train_loss:9.3596'}\n",
      "[Train Epoch]1/5 [Time]14392.58 [Step]19687 [Batch]315000 [Speed]45.69ms/step [Loss]9.3592 [Metrics]{'train_loss:9.3592'}\n",
      "[Train Epoch]1/5 [Time]14415.26 [Step]19718 [Batch]315500 [Speed]45.69ms/step [Loss]9.3590 [Metrics]{'train_loss:9.3590'}\n",
      "[Train Epoch]1/5 [Time]14437.94 [Step]19750 [Batch]316000 [Speed]45.69ms/step [Loss]9.3587 [Metrics]{'train_loss:9.3587'}\n",
      "[Train Epoch]1/5 [Time]14460.66 [Step]19781 [Batch]316500 [Speed]45.69ms/step [Loss]9.3585 [Metrics]{'train_loss:9.3585'}\n",
      "[Train Epoch]1/5 [Time]14483.34 [Step]19812 [Batch]317000 [Speed]45.69ms/step [Loss]9.3581 [Metrics]{'train_loss:9.3581'}\n",
      "[Train Epoch]1/5 [Time]14505.94 [Step]19843 [Batch]317500 [Speed]45.69ms/step [Loss]9.3578 [Metrics]{'train_loss:9.3578'}\n",
      "[Train Epoch]1/5 [Time]14528.71 [Step]19875 [Batch]318000 [Speed]45.69ms/step [Loss]9.3576 [Metrics]{'train_loss:9.3576'}\n",
      "[Train Epoch]1/5 [Time]14551.39 [Step]19906 [Batch]318500 [Speed]45.69ms/step [Loss]9.3574 [Metrics]{'train_loss:9.3574'}\n",
      "[Train Epoch]1/5 [Time]14574.11 [Step]19937 [Batch]319000 [Speed]45.69ms/step [Loss]9.3571 [Metrics]{'train_loss:9.3571'}\n",
      "[Train Epoch]1/5 [Time]14596.82 [Step]19968 [Batch]319500 [Speed]45.69ms/step [Loss]9.3568 [Metrics]{'train_loss:9.3568'}\n",
      "Saving checkpoint for epoch 1 at step 320000 on path ../2_Models/model_bert4rec_complete_0.5/checkpoints/\n",
      "[Train Epoch]1/5 [Time]14621.31 [Step]20000 [Batch]320000 [Speed]45.69ms/step [Loss]9.3565 [Metrics]{'train_loss:9.3565'}\n",
      "[Train Epoch]1/5 [Time]14644.04 [Step]20031 [Batch]320500 [Speed]45.69ms/step [Loss]9.3563 [Metrics]{'train_loss:9.3563'}\n",
      "[Train Epoch]1/5 [Time]14666.81 [Step]20062 [Batch]321000 [Speed]45.69ms/step [Loss]9.3562 [Metrics]{'train_loss:9.3562'}\n",
      "[Train Epoch]1/5 [Time]14689.55 [Step]20093 [Batch]321500 [Speed]45.69ms/step [Loss]9.3563 [Metrics]{'train_loss:9.3563'}\n",
      "[Train Epoch]1/5 [Time]14712.32 [Step]20125 [Batch]322000 [Speed]45.69ms/step [Loss]9.3563 [Metrics]{'train_loss:9.3563'}\n",
      "[Train Epoch]1/5 [Time]14734.92 [Step]20156 [Batch]322500 [Speed]45.69ms/step [Loss]9.3561 [Metrics]{'train_loss:9.3561'}\n",
      "[Train Epoch]1/5 [Time]14757.61 [Step]20187 [Batch]323000 [Speed]45.69ms/step [Loss]9.3561 [Metrics]{'train_loss:9.3561'}\n",
      "[Train Epoch]1/5 [Time]14780.31 [Step]20218 [Batch]323500 [Speed]45.69ms/step [Loss]9.3562 [Metrics]{'train_loss:9.3562'}\n",
      "[Train Epoch]1/5 [Time]14803.04 [Step]20250 [Batch]324000 [Speed]45.69ms/step [Loss]9.3562 [Metrics]{'train_loss:9.3562'}\n",
      "[Train Epoch]1/5 [Time]14825.73 [Step]20281 [Batch]324500 [Speed]45.69ms/step [Loss]9.3561 [Metrics]{'train_loss:9.3561'}\n",
      "[Train Epoch]1/5 [Time]14848.48 [Step]20312 [Batch]325000 [Speed]45.69ms/step [Loss]9.3561 [Metrics]{'train_loss:9.3561'}\n",
      "[Train Epoch]1/5 [Time]14871.22 [Step]20343 [Batch]325500 [Speed]45.69ms/step [Loss]9.3560 [Metrics]{'train_loss:9.3560'}\n",
      "[Train Epoch]1/5 [Time]14893.84 [Step]20375 [Batch]326000 [Speed]45.69ms/step [Loss]9.3560 [Metrics]{'train_loss:9.3560'}\n",
      "[Train Epoch]1/5 [Time]14916.62 [Step]20406 [Batch]326500 [Speed]45.69ms/step [Loss]9.3559 [Metrics]{'train_loss:9.3559'}\n",
      "[Train Epoch]1/5 [Time]14939.29 [Step]20437 [Batch]327000 [Speed]45.69ms/step [Loss]9.3560 [Metrics]{'train_loss:9.3560'}\n",
      "[Train Epoch]1/5 [Time]14962.03 [Step]20468 [Batch]327500 [Speed]45.69ms/step [Loss]9.3560 [Metrics]{'train_loss:9.3560'}\n",
      "[Train Epoch]1/5 [Time]14984.76 [Step]20500 [Batch]328000 [Speed]45.69ms/step [Loss]9.3560 [Metrics]{'train_loss:9.3560'}\n",
      "[Train Epoch]1/5 [Time]15007.50 [Step]20531 [Batch]328500 [Speed]45.68ms/step [Loss]9.3560 [Metrics]{'train_loss:9.3560'}\n",
      "[Train Epoch]1/5 [Time]15030.18 [Step]20562 [Batch]329000 [Speed]45.68ms/step [Loss]9.3559 [Metrics]{'train_loss:9.3559'}\n",
      "[Train Epoch]1/5 [Time]15052.80 [Step]20593 [Batch]329500 [Speed]45.68ms/step [Loss]9.3558 [Metrics]{'train_loss:9.3558'}\n",
      "[Train Epoch]1/5 [Time]15075.54 [Step]20625 [Batch]330000 [Speed]45.68ms/step [Loss]9.3558 [Metrics]{'train_loss:9.3558'}\n",
      "[Train Epoch]1/5 [Time]15098.23 [Step]20656 [Batch]330500 [Speed]45.68ms/step [Loss]9.3556 [Metrics]{'train_loss:9.3556'}\n",
      "[Train Epoch]1/5 [Time]15120.99 [Step]20687 [Batch]331000 [Speed]45.68ms/step [Loss]9.3556 [Metrics]{'train_loss:9.3556'}\n",
      "[Train Epoch]1/5 [Time]15143.70 [Step]20718 [Batch]331500 [Speed]45.68ms/step [Loss]9.3555 [Metrics]{'train_loss:9.3555'}\n",
      "[Train Epoch]1/5 [Time]15166.45 [Step]20750 [Batch]332000 [Speed]45.68ms/step [Loss]9.3556 [Metrics]{'train_loss:9.3556'}\n",
      "[Train Epoch]1/5 [Time]15189.18 [Step]20781 [Batch]332500 [Speed]45.68ms/step [Loss]9.3554 [Metrics]{'train_loss:9.3554'}\n",
      "[Train Epoch]1/5 [Time]15211.84 [Step]20812 [Batch]333000 [Speed]45.68ms/step [Loss]9.3554 [Metrics]{'train_loss:9.3554'}\n",
      "[Train Epoch]1/5 [Time]15234.54 [Step]20843 [Batch]333500 [Speed]45.68ms/step [Loss]9.3553 [Metrics]{'train_loss:9.3553'}\n",
      "[Train Epoch]1/5 [Time]15257.32 [Step]20875 [Batch]334000 [Speed]45.68ms/step [Loss]9.3551 [Metrics]{'train_loss:9.3551'}\n",
      "[Train Epoch]1/5 [Time]15280.04 [Step]20906 [Batch]334500 [Speed]45.68ms/step [Loss]9.3549 [Metrics]{'train_loss:9.3549'}\n",
      "[Train Epoch]1/5 [Time]15302.75 [Step]20937 [Batch]335000 [Speed]45.68ms/step [Loss]9.3549 [Metrics]{'train_loss:9.3549'}\n",
      "[Train Epoch]1/5 [Time]15325.44 [Step]20968 [Batch]335500 [Speed]45.68ms/step [Loss]9.3548 [Metrics]{'train_loss:9.3548'}\n",
      "[Train Epoch]1/5 [Time]15348.16 [Step]21000 [Batch]336000 [Speed]45.68ms/step [Loss]9.3548 [Metrics]{'train_loss:9.3548'}\n",
      "[Train Epoch]1/5 [Time]15370.84 [Step]21031 [Batch]336500 [Speed]45.68ms/step [Loss]9.3548 [Metrics]{'train_loss:9.3548'}\n",
      "[Train Epoch]1/5 [Time]15393.56 [Step]21062 [Batch]337000 [Speed]45.68ms/step [Loss]9.3550 [Metrics]{'train_loss:9.3550'}\n",
      "[Train Epoch]1/5 [Time]15416.29 [Step]21093 [Batch]337500 [Speed]45.68ms/step [Loss]9.3550 [Metrics]{'train_loss:9.3550'}\n",
      "[Train Epoch]1/5 [Time]15439.02 [Step]21125 [Batch]338000 [Speed]45.68ms/step [Loss]9.3548 [Metrics]{'train_loss:9.3548'}\n",
      "[Train Epoch]1/5 [Time]15461.77 [Step]21156 [Batch]338500 [Speed]45.68ms/step [Loss]9.3547 [Metrics]{'train_loss:9.3547'}\n",
      "[Train Epoch]1/5 [Time]15484.46 [Step]21187 [Batch]339000 [Speed]45.68ms/step [Loss]9.3547 [Metrics]{'train_loss:9.3547'}\n",
      "[Train Epoch]1/5 [Time]15507.18 [Step]21218 [Batch]339500 [Speed]45.68ms/step [Loss]9.3547 [Metrics]{'train_loss:9.3547'}\n",
      "[Train Epoch]1/5 [Time]15529.81 [Step]21250 [Batch]340000 [Speed]45.68ms/step [Loss]9.3547 [Metrics]{'train_loss:9.3547'}\n",
      "[Train Epoch]1/5 [Time]15552.57 [Step]21281 [Batch]340500 [Speed]45.68ms/step [Loss]9.3547 [Metrics]{'train_loss:9.3547'}\n",
      "[Train Epoch]1/5 [Time]15575.29 [Step]21312 [Batch]341000 [Speed]45.68ms/step [Loss]9.3547 [Metrics]{'train_loss:9.3547'}\n",
      "[Train Epoch]1/5 [Time]15598.03 [Step]21343 [Batch]341500 [Speed]45.68ms/step [Loss]9.3547 [Metrics]{'train_loss:9.3547'}\n",
      "[Train Epoch]1/5 [Time]15620.80 [Step]21375 [Batch]342000 [Speed]45.67ms/step [Loss]9.3546 [Metrics]{'train_loss:9.3546'}\n",
      "[Train Epoch]1/5 [Time]15643.56 [Step]21406 [Batch]342500 [Speed]45.67ms/step [Loss]9.3546 [Metrics]{'train_loss:9.3546'}\n",
      "[Train Epoch]1/5 [Time]15666.26 [Step]21437 [Batch]343000 [Speed]45.67ms/step [Loss]9.3545 [Metrics]{'train_loss:9.3545'}\n",
      "[Train Epoch]1/5 [Time]15688.89 [Step]21468 [Batch]343500 [Speed]45.67ms/step [Loss]9.3546 [Metrics]{'train_loss:9.3546'}\n",
      "[Train Epoch]1/5 [Time]15711.63 [Step]21500 [Batch]344000 [Speed]45.67ms/step [Loss]9.3545 [Metrics]{'train_loss:9.3545'}\n",
      "[Train Epoch]1/5 [Time]15734.32 [Step]21531 [Batch]344500 [Speed]45.67ms/step [Loss]9.3544 [Metrics]{'train_loss:9.3544'}\n",
      "[Train Epoch]1/5 [Time]15757.05 [Step]21562 [Batch]345000 [Speed]45.67ms/step [Loss]9.3544 [Metrics]{'train_loss:9.3544'}\n",
      "[Train Epoch]1/5 [Time]15779.80 [Step]21593 [Batch]345500 [Speed]45.67ms/step [Loss]9.3543 [Metrics]{'train_loss:9.3543'}\n",
      "[Train Epoch]1/5 [Time]15802.54 [Step]21625 [Batch]346000 [Speed]45.67ms/step [Loss]9.3543 [Metrics]{'train_loss:9.3543'}\n",
      "[Train Epoch]1/5 [Time]15825.26 [Step]21656 [Batch]346500 [Speed]45.67ms/step [Loss]9.3543 [Metrics]{'train_loss:9.3543'}\n",
      "[Train Epoch]1/5 [Time]15847.95 [Step]21687 [Batch]347000 [Speed]45.67ms/step [Loss]9.3542 [Metrics]{'train_loss:9.3542'}\n",
      "[Train Epoch]1/5 [Time]15870.65 [Step]21718 [Batch]347500 [Speed]45.67ms/step [Loss]9.3542 [Metrics]{'train_loss:9.3542'}\n",
      "[Train Epoch]1/5 [Time]15893.42 [Step]21750 [Batch]348000 [Speed]45.67ms/step [Loss]9.3542 [Metrics]{'train_loss:9.3542'}\n",
      "[Train Epoch]1/5 [Time]15916.16 [Step]21781 [Batch]348500 [Speed]45.67ms/step [Loss]9.3540 [Metrics]{'train_loss:9.3540'}\n",
      "[Train Epoch]1/5 [Time]15938.90 [Step]21812 [Batch]349000 [Speed]45.67ms/step [Loss]9.3540 [Metrics]{'train_loss:9.3540'}\n",
      "[Train Epoch]1/5 [Time]15961.67 [Step]21843 [Batch]349500 [Speed]45.67ms/step [Loss]9.3540 [Metrics]{'train_loss:9.3540'}\n",
      "[Train Epoch]1/5 [Time]15984.36 [Step]21875 [Batch]350000 [Speed]45.67ms/step [Loss]9.3540 [Metrics]{'train_loss:9.3540'}\n",
      "[Train Epoch]1/5 [Time]16006.99 [Step]21906 [Batch]350500 [Speed]45.67ms/step [Loss]9.3539 [Metrics]{'train_loss:9.3539'}\n",
      "[Train Epoch]1/5 [Time]16029.73 [Step]21937 [Batch]351000 [Speed]45.67ms/step [Loss]9.3537 [Metrics]{'train_loss:9.3537'}\n",
      "[Train Epoch]1/5 [Time]16052.49 [Step]21968 [Batch]351500 [Speed]45.67ms/step [Loss]9.3536 [Metrics]{'train_loss:9.3536'}\n",
      "[Train Epoch]1/5 [Time]16075.25 [Step]22000 [Batch]352000 [Speed]45.67ms/step [Loss]9.3534 [Metrics]{'train_loss:9.3534'}\n",
      "[Train Epoch]1/5 [Time]16098.06 [Step]22031 [Batch]352500 [Speed]45.67ms/step [Loss]9.3533 [Metrics]{'train_loss:9.3533'}\n",
      "[Train Epoch]1/5 [Time]16120.78 [Step]22062 [Batch]353000 [Speed]45.67ms/step [Loss]9.3534 [Metrics]{'train_loss:9.3534'}\n",
      "[Train Epoch]1/5 [Time]16143.52 [Step]22093 [Batch]353500 [Speed]45.67ms/step [Loss]9.3534 [Metrics]{'train_loss:9.3534'}\n",
      "[Train Epoch]1/5 [Time]16166.20 [Step]22125 [Batch]354000 [Speed]45.67ms/step [Loss]9.3534 [Metrics]{'train_loss:9.3534'}\n",
      "[Train Epoch]1/5 [Time]16188.93 [Step]22156 [Batch]354500 [Speed]45.67ms/step [Loss]9.3534 [Metrics]{'train_loss:9.3534'}\n",
      "[Train Epoch]1/5 [Time]16211.65 [Step]22187 [Batch]355000 [Speed]45.67ms/step [Loss]9.3534 [Metrics]{'train_loss:9.3534'}\n",
      "[Train Epoch]1/5 [Time]16234.42 [Step]22218 [Batch]355500 [Speed]45.67ms/step [Loss]9.3533 [Metrics]{'train_loss:9.3533'}\n",
      "[Train Epoch]1/5 [Time]16257.15 [Step]22250 [Batch]356000 [Speed]45.67ms/step [Loss]9.3533 [Metrics]{'train_loss:9.3533'}\n",
      "[Train Epoch]1/5 [Time]16279.90 [Step]22281 [Batch]356500 [Speed]45.67ms/step [Loss]9.3533 [Metrics]{'train_loss:9.3533'}\n",
      "[Train Epoch]1/5 [Time]16302.64 [Step]22312 [Batch]357000 [Speed]45.67ms/step [Loss]9.3532 [Metrics]{'train_loss:9.3532'}\n",
      "[Train Epoch]1/5 [Time]16325.27 [Step]22343 [Batch]357500 [Speed]45.67ms/step [Loss]9.3533 [Metrics]{'train_loss:9.3533'}\n",
      "[Train Epoch]1/5 [Time]16348.08 [Step]22375 [Batch]358000 [Speed]45.67ms/step [Loss]9.3532 [Metrics]{'train_loss:9.3532'}\n",
      "[Train Epoch]1/5 [Time]16370.80 [Step]22406 [Batch]358500 [Speed]45.66ms/step [Loss]9.3531 [Metrics]{'train_loss:9.3531'}\n",
      "[Train Epoch]1/5 [Time]16393.54 [Step]22437 [Batch]359000 [Speed]45.66ms/step [Loss]9.3531 [Metrics]{'train_loss:9.3531'}\n",
      "[Train Epoch]1/5 [Time]16416.27 [Step]22468 [Batch]359500 [Speed]45.66ms/step [Loss]9.3529 [Metrics]{'train_loss:9.3529'}\n",
      "[Train Epoch]1/5 [Time]16439.05 [Step]22500 [Batch]360000 [Speed]45.66ms/step [Loss]9.3528 [Metrics]{'train_loss:9.3528'}\n",
      "[Train Epoch]1/5 [Time]16461.75 [Step]22531 [Batch]360500 [Speed]45.66ms/step [Loss]9.3528 [Metrics]{'train_loss:9.3528'}\n",
      "[Train Epoch]1/5 [Time]16484.42 [Step]22562 [Batch]361000 [Speed]45.66ms/step [Loss]9.3527 [Metrics]{'train_loss:9.3527'}\n",
      "[Train Epoch]1/5 [Time]16507.14 [Step]22593 [Batch]361500 [Speed]45.66ms/step [Loss]9.3526 [Metrics]{'train_loss:9.3526'}\n",
      "[Train Epoch]1/5 [Time]16529.92 [Step]22625 [Batch]362000 [Speed]45.66ms/step [Loss]9.3527 [Metrics]{'train_loss:9.3527'}\n",
      "[Train Epoch]1/5 [Time]16552.63 [Step]22656 [Batch]362500 [Speed]45.66ms/step [Loss]9.3526 [Metrics]{'train_loss:9.3526'}\n",
      "[Train Epoch]1/5 [Time]16575.39 [Step]22687 [Batch]363000 [Speed]45.66ms/step [Loss]9.3525 [Metrics]{'train_loss:9.3525'}\n",
      "[Train Epoch]1/5 [Time]16598.15 [Step]22718 [Batch]363500 [Speed]45.66ms/step [Loss]9.3526 [Metrics]{'train_loss:9.3526'}\n",
      "[Train Epoch]1/5 [Time]16620.96 [Step]22750 [Batch]364000 [Speed]45.66ms/step [Loss]9.3524 [Metrics]{'train_loss:9.3524'}\n",
      "[Train Epoch]1/5 [Time]16643.62 [Step]22781 [Batch]364500 [Speed]45.66ms/step [Loss]9.3525 [Metrics]{'train_loss:9.3525'}\n",
      "[Train Epoch]1/5 [Time]16666.34 [Step]22812 [Batch]365000 [Speed]45.66ms/step [Loss]9.3523 [Metrics]{'train_loss:9.3523'}\n",
      "[Train Epoch]1/5 [Time]16689.12 [Step]22843 [Batch]365500 [Speed]45.66ms/step [Loss]9.3523 [Metrics]{'train_loss:9.3523'}\n",
      "[Train Epoch]1/5 [Time]16711.87 [Step]22875 [Batch]366000 [Speed]45.66ms/step [Loss]9.3523 [Metrics]{'train_loss:9.3523'}\n",
      "[Train Epoch]1/5 [Time]16734.64 [Step]22906 [Batch]366500 [Speed]45.66ms/step [Loss]9.3522 [Metrics]{'train_loss:9.3522'}\n",
      "[Train Epoch]1/5 [Time]16757.35 [Step]22937 [Batch]367000 [Speed]45.66ms/step [Loss]9.3521 [Metrics]{'train_loss:9.3521'}\n",
      "[Train Epoch]1/5 [Time]16780.11 [Step]22968 [Batch]367500 [Speed]45.66ms/step [Loss]9.3522 [Metrics]{'train_loss:9.3522'}\n",
      "[Train Epoch]1/5 [Time]16802.85 [Step]23000 [Batch]368000 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]16825.60 [Step]23031 [Batch]368500 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]16848.34 [Step]23062 [Batch]369000 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]16871.10 [Step]23093 [Batch]369500 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]16893.86 [Step]23125 [Batch]370000 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]16916.64 [Step]23156 [Batch]370500 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]16939.39 [Step]23187 [Batch]371000 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]16962.06 [Step]23218 [Batch]371500 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]16984.83 [Step]23250 [Batch]372000 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]17007.61 [Step]23281 [Batch]372500 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]17030.38 [Step]23312 [Batch]373000 [Speed]45.66ms/step [Loss]9.3520 [Metrics]{'train_loss:9.3520'}\n",
      "[Train Epoch]1/5 [Time]17053.14 [Step]23343 [Batch]373500 [Speed]45.66ms/step [Loss]9.3519 [Metrics]{'train_loss:9.3519'}\n",
      "[Train Epoch]1/5 [Time]17075.92 [Step]23375 [Batch]374000 [Speed]45.66ms/step [Loss]9.3519 [Metrics]{'train_loss:9.3519'}\n",
      "[Train Epoch]1/5 [Time]17098.68 [Step]23406 [Batch]374500 [Speed]45.66ms/step [Loss]9.3519 [Metrics]{'train_loss:9.3519'}\n",
      "[Train Epoch]1/5 [Time]17121.38 [Step]23437 [Batch]375000 [Speed]45.66ms/step [Loss]9.3518 [Metrics]{'train_loss:9.3518'}\n",
      "[Train Epoch]1/5 [Time]17144.13 [Step]23468 [Batch]375500 [Speed]45.66ms/step [Loss]9.3518 [Metrics]{'train_loss:9.3518'}\n",
      "[Train Epoch]1/5 [Time]17166.91 [Step]23500 [Batch]376000 [Speed]45.66ms/step [Loss]9.3517 [Metrics]{'train_loss:9.3517'}\n",
      "[Train Epoch]1/5 [Time]17189.66 [Step]23531 [Batch]376500 [Speed]45.66ms/step [Loss]9.3516 [Metrics]{'train_loss:9.3516'}\n",
      "[Train Epoch]1/5 [Time]17212.44 [Step]23562 [Batch]377000 [Speed]45.66ms/step [Loss]9.3517 [Metrics]{'train_loss:9.3517'}\n",
      "[Train Epoch]1/5 [Time]17235.18 [Step]23593 [Batch]377500 [Speed]45.66ms/step [Loss]9.3516 [Metrics]{'train_loss:9.3516'}\n",
      "[Train Epoch]1/5 [Time]17257.92 [Step]23625 [Batch]378000 [Speed]45.66ms/step [Loss]9.3515 [Metrics]{'train_loss:9.3515'}\n",
      "[Train Epoch]1/5 [Time]17280.64 [Step]23656 [Batch]378500 [Speed]45.66ms/step [Loss]9.3514 [Metrics]{'train_loss:9.3514'}\n",
      "[Train Epoch]1/5 [Time]17303.42 [Step]23687 [Batch]379000 [Speed]45.66ms/step [Loss]9.3514 [Metrics]{'train_loss:9.3514'}\n",
      "[Train Epoch]1/5 [Time]17326.22 [Step]23718 [Batch]379500 [Speed]45.66ms/step [Loss]9.3513 [Metrics]{'train_loss:9.3513'}\n",
      "[Train Epoch]1/5 [Time]17348.99 [Step]23750 [Batch]380000 [Speed]45.66ms/step [Loss]9.3513 [Metrics]{'train_loss:9.3513'}\n",
      "[Train Epoch]1/5 [Time]17371.78 [Step]23781 [Batch]380500 [Speed]45.66ms/step [Loss]9.3513 [Metrics]{'train_loss:9.3513'}\n",
      "[Train Epoch]1/5 [Time]17394.54 [Step]23812 [Batch]381000 [Speed]45.65ms/step [Loss]9.3512 [Metrics]{'train_loss:9.3512'}\n",
      "[Train Epoch]1/5 [Time]17417.31 [Step]23843 [Batch]381500 [Speed]45.65ms/step [Loss]9.3510 [Metrics]{'train_loss:9.3510'}\n",
      "[Train Epoch]1/5 [Time]17440.00 [Step]23875 [Batch]382000 [Speed]45.65ms/step [Loss]9.3508 [Metrics]{'train_loss:9.3508'}\n",
      "[Train Epoch]1/5 [Time]17462.79 [Step]23906 [Batch]382500 [Speed]45.65ms/step [Loss]9.3508 [Metrics]{'train_loss:9.3508'}\n",
      "[Train Epoch]1/5 [Time]17485.59 [Step]23937 [Batch]383000 [Speed]45.65ms/step [Loss]9.3508 [Metrics]{'train_loss:9.3508'}\n",
      "[Train Epoch]1/5 [Time]17508.39 [Step]23968 [Batch]383500 [Speed]45.65ms/step [Loss]9.3507 [Metrics]{'train_loss:9.3507'}\n",
      "[Train Epoch]1/5 [Time]17531.18 [Step]24000 [Batch]384000 [Speed]45.65ms/step [Loss]9.3506 [Metrics]{'train_loss:9.3506'}\n",
      "[Train Epoch]1/5 [Time]17553.96 [Step]24031 [Batch]384500 [Speed]45.65ms/step [Loss]9.3505 [Metrics]{'train_loss:9.3505'}\n",
      "[Train Epoch]1/5 [Time]17576.69 [Step]24062 [Batch]385000 [Speed]45.65ms/step [Loss]9.3503 [Metrics]{'train_loss:9.3503'}\n",
      "[Train Epoch]1/5 [Time]17599.41 [Step]24093 [Batch]385500 [Speed]45.65ms/step [Loss]9.3501 [Metrics]{'train_loss:9.3501'}\n",
      "[Train Epoch]1/5 [Time]17622.19 [Step]24125 [Batch]386000 [Speed]45.65ms/step [Loss]9.3502 [Metrics]{'train_loss:9.3502'}\n",
      "[Train Epoch]1/5 [Time]17644.96 [Step]24156 [Batch]386500 [Speed]45.65ms/step [Loss]9.3502 [Metrics]{'train_loss:9.3502'}\n",
      "[Train Epoch]1/5 [Time]17667.73 [Step]24187 [Batch]387000 [Speed]45.65ms/step [Loss]9.3502 [Metrics]{'train_loss:9.3502'}\n",
      "[Train Epoch]1/5 [Time]17690.49 [Step]24218 [Batch]387500 [Speed]45.65ms/step [Loss]9.3501 [Metrics]{'train_loss:9.3501'}\n",
      "[Train Epoch]1/5 [Time]17713.31 [Step]24250 [Batch]388000 [Speed]45.65ms/step [Loss]9.3500 [Metrics]{'train_loss:9.3500'}\n",
      "[Train Epoch]1/5 [Time]17736.08 [Step]24281 [Batch]388500 [Speed]45.65ms/step [Loss]9.3500 [Metrics]{'train_loss:9.3500'}\n",
      "[Train Epoch]1/5 [Time]17758.79 [Step]24312 [Batch]389000 [Speed]45.65ms/step [Loss]9.3499 [Metrics]{'train_loss:9.3499'}\n",
      "[Train Epoch]1/5 [Time]17781.56 [Step]24343 [Batch]389500 [Speed]45.65ms/step [Loss]9.3498 [Metrics]{'train_loss:9.3498'}\n",
      "[Train Epoch]1/5 [Time]17804.37 [Step]24375 [Batch]390000 [Speed]45.65ms/step [Loss]9.3499 [Metrics]{'train_loss:9.3499'}\n",
      "[Train Epoch]1/5 [Time]17827.17 [Step]24406 [Batch]390500 [Speed]45.65ms/step [Loss]9.3498 [Metrics]{'train_loss:9.3498'}\n",
      "[Train Epoch]1/5 [Time]17849.93 [Step]24437 [Batch]391000 [Speed]45.65ms/step [Loss]9.3498 [Metrics]{'train_loss:9.3498'}\n",
      "[Train Epoch]1/5 [Time]17872.69 [Step]24468 [Batch]391500 [Speed]45.65ms/step [Loss]9.3496 [Metrics]{'train_loss:9.3496'}\n",
      "[Train Epoch]1/5 [Time]17895.51 [Step]24500 [Batch]392000 [Speed]45.65ms/step [Loss]9.3495 [Metrics]{'train_loss:9.3495'}\n",
      "[Train Epoch]1/5 [Time]17918.28 [Step]24531 [Batch]392500 [Speed]45.65ms/step [Loss]9.3494 [Metrics]{'train_loss:9.3494'}\n",
      "[Train Epoch]1/5 [Time]17941.00 [Step]24562 [Batch]393000 [Speed]45.65ms/step [Loss]9.3493 [Metrics]{'train_loss:9.3493'}\n",
      "[Train Epoch]1/5 [Time]17963.75 [Step]24593 [Batch]393500 [Speed]45.65ms/step [Loss]9.3493 [Metrics]{'train_loss:9.3493'}\n",
      "[Train Epoch]1/5 [Time]17986.56 [Step]24625 [Batch]394000 [Speed]45.65ms/step [Loss]9.3491 [Metrics]{'train_loss:9.3491'}\n",
      "[Train Epoch]1/5 [Time]18009.33 [Step]24656 [Batch]394500 [Speed]45.65ms/step [Loss]9.3491 [Metrics]{'train_loss:9.3491'}\n",
      "[Train Epoch]1/5 [Time]18032.05 [Step]24687 [Batch]395000 [Speed]45.65ms/step [Loss]9.3490 [Metrics]{'train_loss:9.3490'}\n",
      "[Train Epoch]1/5 [Time]18054.83 [Step]24718 [Batch]395500 [Speed]45.65ms/step [Loss]9.3489 [Metrics]{'train_loss:9.3489'}\n",
      "[Train Epoch]1/5 [Time]18077.56 [Step]24750 [Batch]396000 [Speed]45.65ms/step [Loss]9.3489 [Metrics]{'train_loss:9.3489'}\n",
      "[Train Epoch]1/5 [Time]18100.36 [Step]24781 [Batch]396500 [Speed]45.65ms/step [Loss]9.3489 [Metrics]{'train_loss:9.3489'}\n",
      "[Train Epoch]1/5 [Time]18123.10 [Step]24812 [Batch]397000 [Speed]45.65ms/step [Loss]9.3489 [Metrics]{'train_loss:9.3489'}\n",
      "[Train Epoch]1/5 [Time]18145.93 [Step]24843 [Batch]397500 [Speed]45.65ms/step [Loss]9.3488 [Metrics]{'train_loss:9.3488'}\n",
      "[Train Epoch]1/5 [Time]18168.68 [Step]24875 [Batch]398000 [Speed]45.65ms/step [Loss]9.3486 [Metrics]{'train_loss:9.3486'}\n",
      "[Train Epoch]1/5 [Time]18191.47 [Step]24906 [Batch]398500 [Speed]45.65ms/step [Loss]9.3485 [Metrics]{'train_loss:9.3485'}\n",
      "[Train Epoch]1/5 [Time]18214.25 [Step]24937 [Batch]399000 [Speed]45.65ms/step [Loss]9.3485 [Metrics]{'train_loss:9.3485'}\n",
      "[Train Epoch]1/5 [Time]18236.94 [Step]24968 [Batch]399500 [Speed]45.65ms/step [Loss]9.3485 [Metrics]{'train_loss:9.3485'}\n",
      "Saving checkpoint for epoch 1 at step 400000 on path ../2_Models/model_bert4rec_complete_0.5/checkpoints/\n",
      "[Train Epoch]1/5 [Time]18261.51 [Step]25000 [Batch]400000 [Speed]45.65ms/step [Loss]9.3485 [Metrics]{'train_loss:9.3485'}\n",
      "[Train Epoch]1/5 [Time]18284.18 [Step]25031 [Batch]400500 [Speed]45.65ms/step [Loss]9.3485 [Metrics]{'train_loss:9.3485'}\n",
      "[Train Epoch]1/5 [Time]18307.06 [Step]25062 [Batch]401000 [Speed]45.65ms/step [Loss]9.3485 [Metrics]{'train_loss:9.3485'}\n",
      "[Train Epoch]1/5 [Time]18329.87 [Step]25093 [Batch]401500 [Speed]45.65ms/step [Loss]9.3485 [Metrics]{'train_loss:9.3485'}\n",
      "[Train Epoch]1/5 [Time]18352.69 [Step]25125 [Batch]402000 [Speed]45.65ms/step [Loss]9.3485 [Metrics]{'train_loss:9.3485'}\n",
      "[Train Epoch]1/5 [Time]18375.44 [Step]25156 [Batch]402500 [Speed]45.65ms/step [Loss]9.3484 [Metrics]{'train_loss:9.3484'}\n",
      "[Train Epoch]1/5 [Time]18398.27 [Step]25187 [Batch]403000 [Speed]45.65ms/step [Loss]9.3483 [Metrics]{'train_loss:9.3483'}\n",
      "[Train Epoch]1/5 [Time]18421.05 [Step]25218 [Batch]403500 [Speed]45.65ms/step [Loss]9.3483 [Metrics]{'train_loss:9.3483'}\n",
      "[Train Epoch]1/5 [Time]18443.85 [Step]25250 [Batch]404000 [Speed]45.65ms/step [Loss]9.3483 [Metrics]{'train_loss:9.3483'}\n",
      "[Train Epoch]1/5 [Time]18466.55 [Step]25281 [Batch]404500 [Speed]45.65ms/step [Loss]9.3483 [Metrics]{'train_loss:9.3483'}\n",
      "[Train Epoch]1/5 [Time]18489.41 [Step]25312 [Batch]405000 [Speed]45.65ms/step [Loss]9.3482 [Metrics]{'train_loss:9.3482'}\n",
      "[Train Epoch]1/5 [Time]18512.23 [Step]25343 [Batch]405500 [Speed]45.65ms/step [Loss]9.3482 [Metrics]{'train_loss:9.3482'}\n",
      "[Train Epoch]1/5 [Time]18535.04 [Step]25375 [Batch]406000 [Speed]45.65ms/step [Loss]9.3482 [Metrics]{'train_loss:9.3482'}\n",
      "[Train Epoch]1/5 [Time]18557.90 [Step]25406 [Batch]406500 [Speed]45.65ms/step [Loss]9.3481 [Metrics]{'train_loss:9.3481'}\n",
      "[Train Epoch]1/5 [Time]18580.66 [Step]25437 [Batch]407000 [Speed]45.65ms/step [Loss]9.3480 [Metrics]{'train_loss:9.3480'}\n",
      "[Train Epoch]1/5 [Time]18603.47 [Step]25468 [Batch]407500 [Speed]45.65ms/step [Loss]9.3478 [Metrics]{'train_loss:9.3478'}\n",
      "[Train Epoch]1/5 [Time]18626.17 [Step]25500 [Batch]408000 [Speed]45.65ms/step [Loss]9.3477 [Metrics]{'train_loss:9.3477'}\n",
      "[Train Epoch]1/5 [Time]18648.99 [Step]25531 [Batch]408500 [Speed]45.65ms/step [Loss]9.3477 [Metrics]{'train_loss:9.3477'}\n",
      "[Train Epoch]1/5 [Time]18671.81 [Step]25562 [Batch]409000 [Speed]45.65ms/step [Loss]9.3475 [Metrics]{'train_loss:9.3475'}\n",
      "[Train Epoch]1/5 [Time]18694.62 [Step]25593 [Batch]409500 [Speed]45.65ms/step [Loss]9.3474 [Metrics]{'train_loss:9.3474'}\n",
      "[Train Epoch]1/5 [Time]18717.45 [Step]25625 [Batch]410000 [Speed]45.65ms/step [Loss]9.3473 [Metrics]{'train_loss:9.3473'}\n",
      "[Train Epoch]1/5 [Time]18740.24 [Step]25656 [Batch]410500 [Speed]45.65ms/step [Loss]9.3472 [Metrics]{'train_loss:9.3472'}\n",
      "[Train Epoch]1/5 [Time]18763.03 [Step]25687 [Batch]411000 [Speed]45.65ms/step [Loss]9.3472 [Metrics]{'train_loss:9.3472'}\n",
      "[Train Epoch]1/5 [Time]18785.70 [Step]25718 [Batch]411500 [Speed]45.65ms/step [Loss]9.3472 [Metrics]{'train_loss:9.3472'}\n",
      "[Train Epoch]1/5 [Time]18808.55 [Step]25750 [Batch]412000 [Speed]45.65ms/step [Loss]9.3470 [Metrics]{'train_loss:9.3470'}\n",
      "[Train Epoch]1/5 [Time]18831.39 [Step]25781 [Batch]412500 [Speed]45.65ms/step [Loss]9.3470 [Metrics]{'train_loss:9.3470'}\n",
      "[Train Epoch]1/5 [Time]18854.22 [Step]25812 [Batch]413000 [Speed]45.65ms/step [Loss]9.3470 [Metrics]{'train_loss:9.3470'}\n",
      "[Train Epoch]1/5 [Time]18877.03 [Step]25843 [Batch]413500 [Speed]45.65ms/step [Loss]9.3470 [Metrics]{'train_loss:9.3470'}\n",
      "[Train Epoch]1/5 [Time]18899.89 [Step]25875 [Batch]414000 [Speed]45.65ms/step [Loss]9.3470 [Metrics]{'train_loss:9.3470'}\n",
      "[Train Epoch]1/5 [Time]18922.71 [Step]25906 [Batch]414500 [Speed]45.65ms/step [Loss]9.3470 [Metrics]{'train_loss:9.3470'}\n",
      "[Train Epoch]1/5 [Time]18945.47 [Step]25937 [Batch]415000 [Speed]45.65ms/step [Loss]9.3470 [Metrics]{'train_loss:9.3470'}\n",
      "[Train Epoch]1/5 [Time]18968.27 [Step]25968 [Batch]415500 [Speed]45.65ms/step [Loss]9.3470 [Metrics]{'train_loss:9.3470'}\n",
      "[Train Epoch]1/5 [Time]18991.14 [Step]26000 [Batch]416000 [Speed]45.65ms/step [Loss]9.3468 [Metrics]{'train_loss:9.3468'}\n",
      "[Train Epoch]1/5 [Time]19013.95 [Step]26031 [Batch]416500 [Speed]45.65ms/step [Loss]9.3467 [Metrics]{'train_loss:9.3467'}\n",
      "[Train Epoch]1/5 [Time]19036.78 [Step]26062 [Batch]417000 [Speed]45.65ms/step [Loss]9.3465 [Metrics]{'train_loss:9.3465'}\n",
      "[Train Epoch]1/5 [Time]19059.56 [Step]26093 [Batch]417500 [Speed]45.65ms/step [Loss]9.3464 [Metrics]{'train_loss:9.3464'}\n",
      "[Train Epoch]1/5 [Time]19082.42 [Step]26125 [Batch]418000 [Speed]45.65ms/step [Loss]9.3463 [Metrics]{'train_loss:9.3463'}\n",
      "[Train Epoch]1/5 [Time]19105.18 [Step]26156 [Batch]418500 [Speed]45.65ms/step [Loss]9.3463 [Metrics]{'train_loss:9.3463'}\n",
      "[Train Epoch]1/5 [Time]19128.00 [Step]26187 [Batch]419000 [Speed]45.65ms/step [Loss]9.3462 [Metrics]{'train_loss:9.3462'}\n",
      "[Train Epoch]1/5 [Time]19150.83 [Step]26218 [Batch]419500 [Speed]45.65ms/step [Loss]9.3463 [Metrics]{'train_loss:9.3463'}\n",
      "[Train Epoch]1/5 [Time]19173.67 [Step]26250 [Batch]420000 [Speed]45.65ms/step [Loss]9.3461 [Metrics]{'train_loss:9.3461'}\n",
      "[Train Epoch]1/5 [Time]19196.49 [Step]26281 [Batch]420500 [Speed]45.65ms/step [Loss]9.3460 [Metrics]{'train_loss:9.3460'}\n",
      "[Train Epoch]1/5 [Time]19219.34 [Step]26312 [Batch]421000 [Speed]45.65ms/step [Loss]9.3459 [Metrics]{'train_loss:9.3459'}\n",
      "[Train Epoch]1/5 [Time]19242.16 [Step]26343 [Batch]421500 [Speed]45.65ms/step [Loss]9.3460 [Metrics]{'train_loss:9.3460'}\n",
      "[Train Epoch]1/5 [Time]19264.90 [Step]26375 [Batch]422000 [Speed]45.65ms/step [Loss]9.3458 [Metrics]{'train_loss:9.3458'}\n",
      "[Train Epoch]1/5 [Time]19287.74 [Step]26406 [Batch]422500 [Speed]45.65ms/step [Loss]9.3458 [Metrics]{'train_loss:9.3458'}\n",
      "[Train Epoch]1/5 [Time]19310.56 [Step]26437 [Batch]423000 [Speed]45.65ms/step [Loss]9.3459 [Metrics]{'train_loss:9.3459'}\n",
      "[Train Epoch]1/5 [Time]19333.39 [Step]26468 [Batch]423500 [Speed]45.65ms/step [Loss]9.3457 [Metrics]{'train_loss:9.3457'}\n",
      "[Train Epoch]1/5 [Time]19356.23 [Step]26500 [Batch]424000 [Speed]45.65ms/step [Loss]9.3455 [Metrics]{'train_loss:9.3455'}\n",
      "[Train Epoch]1/5 [Time]19379.04 [Step]26531 [Batch]424500 [Speed]45.65ms/step [Loss]9.3454 [Metrics]{'train_loss:9.3454'}\n",
      "[Train Epoch]1/5 [Time]19401.86 [Step]26562 [Batch]425000 [Speed]45.65ms/step [Loss]9.3454 [Metrics]{'train_loss:9.3454'}\n",
      "[Train Epoch]1/5 [Time]19424.64 [Step]26593 [Batch]425500 [Speed]45.65ms/step [Loss]9.3454 [Metrics]{'train_loss:9.3454'}\n",
      "[Train Epoch]1/5 [Time]19447.46 [Step]26625 [Batch]426000 [Speed]45.65ms/step [Loss]9.3454 [Metrics]{'train_loss:9.3454'}\n",
      "[Train Epoch]1/5 [Time]19470.29 [Step]26656 [Batch]426500 [Speed]45.65ms/step [Loss]9.3454 [Metrics]{'train_loss:9.3454'}\n",
      "[Train Epoch]1/5 [Time]19493.13 [Step]26687 [Batch]427000 [Speed]45.65ms/step [Loss]9.3451 [Metrics]{'train_loss:9.3451'}\n",
      "[Train Epoch]1/5 [Time]19515.95 [Step]26718 [Batch]427500 [Speed]45.65ms/step [Loss]9.3450 [Metrics]{'train_loss:9.3450'}\n",
      "[Train Epoch]1/5 [Time]19538.82 [Step]26750 [Batch]428000 [Speed]45.65ms/step [Loss]9.3449 [Metrics]{'train_loss:9.3449'}\n",
      "[Train Epoch]1/5 [Time]19561.64 [Step]26781 [Batch]428500 [Speed]45.65ms/step [Loss]9.3448 [Metrics]{'train_loss:9.3448'}\n",
      "[Train Epoch]1/5 [Time]19584.41 [Step]26812 [Batch]429000 [Speed]45.65ms/step [Loss]9.3447 [Metrics]{'train_loss:9.3447'}\n",
      "[Train Epoch]1/5 [Time]19607.23 [Step]26843 [Batch]429500 [Speed]45.65ms/step [Loss]9.3447 [Metrics]{'train_loss:9.3447'}\n",
      "[Train Epoch]1/5 [Time]19630.10 [Step]26875 [Batch]430000 [Speed]45.65ms/step [Loss]9.3446 [Metrics]{'train_loss:9.3446'}\n",
      "[Train Epoch]1/5 [Time]19652.92 [Step]26906 [Batch]430500 [Speed]45.65ms/step [Loss]9.3444 [Metrics]{'train_loss:9.3444'}\n",
      "[Train Epoch]1/5 [Time]19675.76 [Step]26937 [Batch]431000 [Speed]45.65ms/step [Loss]9.3444 [Metrics]{'train_loss:9.3444'}\n",
      "[Train Epoch]1/5 [Time]19698.55 [Step]26968 [Batch]431500 [Speed]45.65ms/step [Loss]9.3443 [Metrics]{'train_loss:9.3443'}\n",
      "[Train Epoch]1/5 [Time]19721.43 [Step]27000 [Batch]432000 [Speed]45.65ms/step [Loss]9.3442 [Metrics]{'train_loss:9.3442'}\n",
      "[Train Epoch]1/5 [Time]19744.17 [Step]27031 [Batch]432500 [Speed]45.65ms/step [Loss]9.3441 [Metrics]{'train_loss:9.3441'}\n",
      "[Train Epoch]1/5 [Time]19767.03 [Step]27062 [Batch]433000 [Speed]45.65ms/step [Loss]9.3441 [Metrics]{'train_loss:9.3441'}\n",
      "[Train Epoch]1/5 [Time]19789.84 [Step]27093 [Batch]433500 [Speed]45.65ms/step [Loss]9.3440 [Metrics]{'train_loss:9.3440'}\n",
      "[Train Epoch]1/5 [Time]19812.71 [Step]27125 [Batch]434000 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]19835.59 [Step]27156 [Batch]434500 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]19858.45 [Step]27187 [Batch]435000 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]19881.29 [Step]27218 [Batch]435500 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]19904.10 [Step]27250 [Batch]436000 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]19926.95 [Step]27281 [Batch]436500 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]19949.78 [Step]27312 [Batch]437000 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]19972.63 [Step]27343 [Batch]437500 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]19995.46 [Step]27375 [Batch]438000 [Speed]45.65ms/step [Loss]9.3439 [Metrics]{'train_loss:9.3439'}\n",
      "[Train Epoch]1/5 [Time]20018.32 [Step]27406 [Batch]438500 [Speed]45.65ms/step [Loss]9.3438 [Metrics]{'train_loss:9.3438'}\n",
      "[Train Epoch]1/5 [Time]20041.17 [Step]27437 [Batch]439000 [Speed]45.65ms/step [Loss]9.3437 [Metrics]{'train_loss:9.3437'}\n",
      "[Train Epoch]1/5 [Time]20065.77 [Step]27468 [Batch]439500 [Speed]45.66ms/step [Loss]9.3437 [Metrics]{'train_loss:9.3437'}\n",
      "[Train Epoch]1/5 [Time]20090.35 [Step]27500 [Batch]440000 [Speed]45.66ms/step [Loss]9.3436 [Metrics]{'train_loss:9.3436'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 108\u001b[0m\n\u001b[0;32m    106\u001b[0m inputs, target \u001b[39m=\u001b[39m batch_data\n\u001b[0;32m    107\u001b[0m step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39mtarget, loss\u001b[39m=\u001b[39mtrain_loss, num_accum_steps\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mnum_grad_accum_steps)\n\u001b[1;32m--> 108\u001b[0m global_gradients \u001b[39m=\u001b[39m backward_optimization(BERT4REC_CONFIG\u001b[39m.\u001b[39;49mnum_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    110\u001b[0m     train_dict_metrics \u001b[39m=\u001b[39m {x\u001b[39m.\u001b[39mname : x\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [train_loss]}\n",
      "Cell \u001b[1;32mIn [8], line 20\u001b[0m, in \u001b[0;36mbackward_optimization\u001b[1;34m(num_grad_steps, global_gradients, step_gradients, step, model, optimizer)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[39mfor\u001b[39;00m i, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(step_gradients):\n\u001b[1;32m---> 20\u001b[0m         global_gradients[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_gradients(g)\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m num_grad_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     22\u001b[0m     global_gradients \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(global_gradients, model\u001b[39m.\u001b[39mtrainable_variables)\n",
      "Cell \u001b[1;32mIn [8], line 8\u001b[0m, in \u001b[0;36mflat_gradients\u001b[1;34m(grads_or_idx_slices)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m'''Convert gradients if it's tf.IndexedSlices.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mWhen computing gradients for operation concerning `tf.gather`, the type of gradients \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(grads_or_idx_slices) \u001b[39m==\u001b[39m tf\u001b[39m.\u001b[39mIndexedSlices:\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mscatter_nd(\n\u001b[0;32m      9\u001b[0m         tf\u001b[39m.\u001b[39;49mexpand_dims(grads_or_idx_slices\u001b[39m.\u001b[39;49mindices, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m     10\u001b[0m         grads_or_idx_slices\u001b[39m.\u001b[39;49mvalues,\n\u001b[0;32m     11\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(grads_or_idx_slices\u001b[39m.\u001b[39;49mdense_shape, tf\u001b[39m.\u001b[39;49mint64)\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m grads_or_idx_slices\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:9154\u001b[0m, in \u001b[0;36mscatter_nd\u001b[1;34m(indices, updates, shape, name)\u001b[0m\n\u001b[0;32m   9152\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   9153\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 9154\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   9155\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mScatterNd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, indices, updates, shape)\n\u001b[0;32m   9156\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   9157\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.3/'\n",
    "    restore_last_chekpoint = (True, 'model_bert4rec_complete_0.5/checkpoints/', 'ckpt-2')\n",
    "    model_name = 'model_bert4rec_complete_0.5'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 12_000_000\n",
    "    batch_size = 10\n",
    "    num_grad_accum_steps = 16\n",
    "    seq_len = 20\n",
    "    mask_prob = 0.35\n",
    "    reverse_prob = 0.25\n",
    "    emb_dim = 32\n",
    "    trf_dim = 32\n",
    "    num_heads = 2\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 5\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 200\n",
    "    clipnorm = 1\n",
    "    num_iters_save_checkpoint = 5_000 * num_grad_accum_steps\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    log_wandb = False\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.restore_last_chekpoint[1]}/', compile=False)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "                            warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "# optimizer = AdamW(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "#                     warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "#                     clipnorm=BERT4REC_CONFIG.clipnorm,\n",
    "#                     weight_decay=1e-4)                            \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = custom_loss_bert4rec()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "##############################################\n",
    "\n",
    "total_step, val_step = 0, 0\n",
    "global_gradients = []\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        step_gradients = train_step(inputs, target=target, loss=train_loss, num_accum_steps=BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "        global_gradients = backward_optimization(BERT4REC_CONFIG.num_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss]}\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step // BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics) \n",
    "        \n",
    "        total_step += 1  \n",
    "\n",
    "        if total_step % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')        \n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            \n",
    "    for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "        inputs, target = val_batch_data\n",
    "        test_step(inputs, target=target, loss=val_loss)\n",
    "        val_step += 1\n",
    "        if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "            val_dict_metrics = {x.name : x.result() for x in [val_loss]}\n",
    "            fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "                # if val_batch_num==0:\n",
    "                #     log_wandb_metrics(step=None, plot_image=True, \n",
    "                #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [04:04,  8.17it/s]\n",
      "100%|██████████| 96048/96048 [00:01<00:00, 70109.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.604800e+04</td>\n",
       "      <td>40432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.358388e+06</td>\n",
       "      <td>0.209254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.721844e+06</td>\n",
       "      <td>0.398050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.200000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.119220e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.336272e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.541742e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289966e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session         score\n",
       "count  9.604800e+04  40432.000000\n",
       "mean   6.358388e+06      0.209254\n",
       "std    3.721844e+06      0.398050\n",
       "min    2.200000e+02      0.000000\n",
       "25%    3.119220e+06      0.000000\n",
       "50%    6.336272e+06      0.000000\n",
       "75%    9.541742e+06      0.000000\n",
       "max    1.289966e+07      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.2551911009697661,\n",
       " 'clicks': 0.184255430859093,\n",
       " 'orders': 0.3585078712115372}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.3101\n"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0\n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.5/checkpoints'))\n",
    "# model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.4_finetuned/', compile=False)\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.3/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=16, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_predictions, list_trues, list_types = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    target, type_target = targets\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "    if num_batch==2_000:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# v0.4_finetuned seqlen=10\n",
    "# {'carts': 0.23272587826464677,\n",
    "#  'clicks': 0.16818629058707774,\n",
    "#  'orders': 0.31957377011651095}\n",
    "# Kaggle Metric: 0.2783808\n",
    "\n",
    "# model_bert4rec_complete_0.4.1 - ckpt42\n",
    "# mean = 0.202564\n",
    "# {'carts': 0.2417327288193879,\n",
    "#  'clicks': 0.18081338143653658,\n",
    "#  'orders': 0.33429939670611314}\n",
    "# Kaggle Metric: 0.2912\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.5 - ckpt7\n",
    "# mean = 0.202564\n",
    "# {'carts': 0.2551911009697661,\n",
    "#  'clicks': 0.184255430859093,\n",
    "#  'orders': 0.3585078712115372}\n",
    "# Kaggle Metric: 0.3101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.keras.backend.clear_session()\n",
    "model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.4/', compile=False)\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.3/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=10,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, target, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 52244it [2:47:45,  5.19it/s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c4b929e2472036a63dc2b4145b104daea13432f82a7dbc65e279332da4f8b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
