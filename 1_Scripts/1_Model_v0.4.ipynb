{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 22:04:32.537758: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 22:04:32.594018: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-01 22:04:32.609584: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-01 22:04:32.918279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-12-01 22:04:32.918307: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-12-01 22:04:32.918310: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 22:04:33.633220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:04:33.647113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:04:33.647192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries #\n",
    "\n",
    "from dataloader import Bert4RecDataLoader, SASRecDataLoader\n",
    "from models import build_model_bert4Rec\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 8303014.07it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.5/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "# \n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "# \n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 22:04:35.315492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 22:04:35.316107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:04:35.316195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:04:35.316235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:04:35.597836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:04:35.597920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:04:35.597965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:04:35.598010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21901 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 20, 1]), TensorShape([32, 20, 1]), TensorShape([32, 20, 8]), TensorShape([32, 20, 1])]\n",
      "[     0 827570      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[808785      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.5/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=train')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                num_items=NUM_ITEMS, \n",
    "                                seq_len=20, \n",
    "                                seq_len_target=None,\n",
    "                                batch_size=32, \n",
    "                                mask_prob=0.4, \n",
    "                                reverse_prob=0.0, \n",
    "                                get_session=False,\n",
    "                                is_val=False,\n",
    "                                is_test=False,\n",
    "                                shuffle=False).get_generator()\n",
    "# Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    break\n",
    "\n",
    "# # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     idx_mask = target\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     target, type_target, idx_mask = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 4\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(idx_mask[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time, seq_recency\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "# def custom_loss_bert4rec(tensor_weights=None):\n",
    "#     # @tf.function(jit_compile=True)\n",
    "#     def loss(y_true, y_pred):\n",
    "#         mask = tf.where(y_true >= 1, 1., 0.)\n",
    "#         loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "#         if tensor_weights is not None:\n",
    "#             weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "#             return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "#         else:\n",
    "#             return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "#     loss.__name__ = f'loss_bert4rec'\n",
    "#     return loss\n",
    "\n",
    "def weighted_loss_bert4rec(apply_weights=False):\n",
    "    # @tf.function(jit_compile=True)\n",
    "    def loss(y_true, y_pred, y_type):\n",
    "        y_type = tf.squeeze(y_type, -1)\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if apply_weights:\n",
    "            w_clicks = tf.cast(y_type==1, tf.float32) * 1\n",
    "            w_cart = tf.cast(y_type==2, tf.float32) * 3\n",
    "            w_order = tf.cast(y_type==3, tf.float32) * 6\n",
    "            weights = tf.reduce_max(tf.stack([w_clicks, w_cart, w_order], axis=-1), -1)\n",
    "            return tf.reduce_sum(loss * mask * weights) / (tf.reduce_sum(mask * weights) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'weighted_loss_bert4rec'\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def custom_accuracy():\n",
    "    def masked_accuracy(y_true, y_pred, y_type):\n",
    "        y_pred = tf.argmax(y_pred, axis=2)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        y_type = y_type[:, :, 0]\n",
    "        mask_padding = y_true != 0\n",
    "        mask_clicks = y_type == 1\n",
    "        mask_carts = y_type == 2\n",
    "        mask_orders = y_type == 3\n",
    "        match = y_true == y_pred\n",
    "        match_clicks = match & mask_padding & mask_clicks\n",
    "        match_carts = match & mask_padding & mask_carts\n",
    "        match_orders = match & mask_padding & mask_orders\n",
    "        match_clicks, mask_clicks = tf.cast(match_clicks, dtype=tf.float32), tf.cast(mask_clicks, dtype=tf.float32)\n",
    "        match_carts, mask_carts = tf.cast(match_carts, dtype=tf.float32), tf.cast(mask_carts, dtype=tf.float32)\n",
    "        match_orders, mask_orders = tf.cast(match_orders, dtype=tf.float32), tf.cast(mask_orders, dtype=tf.float32)\n",
    "        mask_padding = tf.cast(mask_padding, dtype=tf.float32)\n",
    "        acc_clicks = tf.reduce_sum(match_clicks)/(tf.reduce_sum(mask_clicks * mask_padding)+1e-8)\n",
    "        acc_carts = tf.reduce_sum(match_carts)/(tf.reduce_sum(mask_carts * mask_padding)+1e-8)\n",
    "        acc_orders = tf.reduce_sum(match_orders)/(tf.reduce_sum(mask_orders * mask_padding)+1e-8)\n",
    "        # score = 0.1*acc_clicks + 0.3*acc_carts + 0.6*acc_orders\n",
    "        return acc_clicks, acc_carts, acc_orders\n",
    "    masked_accuracy.__name__ = f'seq_acc'\n",
    "    return masked_accuracy\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "\n",
    "def recall_top_k(top_k=1, seq_len=10):\n",
    "    # @tf.function\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_pred)[0]\n",
    "        y_true = tf.cast(y_true, tf.int64)\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.int32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.int64)\n",
    "        # cum_sum = tf.zeros(n_samples, tf.int32)\n",
    "        result = tf.constant(0, tf.int32)\n",
    "        for i in tf.range(seq_len):\n",
    "            indexes_i = top_index[:, i, :]\n",
    "            is_true = tf.reduce_sum(tf.reduce_max(tf.where(y_true[:, i:i+1]==indexes_i, 1, 0), -1) * mask[:, i])\n",
    "            result += is_true\n",
    "        return tf.cast(result, tf.float32) / (tf.cast(tf.reduce_sum(mask), tf.float32) + 1e-8)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name\n",
    "\n",
    "def set_seed(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "plt.plot(tmp_lr(tf.range(13_000_000 // (64* 2), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = [flat_gradients(g) / num_grad_steps for g in step_gradients] \n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g) / num_grad_steps\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        optimizer.apply_gradients(zip(global_gradients, model.trainable_variables))\n",
    "        global_gradients = []\n",
    "        total_step += 1\n",
    "    return global_gradients, total_step\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, model, optimizer, num_accum_steps, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions, seq_type)\n",
    "        acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "\n",
    "    gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(gradients)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions, seq_type)\n",
    "    acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.6f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name='', dict_config=None):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"),\n",
    "               config=dict_config)\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "\n",
    "def grad_accum_scheduler(num_samples, list_scheduler, max_grad_accum):\n",
    "    if num_samples >= len(list_scheduler):\n",
    "        return max_grad_accum\n",
    "    return list_scheduler[num_samples]\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menric1296\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/enric/SSD1TB/KAGGLE/025_Kaggle-OTTO Recsys-2022/1_Scripts/wandb/run-20221201_220438-20oylrae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/20oylrae\" target=\"_blank\">model_bert4rec_complete_0.13_2022-12-01 22:04:37</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n",
      "================================================================================\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 22:04:40.737690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:436: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2022-12-01 22:04:41.733488: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1fffc110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-01 22:04:41.733504: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2022-12-01 22:04:41.756479: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model_bert4_rec/encoder_transformer_block/dropout_1/dropout/random_uniform/RandomUniform\n",
      "2022-12-01 22:04:41.759978: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-01 22:04:43.672445: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-12-01 22:04:44.207185: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Epoch]1/3 [Time]3.59 [Step]1 [Batch]0 [Speed]3592.30ms/step [Loss]14.2032 [Metrics]{'train_loss:14.203168 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000000 grad_accum:1.000000 total_samples:0.000000'}\n",
      "Saving checkpoint for epoch 1 at step 1 on path model_bert4rec_complete_0.13\n",
      "[Train Epoch]1/3 [Time]70.55 [Step]501 [Batch]500 [Speed]141.10ms/step [Loss]14.0835 [Metrics]{'train_loss:14.083467 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000044 grad_accum:1.000000 total_samples:32000.000000'}\n",
      "[Train Epoch]1/3 [Time]131.84 [Step]1001 [Batch]1000 [Speed]131.84ms/step [Loss]13.6850 [Metrics]{'train_loss:13.684999 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000088 grad_accum:1.000000 total_samples:64000.000000'}\n",
      "[Train Epoch]1/3 [Time]193.43 [Step]1501 [Batch]1500 [Speed]128.95ms/step [Loss]13.3378 [Metrics]{'train_loss:13.337763 train_acc_clicks:0.001294 train_acc_carts:0.003233 train_acc_orders:0.003027 lr:0.000133 grad_accum:1.000000 total_samples:96000.000000'}\n",
      "[Train Epoch]1/3 [Time]254.45 [Step]2001 [Batch]2000 [Speed]127.23ms/step [Loss]13.0831 [Metrics]{'train_loss:13.083098 train_acc_clicks:0.006278 train_acc_carts:0.015467 train_acc_orders:0.017518 lr:0.000177 grad_accum:1.000000 total_samples:128000.000000'}\n",
      "[Train Epoch]1/3 [Time]315.69 [Step]2501 [Batch]2500 [Speed]126.28ms/step [Loss]12.8811 [Metrics]{'train_loss:12.881124 train_acc_clicks:0.011467 train_acc_carts:0.028176 train_acc_orders:0.029588 lr:0.000221 grad_accum:1.000000 total_samples:160000.000000'}\n",
      "[Train Epoch]1/3 [Time]376.98 [Step]3001 [Batch]3000 [Speed]125.66ms/step [Loss]12.7018 [Metrics]{'train_loss:12.701839 train_acc_clicks:0.018058 train_acc_carts:0.043330 train_acc_orders:0.048499 lr:0.000265 grad_accum:1.000000 total_samples:192000.000000'}\n",
      "[Train Epoch]1/3 [Time]438.14 [Step]3501 [Batch]3500 [Speed]125.18ms/step [Loss]12.5503 [Metrics]{'train_loss:12.550294 train_acc_clicks:0.025546 train_acc_carts:0.059302 train_acc_orders:0.066224 lr:0.000309 grad_accum:1.000000 total_samples:224000.000000'}\n",
      "[Train Epoch]1/3 [Time]498.79 [Step]4001 [Batch]4000 [Speed]124.70ms/step [Loss]12.4121 [Metrics]{'train_loss:12.412134 train_acc_clicks:0.033027 train_acc_carts:0.075410 train_acc_orders:0.081418 lr:0.000354 grad_accum:1.000000 total_samples:256000.000000'}\n",
      "[Train Epoch]1/3 [Time]559.73 [Step]4501 [Batch]4500 [Speed]124.39ms/step [Loss]12.2869 [Metrics]{'train_loss:12.286874 train_acc_clicks:0.039481 train_acc_carts:0.088952 train_acc_orders:0.093503 lr:0.000398 grad_accum:1.000000 total_samples:288000.000000'}\n",
      "[Train Epoch]1/3 [Time]621.06 [Step]5001 [Batch]5000 [Speed]124.21ms/step [Loss]12.1726 [Metrics]{'train_loss:12.172607 train_acc_clicks:0.044688 train_acc_carts:0.099181 train_acc_orders:0.106320 lr:0.000442 grad_accum:1.000000 total_samples:320000.000000'}\n",
      "[Train Epoch]1/3 [Time]682.12 [Step]5501 [Batch]5500 [Speed]124.02ms/step [Loss]12.0641 [Metrics]{'train_loss:12.064070 train_acc_clicks:0.049675 train_acc_carts:0.108219 train_acc_orders:0.114980 lr:0.000486 grad_accum:1.000000 total_samples:352000.000000'}\n",
      "[Train Epoch]1/3 [Time]743.17 [Step]6001 [Batch]6000 [Speed]123.86ms/step [Loss]11.9619 [Metrics]{'train_loss:11.961871 train_acc_clicks:0.053930 train_acc_carts:0.116172 train_acc_orders:0.124457 lr:0.000530 grad_accum:1.000000 total_samples:384000.000000'}\n",
      "[Train Epoch]1/3 [Time]803.55 [Step]6501 [Batch]6500 [Speed]123.62ms/step [Loss]11.8655 [Metrics]{'train_loss:11.865465 train_acc_clicks:0.057726 train_acc_carts:0.123554 train_acc_orders:0.132723 lr:0.000575 grad_accum:1.000000 total_samples:416000.000000'}\n",
      "[Train Epoch]1/3 [Time]864.32 [Step]7001 [Batch]7000 [Speed]123.47ms/step [Loss]11.7778 [Metrics]{'train_loss:11.777815 train_acc_clicks:0.060782 train_acc_carts:0.130495 train_acc_orders:0.140928 lr:0.000619 grad_accum:1.000000 total_samples:448000.000000'}\n",
      "[Train Epoch]1/3 [Time]924.53 [Step]7501 [Batch]7500 [Speed]123.27ms/step [Loss]11.6926 [Metrics]{'train_loss:11.692603 train_acc_clicks:0.063295 train_acc_carts:0.136461 train_acc_orders:0.148029 lr:0.000663 grad_accum:1.000000 total_samples:480000.000000'}\n",
      "[Train Epoch]1/3 [Time]985.01 [Step]8001 [Batch]8000 [Speed]123.13ms/step [Loss]11.6106 [Metrics]{'train_loss:11.610612 train_acc_clicks:0.065567 train_acc_carts:0.141392 train_acc_orders:0.152598 lr:0.000707 grad_accum:1.000000 total_samples:512000.000000'}\n",
      "[Train Epoch]1/3 [Time]1045.89 [Step]8501 [Batch]8500 [Speed]123.05ms/step [Loss]11.5319 [Metrics]{'train_loss:11.531855 train_acc_clicks:0.067639 train_acc_carts:0.145235 train_acc_orders:0.156201 lr:0.000751 grad_accum:1.000000 total_samples:544000.000000'}\n",
      "[Train Epoch]1/3 [Time]1107.91 [Step]9001 [Batch]9000 [Speed]123.10ms/step [Loss]11.4572 [Metrics]{'train_loss:11.457250 train_acc_clicks:0.069454 train_acc_carts:0.148595 train_acc_orders:0.159855 lr:0.000796 grad_accum:1.000000 total_samples:576000.000000'}\n",
      "[Train Epoch]1/3 [Time]1169.33 [Step]9501 [Batch]9500 [Speed]123.09ms/step [Loss]11.3876 [Metrics]{'train_loss:11.387628 train_acc_clicks:0.070949 train_acc_carts:0.151590 train_acc_orders:0.162978 lr:0.000840 grad_accum:1.000000 total_samples:608000.000000'}\n",
      "[Train Epoch]1/3 [Time]1228.00 [Step]10001 [Batch]10000 [Speed]122.80ms/step [Loss]11.3212 [Metrics]{'train_loss:11.321209 train_acc_clicks:0.072282 train_acc_carts:0.154226 train_acc_orders:0.165218 lr:0.000884 grad_accum:1.000000 total_samples:640000.000000'}\n",
      "[Train Epoch]1/3 [Time]1288.92 [Step]10501 [Batch]10500 [Speed]122.75ms/step [Loss]11.2563 [Metrics]{'train_loss:11.256252 train_acc_clicks:0.073509 train_acc_carts:0.156733 train_acc_orders:0.169062 lr:0.000863 grad_accum:1.000000 total_samples:672000.000000'}\n",
      "[Train Epoch]1/3 [Time]1349.17 [Step]11001 [Batch]11000 [Speed]122.65ms/step [Loss]11.1949 [Metrics]{'train_loss:11.194897 train_acc_clicks:0.074659 train_acc_carts:0.159865 train_acc_orders:0.170479 lr:0.000843 grad_accum:1.000000 total_samples:704000.000000'}\n",
      "[Train Epoch]1/3 [Time]1409.81 [Step]11501 [Batch]11500 [Speed]122.59ms/step [Loss]11.1334 [Metrics]{'train_loss:11.133440 train_acc_clicks:0.075751 train_acc_carts:0.162894 train_acc_orders:0.173569 lr:0.000824 grad_accum:1.000000 total_samples:736000.000000'}\n",
      "[Train Epoch]1/3 [Time]1470.98 [Step]12001 [Batch]12000 [Speed]122.58ms/step [Loss]11.0749 [Metrics]{'train_loss:11.074899 train_acc_clicks:0.076861 train_acc_carts:0.165400 train_acc_orders:0.175731 lr:0.000807 grad_accum:1.000000 total_samples:768000.000000'}\n",
      "[Train Epoch]1/3 [Time]1531.43 [Step]12501 [Batch]12500 [Speed]122.51ms/step [Loss]11.0193 [Metrics]{'train_loss:11.019294 train_acc_clicks:0.077836 train_acc_carts:0.168352 train_acc_orders:0.177540 lr:0.000791 grad_accum:1.000000 total_samples:800000.000000'}\n",
      "[Train Epoch]1/3 [Time]1591.87 [Step]13001 [Batch]13000 [Speed]122.45ms/step [Loss]10.9657 [Metrics]{'train_loss:10.965721 train_acc_clicks:0.078765 train_acc_carts:0.171033 train_acc_orders:0.179129 lr:0.000775 grad_accum:1.000000 total_samples:832000.000000'}\n",
      "[Train Epoch]1/3 [Time]1651.98 [Step]13501 [Batch]13500 [Speed]122.37ms/step [Loss]10.9105 [Metrics]{'train_loss:10.910515 train_acc_clicks:0.079754 train_acc_carts:0.173629 train_acc_orders:0.181014 lr:0.000761 grad_accum:1.000000 total_samples:864000.000000'}\n",
      "[Train Epoch]1/3 [Time]1712.67 [Step]14001 [Batch]14000 [Speed]122.33ms/step [Loss]10.8601 [Metrics]{'train_loss:10.860074 train_acc_clicks:0.080639 train_acc_carts:0.176065 train_acc_orders:0.182000 lr:0.000747 grad_accum:1.000000 total_samples:896000.000000'}\n",
      "[Train Epoch]1/3 [Time]1773.28 [Step]14501 [Batch]14500 [Speed]122.30ms/step [Loss]10.8108 [Metrics]{'train_loss:10.810791 train_acc_clicks:0.081426 train_acc_carts:0.178656 train_acc_orders:0.183777 lr:0.000734 grad_accum:1.000000 total_samples:928000.000000'}\n",
      "[Train Epoch]1/3 [Time]1834.04 [Step]15001 [Batch]15000 [Speed]122.27ms/step [Loss]10.7626 [Metrics]{'train_loss:10.762631 train_acc_clicks:0.082316 train_acc_carts:0.181361 train_acc_orders:0.184943 lr:0.000722 grad_accum:1.000000 total_samples:960000.000000'}\n",
      "Saving checkpoint for epoch 1 at step 15001 on path model_bert4rec_complete_0.13\n",
      "[Train Epoch]1/3 [Time]1896.23 [Step]15501 [Batch]15500 [Speed]122.34ms/step [Loss]10.7162 [Metrics]{'train_loss:10.716235 train_acc_clicks:0.083175 train_acc_carts:0.183656 train_acc_orders:0.187512 lr:0.000710 grad_accum:1.000000 total_samples:992000.000000'}\n",
      "[Train Epoch]1/3 [Time]1949.66 [Step]16001 [Batch]16000 [Speed]121.85ms/step [Loss]10.6716 [Metrics]{'train_loss:10.671558 train_acc_clicks:0.083979 train_acc_carts:0.185986 train_acc_orders:0.188912 lr:0.000699 grad_accum:1.000000 total_samples:1024000.000000'}\n",
      "[Train Epoch]1/3 [Time]2003.06 [Step]16501 [Batch]16500 [Speed]121.40ms/step [Loss]10.6256 [Metrics]{'train_loss:10.625606 train_acc_clicks:0.084878 train_acc_carts:0.188573 train_acc_orders:0.190869 lr:0.000688 grad_accum:1.000000 total_samples:1056000.000000'}\n",
      "[Train Epoch]1/3 [Time]2056.49 [Step]17001 [Batch]17000 [Speed]120.97ms/step [Loss]10.5819 [Metrics]{'train_loss:10.581948 train_acc_clicks:0.085762 train_acc_carts:0.190775 train_acc_orders:0.192527 lr:0.000678 grad_accum:1.000000 total_samples:1088000.000000'}\n",
      "[Train Epoch]1/3 [Time]2110.06 [Step]17501 [Batch]17500 [Speed]120.58ms/step [Loss]10.5394 [Metrics]{'train_loss:10.539358 train_acc_clicks:0.086583 train_acc_carts:0.193527 train_acc_orders:0.194369 lr:0.000668 grad_accum:1.000000 total_samples:1120000.000000'}\n",
      "[Train Epoch]1/3 [Time]2163.63 [Step]18001 [Batch]18000 [Speed]120.20ms/step [Loss]10.4981 [Metrics]{'train_loss:10.498056 train_acc_clicks:0.087343 train_acc_carts:0.196019 train_acc_orders:0.196952 lr:0.000659 grad_accum:1.000000 total_samples:1152000.000000'}\n",
      "[Train Epoch]1/3 [Time]2217.12 [Step]18501 [Batch]18500 [Speed]119.84ms/step [Loss]10.4579 [Metrics]{'train_loss:10.457851 train_acc_clicks:0.088089 train_acc_carts:0.198334 train_acc_orders:0.198352 lr:0.000650 grad_accum:1.000000 total_samples:1184000.000000'}\n",
      "[Train Epoch]1/3 [Time]2270.67 [Step]19001 [Batch]19000 [Speed]119.51ms/step [Loss]10.4183 [Metrics]{'train_loss:10.418254 train_acc_clicks:0.088887 train_acc_carts:0.200931 train_acc_orders:0.200524 lr:0.000641 grad_accum:1.000000 total_samples:1216000.000000'}\n",
      "[Train Epoch]1/3 [Time]2327.70 [Step]19501 [Batch]19500 [Speed]119.37ms/step [Loss]10.3795 [Metrics]{'train_loss:10.379518 train_acc_clicks:0.089649 train_acc_carts:0.203486 train_acc_orders:0.201988 lr:0.000633 grad_accum:1.000000 total_samples:1248000.000000'}\n",
      "[Train Epoch]1/3 [Time]2389.03 [Step]20001 [Batch]20000 [Speed]119.45ms/step [Loss]10.3417 [Metrics]{'train_loss:10.341654 train_acc_clicks:0.090369 train_acc_carts:0.205745 train_acc_orders:0.203895 lr:0.000625 grad_accum:1.000000 total_samples:1280000.000000'}\n",
      "[Train Epoch]1/3 [Time]2449.50 [Step]20501 [Batch]20500 [Speed]119.49ms/step [Loss]10.3060 [Metrics]{'train_loss:10.305961 train_acc_clicks:0.091022 train_acc_carts:0.207816 train_acc_orders:0.205355 lr:0.000617 grad_accum:1.000000 total_samples:1312000.000000'}\n",
      "[Train Epoch]1/3 [Time]2509.56 [Step]21001 [Batch]21000 [Speed]119.50ms/step [Loss]10.2700 [Metrics]{'train_loss:10.270042 train_acc_clicks:0.091766 train_acc_carts:0.210113 train_acc_orders:0.206781 lr:0.000610 grad_accum:1.000000 total_samples:1344000.000000'}\n",
      "[Train Epoch]1/3 [Time]2569.89 [Step]21501 [Batch]21500 [Speed]119.53ms/step [Loss]10.2360 [Metrics]{'train_loss:10.235970 train_acc_clicks:0.092411 train_acc_carts:0.211929 train_acc_orders:0.208332 lr:0.000603 grad_accum:1.000000 total_samples:1376000.000000'}\n",
      "[Train Epoch]1/3 [Time]2630.94 [Step]22001 [Batch]22000 [Speed]119.59ms/step [Loss]10.2030 [Metrics]{'train_loss:10.202951 train_acc_clicks:0.093033 train_acc_carts:0.213909 train_acc_orders:0.209283 lr:0.000596 grad_accum:1.000000 total_samples:1408000.000000'}\n",
      "[Train Epoch]1/3 [Time]2691.50 [Step]22501 [Batch]22500 [Speed]119.62ms/step [Loss]10.1710 [Metrics]{'train_loss:10.170979 train_acc_clicks:0.093663 train_acc_carts:0.215888 train_acc_orders:0.210641 lr:0.000589 grad_accum:1.000000 total_samples:1440000.000000'}\n",
      "[Train Epoch]1/3 [Time]2752.31 [Step]23001 [Batch]23000 [Speed]119.67ms/step [Loss]10.1393 [Metrics]{'train_loss:10.139275 train_acc_clicks:0.094292 train_acc_carts:0.218216 train_acc_orders:0.211969 lr:0.000583 grad_accum:1.000000 total_samples:1472000.000000'}\n",
      "[Train Epoch]1/3 [Time]2812.88 [Step]23501 [Batch]23500 [Speed]119.70ms/step [Loss]10.1083 [Metrics]{'train_loss:10.108298 train_acc_clicks:0.094855 train_acc_carts:0.220357 train_acc_orders:0.213265 lr:0.000577 grad_accum:1.000000 total_samples:1504000.000000'}\n",
      "[Train Epoch]1/3 [Time]2872.93 [Step]24001 [Batch]24000 [Speed]119.71ms/step [Loss]10.0783 [Metrics]{'train_loss:10.078338 train_acc_clicks:0.095395 train_acc_carts:0.222396 train_acc_orders:0.214482 lr:0.000571 grad_accum:1.000000 total_samples:1536000.000000'}\n",
      "[Train Epoch]1/3 [Time]2933.24 [Step]24501 [Batch]24500 [Speed]119.72ms/step [Loss]10.0498 [Metrics]{'train_loss:10.049766 train_acc_clicks:0.095969 train_acc_carts:0.224312 train_acc_orders:0.215478 lr:0.000565 grad_accum:1.000000 total_samples:1568000.000000'}\n",
      "[Train Epoch]1/3 [Time]2988.33 [Step]25001 [Batch]25000 [Speed]119.53ms/step [Loss]10.0217 [Metrics]{'train_loss:10.021671 train_acc_clicks:0.096548 train_acc_carts:0.226023 train_acc_orders:0.216531 lr:0.000559 grad_accum:1.000000 total_samples:1600000.000000'}\n",
      "[Train Epoch]1/3 [Time]3047.19 [Step]25501 [Batch]25500 [Speed]119.50ms/step [Loss]9.9937 [Metrics]{'train_loss:9.993706 train_acc_clicks:0.097100 train_acc_carts:0.227898 train_acc_orders:0.217665 lr:0.000553 grad_accum:1.000000 total_samples:1632000.000000'}\n",
      "[Train Epoch]1/3 [Time]3107.35 [Step]26001 [Batch]26000 [Speed]119.51ms/step [Loss]9.9672 [Metrics]{'train_loss:9.967182 train_acc_clicks:0.097583 train_acc_carts:0.229757 train_acc_orders:0.218733 lr:0.000548 grad_accum:1.000000 total_samples:1664000.000000'}\n",
      "[Train Epoch]1/3 [Time]3167.86 [Step]26501 [Batch]26500 [Speed]119.54ms/step [Loss]9.9409 [Metrics]{'train_loss:9.940902 train_acc_clicks:0.098079 train_acc_carts:0.231834 train_acc_orders:0.219683 lr:0.000543 grad_accum:1.000000 total_samples:1696000.000000'}\n",
      "[Train Epoch]1/3 [Time]3228.97 [Step]27001 [Batch]27000 [Speed]119.59ms/step [Loss]9.9159 [Metrics]{'train_loss:9.915930 train_acc_clicks:0.098557 train_acc_carts:0.233569 train_acc_orders:0.221063 lr:0.000538 grad_accum:1.000000 total_samples:1728000.000000'}\n",
      "[Train Epoch]1/3 [Time]3289.48 [Step]27501 [Batch]27500 [Speed]119.62ms/step [Loss]9.8912 [Metrics]{'train_loss:9.891182 train_acc_clicks:0.098985 train_acc_carts:0.235018 train_acc_orders:0.221619 lr:0.000533 grad_accum:1.000000 total_samples:1760000.000000'}\n",
      "[Train Epoch]1/3 [Time]3350.09 [Step]28001 [Batch]28000 [Speed]119.65ms/step [Loss]9.8666 [Metrics]{'train_loss:9.866609 train_acc_clicks:0.099454 train_acc_carts:0.236434 train_acc_orders:0.222493 lr:0.000528 grad_accum:1.000000 total_samples:1792000.000000'}\n",
      "[Train Epoch]1/3 [Time]3410.55 [Step]28501 [Batch]28500 [Speed]119.67ms/step [Loss]9.8430 [Metrics]{'train_loss:9.843030 train_acc_clicks:0.099842 train_acc_carts:0.237932 train_acc_orders:0.222910 lr:0.000524 grad_accum:1.000000 total_samples:1824000.000000'}\n",
      "[Train Epoch]1/3 [Time]3471.08 [Step]29001 [Batch]29000 [Speed]119.69ms/step [Loss]9.8205 [Metrics]{'train_loss:9.820470 train_acc_clicks:0.100226 train_acc_carts:0.239330 train_acc_orders:0.223381 lr:0.000519 grad_accum:1.000000 total_samples:1856000.000000'}\n",
      "[Train Epoch]1/3 [Time]3531.43 [Step]29501 [Batch]29500 [Speed]119.71ms/step [Loss]9.7977 [Metrics]{'train_loss:9.797695 train_acc_clicks:0.100637 train_acc_carts:0.240724 train_acc_orders:0.224240 lr:0.000515 grad_accum:1.000000 total_samples:1888000.000000'}\n",
      "[Train Epoch]1/3 [Time]3585.53 [Step]30001 [Batch]30000 [Speed]119.52ms/step [Loss]9.7760 [Metrics]{'train_loss:9.776012 train_acc_clicks:0.101062 train_acc_carts:0.242174 train_acc_orders:0.225178 lr:0.000510 grad_accum:1.000000 total_samples:1920000.000000'}\n",
      "Saving checkpoint for epoch 1 at step 30001 on path model_bert4rec_complete_0.13\n",
      "[Train Epoch]1/3 [Time]3643.38 [Step]30501 [Batch]30500 [Speed]119.46ms/step [Loss]9.7542 [Metrics]{'train_loss:9.754177 train_acc_clicks:0.101459 train_acc_carts:0.243574 train_acc_orders:0.226381 lr:0.000506 grad_accum:1.000000 total_samples:1952000.000000'}\n",
      "[Train Epoch]1/3 [Time]3697.03 [Step]31001 [Batch]31000 [Speed]119.26ms/step [Loss]9.7331 [Metrics]{'train_loss:9.733126 train_acc_clicks:0.101882 train_acc_carts:0.244742 train_acc_orders:0.227052 lr:0.000502 grad_accum:1.000000 total_samples:1984000.000000'}\n",
      "[Train Epoch]1/3 [Time]3749.30 [Step]31375 [Batch]31500 [Speed]119.03ms/step [Loss]9.7132 [Metrics]{'train_loss:9.713158 train_acc_clicks:0.102215 train_acc_carts:0.246045 train_acc_orders:0.227469 lr:0.000499 grad_accum:2.000000 total_samples:2016000.000000'}\n",
      "[Train Epoch]1/3 [Time]3800.12 [Step]31625 [Batch]32000 [Speed]118.75ms/step [Loss]9.6926 [Metrics]{'train_loss:9.692625 train_acc_clicks:0.102583 train_acc_carts:0.247487 train_acc_orders:0.228295 lr:0.000497 grad_accum:2.000000 total_samples:2048000.000000'}\n",
      "[Train Epoch]1/3 [Time]3850.99 [Step]31875 [Batch]32500 [Speed]118.49ms/step [Loss]9.6717 [Metrics]{'train_loss:9.671700 train_acc_clicks:0.102956 train_acc_carts:0.249114 train_acc_orders:0.229319 lr:0.000495 grad_accum:2.000000 total_samples:2080000.000000'}\n",
      "[Train Epoch]1/3 [Time]3901.90 [Step]32125 [Batch]33000 [Speed]118.24ms/step [Loss]9.6522 [Metrics]{'train_loss:9.652193 train_acc_clicks:0.103320 train_acc_carts:0.250438 train_acc_orders:0.229721 lr:0.000493 grad_accum:2.000000 total_samples:2112000.000000'}\n",
      "[Train Epoch]1/3 [Time]3952.77 [Step]32375 [Batch]33500 [Speed]117.99ms/step [Loss]9.6322 [Metrics]{'train_loss:9.632184 train_acc_clicks:0.103692 train_acc_carts:0.251819 train_acc_orders:0.230527 lr:0.000491 grad_accum:2.000000 total_samples:2144000.000000'}\n",
      "[Train Epoch]1/3 [Time]4003.62 [Step]32625 [Batch]34000 [Speed]117.75ms/step [Loss]9.6124 [Metrics]{'train_loss:9.612358 train_acc_clicks:0.104062 train_acc_carts:0.253173 train_acc_orders:0.231111 lr:0.000489 grad_accum:2.000000 total_samples:2176000.000000'}\n",
      "[Train Epoch]1/3 [Time]4054.53 [Step]32875 [Batch]34500 [Speed]117.52ms/step [Loss]9.5920 [Metrics]{'train_loss:9.592019 train_acc_clicks:0.104424 train_acc_carts:0.254455 train_acc_orders:0.231740 lr:0.000487 grad_accum:2.000000 total_samples:2208000.000000'}\n",
      "[Train Epoch]1/3 [Time]4105.49 [Step]33125 [Batch]35000 [Speed]117.30ms/step [Loss]9.5725 [Metrics]{'train_loss:9.572475 train_acc_clicks:0.104758 train_acc_carts:0.255671 train_acc_orders:0.232463 lr:0.000486 grad_accum:2.000000 total_samples:2240000.000000'}\n",
      "[Train Epoch]1/3 [Time]4156.31 [Step]33375 [Batch]35500 [Speed]117.08ms/step [Loss]9.5538 [Metrics]{'train_loss:9.553823 train_acc_clicks:0.105068 train_acc_carts:0.256984 train_acc_orders:0.233170 lr:0.000484 grad_accum:2.000000 total_samples:2272000.000000'}\n",
      "[Train Epoch]1/3 [Time]4207.15 [Step]33625 [Batch]36000 [Speed]116.87ms/step [Loss]9.5355 [Metrics]{'train_loss:9.535469 train_acc_clicks:0.105404 train_acc_carts:0.258295 train_acc_orders:0.234154 lr:0.000482 grad_accum:2.000000 total_samples:2304000.000000'}\n",
      "[Train Epoch]1/3 [Time]4258.02 [Step]33875 [Batch]36500 [Speed]116.66ms/step [Loss]9.5176 [Metrics]{'train_loss:9.517565 train_acc_clicks:0.105688 train_acc_carts:0.259420 train_acc_orders:0.234644 lr:0.000480 grad_accum:2.000000 total_samples:2336000.000000'}\n",
      "[Train Epoch]1/3 [Time]4308.91 [Step]34125 [Batch]37000 [Speed]116.46ms/step [Loss]9.4997 [Metrics]{'train_loss:9.499663 train_acc_clicks:0.106033 train_acc_carts:0.260458 train_acc_orders:0.235295 lr:0.000478 grad_accum:2.000000 total_samples:2368000.000000'}\n",
      "[Train Epoch]1/3 [Time]4359.66 [Step]34375 [Batch]37500 [Speed]116.26ms/step [Loss]9.4817 [Metrics]{'train_loss:9.481678 train_acc_clicks:0.106346 train_acc_carts:0.261702 train_acc_orders:0.235983 lr:0.000477 grad_accum:2.000000 total_samples:2400000.000000'}\n",
      "[Train Epoch]1/3 [Time]4410.52 [Step]34625 [Batch]38000 [Speed]116.07ms/step [Loss]9.4646 [Metrics]{'train_loss:9.464581 train_acc_clicks:0.106638 train_acc_carts:0.262867 train_acc_orders:0.236655 lr:0.000475 grad_accum:2.000000 total_samples:2432000.000000'}\n",
      "[Train Epoch]1/3 [Time]4461.47 [Step]34875 [Batch]38500 [Speed]115.88ms/step [Loss]9.4480 [Metrics]{'train_loss:9.448039 train_acc_clicks:0.106926 train_acc_carts:0.263853 train_acc_orders:0.237183 lr:0.000473 grad_accum:2.000000 total_samples:2464000.000000'}\n",
      "[Train Epoch]1/3 [Time]4512.26 [Step]35125 [Batch]39000 [Speed]115.70ms/step [Loss]9.4310 [Metrics]{'train_loss:9.430952 train_acc_clicks:0.107233 train_acc_carts:0.264991 train_acc_orders:0.237886 lr:0.000472 grad_accum:2.000000 total_samples:2496000.000000'}\n",
      "[Train Epoch]1/3 [Time]4563.03 [Step]35375 [Batch]39500 [Speed]115.52ms/step [Loss]9.4141 [Metrics]{'train_loss:9.414091 train_acc_clicks:0.107567 train_acc_carts:0.266088 train_acc_orders:0.238367 lr:0.000470 grad_accum:2.000000 total_samples:2528000.000000'}\n",
      "[Train Epoch]1/3 [Time]4613.86 [Step]35625 [Batch]40000 [Speed]115.35ms/step [Loss]9.3978 [Metrics]{'train_loss:9.397795 train_acc_clicks:0.107852 train_acc_carts:0.267284 train_acc_orders:0.238715 lr:0.000468 grad_accum:2.000000 total_samples:2560000.000000'}\n",
      "[Train Epoch]1/3 [Time]4664.67 [Step]35875 [Batch]40500 [Speed]115.18ms/step [Loss]9.3818 [Metrics]{'train_loss:9.381801 train_acc_clicks:0.108154 train_acc_carts:0.268418 train_acc_orders:0.239095 lr:0.000467 grad_accum:2.000000 total_samples:2592000.000000'}\n",
      "[Train Epoch]1/3 [Time]4715.60 [Step]36125 [Batch]41000 [Speed]115.01ms/step [Loss]9.3654 [Metrics]{'train_loss:9.365429 train_acc_clicks:0.108472 train_acc_carts:0.269407 train_acc_orders:0.239764 lr:0.000465 grad_accum:2.000000 total_samples:2624000.000000'}\n",
      "[Train Epoch]1/3 [Time]4766.43 [Step]36375 [Batch]41500 [Speed]114.85ms/step [Loss]9.3496 [Metrics]{'train_loss:9.349597 train_acc_clicks:0.108748 train_acc_carts:0.270491 train_acc_orders:0.240159 lr:0.000463 grad_accum:2.000000 total_samples:2656000.000000'}\n",
      "[Train Epoch]1/3 [Time]4817.25 [Step]36625 [Batch]42000 [Speed]114.70ms/step [Loss]9.3348 [Metrics]{'train_loss:9.334764 train_acc_clicks:0.109037 train_acc_carts:0.271474 train_acc_orders:0.240722 lr:0.000462 grad_accum:2.000000 total_samples:2688000.000000'}\n",
      "[Train Epoch]1/3 [Time]4868.07 [Step]36875 [Batch]42500 [Speed]114.54ms/step [Loss]9.3193 [Metrics]{'train_loss:9.319263 train_acc_clicks:0.109312 train_acc_carts:0.272627 train_acc_orders:0.241362 lr:0.000460 grad_accum:2.000000 total_samples:2720000.000000'}\n",
      "[Train Epoch]1/3 [Time]4918.88 [Step]37125 [Batch]43000 [Speed]114.39ms/step [Loss]9.3044 [Metrics]{'train_loss:9.304370 train_acc_clicks:0.109573 train_acc_carts:0.273597 train_acc_orders:0.242085 lr:0.000459 grad_accum:2.000000 total_samples:2752000.000000'}\n",
      "[Train Epoch]1/3 [Time]4969.69 [Step]37375 [Batch]43500 [Speed]114.25ms/step [Loss]9.2902 [Metrics]{'train_loss:9.290236 train_acc_clicks:0.109781 train_acc_carts:0.274420 train_acc_orders:0.242410 lr:0.000457 grad_accum:2.000000 total_samples:2784000.000000'}\n",
      "[Train Epoch]1/3 [Time]5020.45 [Step]37625 [Batch]44000 [Speed]114.10ms/step [Loss]9.2759 [Metrics]{'train_loss:9.275863 train_acc_clicks:0.110033 train_acc_carts:0.275310 train_acc_orders:0.242775 lr:0.000456 grad_accum:2.000000 total_samples:2816000.000000'}\n",
      "[Train Epoch]1/3 [Time]5071.19 [Step]37875 [Batch]44500 [Speed]113.96ms/step [Loss]9.2617 [Metrics]{'train_loss:9.261735 train_acc_clicks:0.110253 train_acc_carts:0.276199 train_acc_orders:0.243272 lr:0.000454 grad_accum:2.000000 total_samples:2848000.000000'}\n",
      "[Train Epoch]1/3 [Time]5122.04 [Step]38125 [Batch]45000 [Speed]113.82ms/step [Loss]9.2473 [Metrics]{'train_loss:9.247274 train_acc_clicks:0.110497 train_acc_carts:0.277252 train_acc_orders:0.244005 lr:0.000453 grad_accum:2.000000 total_samples:2880000.000000'}\n",
      "Saving checkpoint for epoch 1 at step 38125 on path model_bert4rec_complete_0.13\n",
      "[Train Epoch]1/3 [Time]5176.99 [Step]38375 [Batch]45500 [Speed]113.78ms/step [Loss]9.2336 [Metrics]{'train_loss:9.233550 train_acc_clicks:0.110766 train_acc_carts:0.277955 train_acc_orders:0.244414 lr:0.000451 grad_accum:2.000000 total_samples:2912000.000000'}\n",
      "[Train Epoch]1/3 [Time]5227.74 [Step]38625 [Batch]46000 [Speed]113.65ms/step [Loss]9.2202 [Metrics]{'train_loss:9.220151 train_acc_clicks:0.110988 train_acc_carts:0.278735 train_acc_orders:0.244872 lr:0.000450 grad_accum:2.000000 total_samples:2944000.000000'}\n",
      "[Train Epoch]1/3 [Time]5278.64 [Step]38875 [Batch]46500 [Speed]113.52ms/step [Loss]9.2066 [Metrics]{'train_loss:9.206633 train_acc_clicks:0.111225 train_acc_carts:0.279597 train_acc_orders:0.245386 lr:0.000448 grad_accum:2.000000 total_samples:2976000.000000'}\n",
      "[Train Epoch]1/3 [Time]5329.43 [Step]39125 [Batch]47000 [Speed]113.39ms/step [Loss]9.1930 [Metrics]{'train_loss:9.193039 train_acc_clicks:0.111435 train_acc_carts:0.280413 train_acc_orders:0.245523 lr:0.000447 grad_accum:2.000000 total_samples:3008000.000000'}\n",
      "[Train Epoch]1/3 [Time]5380.19 [Step]39375 [Batch]47500 [Speed]113.27ms/step [Loss]9.1803 [Metrics]{'train_loss:9.180326 train_acc_clicks:0.111642 train_acc_carts:0.281213 train_acc_orders:0.245930 lr:0.000445 grad_accum:2.000000 total_samples:3040000.000000'}\n",
      "[Train Epoch]1/3 [Time]5430.94 [Step]39625 [Batch]48000 [Speed]113.14ms/step [Loss]9.1676 [Metrics]{'train_loss:9.167619 train_acc_clicks:0.111838 train_acc_carts:0.282087 train_acc_orders:0.246405 lr:0.000444 grad_accum:2.000000 total_samples:3072000.000000'}\n",
      "[Train Epoch]1/3 [Time]5481.69 [Step]39875 [Batch]48500 [Speed]113.02ms/step [Loss]9.1544 [Metrics]{'train_loss:9.154448 train_acc_clicks:0.112069 train_acc_carts:0.282904 train_acc_orders:0.246761 lr:0.000443 grad_accum:2.000000 total_samples:3104000.000000'}\n",
      "[Train Epoch]1/3 [Time]5532.50 [Step]40125 [Batch]49000 [Speed]112.91ms/step [Loss]9.1418 [Metrics]{'train_loss:9.141812 train_acc_clicks:0.112280 train_acc_carts:0.283910 train_acc_orders:0.246950 lr:0.000441 grad_accum:2.000000 total_samples:3136000.000000'}\n",
      "[Train Epoch]1/3 [Time]5583.29 [Step]40375 [Batch]49500 [Speed]112.79ms/step [Loss]9.1290 [Metrics]{'train_loss:9.128971 train_acc_clicks:0.112528 train_acc_carts:0.284714 train_acc_orders:0.247651 lr:0.000440 grad_accum:2.000000 total_samples:3168000.000000'}\n",
      "[Train Epoch]1/3 [Time]5634.08 [Step]40625 [Batch]50000 [Speed]112.68ms/step [Loss]9.1168 [Metrics]{'train_loss:9.116779 train_acc_clicks:0.112740 train_acc_carts:0.285547 train_acc_orders:0.248288 lr:0.000439 grad_accum:2.000000 total_samples:3200000.000000'}\n",
      "[Train Epoch]1/3 [Time]5684.97 [Step]40875 [Batch]50500 [Speed]112.57ms/step [Loss]9.1047 [Metrics]{'train_loss:9.104730 train_acc_clicks:0.112932 train_acc_carts:0.286340 train_acc_orders:0.248785 lr:0.000437 grad_accum:2.000000 total_samples:3232000.000000'}\n",
      "[Train Epoch]1/3 [Time]5735.82 [Step]41125 [Batch]51000 [Speed]112.47ms/step [Loss]9.0928 [Metrics]{'train_loss:9.092779 train_acc_clicks:0.113130 train_acc_carts:0.287139 train_acc_orders:0.249226 lr:0.000436 grad_accum:2.000000 total_samples:3264000.000000'}\n",
      "[Train Epoch]1/3 [Time]5786.60 [Step]41375 [Batch]51500 [Speed]112.36ms/step [Loss]9.0807 [Metrics]{'train_loss:9.080716 train_acc_clicks:0.113331 train_acc_carts:0.287969 train_acc_orders:0.249730 lr:0.000435 grad_accum:2.000000 total_samples:3296000.000000'}\n",
      "[Train Epoch]1/3 [Time]5837.43 [Step]41625 [Batch]52000 [Speed]112.26ms/step [Loss]9.0692 [Metrics]{'train_loss:9.069199 train_acc_clicks:0.113523 train_acc_carts:0.288705 train_acc_orders:0.250006 lr:0.000433 grad_accum:2.000000 total_samples:3328000.000000'}\n",
      "[Train Epoch]1/3 [Time]5888.26 [Step]41875 [Batch]52500 [Speed]112.16ms/step [Loss]9.0577 [Metrics]{'train_loss:9.057747 train_acc_clicks:0.113724 train_acc_carts:0.289524 train_acc_orders:0.250398 lr:0.000432 grad_accum:2.000000 total_samples:3360000.000000'}\n",
      "[Train Epoch]1/3 [Time]5939.19 [Step]42125 [Batch]53000 [Speed]112.06ms/step [Loss]9.0463 [Metrics]{'train_loss:9.046327 train_acc_clicks:0.113929 train_acc_carts:0.290276 train_acc_orders:0.250728 lr:0.000431 grad_accum:2.000000 total_samples:3392000.000000'}\n",
      "[Train Epoch]1/3 [Time]5990.05 [Step]42375 [Batch]53500 [Speed]111.96ms/step [Loss]9.0354 [Metrics]{'train_loss:9.035427 train_acc_clicks:0.114095 train_acc_carts:0.291059 train_acc_orders:0.250790 lr:0.000429 grad_accum:2.000000 total_samples:3424000.000000'}\n",
      "[Train Epoch]1/3 [Time]6040.86 [Step]42625 [Batch]54000 [Speed]111.87ms/step [Loss]9.0247 [Metrics]{'train_loss:9.024726 train_acc_clicks:0.114264 train_acc_carts:0.291800 train_acc_orders:0.251095 lr:0.000428 grad_accum:2.000000 total_samples:3456000.000000'}\n",
      "[Train Epoch]1/3 [Time]6091.61 [Step]42875 [Batch]54500 [Speed]111.77ms/step [Loss]9.0142 [Metrics]{'train_loss:9.014192 train_acc_clicks:0.114444 train_acc_carts:0.292403 train_acc_orders:0.251447 lr:0.000427 grad_accum:2.000000 total_samples:3488000.000000'}\n",
      "[Train Epoch]1/3 [Time]6142.42 [Step]43125 [Batch]55000 [Speed]111.68ms/step [Loss]9.0033 [Metrics]{'train_loss:9.003312 train_acc_clicks:0.114652 train_acc_carts:0.293008 train_acc_orders:0.252031 lr:0.000426 grad_accum:2.000000 total_samples:3520000.000000'}\n",
      "[Train Epoch]1/3 [Time]6193.22 [Step]43375 [Batch]55500 [Speed]111.59ms/step [Loss]8.9929 [Metrics]{'train_loss:8.992908 train_acc_clicks:0.114823 train_acc_carts:0.293755 train_acc_orders:0.252539 lr:0.000424 grad_accum:2.000000 total_samples:3552000.000000'}\n",
      "[Train Epoch]1/3 [Time]6243.94 [Step]43625 [Batch]56000 [Speed]111.50ms/step [Loss]8.9826 [Metrics]{'train_loss:8.982575 train_acc_clicks:0.114991 train_acc_carts:0.294440 train_acc_orders:0.252979 lr:0.000423 grad_accum:2.000000 total_samples:3584000.000000'}\n",
      "[Train Epoch]1/3 [Time]6294.74 [Step]43875 [Batch]56500 [Speed]111.41ms/step [Loss]8.9723 [Metrics]{'train_loss:8.972266 train_acc_clicks:0.115162 train_acc_carts:0.294956 train_acc_orders:0.253558 lr:0.000422 grad_accum:2.000000 total_samples:3616000.000000'}\n",
      "[Train Epoch]1/3 [Time]6345.59 [Step]44125 [Batch]57000 [Speed]111.33ms/step [Loss]8.9620 [Metrics]{'train_loss:8.961977 train_acc_clicks:0.115327 train_acc_carts:0.295666 train_acc_orders:0.254004 lr:0.000421 grad_accum:2.000000 total_samples:3648000.000000'}\n",
      "[Train Epoch]1/3 [Time]6396.44 [Step]44375 [Batch]57500 [Speed]111.24ms/step [Loss]8.9515 [Metrics]{'train_loss:8.951491 train_acc_clicks:0.115520 train_acc_carts:0.296410 train_acc_orders:0.254508 lr:0.000420 grad_accum:2.000000 total_samples:3680000.000000'}\n",
      "[Train Epoch]1/3 [Time]6447.21 [Step]44625 [Batch]58000 [Speed]111.16ms/step [Loss]8.9415 [Metrics]{'train_loss:8.941495 train_acc_clicks:0.115687 train_acc_carts:0.296980 train_acc_orders:0.254846 lr:0.000418 grad_accum:2.000000 total_samples:3712000.000000'}\n",
      "[Train Epoch]1/3 [Time]6498.04 [Step]44875 [Batch]58500 [Speed]111.08ms/step [Loss]8.9316 [Metrics]{'train_loss:8.931611 train_acc_clicks:0.115874 train_acc_carts:0.297596 train_acc_orders:0.255300 lr:0.000417 grad_accum:2.000000 total_samples:3744000.000000'}\n",
      "[Train Epoch]1/3 [Time]6548.87 [Step]45125 [Batch]59000 [Speed]111.00ms/step [Loss]8.9216 [Metrics]{'train_loss:8.921590 train_acc_clicks:0.116041 train_acc_carts:0.298262 train_acc_orders:0.255507 lr:0.000416 grad_accum:2.000000 total_samples:3776000.000000'}\n",
      "[Train Epoch]1/3 [Time]6599.63 [Step]45375 [Batch]59500 [Speed]110.92ms/step [Loss]8.9120 [Metrics]{'train_loss:8.912013 train_acc_clicks:0.116210 train_acc_carts:0.298959 train_acc_orders:0.256045 lr:0.000415 grad_accum:2.000000 total_samples:3808000.000000'}\n",
      "[Train Epoch]1/3 [Time]6650.41 [Step]45625 [Batch]60000 [Speed]110.84ms/step [Loss]8.9022 [Metrics]{'train_loss:8.902218 train_acc_clicks:0.116391 train_acc_carts:0.299563 train_acc_orders:0.256695 lr:0.000414 grad_accum:2.000000 total_samples:3840000.000000'}\n",
      "Saving checkpoint for epoch 1 at step 45625 on path model_bert4rec_complete_0.13\n",
      "[Train Epoch]1/3 [Time]6705.43 [Step]45875 [Batch]60500 [Speed]110.83ms/step [Loss]8.8928 [Metrics]{'train_loss:8.892845 train_acc_clicks:0.116540 train_acc_carts:0.300128 train_acc_orders:0.256967 lr:0.000413 grad_accum:2.000000 total_samples:3872000.000000'}\n",
      "[Train Epoch]1/3 [Time]6756.26 [Step]46125 [Batch]61000 [Speed]110.76ms/step [Loss]8.8835 [Metrics]{'train_loss:8.883500 train_acc_clicks:0.116691 train_acc_carts:0.300791 train_acc_orders:0.257272 lr:0.000412 grad_accum:2.000000 total_samples:3904000.000000'}\n",
      "[Train Epoch]1/3 [Time]6807.12 [Step]46375 [Batch]61500 [Speed]110.68ms/step [Loss]8.8740 [Metrics]{'train_loss:8.874043 train_acc_clicks:0.116861 train_acc_carts:0.301523 train_acc_orders:0.257522 lr:0.000410 grad_accum:2.000000 total_samples:3936000.000000'}\n",
      "[Train Epoch]1/3 [Time]6857.84 [Step]46625 [Batch]62000 [Speed]110.61ms/step [Loss]8.8649 [Metrics]{'train_loss:8.864897 train_acc_clicks:0.117022 train_acc_carts:0.302224 train_acc_orders:0.257974 lr:0.000409 grad_accum:2.000000 total_samples:3968000.000000'}\n",
      "[Train Epoch]1/3 [Time]6908.62 [Step]46875 [Batch]62500 [Speed]110.54ms/step [Loss]8.8557 [Metrics]{'train_loss:8.855730 train_acc_clicks:0.117174 train_acc_carts:0.302676 train_acc_orders:0.258130 lr:0.000408 grad_accum:2.000000 total_samples:4000000.000000'}\n",
      "[Train Epoch]1/3 [Time]6959.45 [Step]47125 [Batch]63000 [Speed]110.47ms/step [Loss]8.8471 [Metrics]{'train_loss:8.847119 train_acc_clicks:0.117322 train_acc_carts:0.303227 train_acc_orders:0.258331 lr:0.000407 grad_accum:2.000000 total_samples:4032000.000000'}\n",
      "[Train Epoch]1/3 [Time]7010.27 [Step]47375 [Batch]63500 [Speed]110.40ms/step [Loss]8.8384 [Metrics]{'train_loss:8.838395 train_acc_clicks:0.117457 train_acc_carts:0.303669 train_acc_orders:0.258729 lr:0.000406 grad_accum:2.000000 total_samples:4064000.000000'}\n",
      "[Train Epoch]1/3 [Time]7061.08 [Step]47625 [Batch]64000 [Speed]110.33ms/step [Loss]8.8298 [Metrics]{'train_loss:8.829827 train_acc_clicks:0.117599 train_acc_carts:0.304191 train_acc_orders:0.259229 lr:0.000405 grad_accum:2.000000 total_samples:4096000.000000'}\n",
      "[Train Epoch]1/3 [Time]7111.94 [Step]47875 [Batch]64500 [Speed]110.26ms/step [Loss]8.8212 [Metrics]{'train_loss:8.821231 train_acc_clicks:0.117720 train_acc_carts:0.304746 train_acc_orders:0.259644 lr:0.000404 grad_accum:2.000000 total_samples:4128000.000000'}\n",
      "[Train Epoch]1/3 [Time]7162.68 [Step]48125 [Batch]65000 [Speed]110.20ms/step [Loss]8.8128 [Metrics]{'train_loss:8.812795 train_acc_clicks:0.117863 train_acc_carts:0.305275 train_acc_orders:0.259916 lr:0.000403 grad_accum:2.000000 total_samples:4160000.000000'}\n",
      "[Train Epoch]1/3 [Time]7213.51 [Step]48375 [Batch]65500 [Speed]110.13ms/step [Loss]8.8044 [Metrics]{'train_loss:8.804352 train_acc_clicks:0.118011 train_acc_carts:0.305939 train_acc_orders:0.260181 lr:0.000402 grad_accum:2.000000 total_samples:4192000.000000'}\n",
      "[Train Epoch]1/3 [Time]7264.29 [Step]48625 [Batch]66000 [Speed]110.06ms/step [Loss]8.7960 [Metrics]{'train_loss:8.795968 train_acc_clicks:0.118156 train_acc_carts:0.306469 train_acc_orders:0.260443 lr:0.000401 grad_accum:2.000000 total_samples:4224000.000000'}\n",
      "[Train Epoch]1/3 [Time]7315.01 [Step]48875 [Batch]66500 [Speed]110.00ms/step [Loss]8.7877 [Metrics]{'train_loss:8.787654 train_acc_clicks:0.118288 train_acc_carts:0.306991 train_acc_orders:0.260978 lr:0.000400 grad_accum:2.000000 total_samples:4256000.000000'}\n",
      "[Train Epoch]1/3 [Time]7365.87 [Step]49125 [Batch]67000 [Speed]109.94ms/step [Loss]8.7796 [Metrics]{'train_loss:8.779565 train_acc_clicks:0.118408 train_acc_carts:0.307518 train_acc_orders:0.261161 lr:0.000399 grad_accum:2.000000 total_samples:4288000.000000'}\n",
      "[Train Epoch]1/3 [Time]7416.64 [Step]49375 [Batch]67500 [Speed]109.88ms/step [Loss]8.7716 [Metrics]{'train_loss:8.771579 train_acc_clicks:0.118526 train_acc_carts:0.307991 train_acc_orders:0.261437 lr:0.000398 grad_accum:2.000000 total_samples:4320000.000000'}\n",
      "[Train Epoch]1/3 [Time]7467.39 [Step]49625 [Batch]68000 [Speed]109.81ms/step [Loss]8.7638 [Metrics]{'train_loss:8.763844 train_acc_clicks:0.118651 train_acc_carts:0.308479 train_acc_orders:0.261902 lr:0.000397 grad_accum:2.000000 total_samples:4352000.000000'}\n",
      "[Train Epoch]1/3 [Time]7518.20 [Step]49875 [Batch]68500 [Speed]109.75ms/step [Loss]8.7556 [Metrics]{'train_loss:8.755565 train_acc_clicks:0.118792 train_acc_carts:0.308984 train_acc_orders:0.262208 lr:0.000396 grad_accum:2.000000 total_samples:4384000.000000'}\n",
      "[Train Epoch]1/3 [Time]7569.03 [Step]50125 [Batch]69000 [Speed]109.70ms/step [Loss]8.7477 [Metrics]{'train_loss:8.747735 train_acc_clicks:0.118908 train_acc_carts:0.309554 train_acc_orders:0.262599 lr:0.000395 grad_accum:2.000000 total_samples:4416000.000000'}\n",
      "[Train Epoch]1/3 [Time]7619.83 [Step]50375 [Batch]69500 [Speed]109.64ms/step [Loss]8.7402 [Metrics]{'train_loss:8.740174 train_acc_clicks:0.119033 train_acc_carts:0.310009 train_acc_orders:0.262883 lr:0.000394 grad_accum:2.000000 total_samples:4448000.000000'}\n",
      "[Train Epoch]1/3 [Time]7672.99 [Step]50625 [Batch]70000 [Speed]109.61ms/step [Loss]8.7325 [Metrics]{'train_loss:8.732464 train_acc_clicks:0.119171 train_acc_carts:0.310458 train_acc_orders:0.263236 lr:0.000393 grad_accum:2.000000 total_samples:4480000.000000'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 128\u001b[0m\n\u001b[1;32m    123\u001b[0m grad_accum \u001b[39m=\u001b[39m grad_accum_scheduler(total_samples,\n\u001b[1;32m    124\u001b[0m                                   list_scheduler\u001b[39m=\u001b[39mlist_scheduler, \n\u001b[1;32m    125\u001b[0m                                   max_grad_accum\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mtup_scheduler_grad_accum[\u001b[39m1\u001b[39m])                                                             \n\u001b[1;32m    126\u001b[0m step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39mtarget, model\u001b[39m=\u001b[39mmodel, optimizer\u001b[39m=\u001b[39moptimizer, num_accum_steps\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconstant(grad_accum, tf\u001b[39m.\u001b[39mfloat32), \n\u001b[1;32m    127\u001b[0m                             loss\u001b[39m=\u001b[39mtrain_loss, acc_clicks\u001b[39m=\u001b[39mtrain_acc_clicks, acc_carts\u001b[39m=\u001b[39mtrain_acc_carts, acc_orders\u001b[39m=\u001b[39mtrain_acc_orders, seq_type\u001b[39m=\u001b[39minputs[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 128\u001b[0m global_gradients, total_step \u001b[39m=\u001b[39m backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    130\u001b[0m     train_dict_metrics \u001b[39m=\u001b[39m {x\u001b[39m.\u001b[39mname : x\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
      "Cell \u001b[0;32mIn [7], line 22\u001b[0m, in \u001b[0;36mbackward_optimization\u001b[0;34m(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         global_gradients[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_gradients(g) \u001b[39m/\u001b[39m num_grad_steps\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m num_grad_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 22\u001b[0m     optimizer\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(global_gradients, model\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[1;32m     23\u001b[0m     global_gradients \u001b[39m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m     total_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py:837\u001b[0m, in \u001b[0;36mLossScaleOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m():\n\u001b[1;32m    835\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_gradients(grads, wrapped_vars, name)\n\u001b[0;32m--> 837\u001b[0m     maybe_apply_op \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msmart_cond\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[1;32m    838\u001b[0m         should_apply_grads, apply_fn, do_not_apply_fn\n\u001b[1;32m    839\u001b[0m     )\n\u001b[1;32m    840\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mgroup(maybe_apply_op, loss_scale_update_op)\n\u001b[1;32m    842\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py:52\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m pred_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m pred_value:\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[1;32m     53\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py:835\u001b[0m, in \u001b[0;36mLossScaleOptimizer.apply_gradients.<locals>.apply_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m():\n\u001b[0;32m--> 835\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_gradients(grads, wrapped_vars, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py:876\u001b[0m, in \u001b[0;36mLossScaleOptimizer._apply_gradients\u001b[0;34m(self, grads, wrapped_vars, name)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply_gradients\u001b[39m(\u001b[39mself\u001b[39m, grads, wrapped_vars, name):\n\u001b[1;32m    871\u001b[0m     \u001b[39m# Pass experimental_aggregate_gradients=False since LossScaleOptimizer\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     \u001b[39m# already aggregated the gradients.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m     \u001b[39m# TODO(reedwm): This will raise a fairly cryptic error message if\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     \u001b[39m# self._optimizer.apply_gradients does not take\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     \u001b[39m# experimental_aggregate_gradients.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer\u001b[39m.\u001b[39;49mapply_gradients(\n\u001b[1;32m    877\u001b[0m         \u001b[39mlist\u001b[39;49m(\u001b[39mzip\u001b[39;49m(grads, wrapped_vars\u001b[39m.\u001b[39;49mvalue)),\n\u001b[1;32m    878\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    879\u001b[0m         experimental_aggregate_gradients\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    880\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:736\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    732\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_unaggregated_gradients(\n\u001b[1;32m    733\u001b[0m         grads_and_vars\n\u001b[1;32m    734\u001b[0m     )\n\u001b[1;32m    735\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_gradients(grads_and_vars)\n\u001b[0;32m--> 736\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform_gradients(grads_and_vars)\n\u001b[1;32m    738\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39minterim\u001b[39m.\u001b[39mmaybe_merge_call(\n\u001b[1;32m    739\u001b[0m     functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    740\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distributed_apply, apply_state\u001b[39m=\u001b[39mapply_state\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[1;32m    745\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:537\u001b[0m, in \u001b[0;36mOptimizerV2._transform_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    535\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clipvalue_fn(grads_and_vars)\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clipnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clipnorm_fn(grads_and_vars)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_global_clipnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_global_clipnorm_fn(grads_and_vars)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/utils.py:112\u001b[0m, in \u001b[0;36mmake_gradient_clipnorm_fn.<locals>.gradient_clipnorm_fn\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    101\u001b[0m     tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy(),\n\u001b[1;32m    102\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     ),\n\u001b[1;32m    106\u001b[0m ):\n\u001b[1;32m    107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`clipnorm` is not supported with `CenteralStorageStrategy`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe strategy used is \u001b[39m\u001b[39m{\u001b[39;00mtf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[0;32m--> 112\u001b[0m clipped_grads_and_vars \u001b[39m=\u001b[39m [\n\u001b[1;32m    113\u001b[0m     (tf\u001b[39m.\u001b[39mclip_by_norm(g, clipnorm), v) \u001b[39mfor\u001b[39;00m g, v \u001b[39min\u001b[39;00m grads_and_vars\n\u001b[1;32m    114\u001b[0m ]\n\u001b[1;32m    115\u001b[0m \u001b[39mreturn\u001b[39;00m clipped_grads_and_vars\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/utils.py:113\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    101\u001b[0m     tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy(),\n\u001b[1;32m    102\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     ),\n\u001b[1;32m    106\u001b[0m ):\n\u001b[1;32m    107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`clipnorm` is not supported with `CenteralStorageStrategy`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe strategy used is \u001b[39m\u001b[39m{\u001b[39;00mtf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    112\u001b[0m clipped_grads_and_vars \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 113\u001b[0m     (tf\u001b[39m.\u001b[39;49mclip_by_norm(g, clipnorm), v) \u001b[39mfor\u001b[39;00m g, v \u001b[39min\u001b[39;00m grads_and_vars\n\u001b[1;32m    114\u001b[0m ]\n\u001b[1;32m    115\u001b[0m \u001b[39mreturn\u001b[39;00m clipped_grads_and_vars\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/clip_ops.py:218\u001b[0m, in \u001b[0;36mclip_by_norm\u001b[0;34m(t, clip_norm, axes, name)\u001b[0m\n\u001b[1;32m    213\u001b[0m values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    214\u001b[0m     t\u001b[39m.\u001b[39mvalues \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, indexed_slices\u001b[39m.\u001b[39mIndexedSlices) \u001b[39melse\u001b[39;00m t,\n\u001b[1;32m    215\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[39m# Calculate L2-norm, clip elements by ratio of clip_norm to L2-norm\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m l2sum \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39;49mreduce_sum(values \u001b[39m*\u001b[39;49m values, axes, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    219\u001b[0m pred \u001b[39m=\u001b[39m l2sum \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Two-tap tf.where trick to bypass NaN gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:2313\u001b[0m, in \u001b[0;36mreduce_sum\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.reduce_sum\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreduce_sum\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   2250\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m   2251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum\u001b[39m(input_tensor, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2252\u001b[0m   \u001b[39m\"\"\"Computes the sum of elements across dimensions of a tensor.\u001b[39;00m\n\u001b[1;32m   2253\u001b[0m \n\u001b[1;32m   2254\u001b[0m \u001b[39m  This is the reduction operation for the elementwise `tf.math.add` op.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[39m  @end_compatibility\u001b[39;00m\n\u001b[1;32m   2310\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m   \u001b[39mreturn\u001b[39;00m reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0;32m-> 2313\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:2150\u001b[0m, in \u001b[0;36m_ReductionDims\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[39m# Fast path: avoid creating Rank and Range ops if ndims is known.\u001b[39;00m\n\u001b[1;32m   2149\u001b[0m \u001b[39mif\u001b[39;00m x_rank:\n\u001b[0;32m-> 2150\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(np\u001b[39m.\u001b[39;49marange(x_rank, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mint32))\n\u001b[1;32m   2151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2152\u001b[0m   \u001b[39m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[39;00m\n\u001b[1;32m   2153\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, array_ops\u001b[39m.\u001b[39mrank(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '1_Model_v0.4.ipynb'\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    seed = 12 #42 \n",
    "    num_items = NUM_ITEMS\n",
    "    model_arch = 'bert4rec'\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.5/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.12/checkpoints/', 'ckpt-14')\n",
    "    model_name = f'model_{model_arch}_complete_0.13'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 13_000_000\n",
    "    batch_size = 64\n",
    "    tup_scheduler_grad_accum = (1, 2, 2_000_000) #(start_grad_accum, max_grad_accum, ramp_up_samples)\n",
    "    loss_apply_weights = False\n",
    "    seq_len = 20\n",
    "    mask_prob = 0.3\n",
    "    reverse_prob = 0.5\n",
    "    emb_dim = 128\n",
    "    trf_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 2\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 3\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 250\n",
    "    clipnorm = 1.0\n",
    "    num_iters_save_checkpoint = 15_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    weight_decay = 1e-1\n",
    "    log_wandb = True\n",
    "\n",
    "set_seed(BERT4REC_CONFIG.seed)\n",
    "\n",
    "list_scheduler = np.linspace(BERT4REC_CONFIG.tup_scheduler_grad_accum[0], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[1], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[2]).astype(np.uint8).tolist()\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}', dict_config=dict_config)\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')] + \\\n",
    "                   [f'{BERT4REC_CONFIG.path_tfrecords}na_split=test_aug/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=test_aug')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "                            # weight_decay=BERT4REC_CONFIG.weight_decay)                  \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = weighted_loss_bert4rec(apply_weights=BERT4REC_CONFIG.loss_apply_weights)\n",
    "acc_function = custom_accuracy()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "train_acc_clicks = tf.keras.metrics.Mean(name='train_acc_clicks')\n",
    "train_acc_carts = tf.keras.metrics.Mean(name='train_acc_carts')\n",
    "train_acc_orders = tf.keras.metrics.Mean(name='train_acc_orders')\n",
    "val_acc_clicks = tf.keras.metrics.Mean(name='val_acc_clicks')\n",
    "val_acc_carts = tf.keras.metrics.Mean(name='val_acc_carts')\n",
    "val_acc_orders = tf.keras.metrics.Mean(name='val_acc_orders')\n",
    "\n",
    "##############################################\n",
    "\n",
    "global_gradients = []\n",
    "total_step, val_step, total_samples = 0, 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders, val_acc_clicks, val_acc_carts, val_acc_orders)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        grad_accum = grad_accum_scheduler(total_samples,\n",
    "                                          list_scheduler=list_scheduler, \n",
    "                                          max_grad_accum=BERT4REC_CONFIG.tup_scheduler_grad_accum[1])                                                             \n",
    "        step_gradients = train_step(inputs, target=target, model=model, optimizer=optimizer, num_accum_steps=tf.constant(grad_accum, tf.float32), \n",
    "                                    loss=train_loss, acc_clicks=train_acc_clicks, acc_carts=train_acc_carts, acc_orders=train_acc_orders, seq_type=inputs[1])\n",
    "        global_gradients, total_step = backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "            train_dict_metrics.update({'lr' : optimizer.lr(total_step).numpy().astype(np.float32), 'grad_accum' : grad_accum, 'total_samples' : total_samples})\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                train_dict_metrics.update({'step_grad' : total_step, 'step' : total_step})\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics)     \n",
    "        total_samples += BERT4REC_CONFIG.batch_size * grad_accum if (batch_num+1) % grad_accum==0 else 0\n",
    "        if batch_num % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')\n",
    "     \n",
    "#     for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "#         inputs, target = val_batch_data\n",
    "#         predictions = test_step(inputs, target=target, loss=val_loss, acc_clicks=val_acc_clicks, acc_carts=val_acc_carts, acc_orders=val_acc_orders, seq_type=inputs[1])\n",
    "#         val_step += 1\n",
    "#         if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "#             val_dict_metrics = {x.name : x.result() for x in [val_loss, val_acc_clicks, val_acc_carts, val_acc_orders]}\n",
    "#             fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "#             if BERT4REC_CONFIG.log_wandb:\n",
    "#                 log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "#                 # if val_batch_num==0:\n",
    "#                 #     log_wandb_metrics(step=None, plot_image=True, \n",
    "#                 #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "    \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', num_step=epoch, dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    y_pred = list(set(y_pred))[:k]\n",
    "    score = 0 \n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.13/checkpoints'))\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.5/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_past_items, list_predictions, list_trues, list_types = [], [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target, idx_mask = targets\n",
    "    idxs = idx_mask.numpy() - 1 #tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x]-1 for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([dict_map[_target]-1 for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "        list_past_items.append(seq_items.numpy()[:, :, 0])\n",
    "    if num_batch==500:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'past_items' : np.concatenate(list_past_items).tolist(),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "df_val['qt_trues'] = df_val['trues'].apply(lambda x : len(x))\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "\n",
    "# compare to\n",
    "# (seq_len=20)model_bert4rec_complete_0.10 - ckpt28\n",
    "# {'carts': 0.3811865255508249,\n",
    "#  'clicks': 0.32103439425051333,\n",
    "#  'orders': 0.5298270555929199}\n",
    "# Kaggle Metric: 0.4644\n",
    "\n",
    "# import wandb\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"<path to run>\")\n",
    "# run.summary[\"kaggle_metric\"] = kaggle_metric\n",
    "# run.update()\n",
    "\n",
    "# num_targets=20 - seq_len=20 - model_bert4rec_complete_0.12 - ckpt14\n",
    "# {'carts': 0.3648662318446719,\n",
    "#  'clicks': 0.3193018480492813,\n",
    "#  'orders': 0.506498242822094}\n",
    "# Kaggle Metric: 0.4453"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 19:15:23.433225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "0it [00:00, ?it/s]2022-11-20 19:15:24.337587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "26122it [55:08,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.7/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.5/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, idxs, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    idxs = idxs.numpy() - 1\n",
    "    # idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 26122it [54:28,  7.99it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")\n",
    "\n",
    "import gzip\n",
    "with open(f'../3_Submissions/{name_submission}.csv', 'rb') as f_in, gzip.open(f'../3_Submissions/{name_submission}.csv.gz', 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0432fa0070c5c9f7d9e158f590013ccc765eb84f02e6f69521746370c3bf6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
