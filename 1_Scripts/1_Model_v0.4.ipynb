{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 3272501.06it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "SEED = 12\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.4/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False, drop_remainder=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "        self.drop_remainder = drop_remainder\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*50, reshuffle_each_iteration=True)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=self.drop_remainder).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                # \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                # \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_time_encoding, seq_time_encoding_target = seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding), (seq_items_target_all[:, 0], seq_type_target_all[:, 0]), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "\n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items)), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items))\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_target[:, 0]\n",
    "  \n",
    "  \n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 20, 1]), TensorShape([32, 20, 1]), TensorShape([32, 20, 8])]\n",
      "[      0 1069524 1222831  419353       0       0       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0]\n",
      "[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[40508     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.4/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=train')]\n",
    "\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.4, \n",
    "                                     reverse_prob=0.25, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# # Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    break\n",
    "\n",
    "# # # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     target, type_target = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 6\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(\n",
    "            3+1, \n",
    "            model_cfg.emb_dim,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.mlp_proj_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_encoding(x_seq_encoding, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_time_encoding + x_seq_past_type)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        ones = tf.ones(tf.shape(y_true))\n",
    "        y_pred = y_pred\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "def recall_top_k(top_k=1):\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_true)[0]\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.float32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.float32)\n",
    "        cum_sum = tf.zeros(n_samples)\n",
    "        for i in tf.range(top_k):\n",
    "            indexes_i = top_index[:, :, i]\n",
    "            is_true = tf.reduce_sum(tf.cast(tf.equal(y_true, indexes_i), tf.float32), axis=-1)/tf.reduce_sum(mask, -1)\n",
    "            cum_sum += (is_true/tf.cast(i+1, tf.float32))\n",
    "        return tf.reduce_mean(cum_sum)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "# plt.plot(tmp_lr(tf.range(12_000_000 // (32 * 4), dtype=tf.float32)))\n",
    "plt.plot(tmp_lr(tf.range(12_000_000 // (8 * 20), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g)\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        global_gradients = zip(global_gradients, model.trainable_variables)\n",
    "        optimizer.apply_gradients(global_gradients)\n",
    "        global_gradients = []\n",
    "    return global_gradients\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    num_accum_steps = tf.cast(kwargs['num_accum_steps'], tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss / num_accum_steps)\n",
    "\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    # gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions)\n",
    "    l_loss(loss)\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.4f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, num_batch=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({f'step_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "        wandb.log({f'batch_{name}' : value for name, value in dict_metrics.items()}, step=num_batch)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name='', dict_config=None):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"),\n",
    "               config=dict_config)\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menric1296\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\KAGGLE\\025_Kaggle-OTTO Recsys-2022\\1_Scripts\\wandb\\run-20221113_153738-2x7gm0dc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/2x7gm0dc\" target=\"_blank\">model_bert4rec_complete_0.6_2022-11-13 15:37:36</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n",
      "================================================================================\n",
      "Epoch 1\n",
      "[Train Epoch]1/5 [Time]25.30 [Step]0 [Batch]0 [Speed]25300.05ms/step [Loss]14.0867 [Metrics]{'train_loss:14.0867'}\n",
      "[Train Epoch]1/5 [Time]52.58 [Step]31 [Batch]500 [Speed]105.17ms/step [Loss]14.0911 [Metrics]{'train_loss:14.0911'}\n",
      "[Train Epoch]1/5 [Time]79.99 [Step]62 [Batch]1000 [Speed]79.99ms/step [Loss]14.0911 [Metrics]{'train_loss:14.0911'}\n",
      "[Train Epoch]1/5 [Time]107.56 [Step]93 [Batch]1500 [Speed]71.71ms/step [Loss]14.0908 [Metrics]{'train_loss:14.0908'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 111\u001b[0m\n\u001b[0;32m    109\u001b[0m inputs, target \u001b[39m=\u001b[39m batch_data\n\u001b[0;32m    110\u001b[0m step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39mtarget, loss\u001b[39m=\u001b[39mtrain_loss, num_accum_steps\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mnum_grad_accum_steps)\n\u001b[1;32m--> 111\u001b[0m global_gradients \u001b[39m=\u001b[39m backward_optimization(BERT4REC_CONFIG\u001b[39m.\u001b[39;49mnum_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    113\u001b[0m     train_dict_metrics \u001b[39m=\u001b[39m {x\u001b[39m.\u001b[39mname : x\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [train_loss]}\n",
      "Cell \u001b[1;32mIn [8], line 20\u001b[0m, in \u001b[0;36mbackward_optimization\u001b[1;34m(num_grad_steps, global_gradients, step_gradients, step, model, optimizer)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[39mfor\u001b[39;00m i, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(step_gradients):\n\u001b[1;32m---> 20\u001b[0m         global_gradients[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_gradients(g)\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m num_grad_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     22\u001b[0m     global_gradients \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(global_gradients, model\u001b[39m.\u001b[39mtrainable_variables)\n",
      "Cell \u001b[1;32mIn [8], line 8\u001b[0m, in \u001b[0;36mflat_gradients\u001b[1;34m(grads_or_idx_slices)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m'''Convert gradients if it's tf.IndexedSlices.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mWhen computing gradients for operation concerning `tf.gather`, the type of gradients \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(grads_or_idx_slices) \u001b[39m==\u001b[39m tf\u001b[39m.\u001b[39mIndexedSlices:\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mscatter_nd(\n\u001b[0;32m      9\u001b[0m         tf\u001b[39m.\u001b[39;49mexpand_dims(grads_or_idx_slices\u001b[39m.\u001b[39;49mindices, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m     10\u001b[0m         grads_or_idx_slices\u001b[39m.\u001b[39;49mvalues,\n\u001b[0;32m     11\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(grads_or_idx_slices\u001b[39m.\u001b[39;49mdense_shape, tf\u001b[39m.\u001b[39;49mint64)\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m grads_or_idx_slices\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:9154\u001b[0m, in \u001b[0;36mscatter_nd\u001b[1;34m(indices, updates, shape, name)\u001b[0m\n\u001b[0;32m   9152\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   9153\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 9154\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   9155\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mScatterNd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, indices, updates, shape)\n\u001b[0;32m   9156\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   9157\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.3/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.5/checkpoints/', 'ckpt-7')\n",
    "    model_name = 'model_bert4rec_complete_0.6'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 12_000_000\n",
    "    batch_size = 10\n",
    "    num_grad_accum_steps = 16\n",
    "    seq_len = 20\n",
    "    mask_prob = 0.4\n",
    "    reverse_prob = 0.25\n",
    "    emb_dim = 32\n",
    "    trf_dim = 32\n",
    "    num_heads = 2\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 5\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 200\n",
    "    clipnorm = 1\n",
    "    num_iters_save_checkpoint = 5_000 * num_grad_accum_steps\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    log_wandb = True\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}', dict_config=dict_config)\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.restore_last_chekpoint[1]}/', compile=False)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "                            warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "# optimizer = AdamW(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "#                     warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "#                     clipnorm=BERT4REC_CONFIG.clipnorm,\n",
    "#                     weight_decay=1e-4)                            \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = custom_loss_bert4rec()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "##############################################\n",
    "\n",
    "global_gradients = []\n",
    "total_step, val_step = 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        step_gradients = train_step(inputs, target=target, loss=train_loss, num_accum_steps=BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "        global_gradients = backward_optimization(BERT4REC_CONFIG.num_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss]}\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step // BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='train', num_step=total_step // BERT4REC_CONFIG.num_grad_accum_steps, num_batch=total_step,\n",
    "                                  gradients=global_gradients, dict_metrics=train_dict_metrics) \n",
    "        \n",
    "        total_step += 1  \n",
    "\n",
    "        if total_step % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')        \n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            \n",
    "    for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "        inputs, target = val_batch_data\n",
    "        test_step(inputs, target=target, loss=val_loss)\n",
    "        val_step += 1\n",
    "        if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "            val_dict_metrics = {x.name : x.result() for x in [val_loss]}\n",
    "            fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "                # if val_batch_num==0:\n",
    "                #     log_wandb_metrics(step=None, plot_image=True, \n",
    "                #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m features \u001b[39m=\u001b[39m (seq_items, tf\u001b[39m.\u001b[39mstack(seq_type_new, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), seq_time)\n\u001b[0;32m     46\u001b[0m preds \u001b[39m=\u001b[39m model(features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 47\u001b[0m preds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mgather(preds, indices\u001b[39m=\u001b[39;49midxs, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_dims\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     48\u001b[0m topk_scores, topk_idxs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mtop_k(preds, k\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m     49\u001b[0m topk_idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray([[x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m topk_idxs\u001b[39m.\u001b[39mnumpy()[i, :]] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(topk_idxs\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])])\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5238\u001b[0m, in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, validate_indices, axis, batch_dims, name)\u001b[0m\n\u001b[0;32m   5230\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mgather\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   5231\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   5232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgather_v2\u001b[39m(params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5236\u001b[0m               batch_dims\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   5237\u001b[0m               name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 5238\u001b[0m   \u001b[39mreturn\u001b[39;00m gather(\n\u001b[0;32m   5239\u001b[0m       params,\n\u001b[0;32m   5240\u001b[0m       indices,\n\u001b[0;32m   5241\u001b[0m       validate_indices\u001b[39m=\u001b[39;49mvalidate_indices,\n\u001b[0;32m   5242\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   5243\u001b[0m       axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5244\u001b[0m       batch_dims\u001b[39m=\u001b[39;49mbatch_dims)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:548\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    541\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    542\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    543\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[0;32m    547\u001b[0m           instructions)\n\u001b[1;32m--> 548\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5220\u001b[0m, in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   5218\u001b[0m   axis \u001b[39m=\u001b[39m batch_dims\n\u001b[0;32m   5219\u001b[0m \u001b[39mif\u001b[39;00m tensor_util\u001b[39m.\u001b[39mconstant_value(axis) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 5220\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mgather_v2(\n\u001b[0;32m   5221\u001b[0m       params, indices, axis, batch_dims\u001b[39m=\u001b[39;49mbatch_dims, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   5222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   5223\u001b[0m   \u001b[39m# TODO(apassos) find a less bad way of detecting resource variables\u001b[39;00m\n\u001b[0;32m   5224\u001b[0m   \u001b[39m# without introducing a circular dependency.\u001b[39;00m\n\u001b[0;32m   5225\u001b[0m   \u001b[39mreturn\u001b[39;00m params\u001b[39m.\u001b[39msparse_read(indices, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3934\u001b[0m, in \u001b[0;36mgather_v2\u001b[1;34m(params, indices, axis, batch_dims, name)\u001b[0m\n\u001b[0;32m   3932\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3933\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3934\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3935\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mGatherV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, params, indices, axis, \u001b[39m\"\u001b[39;49m\u001b[39mbatch_dims\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   3936\u001b[0m       batch_dims)\n\u001b[0;32m   3937\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3938\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0\n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.5/checkpoints'))\n",
    "# model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.4_finetuned/', compile=False)\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.3/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=16, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_predictions, list_trues, list_types = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    target, type_target = targets\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "    if num_batch==2_000:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# v0.4_finetuned seqlen=10\n",
    "# {'carts': 0.23272587826464677,\n",
    "#  'clicks': 0.16818629058707774,\n",
    "#  'orders': 0.31957377011651095}\n",
    "# Kaggle Metric: 0.2783808\n",
    "\n",
    "# model_bert4rec_complete_0.4.1 - ckpt42\n",
    "# mean = 0.202564\n",
    "# {'carts': 0.2417327288193879,\n",
    "#  'clicks': 0.18081338143653658,\n",
    "#  'orders': 0.33429939670611314}\n",
    "# Kaggle Metric: 0.2912\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.5 - ckpt10\n",
    "# {'carts': 0.2597342763878702,\n",
    "#  'clicks': 0.18694624926166567,\n",
    "#  'orders': 0.3624662713766583}\n",
    "# Kaggle Metric: 0.3141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.current_loss_scale\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.good_steps\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18995it [37:50,  8.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m type_ \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mclicks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcarts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morders\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m---> 26\u001b[0m     seq_type_new \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mconcat([\n\u001b[0;32m     27\u001b[0m                     seq_type[i, :ix],\n\u001b[0;32m     28\u001b[0m                     tf\u001b[39m.\u001b[39mconstant([[dict_map_type[type_]]], tf\u001b[39m.\u001b[39mint64),\n\u001b[0;32m     29\u001b[0m                     seq_type[i, ix\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m                 \u001b[39mfor\u001b[39;00m i, ix \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idxs)]\n\u001b[0;32m     31\u001b[0m     features \u001b[39m=\u001b[39m (seq_items, tf\u001b[39m.\u001b[39mstack(seq_type_new, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), seq_time)\n\u001b[0;32m     32\u001b[0m     preds \u001b[39m=\u001b[39m model(features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [11], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m type_ \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mclicks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcarts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morders\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     26\u001b[0m     seq_type_new \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mconcat([\n\u001b[1;32m---> 27\u001b[0m                     seq_type[i, :ix],\n\u001b[0;32m     28\u001b[0m                     tf\u001b[39m.\u001b[39mconstant([[dict_map_type[type_]]], tf\u001b[39m.\u001b[39mint64),\n\u001b[0;32m     29\u001b[0m                     seq_type[i, ix\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m                 \u001b[39mfor\u001b[39;00m i, ix \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idxs)]\n\u001b[0;32m     31\u001b[0m     features \u001b[39m=\u001b[39m (seq_items, tf\u001b[39m.\u001b[39mstack(seq_type_new, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), seq_time)\n\u001b[0;32m     32\u001b[0m     preds \u001b[39m=\u001b[39m model(features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1038\u001b[0m, in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\n\u001b[0;32m   1034\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1035\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstrided_slice\u001b[39m\u001b[39m\"\u001b[39m, [tensor] \u001b[39m+\u001b[39m begin \u001b[39m+\u001b[39m end \u001b[39m+\u001b[39m strides,\n\u001b[0;32m   1036\u001b[0m     skip_on_eager\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m name:\n\u001b[0;32m   1037\u001b[0m   \u001b[39mif\u001b[39;00m begin:\n\u001b[1;32m-> 1038\u001b[0m     packed_begin, packed_end, packed_strides \u001b[39m=\u001b[39m (stack(begin), stack(end),\n\u001b[0;32m   1039\u001b[0m                                                 stack(strides))\n\u001b[0;32m   1040\u001b[0m     \u001b[39mif\u001b[39;00m (packed_begin\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64 \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m         packed_end\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64 \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m         packed_strides\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64):\n\u001b[0;32m   1043\u001b[0m       \u001b[39mif\u001b[39;00m packed_begin\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtypes\u001b[39m.\u001b[39mint64:\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1424\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1422\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1423\u001b[0m     \u001b[39m# If the input is a constant list, it can be converted to a constant op\u001b[39;00m\n\u001b[1;32m-> 1424\u001b[0m     \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(values, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1425\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1426\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Input list contains non-constant tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1691\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1692\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   1694\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1695\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1697\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1698\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    342\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.5/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.3/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=16, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, target, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 52244it [2:47:45,  5.19it/s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c4b929e2472036a63dc2b4145b104daea13432f82a7dbc65e279332da4f8b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
