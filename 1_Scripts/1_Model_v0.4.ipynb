{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 22:31:53.567181: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:31:53.626408: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-30 22:31:53.642512: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-30 22:31:53.951239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-30 22:31:53.951264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-30 22:31:53.951266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 22:31:54.677000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 22:31:54.689415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 22:31:54.689492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries #\n",
    "\n",
    "from dataloader import Bert4RecDataLoader, SASRecDataLoader\n",
    "from models import build_model_bert4Rec\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 7689162.99it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.5/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "# \n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "# \n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 22:31:56.367503: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:31:56.368190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 22:31:56.368281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 22:31:56.368383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 22:31:56.630650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 22:31:56.630735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 22:31:56.630786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 22:31:56.630832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21890 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 40, 1]), TensorShape([32, 40, 1]), TensorShape([32, 40, 8]), TensorShape([32, 40, 1])]\n",
      "[ 586668  275523  164950  849746 1240115  369673  369673   30011  280982\n",
      "  416175 1200323  732660  435547  914955 1149973  857961  591278 1065462\n",
      "  234511 1150803  650516  389047 1284083       0  337433 1149973 1252579\n",
      "  392174  926655   86497  336158  475473  836341  370706       0 1034949\n",
      " 1034949 1000952 1034949 1171435]\n",
      "[1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "[     0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0 534990      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.5/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=train')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                num_items=NUM_ITEMS, \n",
    "                                seq_len=40, \n",
    "                                seq_len_target=None,\n",
    "                                batch_size=32, \n",
    "                                mask_prob=0.0, \n",
    "                                reverse_prob=0.5, \n",
    "                                get_session=False,\n",
    "                                is_val=False,\n",
    "                                is_test=False,\n",
    "                                shuffle=False).get_generator()\n",
    "# Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    break\n",
    "\n",
    "# # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     idx_mask = target\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     target, type_target, idx_mask = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 11\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(idx_mask[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time, seq_recency\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "# def custom_loss_bert4rec(tensor_weights=None):\n",
    "#     # @tf.function(jit_compile=True)\n",
    "#     def loss(y_true, y_pred):\n",
    "#         mask = tf.where(y_true >= 1, 1., 0.)\n",
    "#         loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "#         if tensor_weights is not None:\n",
    "#             weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "#             return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "#         else:\n",
    "#             return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "#     loss.__name__ = f'loss_bert4rec'\n",
    "#     return loss\n",
    "\n",
    "def weighted_loss_bert4rec(apply_weights=False):\n",
    "    # @tf.function(jit_compile=True)\n",
    "    def loss(y_true, y_pred, y_type):\n",
    "        y_type = tf.squeeze(y_type, -1)\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if apply_weights:\n",
    "            w_clicks = tf.cast(y_type==1, tf.float32) * 0.1\n",
    "            w_cart = tf.cast(y_type==2, tf.float32) * 0.3\n",
    "            w_order = tf.cast(y_type==3, tf.float32) * 0.6\n",
    "            weights = tf.reduce_max(tf.stack([w_clicks, w_cart, w_order], axis=-1), -1)\n",
    "            return tf.reduce_sum(loss * mask * weights) / (tf.reduce_sum(mask * weights) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'weighted_loss_bert4rec'\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def custom_accuracy():\n",
    "    def masked_accuracy(y_true, y_pred, y_type):\n",
    "        y_pred = tf.argmax(y_pred, axis=2)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        y_type = y_type[:, :, 0]\n",
    "        mask_padding = y_true != 0\n",
    "        mask_clicks = y_type == 1\n",
    "        mask_carts = y_type == 2\n",
    "        mask_orders = y_type == 3\n",
    "        match = y_true == y_pred\n",
    "        match_clicks = match & mask_padding & mask_clicks\n",
    "        match_carts = match & mask_padding & mask_carts\n",
    "        match_orders = match & mask_padding & mask_orders\n",
    "        match_clicks, mask_clicks = tf.cast(match_clicks, dtype=tf.float32), tf.cast(mask_clicks, dtype=tf.float32)\n",
    "        match_carts, mask_carts = tf.cast(match_carts, dtype=tf.float32), tf.cast(mask_carts, dtype=tf.float32)\n",
    "        match_orders, mask_orders = tf.cast(match_orders, dtype=tf.float32), tf.cast(mask_orders, dtype=tf.float32)\n",
    "        mask_padding = tf.cast(mask_padding, dtype=tf.float32)\n",
    "        acc_clicks = tf.reduce_sum(match_clicks)/(tf.reduce_sum(mask_clicks * mask_padding)+1e-8)\n",
    "        acc_carts = tf.reduce_sum(match_carts)/(tf.reduce_sum(mask_carts * mask_padding)+1e-8)\n",
    "        acc_orders = tf.reduce_sum(match_orders)/(tf.reduce_sum(mask_orders * mask_padding)+1e-8)\n",
    "        # score = 0.1*acc_clicks + 0.3*acc_carts + 0.6*acc_orders\n",
    "        return acc_clicks, acc_carts, acc_orders\n",
    "    masked_accuracy.__name__ = f'seq_acc'\n",
    "    return masked_accuracy\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "\n",
    "def recall_top_k(top_k=1, seq_len=10):\n",
    "    # @tf.function\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_pred)[0]\n",
    "        y_true = tf.cast(y_true, tf.int64)\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.int32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.int64)\n",
    "        # cum_sum = tf.zeros(n_samples, tf.int32)\n",
    "        result = tf.constant(0, tf.int32)\n",
    "        for i in tf.range(seq_len):\n",
    "            indexes_i = top_index[:, i, :]\n",
    "            is_true = tf.reduce_sum(tf.reduce_max(tf.where(y_true[:, i:i+1]==indexes_i, 1, 0), -1) * mask[:, i])\n",
    "            result += is_true\n",
    "        return tf.cast(result, tf.float32) / (tf.cast(tf.reduce_sum(mask), tf.float32) + 1e-8)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name\n",
    "\n",
    "def set_seed(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "plt.plot(tmp_lr(tf.range(12_500_000 // (32* 5), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = [flat_gradients(g) / num_grad_steps for g in step_gradients] \n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g) / num_grad_steps\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        optimizer.apply_gradients(zip(global_gradients, model.trainable_variables))\n",
    "        global_gradients = []\n",
    "        total_step += 1\n",
    "    return global_gradients, total_step\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, model, optimizer, num_accum_steps, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions, seq_type)\n",
    "        acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "\n",
    "    gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(gradients)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions, seq_type)\n",
    "    acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.6f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name='', dict_config=None):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"),\n",
    "               config=dict_config)\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "\n",
    "def grad_accum_scheduler(num_samples, list_scheduler, max_grad_accum):\n",
    "    if num_samples >= len(list_scheduler):\n",
    "        return max_grad_accum\n",
    "    return list_scheduler[num_samples]\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menric1296\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/enric/SSD1TB/KAGGLE/025_Kaggle-OTTO Recsys-2022/1_Scripts/wandb/run-20221130_223158-xhe0vx3s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/xhe0vx3s\" target=\"_blank\">model_bert4rec_complete_0.12_2022-11-30 22:31:57</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n",
      "================================================================================\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 22:32:00.907110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:436: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2022-11-30 22:32:01.851707: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2063c1a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-30 22:32:01.851725: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2022-11-30 22:32:01.874375: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model_bert4_rec/encoder_transformer_block/dropout_1/dropout/random_uniform/RandomUniform\n",
      "2022-11-30 22:32:01.877853: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-11-30 22:32:03.830960: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-11-30 22:32:04.265617: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Epoch]1/3 [Time]3.43 [Step]1 [Batch]0 [Speed]3428.94ms/step [Loss]14.3271 [Metrics]{'train_loss:14.327146 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000000 grad_accum:1.000000 total_samples:0.000000'}\n",
      "Saving checkpoint for epoch 1 at step 1 on path model_bert4rec_complete_0.12_v1\n",
      "[Train Epoch]1/3 [Time]41.84 [Step]501 [Batch]500 [Speed]83.67ms/step [Loss]14.1386 [Metrics]{'train_loss:14.138623 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000044 grad_accum:1.000000 total_samples:16000.000000'}\n",
      "[Train Epoch]1/3 [Time]74.48 [Step]1001 [Batch]1000 [Speed]74.48ms/step [Loss]13.8401 [Metrics]{'train_loss:13.840085 train_acc_clicks:0.000088 train_acc_carts:0.000000 train_acc_orders:0.000200 lr:0.000088 grad_accum:1.000000 total_samples:32000.000000'}\n",
      "[Train Epoch]1/3 [Time]107.13 [Step]1501 [Batch]1500 [Speed]71.42ms/step [Loss]13.6401 [Metrics]{'train_loss:13.640131 train_acc_clicks:0.000263 train_acc_carts:0.000000 train_acc_orders:0.000133 lr:0.000133 grad_accum:1.000000 total_samples:48000.000000'}\n",
      "[Train Epoch]1/3 [Time]139.73 [Step]2001 [Batch]2000 [Speed]69.87ms/step [Loss]13.4885 [Metrics]{'train_loss:13.488535 train_acc_clicks:0.000315 train_acc_carts:0.000125 train_acc_orders:0.000600 lr:0.000177 grad_accum:1.000000 total_samples:64000.000000'}\n",
      "[Train Epoch]1/3 [Time]172.33 [Step]2501 [Batch]2500 [Speed]68.93ms/step [Loss]13.3593 [Metrics]{'train_loss:13.359255 train_acc_clicks:0.000464 train_acc_carts:0.001080 train_acc_orders:0.000613 lr:0.000221 grad_accum:1.000000 total_samples:80000.000000'}\n",
      "[Train Epoch]1/3 [Time]205.03 [Step]3001 [Batch]3000 [Speed]68.34ms/step [Loss]13.2538 [Metrics]{'train_loss:13.253814 train_acc_clicks:0.000578 train_acc_carts:0.001417 train_acc_orders:0.000511 lr:0.000265 grad_accum:1.000000 total_samples:96000.000000'}\n",
      "[Train Epoch]1/3 [Time]237.68 [Step]3501 [Batch]3500 [Speed]67.91ms/step [Loss]13.1652 [Metrics]{'train_loss:13.165174 train_acc_clicks:0.000668 train_acc_carts:0.001631 train_acc_orders:0.000438 lr:0.000309 grad_accum:1.000000 total_samples:112000.000000'}\n",
      "[Train Epoch]1/3 [Time]270.33 [Step]4001 [Batch]4000 [Speed]67.58ms/step [Loss]13.0928 [Metrics]{'train_loss:13.092791 train_acc_clicks:0.000765 train_acc_carts:0.002170 train_acc_orders:0.000383 lr:0.000354 grad_accum:1.000000 total_samples:128000.000000'}\n",
      "[Train Epoch]1/3 [Time]302.95 [Step]4501 [Batch]4500 [Speed]67.32ms/step [Loss]13.0336 [Metrics]{'train_loss:13.033567 train_acc_clicks:0.000809 train_acc_carts:0.002288 train_acc_orders:0.000341 lr:0.000398 grad_accum:1.000000 total_samples:144000.000000'}\n",
      "[Train Epoch]1/3 [Time]335.64 [Step]5001 [Batch]5000 [Speed]67.13ms/step [Loss]12.9805 [Metrics]{'train_loss:12.980457 train_acc_clicks:0.000833 train_acc_carts:0.002486 train_acc_orders:0.000307 lr:0.000442 grad_accum:1.000000 total_samples:160000.000000'}\n",
      "[Train Epoch]1/3 [Time]368.25 [Step]5501 [Batch]5500 [Speed]66.96ms/step [Loss]12.9349 [Metrics]{'train_loss:12.934882 train_acc_clicks:0.000858 train_acc_carts:0.002433 train_acc_orders:0.000279 lr:0.000486 grad_accum:1.000000 total_samples:176000.000000'}\n",
      "[Train Epoch]1/3 [Time]400.87 [Step]6001 [Batch]6000 [Speed]66.81ms/step [Loss]12.8894 [Metrics]{'train_loss:12.889442 train_acc_clicks:0.000912 train_acc_carts:0.002542 train_acc_orders:0.000256 lr:0.000530 grad_accum:1.000000 total_samples:192000.000000'}\n",
      "[Train Epoch]1/3 [Time]433.45 [Step]6501 [Batch]6500 [Speed]66.68ms/step [Loss]12.8512 [Metrics]{'train_loss:12.851222 train_acc_clicks:0.000895 train_acc_carts:0.002618 train_acc_orders:0.000236 lr:0.000575 grad_accum:1.000000 total_samples:208000.000000'}\n",
      "[Train Epoch]1/3 [Time]466.09 [Step]7001 [Batch]7000 [Speed]66.58ms/step [Loss]12.8143 [Metrics]{'train_loss:12.814313 train_acc_clicks:0.000908 train_acc_carts:0.002485 train_acc_orders:0.000219 lr:0.000619 grad_accum:1.000000 total_samples:224000.000000'}\n",
      "[Train Epoch]1/3 [Time]498.75 [Step]7501 [Batch]7500 [Speed]66.50ms/step [Loss]12.7786 [Metrics]{'train_loss:12.778577 train_acc_clicks:0.000960 train_acc_carts:0.002518 train_acc_orders:0.000204 lr:0.000663 grad_accum:1.000000 total_samples:240000.000000'}\n",
      "[Train Epoch]1/3 [Time]531.35 [Step]8001 [Batch]8000 [Speed]66.42ms/step [Loss]12.7460 [Metrics]{'train_loss:12.745954 train_acc_clicks:0.001018 train_acc_carts:0.002583 train_acc_orders:0.000192 lr:0.000707 grad_accum:1.000000 total_samples:256000.000000'}\n",
      "[Train Epoch]1/3 [Time]563.98 [Step]8501 [Batch]8500 [Speed]66.35ms/step [Loss]12.7140 [Metrics]{'train_loss:12.713993 train_acc_clicks:0.001086 train_acc_carts:0.002668 train_acc_orders:0.000180 lr:0.000751 grad_accum:1.000000 total_samples:272000.000000'}\n",
      "[Train Epoch]1/3 [Time]596.61 [Step]9001 [Batch]9000 [Speed]66.29ms/step [Loss]12.6838 [Metrics]{'train_loss:12.683771 train_acc_clicks:0.001134 train_acc_carts:0.002704 train_acc_orders:0.000170 lr:0.000796 grad_accum:1.000000 total_samples:288000.000000'}\n",
      "[Train Epoch]1/3 [Time]629.19 [Step]9501 [Batch]9500 [Speed]66.23ms/step [Loss]12.6540 [Metrics]{'train_loss:12.654046 train_acc_clicks:0.001221 train_acc_carts:0.002718 train_acc_orders:0.000267 lr:0.000840 grad_accum:1.000000 total_samples:304000.000000'}\n",
      "[Train Epoch]1/3 [Time]661.78 [Step]10001 [Batch]10000 [Speed]66.18ms/step [Loss]12.6251 [Metrics]{'train_loss:12.625094 train_acc_clicks:0.001318 train_acc_carts:0.002968 train_acc_orders:0.000353 lr:0.000884 grad_accum:1.000000 total_samples:320000.000000'}\n",
      "[Train Epoch]1/3 [Time]694.39 [Step]10501 [Batch]10500 [Speed]66.13ms/step [Loss]12.5972 [Metrics]{'train_loss:12.597181 train_acc_clicks:0.001416 train_acc_carts:0.003098 train_acc_orders:0.000606 lr:0.000863 grad_accum:1.000000 total_samples:336000.000000'}\n",
      "[Train Epoch]1/3 [Time]727.04 [Step]11001 [Batch]11000 [Speed]66.09ms/step [Loss]12.5667 [Metrics]{'train_loss:12.566727 train_acc_clicks:0.001571 train_acc_carts:0.003220 train_acc_orders:0.000779 lr:0.000843 grad_accum:1.000000 total_samples:352000.000000'}\n",
      "[Train Epoch]1/3 [Time]759.75 [Step]11501 [Batch]11500 [Speed]66.07ms/step [Loss]12.5371 [Metrics]{'train_loss:12.537087 train_acc_clicks:0.001768 train_acc_carts:0.003708 train_acc_orders:0.001136 lr:0.000824 grad_accum:1.000000 total_samples:368000.000000'}\n",
      "[Train Epoch]1/3 [Time]792.42 [Step]12001 [Batch]12000 [Speed]66.03ms/step [Loss]12.5084 [Metrics]{'train_loss:12.508384 train_acc_clicks:0.001964 train_acc_carts:0.004237 train_acc_orders:0.001401 lr:0.000807 grad_accum:1.000000 total_samples:384000.000000'}\n",
      "[Train Epoch]1/3 [Time]825.02 [Step]12501 [Batch]12500 [Speed]66.00ms/step [Loss]12.4796 [Metrics]{'train_loss:12.479647 train_acc_clicks:0.002149 train_acc_carts:0.004785 train_acc_orders:0.001532 lr:0.000791 grad_accum:1.000000 total_samples:400000.000000'}\n",
      "[Train Epoch]1/3 [Time]857.64 [Step]13001 [Batch]13000 [Speed]65.97ms/step [Loss]12.4508 [Metrics]{'train_loss:12.450835 train_acc_clicks:0.002388 train_acc_carts:0.005214 train_acc_orders:0.001877 lr:0.000775 grad_accum:1.000000 total_samples:416000.000000'}\n",
      "[Train Epoch]1/3 [Time]890.32 [Step]13501 [Batch]13500 [Speed]65.95ms/step [Loss]12.4236 [Metrics]{'train_loss:12.423620 train_acc_clicks:0.002652 train_acc_carts:0.005650 train_acc_orders:0.002384 lr:0.000761 grad_accum:1.000000 total_samples:432000.000000'}\n",
      "[Train Epoch]1/3 [Time]922.87 [Step]14001 [Batch]14000 [Speed]65.92ms/step [Loss]12.3963 [Metrics]{'train_loss:12.396261 train_acc_clicks:0.002925 train_acc_carts:0.006232 train_acc_orders:0.002629 lr:0.000747 grad_accum:1.000000 total_samples:448000.000000'}\n",
      "[Train Epoch]1/3 [Time]955.51 [Step]14501 [Batch]14500 [Speed]65.90ms/step [Loss]12.3685 [Metrics]{'train_loss:12.368538 train_acc_clicks:0.003251 train_acc_carts:0.006759 train_acc_orders:0.003079 lr:0.000734 grad_accum:1.000000 total_samples:464000.000000'}\n",
      "[Train Epoch]1/3 [Time]988.18 [Step]15001 [Batch]15000 [Speed]65.88ms/step [Loss]12.3410 [Metrics]{'train_loss:12.341000 train_acc_clicks:0.003557 train_acc_carts:0.007136 train_acc_orders:0.003484 lr:0.000722 grad_accum:1.000000 total_samples:480000.000000'}\n",
      "[Train Epoch]1/3 [Time]1020.78 [Step]15501 [Batch]15500 [Speed]65.86ms/step [Loss]12.3147 [Metrics]{'train_loss:12.314658 train_acc_clicks:0.003885 train_acc_carts:0.007710 train_acc_orders:0.003795 lr:0.000710 grad_accum:1.000000 total_samples:496000.000000'}\n",
      "[Train Epoch]1/3 [Time]1051.05 [Step]15813 [Batch]16000 [Speed]65.69ms/step [Loss]12.2862 [Metrics]{'train_loss:12.286222 train_acc_clicks:0.004214 train_acc_carts:0.008216 train_acc_orders:0.004401 lr:0.000703 grad_accum:2.000000 total_samples:512032.000000'}\n",
      "[Train Epoch]1/3 [Time]1080.57 [Step]16063 [Batch]16500 [Speed]65.49ms/step [Loss]12.2585 [Metrics]{'train_loss:12.258526 train_acc_clicks:0.004618 train_acc_carts:0.008886 train_acc_orders:0.004870 lr:0.000697 grad_accum:2.000000 total_samples:528032.000000'}\n",
      "[Train Epoch]1/3 [Time]1110.13 [Step]16313 [Batch]17000 [Speed]65.30ms/step [Loss]12.2308 [Metrics]{'train_loss:12.230825 train_acc_clicks:0.004993 train_acc_carts:0.009639 train_acc_orders:0.005314 lr:0.000692 grad_accum:2.000000 total_samples:544032.000000'}\n",
      "[Train Epoch]1/3 [Time]1139.67 [Step]16563 [Batch]17500 [Speed]65.12ms/step [Loss]12.2041 [Metrics]{'train_loss:12.204088 train_acc_clicks:0.005365 train_acc_carts:0.010382 train_acc_orders:0.005631 lr:0.000687 grad_accum:2.000000 total_samples:560032.000000'}\n",
      "[Train Epoch]1/3 [Time]1169.19 [Step]16813 [Batch]18000 [Speed]64.96ms/step [Loss]12.1762 [Metrics]{'train_loss:12.176172 train_acc_clicks:0.005789 train_acc_carts:0.011138 train_acc_orders:0.006026 lr:0.000682 grad_accum:2.000000 total_samples:576032.000000'}\n",
      "[Train Epoch]1/3 [Time]1198.68 [Step]17063 [Batch]18500 [Speed]64.79ms/step [Loss]12.1493 [Metrics]{'train_loss:12.149320 train_acc_clicks:0.006204 train_acc_carts:0.011885 train_acc_orders:0.006694 lr:0.000677 grad_accum:2.000000 total_samples:592032.000000'}\n",
      "[Train Epoch]1/3 [Time]1228.21 [Step]17313 [Batch]19000 [Speed]64.64ms/step [Loss]12.1230 [Metrics]{'train_loss:12.123009 train_acc_clicks:0.006588 train_acc_carts:0.012671 train_acc_orders:0.007285 lr:0.000672 grad_accum:2.000000 total_samples:608032.000000'}\n",
      "[Train Epoch]1/3 [Time]1257.75 [Step]17563 [Batch]19500 [Speed]64.50ms/step [Loss]12.0988 [Metrics]{'train_loss:12.098815 train_acc_clicks:0.006996 train_acc_carts:0.013048 train_acc_orders:0.007427 lr:0.000667 grad_accum:2.000000 total_samples:624032.000000'}\n",
      "[Train Epoch]1/3 [Time]1287.26 [Step]17813 [Batch]20000 [Speed]64.36ms/step [Loss]12.0745 [Metrics]{'train_loss:12.074464 train_acc_clicks:0.007384 train_acc_carts:0.013857 train_acc_orders:0.007810 lr:0.000662 grad_accum:2.000000 total_samples:640032.000000'}\n",
      "[Train Epoch]1/3 [Time]1316.79 [Step]18063 [Batch]20500 [Speed]64.23ms/step [Loss]12.0502 [Metrics]{'train_loss:12.050194 train_acc_clicks:0.007758 train_acc_carts:0.014485 train_acc_orders:0.008081 lr:0.000658 grad_accum:2.000000 total_samples:656032.000000'}\n",
      "[Train Epoch]1/3 [Time]1346.35 [Step]18313 [Batch]21000 [Speed]64.11ms/step [Loss]12.0248 [Metrics]{'train_loss:12.024808 train_acc_clicks:0.008119 train_acc_carts:0.015408 train_acc_orders:0.008568 lr:0.000653 grad_accum:2.000000 total_samples:672032.000000'}\n",
      "[Train Epoch]1/3 [Time]1375.89 [Step]18563 [Batch]21500 [Speed]63.99ms/step [Loss]12.0012 [Metrics]{'train_loss:12.001189 train_acc_clicks:0.008476 train_acc_carts:0.016232 train_acc_orders:0.009053 lr:0.000649 grad_accum:2.000000 total_samples:688032.000000'}\n",
      "[Train Epoch]1/3 [Time]1405.44 [Step]18813 [Batch]22000 [Speed]63.88ms/step [Loss]11.9787 [Metrics]{'train_loss:11.978650 train_acc_clicks:0.008846 train_acc_carts:0.016810 train_acc_orders:0.009329 lr:0.000644 grad_accum:2.000000 total_samples:704032.000000'}\n",
      "[Train Epoch]1/3 [Time]1434.95 [Step]19063 [Batch]22500 [Speed]63.78ms/step [Loss]11.9548 [Metrics]{'train_loss:11.954825 train_acc_clicks:0.009274 train_acc_carts:0.017478 train_acc_orders:0.009940 lr:0.000640 grad_accum:2.000000 total_samples:720032.000000'}\n",
      "[Train Epoch]1/3 [Time]1464.48 [Step]19313 [Batch]23000 [Speed]63.67ms/step [Loss]11.9315 [Metrics]{'train_loss:11.931532 train_acc_clicks:0.009704 train_acc_carts:0.018241 train_acc_orders:0.010374 lr:0.000636 grad_accum:2.000000 total_samples:736032.000000'}\n",
      "[Train Epoch]1/3 [Time]1494.00 [Step]19563 [Batch]23500 [Speed]63.57ms/step [Loss]11.9076 [Metrics]{'train_loss:11.907616 train_acc_clicks:0.010113 train_acc_carts:0.018888 train_acc_orders:0.010705 lr:0.000632 grad_accum:2.000000 total_samples:752032.000000'}\n",
      "[Train Epoch]1/3 [Time]1523.57 [Step]19813 [Batch]24000 [Speed]63.48ms/step [Loss]11.8845 [Metrics]{'train_loss:11.884472 train_acc_clicks:0.010552 train_acc_carts:0.019754 train_acc_orders:0.010902 lr:0.000628 grad_accum:2.000000 total_samples:768032.000000'}\n",
      "[Train Epoch]1/3 [Time]1553.09 [Step]20063 [Batch]24500 [Speed]63.39ms/step [Loss]11.8622 [Metrics]{'train_loss:11.862239 train_acc_clicks:0.010969 train_acc_carts:0.020536 train_acc_orders:0.011255 lr:0.000624 grad_accum:2.000000 total_samples:784032.000000'}\n",
      "[Train Epoch]1/3 [Time]1582.63 [Step]20313 [Batch]25000 [Speed]63.31ms/step [Loss]11.8405 [Metrics]{'train_loss:11.840510 train_acc_clicks:0.011388 train_acc_carts:0.021408 train_acc_orders:0.011749 lr:0.000620 grad_accum:2.000000 total_samples:800032.000000'}\n",
      "Saving checkpoint for epoch 1 at step 20313 on path model_bert4rec_complete_0.12_v1\n",
      "[Train Epoch]1/3 [Time]1616.29 [Step]20563 [Batch]25500 [Speed]63.38ms/step [Loss]11.8183 [Metrics]{'train_loss:11.818350 train_acc_clicks:0.011840 train_acc_carts:0.022264 train_acc_orders:0.012423 lr:0.000616 grad_accum:2.000000 total_samples:816032.000000'}\n",
      "[Train Epoch]1/3 [Time]1645.82 [Step]20813 [Batch]26000 [Speed]63.30ms/step [Loss]11.7971 [Metrics]{'train_loss:11.797137 train_acc_clicks:0.012258 train_acc_carts:0.023321 train_acc_orders:0.013035 lr:0.000613 grad_accum:2.000000 total_samples:832032.000000'}\n",
      "[Train Epoch]1/3 [Time]1675.40 [Step]21063 [Batch]26500 [Speed]63.22ms/step [Loss]11.7756 [Metrics]{'train_loss:11.775561 train_acc_clicks:0.012687 train_acc_carts:0.024219 train_acc_orders:0.013403 lr:0.000609 grad_accum:2.000000 total_samples:848032.000000'}\n",
      "[Train Epoch]1/3 [Time]1704.96 [Step]21313 [Batch]27000 [Speed]63.15ms/step [Loss]11.7540 [Metrics]{'train_loss:11.753961 train_acc_clicks:0.013087 train_acc_carts:0.025172 train_acc_orders:0.014092 lr:0.000605 grad_accum:2.000000 total_samples:864032.000000'}\n",
      "[Train Epoch]1/3 [Time]1734.53 [Step]21563 [Batch]27500 [Speed]63.07ms/step [Loss]11.7337 [Metrics]{'train_loss:11.733745 train_acc_clicks:0.013494 train_acc_carts:0.025962 train_acc_orders:0.014492 lr:0.000602 grad_accum:2.000000 total_samples:880032.000000'}\n",
      "[Train Epoch]1/3 [Time]1764.04 [Step]21813 [Batch]28000 [Speed]63.00ms/step [Loss]11.7135 [Metrics]{'train_loss:11.713451 train_acc_clicks:0.013900 train_acc_carts:0.026591 train_acc_orders:0.014976 lr:0.000598 grad_accum:2.000000 total_samples:896032.000000'}\n",
      "[Train Epoch]1/3 [Time]1793.61 [Step]22063 [Batch]28500 [Speed]62.93ms/step [Loss]11.6917 [Metrics]{'train_loss:11.691723 train_acc_clicks:0.014388 train_acc_carts:0.027772 train_acc_orders:0.015704 lr:0.000595 grad_accum:2.000000 total_samples:912032.000000'}\n",
      "[Train Epoch]1/3 [Time]1823.15 [Step]22313 [Batch]29000 [Speed]62.87ms/step [Loss]11.6713 [Metrics]{'train_loss:11.671276 train_acc_clicks:0.014846 train_acc_carts:0.028709 train_acc_orders:0.016451 lr:0.000592 grad_accum:2.000000 total_samples:928032.000000'}\n",
      "[Train Epoch]1/3 [Time]1852.68 [Step]22563 [Batch]29500 [Speed]62.80ms/step [Loss]11.6504 [Metrics]{'train_loss:11.650407 train_acc_clicks:0.015351 train_acc_carts:0.029809 train_acc_orders:0.016818 lr:0.000588 grad_accum:2.000000 total_samples:944032.000000'}\n",
      "[Train Epoch]1/3 [Time]1882.18 [Step]22813 [Batch]30000 [Speed]62.74ms/step [Loss]11.6299 [Metrics]{'train_loss:11.629929 train_acc_clicks:0.015823 train_acc_carts:0.030833 train_acc_orders:0.017438 lr:0.000585 grad_accum:2.000000 total_samples:960032.000000'}\n",
      "[Train Epoch]1/3 [Time]1911.68 [Step]23063 [Batch]30500 [Speed]62.68ms/step [Loss]11.6099 [Metrics]{'train_loss:11.609880 train_acc_clicks:0.016326 train_acc_carts:0.031800 train_acc_orders:0.017821 lr:0.000582 grad_accum:2.000000 total_samples:976032.000000'}\n",
      "[Train Epoch]1/3 [Time]1941.25 [Step]23313 [Batch]31000 [Speed]62.62ms/step [Loss]11.5896 [Metrics]{'train_loss:11.589624 train_acc_clicks:0.016859 train_acc_carts:0.032825 train_acc_orders:0.018675 lr:0.000579 grad_accum:2.000000 total_samples:992032.000000'}\n",
      "[Train Epoch]1/3 [Time]1970.34 [Step]23522 [Batch]31500 [Speed]62.55ms/step [Loss]11.5709 [Metrics]{'train_loss:11.570864 train_acc_clicks:0.017374 train_acc_carts:0.033965 train_acc_orders:0.019303 lr:0.000576 grad_accum:3.000000 total_samples:1008096.000000'}\n",
      "[Train Epoch]1/3 [Time]1998.91 [Step]23689 [Batch]32000 [Speed]62.47ms/step [Loss]11.5510 [Metrics]{'train_loss:11.550973 train_acc_clicks:0.017871 train_acc_carts:0.035218 train_acc_orders:0.020137 lr:0.000574 grad_accum:3.000000 total_samples:1024032.000000'}\n",
      "[Train Epoch]1/3 [Time]2027.53 [Step]23855 [Batch]32500 [Speed]62.39ms/step [Loss]11.5307 [Metrics]{'train_loss:11.530737 train_acc_clicks:0.018437 train_acc_carts:0.036283 train_acc_orders:0.020954 lr:0.000572 grad_accum:3.000000 total_samples:1040064.000000'}\n",
      "[Train Epoch]1/3 [Time]2056.17 [Step]24022 [Batch]33000 [Speed]62.31ms/step [Loss]11.5108 [Metrics]{'train_loss:11.510828 train_acc_clicks:0.019015 train_acc_carts:0.037471 train_acc_orders:0.021987 lr:0.000570 grad_accum:3.000000 total_samples:1056096.000000'}\n",
      "[Train Epoch]1/3 [Time]2084.81 [Step]24189 [Batch]33500 [Speed]62.23ms/step [Loss]11.4913 [Metrics]{'train_loss:11.491324 train_acc_clicks:0.019585 train_acc_carts:0.038793 train_acc_orders:0.022884 lr:0.000568 grad_accum:3.000000 total_samples:1072032.000000'}\n",
      "[Train Epoch]1/3 [Time]2113.41 [Step]24355 [Batch]34000 [Speed]62.16ms/step [Loss]11.4722 [Metrics]{'train_loss:11.472179 train_acc_clicks:0.020167 train_acc_carts:0.039978 train_acc_orders:0.023735 lr:0.000566 grad_accum:3.000000 total_samples:1088064.000000'}\n",
      "[Train Epoch]1/3 [Time]2141.99 [Step]24522 [Batch]34500 [Speed]62.09ms/step [Loss]11.4535 [Metrics]{'train_loss:11.453464 train_acc_clicks:0.020731 train_acc_carts:0.041276 train_acc_orders:0.024530 lr:0.000564 grad_accum:3.000000 total_samples:1104096.000000'}\n",
      "[Train Epoch]1/3 [Time]2170.59 [Step]24689 [Batch]35000 [Speed]62.02ms/step [Loss]11.4339 [Metrics]{'train_loss:11.433880 train_acc_clicks:0.021330 train_acc_carts:0.042630 train_acc_orders:0.025400 lr:0.000563 grad_accum:3.000000 total_samples:1120032.000000'}\n",
      "[Train Epoch]1/3 [Time]2199.14 [Step]24855 [Batch]35500 [Speed]61.95ms/step [Loss]11.4147 [Metrics]{'train_loss:11.414709 train_acc_clicks:0.021895 train_acc_carts:0.043960 train_acc_orders:0.026272 lr:0.000561 grad_accum:3.000000 total_samples:1136064.000000'}\n",
      "[Train Epoch]1/3 [Time]2227.79 [Step]25022 [Batch]36000 [Speed]61.88ms/step [Loss]11.3965 [Metrics]{'train_loss:11.396485 train_acc_clicks:0.022447 train_acc_carts:0.045333 train_acc_orders:0.027236 lr:0.000559 grad_accum:3.000000 total_samples:1152096.000000'}\n",
      "[Train Epoch]1/3 [Time]2256.36 [Step]25189 [Batch]36500 [Speed]61.82ms/step [Loss]11.3780 [Metrics]{'train_loss:11.377998 train_acc_clicks:0.023057 train_acc_carts:0.046601 train_acc_orders:0.028223 lr:0.000557 grad_accum:3.000000 total_samples:1168032.000000'}\n",
      "[Train Epoch]1/3 [Time]2284.92 [Step]25355 [Batch]37000 [Speed]61.75ms/step [Loss]11.3590 [Metrics]{'train_loss:11.359006 train_acc_clicks:0.023660 train_acc_carts:0.048029 train_acc_orders:0.029035 lr:0.000555 grad_accum:3.000000 total_samples:1184064.000000'}\n",
      "[Train Epoch]1/3 [Time]2313.49 [Step]25522 [Batch]37500 [Speed]61.69ms/step [Loss]11.3413 [Metrics]{'train_loss:11.341311 train_acc_clicks:0.024232 train_acc_carts:0.049383 train_acc_orders:0.030124 lr:0.000553 grad_accum:3.000000 total_samples:1200096.000000'}\n",
      "[Train Epoch]1/3 [Time]2342.09 [Step]25689 [Batch]38000 [Speed]61.63ms/step [Loss]11.3231 [Metrics]{'train_loss:11.323133 train_acc_clicks:0.024823 train_acc_carts:0.050826 train_acc_orders:0.031026 lr:0.000551 grad_accum:3.000000 total_samples:1216032.000000'}\n",
      "[Train Epoch]1/3 [Time]2370.69 [Step]25855 [Batch]38500 [Speed]61.58ms/step [Loss]11.3047 [Metrics]{'train_loss:11.304687 train_acc_clicks:0.025448 train_acc_carts:0.052236 train_acc_orders:0.032110 lr:0.000550 grad_accum:3.000000 total_samples:1232064.000000'}\n",
      "[Train Epoch]1/3 [Time]2399.26 [Step]26022 [Batch]39000 [Speed]61.52ms/step [Loss]11.2866 [Metrics]{'train_loss:11.286551 train_acc_clicks:0.026082 train_acc_carts:0.053790 train_acc_orders:0.033364 lr:0.000548 grad_accum:3.000000 total_samples:1248096.000000'}\n",
      "[Train Epoch]1/3 [Time]2427.80 [Step]26189 [Batch]39500 [Speed]61.46ms/step [Loss]11.2684 [Metrics]{'train_loss:11.268379 train_acc_clicks:0.026722 train_acc_carts:0.055329 train_acc_orders:0.034564 lr:0.000546 grad_accum:3.000000 total_samples:1264032.000000'}\n",
      "[Train Epoch]1/3 [Time]2456.35 [Step]26355 [Batch]40000 [Speed]61.41ms/step [Loss]11.2515 [Metrics]{'train_loss:11.251506 train_acc_clicks:0.027303 train_acc_carts:0.056947 train_acc_orders:0.035711 lr:0.000544 grad_accum:3.000000 total_samples:1280064.000000'}\n",
      "[Train Epoch]1/3 [Time]2484.97 [Step]26522 [Batch]40500 [Speed]61.36ms/step [Loss]11.2336 [Metrics]{'train_loss:11.233550 train_acc_clicks:0.027968 train_acc_carts:0.058273 train_acc_orders:0.036903 lr:0.000543 grad_accum:3.000000 total_samples:1296096.000000'}\n",
      "[Train Epoch]1/3 [Time]2513.60 [Step]26689 [Batch]41000 [Speed]61.31ms/step [Loss]11.2162 [Metrics]{'train_loss:11.216158 train_acc_clicks:0.028587 train_acc_carts:0.059974 train_acc_orders:0.038118 lr:0.000541 grad_accum:3.000000 total_samples:1312032.000000'}\n",
      "[Train Epoch]1/3 [Time]2542.17 [Step]26855 [Batch]41500 [Speed]61.26ms/step [Loss]11.1986 [Metrics]{'train_loss:11.198602 train_acc_clicks:0.029240 train_acc_carts:0.061665 train_acc_orders:0.039069 lr:0.000539 grad_accum:3.000000 total_samples:1328064.000000'}\n",
      "[Train Epoch]1/3 [Time]2570.75 [Step]27022 [Batch]42000 [Speed]61.21ms/step [Loss]11.1812 [Metrics]{'train_loss:11.181237 train_acc_clicks:0.029888 train_acc_carts:0.063387 train_acc_orders:0.040206 lr:0.000538 grad_accum:3.000000 total_samples:1344096.000000'}\n",
      "[Train Epoch]1/3 [Time]2599.35 [Step]27189 [Batch]42500 [Speed]61.16ms/step [Loss]11.1639 [Metrics]{'train_loss:11.163871 train_acc_clicks:0.030531 train_acc_carts:0.065014 train_acc_orders:0.041659 lr:0.000536 grad_accum:3.000000 total_samples:1360032.000000'}\n",
      "[Train Epoch]1/3 [Time]2627.98 [Step]27355 [Batch]43000 [Speed]61.12ms/step [Loss]11.1468 [Metrics]{'train_loss:11.146812 train_acc_clicks:0.031206 train_acc_carts:0.066531 train_acc_orders:0.042785 lr:0.000534 grad_accum:3.000000 total_samples:1376064.000000'}\n",
      "[Train Epoch]1/3 [Time]2656.58 [Step]27522 [Batch]43500 [Speed]61.07ms/step [Loss]11.1305 [Metrics]{'train_loss:11.130482 train_acc_clicks:0.031813 train_acc_carts:0.068332 train_acc_orders:0.043913 lr:0.000533 grad_accum:3.000000 total_samples:1392096.000000'}\n",
      "[Train Epoch]1/3 [Time]2685.20 [Step]27689 [Batch]44000 [Speed]61.03ms/step [Loss]11.1141 [Metrics]{'train_loss:11.114122 train_acc_clicks:0.032446 train_acc_carts:0.069931 train_acc_orders:0.044841 lr:0.000531 grad_accum:3.000000 total_samples:1408032.000000'}\n",
      "[Train Epoch]1/3 [Time]2713.82 [Step]27855 [Batch]44500 [Speed]60.98ms/step [Loss]11.0980 [Metrics]{'train_loss:11.097964 train_acc_clicks:0.033097 train_acc_carts:0.071466 train_acc_orders:0.045977 lr:0.000530 grad_accum:3.000000 total_samples:1424064.000000'}\n",
      "[Train Epoch]1/3 [Time]2742.38 [Step]28022 [Batch]45000 [Speed]60.94ms/step [Loss]11.0812 [Metrics]{'train_loss:11.081170 train_acc_clicks:0.033772 train_acc_carts:0.073212 train_acc_orders:0.047185 lr:0.000528 grad_accum:3.000000 total_samples:1440096.000000'}\n",
      "[Train Epoch]1/3 [Time]2770.98 [Step]28189 [Batch]45500 [Speed]60.90ms/step [Loss]11.0650 [Metrics]{'train_loss:11.065009 train_acc_clicks:0.034393 train_acc_carts:0.074943 train_acc_orders:0.048384 lr:0.000526 grad_accum:3.000000 total_samples:1456032.000000'}\n",
      "[Train Epoch]1/3 [Time]2799.57 [Step]28355 [Batch]46000 [Speed]60.86ms/step [Loss]11.0486 [Metrics]{'train_loss:11.048553 train_acc_clicks:0.035055 train_acc_carts:0.076624 train_acc_orders:0.049604 lr:0.000525 grad_accum:3.000000 total_samples:1472064.000000'}\n",
      "[Train Epoch]1/3 [Time]2828.17 [Step]28522 [Batch]46500 [Speed]60.82ms/step [Loss]11.0324 [Metrics]{'train_loss:11.032377 train_acc_clicks:0.035703 train_acc_carts:0.078122 train_acc_orders:0.050899 lr:0.000523 grad_accum:3.000000 total_samples:1488096.000000'}\n",
      "[Train Epoch]1/3 [Time]2856.67 [Step]28678 [Batch]47000 [Speed]60.78ms/step [Loss]11.0168 [Metrics]{'train_loss:11.016763 train_acc_clicks:0.036361 train_acc_carts:0.079766 train_acc_orders:0.051890 lr:0.000522 grad_accum:4.000000 total_samples:1504096.000000'}\n",
      "[Train Epoch]1/3 [Time]2884.68 [Step]28803 [Batch]47500 [Speed]60.73ms/step [Loss]11.0008 [Metrics]{'train_loss:11.000839 train_acc_clicks:0.037002 train_acc_carts:0.081425 train_acc_orders:0.053207 lr:0.000521 grad_accum:4.000000 total_samples:1520096.000000'}\n",
      "[Train Epoch]1/3 [Time]2912.71 [Step]28928 [Batch]48000 [Speed]60.68ms/step [Loss]10.9847 [Metrics]{'train_loss:10.984714 train_acc_clicks:0.037669 train_acc_carts:0.083265 train_acc_orders:0.054405 lr:0.000520 grad_accum:4.000000 total_samples:1536096.000000'}\n",
      "[Train Epoch]1/3 [Time]2940.73 [Step]29053 [Batch]48500 [Speed]60.63ms/step [Loss]10.9692 [Metrics]{'train_loss:10.969208 train_acc_clicks:0.038340 train_acc_carts:0.085092 train_acc_orders:0.055647 lr:0.000519 grad_accum:4.000000 total_samples:1552096.000000'}\n",
      "[Train Epoch]1/3 [Time]2968.76 [Step]29178 [Batch]49000 [Speed]60.59ms/step [Loss]10.9535 [Metrics]{'train_loss:10.953486 train_acc_clicks:0.038981 train_acc_carts:0.086789 train_acc_orders:0.056882 lr:0.000517 grad_accum:4.000000 total_samples:1568096.000000'}\n",
      "[Train Epoch]1/3 [Time]2996.83 [Step]29303 [Batch]49500 [Speed]60.54ms/step [Loss]10.9378 [Metrics]{'train_loss:10.937777 train_acc_clicks:0.039636 train_acc_carts:0.088605 train_acc_orders:0.057972 lr:0.000516 grad_accum:4.000000 total_samples:1584096.000000'}\n",
      "[Train Epoch]1/3 [Time]3024.88 [Step]29428 [Batch]50000 [Speed]60.50ms/step [Loss]10.9224 [Metrics]{'train_loss:10.922354 train_acc_clicks:0.040301 train_acc_carts:0.090376 train_acc_orders:0.059047 lr:0.000515 grad_accum:4.000000 total_samples:1600096.000000'}\n",
      "Saving checkpoint for epoch 1 at step 29428 on path model_bert4rec_complete_0.12_v1\n",
      "[Train Epoch]1/3 [Time]3057.07 [Step]29553 [Batch]50500 [Speed]60.54ms/step [Loss]10.9068 [Metrics]{'train_loss:10.906784 train_acc_clicks:0.040946 train_acc_carts:0.092218 train_acc_orders:0.060046 lr:0.000514 grad_accum:4.000000 total_samples:1616096.000000'}\n",
      "[Train Epoch]1/3 [Time]3085.16 [Step]29678 [Batch]51000 [Speed]60.49ms/step [Loss]10.8912 [Metrics]{'train_loss:10.891215 train_acc_clicks:0.041617 train_acc_carts:0.094138 train_acc_orders:0.061262 lr:0.000513 grad_accum:4.000000 total_samples:1632096.000000'}\n",
      "[Train Epoch]1/3 [Time]3113.15 [Step]29803 [Batch]51500 [Speed]60.45ms/step [Loss]10.8758 [Metrics]{'train_loss:10.875798 train_acc_clicks:0.042265 train_acc_carts:0.096041 train_acc_orders:0.062447 lr:0.000512 grad_accum:4.000000 total_samples:1648096.000000'}\n",
      "[Train Epoch]1/3 [Time]3141.18 [Step]29928 [Batch]52000 [Speed]60.41ms/step [Loss]10.8609 [Metrics]{'train_loss:10.860947 train_acc_clicks:0.042915 train_acc_carts:0.097738 train_acc_orders:0.063864 lr:0.000511 grad_accum:4.000000 total_samples:1664096.000000'}\n",
      "[Train Epoch]1/3 [Time]3169.19 [Step]30053 [Batch]52500 [Speed]60.37ms/step [Loss]10.8458 [Metrics]{'train_loss:10.845784 train_acc_clicks:0.043571 train_acc_carts:0.099532 train_acc_orders:0.065057 lr:0.000510 grad_accum:4.000000 total_samples:1680096.000000'}\n",
      "[Train Epoch]1/3 [Time]3197.23 [Step]30178 [Batch]53000 [Speed]60.33ms/step [Loss]10.8310 [Metrics]{'train_loss:10.831048 train_acc_clicks:0.044241 train_acc_carts:0.101322 train_acc_orders:0.066369 lr:0.000509 grad_accum:4.000000 total_samples:1696096.000000'}\n",
      "[Train Epoch]1/3 [Time]3225.27 [Step]30303 [Batch]53500 [Speed]60.29ms/step [Loss]10.8164 [Metrics]{'train_loss:10.816362 train_acc_clicks:0.044881 train_acc_carts:0.102904 train_acc_orders:0.067611 lr:0.000508 grad_accum:4.000000 total_samples:1712096.000000'}\n",
      "[Train Epoch]1/3 [Time]3253.36 [Step]30428 [Batch]54000 [Speed]60.25ms/step [Loss]10.8017 [Metrics]{'train_loss:10.801728 train_acc_clicks:0.045499 train_acc_carts:0.104549 train_acc_orders:0.068782 lr:0.000507 grad_accum:4.000000 total_samples:1728096.000000'}\n",
      "[Train Epoch]1/3 [Time]3281.39 [Step]30553 [Batch]54500 [Speed]60.21ms/step [Loss]10.7875 [Metrics]{'train_loss:10.787493 train_acc_clicks:0.046102 train_acc_carts:0.106361 train_acc_orders:0.070018 lr:0.000506 grad_accum:4.000000 total_samples:1744096.000000'}\n",
      "[Train Epoch]1/3 [Time]3309.45 [Step]30678 [Batch]55000 [Speed]60.17ms/step [Loss]10.7732 [Metrics]{'train_loss:10.773232 train_acc_clicks:0.046719 train_acc_carts:0.107998 train_acc_orders:0.070979 lr:0.000505 grad_accum:4.000000 total_samples:1760096.000000'}\n",
      "[Train Epoch]1/3 [Time]3337.55 [Step]30803 [Batch]55500 [Speed]60.14ms/step [Loss]10.7587 [Metrics]{'train_loss:10.758708 train_acc_clicks:0.047356 train_acc_carts:0.109689 train_acc_orders:0.072535 lr:0.000504 grad_accum:4.000000 total_samples:1776096.000000'}\n",
      "[Train Epoch]1/3 [Time]3365.58 [Step]30928 [Batch]56000 [Speed]60.10ms/step [Loss]10.7441 [Metrics]{'train_loss:10.744148 train_acc_clicks:0.048012 train_acc_carts:0.111370 train_acc_orders:0.073633 lr:0.000503 grad_accum:4.000000 total_samples:1792096.000000'}\n",
      "[Train Epoch]1/3 [Time]3393.64 [Step]31053 [Batch]56500 [Speed]60.06ms/step [Loss]10.7301 [Metrics]{'train_loss:10.730114 train_acc_clicks:0.048612 train_acc_carts:0.113023 train_acc_orders:0.074462 lr:0.000502 grad_accum:4.000000 total_samples:1808096.000000'}\n",
      "[Train Epoch]1/3 [Time]3421.68 [Step]31178 [Batch]57000 [Speed]60.03ms/step [Loss]10.7164 [Metrics]{'train_loss:10.716362 train_acc_clicks:0.049220 train_acc_carts:0.114828 train_acc_orders:0.075634 lr:0.000501 grad_accum:4.000000 total_samples:1824096.000000'}\n",
      "[Train Epoch]1/3 [Time]3449.74 [Step]31303 [Batch]57500 [Speed]60.00ms/step [Loss]10.7029 [Metrics]{'train_loss:10.702900 train_acc_clicks:0.049821 train_acc_carts:0.116733 train_acc_orders:0.076597 lr:0.000500 grad_accum:4.000000 total_samples:1840096.000000'}\n",
      "[Train Epoch]1/3 [Time]3477.77 [Step]31428 [Batch]58000 [Speed]59.96ms/step [Loss]10.6895 [Metrics]{'train_loss:10.689457 train_acc_clicks:0.050404 train_acc_carts:0.118395 train_acc_orders:0.077741 lr:0.000499 grad_accum:4.000000 total_samples:1856096.000000'}\n",
      "[Train Epoch]1/3 [Time]3505.79 [Step]31553 [Batch]58500 [Speed]59.93ms/step [Loss]10.6759 [Metrics]{'train_loss:10.675865 train_acc_clicks:0.051021 train_acc_carts:0.120161 train_acc_orders:0.078931 lr:0.000498 grad_accum:4.000000 total_samples:1872096.000000'}\n",
      "[Train Epoch]1/3 [Time]3533.83 [Step]31678 [Batch]59000 [Speed]59.90ms/step [Loss]10.6624 [Metrics]{'train_loss:10.662356 train_acc_clicks:0.051620 train_acc_carts:0.121748 train_acc_orders:0.079975 lr:0.000497 grad_accum:4.000000 total_samples:1888096.000000'}\n",
      "[Train Epoch]1/3 [Time]3561.83 [Step]31803 [Batch]59500 [Speed]59.86ms/step [Loss]10.6486 [Metrics]{'train_loss:10.648645 train_acc_clicks:0.052254 train_acc_carts:0.123546 train_acc_orders:0.080994 lr:0.000496 grad_accum:4.000000 total_samples:1904096.000000'}\n",
      "[Train Epoch]1/3 [Time]3589.87 [Step]31928 [Batch]60000 [Speed]59.83ms/step [Loss]10.6353 [Metrics]{'train_loss:10.635305 train_acc_clicks:0.052860 train_acc_carts:0.125231 train_acc_orders:0.082176 lr:0.000495 grad_accum:4.000000 total_samples:1920096.000000'}\n",
      "[Train Epoch]1/3 [Time]3617.94 [Step]32053 [Batch]60500 [Speed]59.80ms/step [Loss]10.6224 [Metrics]{'train_loss:10.622450 train_acc_clicks:0.053442 train_acc_carts:0.126903 train_acc_orders:0.083260 lr:0.000494 grad_accum:4.000000 total_samples:1936096.000000'}\n",
      "[Train Epoch]1/3 [Time]3645.98 [Step]32178 [Batch]61000 [Speed]59.77ms/step [Loss]10.6087 [Metrics]{'train_loss:10.608697 train_acc_clicks:0.054047 train_acc_carts:0.128660 train_acc_orders:0.084719 lr:0.000493 grad_accum:4.000000 total_samples:1952096.000000'}\n",
      "[Train Epoch]1/3 [Time]3674.05 [Step]32303 [Batch]61500 [Speed]59.74ms/step [Loss]10.5955 [Metrics]{'train_loss:10.595457 train_acc_clicks:0.054655 train_acc_carts:0.130089 train_acc_orders:0.085676 lr:0.000492 grad_accum:4.000000 total_samples:1968096.000000'}\n",
      "[Train Epoch]1/3 [Time]3702.11 [Step]32428 [Batch]62000 [Speed]59.71ms/step [Loss]10.5825 [Metrics]{'train_loss:10.582524 train_acc_clicks:0.055255 train_acc_carts:0.131796 train_acc_orders:0.086891 lr:0.000491 grad_accum:4.000000 total_samples:1984096.000000'}\n",
      "[Train Epoch]1/3 [Time]3730.16 [Step]32553 [Batch]62500 [Speed]59.68ms/step [Loss]10.5698 [Metrics]{'train_loss:10.569839 train_acc_clicks:0.055838 train_acc_carts:0.133381 train_acc_orders:0.087893 lr:0.000490 grad_accum:5.000000 total_samples:2000096.000000'}\n",
      "[Train Epoch]1/3 [Time]3757.98 [Step]32653 [Batch]63000 [Speed]59.65ms/step [Loss]10.5572 [Metrics]{'train_loss:10.557223 train_acc_clicks:0.056422 train_acc_carts:0.134980 train_acc_orders:0.088975 lr:0.000489 grad_accum:5.000000 total_samples:2016096.000000'}\n",
      "[Train Epoch]1/3 [Time]3785.76 [Step]32753 [Batch]63500 [Speed]59.62ms/step [Loss]10.5447 [Metrics]{'train_loss:10.544675 train_acc_clicks:0.056983 train_acc_carts:0.136561 train_acc_orders:0.089954 lr:0.000488 grad_accum:5.000000 total_samples:2032096.000000'}\n",
      "[Train Epoch]1/3 [Time]3813.56 [Step]32853 [Batch]64000 [Speed]59.59ms/step [Loss]10.5322 [Metrics]{'train_loss:10.532240 train_acc_clicks:0.057533 train_acc_carts:0.138306 train_acc_orders:0.090952 lr:0.000488 grad_accum:5.000000 total_samples:2048096.000000'}\n",
      "[Train Epoch]1/3 [Time]3841.33 [Step]32953 [Batch]64500 [Speed]59.56ms/step [Loss]10.5196 [Metrics]{'train_loss:10.519643 train_acc_clicks:0.058116 train_acc_carts:0.139928 train_acc_orders:0.091946 lr:0.000487 grad_accum:5.000000 total_samples:2064096.000000'}\n",
      "[Train Epoch]1/3 [Time]3869.10 [Step]33053 [Batch]65000 [Speed]59.52ms/step [Loss]10.5070 [Metrics]{'train_loss:10.506965 train_acc_clicks:0.058692 train_acc_carts:0.141744 train_acc_orders:0.092868 lr:0.000486 grad_accum:5.000000 total_samples:2080096.000000'}\n",
      "[Train Epoch]1/3 [Time]3896.90 [Step]33153 [Batch]65500 [Speed]59.49ms/step [Loss]10.4949 [Metrics]{'train_loss:10.494889 train_acc_clicks:0.059236 train_acc_carts:0.143398 train_acc_orders:0.093844 lr:0.000485 grad_accum:5.000000 total_samples:2096096.000000'}\n",
      "[Train Epoch]1/3 [Time]3924.65 [Step]33253 [Batch]66000 [Speed]59.46ms/step [Loss]10.4826 [Metrics]{'train_loss:10.482625 train_acc_clicks:0.059808 train_acc_carts:0.144984 train_acc_orders:0.095127 lr:0.000485 grad_accum:5.000000 total_samples:2112096.000000'}\n",
      "[Train Epoch]1/3 [Time]3952.46 [Step]33353 [Batch]66500 [Speed]59.44ms/step [Loss]10.4703 [Metrics]{'train_loss:10.470317 train_acc_clicks:0.060360 train_acc_carts:0.146521 train_acc_orders:0.096292 lr:0.000484 grad_accum:5.000000 total_samples:2128096.000000'}\n",
      "[Train Epoch]1/3 [Time]3980.24 [Step]33453 [Batch]67000 [Speed]59.41ms/step [Loss]10.4584 [Metrics]{'train_loss:10.458430 train_acc_clicks:0.060907 train_acc_carts:0.148106 train_acc_orders:0.097318 lr:0.000483 grad_accum:5.000000 total_samples:2144096.000000'}\n",
      "[Train Epoch]1/3 [Time]4008.04 [Step]33553 [Batch]67500 [Speed]59.38ms/step [Loss]10.4463 [Metrics]{'train_loss:10.446304 train_acc_clicks:0.061444 train_acc_carts:0.149653 train_acc_orders:0.098314 lr:0.000483 grad_accum:5.000000 total_samples:2160096.000000'}\n",
      "[Train Epoch]1/3 [Time]4035.83 [Step]33653 [Batch]68000 [Speed]59.35ms/step [Loss]10.4342 [Metrics]{'train_loss:10.434208 train_acc_clicks:0.061982 train_acc_carts:0.151162 train_acc_orders:0.099387 lr:0.000482 grad_accum:5.000000 total_samples:2176096.000000'}\n",
      "[Train Epoch]1/3 [Time]4063.60 [Step]33753 [Batch]68500 [Speed]59.32ms/step [Loss]10.4223 [Metrics]{'train_loss:10.422344 train_acc_clicks:0.062516 train_acc_carts:0.152719 train_acc_orders:0.100237 lr:0.000481 grad_accum:5.000000 total_samples:2192096.000000'}\n",
      "[Train Epoch]1/3 [Time]4091.41 [Step]33853 [Batch]69000 [Speed]59.30ms/step [Loss]10.4104 [Metrics]{'train_loss:10.410382 train_acc_clicks:0.063065 train_acc_carts:0.154276 train_acc_orders:0.101201 lr:0.000480 grad_accum:5.000000 total_samples:2208096.000000'}\n",
      "[Train Epoch]1/3 [Time]4119.18 [Step]33953 [Batch]69500 [Speed]59.27ms/step [Loss]10.3984 [Metrics]{'train_loss:10.398416 train_acc_clicks:0.063613 train_acc_carts:0.155797 train_acc_orders:0.102269 lr:0.000480 grad_accum:5.000000 total_samples:2224096.000000'}\n",
      "[Train Epoch]1/3 [Time]4146.99 [Step]34053 [Batch]70000 [Speed]59.24ms/step [Loss]10.3873 [Metrics]{'train_loss:10.387264 train_acc_clicks:0.064143 train_acc_carts:0.157231 train_acc_orders:0.103193 lr:0.000479 grad_accum:5.000000 total_samples:2240096.000000'}\n",
      "[Train Epoch]1/3 [Time]4174.77 [Step]34153 [Batch]70500 [Speed]59.22ms/step [Loss]10.3758 [Metrics]{'train_loss:10.375773 train_acc_clicks:0.064665 train_acc_carts:0.158668 train_acc_orders:0.103946 lr:0.000478 grad_accum:5.000000 total_samples:2256096.000000'}\n",
      "[Train Epoch]1/3 [Time]4202.53 [Step]34253 [Batch]71000 [Speed]59.19ms/step [Loss]10.3644 [Metrics]{'train_loss:10.364364 train_acc_clicks:0.065180 train_acc_carts:0.160111 train_acc_orders:0.104847 lr:0.000478 grad_accum:5.000000 total_samples:2272096.000000'}\n",
      "[Train Epoch]1/3 [Time]4230.32 [Step]34353 [Batch]71500 [Speed]59.17ms/step [Loss]10.3530 [Metrics]{'train_loss:10.353040 train_acc_clicks:0.065705 train_acc_carts:0.161343 train_acc_orders:0.105837 lr:0.000477 grad_accum:5.000000 total_samples:2288096.000000'}\n",
      "[Train Epoch]1/3 [Time]4258.12 [Step]34453 [Batch]72000 [Speed]59.14ms/step [Loss]10.3418 [Metrics]{'train_loss:10.341764 train_acc_clicks:0.066214 train_acc_carts:0.162797 train_acc_orders:0.106821 lr:0.000476 grad_accum:5.000000 total_samples:2304096.000000'}\n",
      "[Train Epoch]1/3 [Time]4285.92 [Step]34553 [Batch]72500 [Speed]59.12ms/step [Loss]10.3313 [Metrics]{'train_loss:10.331319 train_acc_clicks:0.066706 train_acc_carts:0.164166 train_acc_orders:0.107765 lr:0.000476 grad_accum:5.000000 total_samples:2320096.000000'}\n",
      "[Train Epoch]1/3 [Time]4313.71 [Step]34653 [Batch]73000 [Speed]59.09ms/step [Loss]10.3200 [Metrics]{'train_loss:10.320034 train_acc_clicks:0.067210 train_acc_carts:0.165616 train_acc_orders:0.108836 lr:0.000475 grad_accum:5.000000 total_samples:2336096.000000'}\n",
      "[Train Epoch]1/3 [Time]4341.51 [Step]34753 [Batch]73500 [Speed]59.07ms/step [Loss]10.3091 [Metrics]{'train_loss:10.309098 train_acc_clicks:0.067721 train_acc_carts:0.166958 train_acc_orders:0.109845 lr:0.000474 grad_accum:5.000000 total_samples:2352096.000000'}\n",
      "[Train Epoch]1/3 [Time]4369.47 [Step]34853 [Batch]74000 [Speed]59.05ms/step [Loss]10.2979 [Metrics]{'train_loss:10.297929 train_acc_clicks:0.068231 train_acc_carts:0.168415 train_acc_orders:0.111150 lr:0.000473 grad_accum:5.000000 total_samples:2368096.000000'}\n",
      "[Train Epoch]1/3 [Time]4399.93 [Step]34953 [Batch]74500 [Speed]59.06ms/step [Loss]10.2870 [Metrics]{'train_loss:10.286978 train_acc_clicks:0.068726 train_acc_carts:0.169761 train_acc_orders:0.112100 lr:0.000473 grad_accum:5.000000 total_samples:2384096.000000'}\n",
      "[Train Epoch]1/3 [Time]4430.24 [Step]35053 [Batch]75000 [Speed]59.07ms/step [Loss]10.2757 [Metrics]{'train_loss:10.275711 train_acc_clicks:0.069233 train_acc_carts:0.171233 train_acc_orders:0.112900 lr:0.000472 grad_accum:5.000000 total_samples:2400096.000000'}\n",
      "Saving checkpoint for epoch 1 at step 35053 on path model_bert4rec_complete_0.12_v1\n",
      "[Train Epoch]1/3 [Time]4464.61 [Step]35153 [Batch]75500 [Speed]59.13ms/step [Loss]10.2650 [Metrics]{'train_loss:10.265015 train_acc_clicks:0.069710 train_acc_carts:0.172636 train_acc_orders:0.113843 lr:0.000471 grad_accum:5.000000 total_samples:2416096.000000'}\n",
      "[Train Epoch]1/3 [Time]4494.66 [Step]35253 [Batch]76000 [Speed]59.14ms/step [Loss]10.2543 [Metrics]{'train_loss:10.254321 train_acc_clicks:0.070166 train_acc_carts:0.173991 train_acc_orders:0.114423 lr:0.000471 grad_accum:5.000000 total_samples:2432096.000000'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 127\u001b[0m\n\u001b[1;32m    122\u001b[0m grad_accum \u001b[39m=\u001b[39m grad_accum_scheduler(total_samples,\n\u001b[1;32m    123\u001b[0m                                   list_scheduler\u001b[39m=\u001b[39mlist_scheduler, \n\u001b[1;32m    124\u001b[0m                                   max_grad_accum\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mtup_scheduler_grad_accum[\u001b[39m1\u001b[39m])                                                             \n\u001b[1;32m    125\u001b[0m step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39mtarget, model\u001b[39m=\u001b[39mmodel, optimizer\u001b[39m=\u001b[39moptimizer, num_accum_steps\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconstant(grad_accum, tf\u001b[39m.\u001b[39mfloat32), \n\u001b[1;32m    126\u001b[0m                             loss\u001b[39m=\u001b[39mtrain_loss, acc_clicks\u001b[39m=\u001b[39mtrain_acc_clicks, acc_carts\u001b[39m=\u001b[39mtrain_acc_carts, acc_orders\u001b[39m=\u001b[39mtrain_acc_orders, seq_type\u001b[39m=\u001b[39minputs[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 127\u001b[0m global_gradients, total_step \u001b[39m=\u001b[39m backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    129\u001b[0m     train_dict_metrics \u001b[39m=\u001b[39m {x\u001b[39m.\u001b[39mname : x\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
      "Cell \u001b[0;32mIn [7], line 17\u001b[0m, in \u001b[0;36mbackward_optimization\u001b[0;34m(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_optimization\u001b[39m(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer):\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_gradients:\n\u001b[0;32m---> 17\u001b[0m         global_gradients \u001b[39m=\u001b[39m [flat_gradients(g) \u001b[39m/\u001b[39m num_grad_steps \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m step_gradients] \n\u001b[1;32m     18\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[39mfor\u001b[39;00m i, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(step_gradients):\n",
      "Cell \u001b[0;32mIn [7], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_optimization\u001b[39m(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer):\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_gradients:\n\u001b[0;32m---> 17\u001b[0m         global_gradients \u001b[39m=\u001b[39m [flat_gradients(g) \u001b[39m/\u001b[39m num_grad_steps \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m step_gradients] \n\u001b[1;32m     18\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[39mfor\u001b[39;00m i, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(step_gradients):\n",
      "Cell \u001b[0;32mIn [7], line 8\u001b[0m, in \u001b[0;36mflat_gradients\u001b[0;34m(grads_or_idx_slices)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m'''Convert gradients if it's tf.IndexedSlices.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mWhen computing gradients for operation concerning `tf.gather`, the type of gradients \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(grads_or_idx_slices) \u001b[39m==\u001b[39m tf\u001b[39m.\u001b[39mIndexedSlices:\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mscatter_nd(\n\u001b[1;32m      9\u001b[0m         tf\u001b[39m.\u001b[39;49mexpand_dims(grads_or_idx_slices\u001b[39m.\u001b[39;49mindices, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m     10\u001b[0m         grads_or_idx_slices\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     11\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(grads_or_idx_slices\u001b[39m.\u001b[39;49mdense_shape, tf\u001b[39m.\u001b[39;49mint64)\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m grads_or_idx_slices\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:9162\u001b[0m, in \u001b[0;36mscatter_nd\u001b[0;34m(indices, updates, shape, name)\u001b[0m\n\u001b[1;32m   9160\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   9161\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 9162\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   9163\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mScatterNd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, indices, updates, shape)\n\u001b[1;32m   9164\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   9165\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '1_Model_v0.4.ipynb'\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    seed = 12 \n",
    "    num_items = NUM_ITEMS\n",
    "    model_arch = 'bert4rec'\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.5/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.11/checkpoints/', 'ckpt-27')\n",
    "    model_name = f'model_{model_arch}_complete_0.12'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 10_000_000\n",
    "    batch_size = 32\n",
    "    tup_scheduler_grad_accum = (1, 5, 2_000_000) #(start_grad_accum, max_grad_accum, ramp_up_samples)\n",
    "    seq_len = 20\n",
    "    mask_prob = 0.3\n",
    "    reverse_prob = 0.5\n",
    "    emb_dim = 128\n",
    "    trf_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 2\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 3\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 250\n",
    "    clipnorm = 1.0\n",
    "    num_iters_save_checkpoint = 25_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    weight_decay = 1e-1\n",
    "    log_wandb = True\n",
    "\n",
    "set_seed(BERT4REC_CONFIG.seed)\n",
    "\n",
    "list_scheduler = np.linspace(BERT4REC_CONFIG.tup_scheduler_grad_accum[0], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[1], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[2]).astype(np.uint8).tolist()\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}', dict_config=dict_config)\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')] + \\\n",
    "                   [f'{BERT4REC_CONFIG.path_tfrecords}na_split=test_aug/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=test_aug')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "                            # weight_decay=BERT4REC_CONFIG.weight_decay)                  \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = weighted_loss_bert4rec(apply_weights=False)\n",
    "acc_function = custom_accuracy()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "train_acc_clicks = tf.keras.metrics.Mean(name='train_acc_clicks')\n",
    "train_acc_carts = tf.keras.metrics.Mean(name='train_acc_carts')\n",
    "train_acc_orders = tf.keras.metrics.Mean(name='train_acc_orders')\n",
    "val_acc_clicks = tf.keras.metrics.Mean(name='val_acc_clicks')\n",
    "val_acc_carts = tf.keras.metrics.Mean(name='val_acc_carts')\n",
    "val_acc_orders = tf.keras.metrics.Mean(name='val_acc_orders')\n",
    "\n",
    "##############################################\n",
    "\n",
    "global_gradients = []\n",
    "total_step, val_step, total_samples = 0, 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders, val_acc_clicks, val_acc_carts, val_acc_orders)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        grad_accum = grad_accum_scheduler(total_samples,\n",
    "                                          list_scheduler=list_scheduler, \n",
    "                                          max_grad_accum=BERT4REC_CONFIG.tup_scheduler_grad_accum[1])                                                             \n",
    "        step_gradients = train_step(inputs, target=target, model=model, optimizer=optimizer, num_accum_steps=tf.constant(grad_accum, tf.float32), \n",
    "                                    loss=train_loss, acc_clicks=train_acc_clicks, acc_carts=train_acc_carts, acc_orders=train_acc_orders, seq_type=inputs[1])\n",
    "        global_gradients, total_step = backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "            train_dict_metrics.update({'lr' : optimizer.lr(total_step).numpy().astype(np.float32), 'grad_accum' : grad_accum, 'total_samples' : total_samples})\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                train_dict_metrics.update({'step_grad' : total_step, 'step' : total_step})\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics)     \n",
    "        total_samples += BERT4REC_CONFIG.batch_size * grad_accum if (batch_num+1) % grad_accum==0 else 0\n",
    "        if batch_num % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')\n",
    "     \n",
    "#     for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "#         inputs, target = val_batch_data\n",
    "#         predictions = test_step(inputs, target=target, loss=val_loss, acc_clicks=val_acc_clicks, acc_carts=val_acc_carts, acc_orders=val_acc_orders, seq_type=inputs[1])\n",
    "#         val_step += 1\n",
    "#         if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "#             val_dict_metrics = {x.name : x.result() for x in [val_loss, val_acc_clicks, val_acc_carts, val_acc_orders]}\n",
    "#             fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "#             if BERT4REC_CONFIG.log_wandb:\n",
    "#                 log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "#                 # if val_batch_num==0:\n",
    "#                 #     log_wandb_metrics(step=None, plot_image=True, \n",
    "#                 #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "    \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', num_step=epoch, dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:47, 10.47it/s]\n",
      "100%|██████████| 48096/48096 [00:00<00:00, 217657.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>qt_trues</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.809600e+04</td>\n",
       "      <td>48096.000000</td>\n",
       "      <td>20109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.409855e+06</td>\n",
       "      <td>1.399451</td>\n",
       "      <td>0.270446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.715819e+06</td>\n",
       "      <td>2.914157</td>\n",
       "      <td>0.435673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.630000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.190015e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.383588e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.627672e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289967e+07</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session      qt_trues         score\n",
       "count  4.809600e+04  48096.000000  20109.000000\n",
       "mean   6.409855e+06      1.399451      0.270446\n",
       "std    3.715819e+06      2.914157      0.435673\n",
       "min    9.630000e+02      0.000000      0.000000\n",
       "25%    3.190015e+06      0.000000      0.000000\n",
       "50%    6.383588e+06      0.000000      0.000000\n",
       "75%    9.627672e+06      1.000000      1.000000\n",
       "max    1.289967e+07     20.000000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.29642190315145295,\n",
       " 'clicks': 0.25333675564681724,\n",
       " 'orders': 0.4051609141324677}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.3574\n"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0 \n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# ckpt = tf.train.Checkpoint(model=model)\n",
    "# ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.11/checkpoints'))\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.5/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_past_items, list_predictions, list_trues, list_types = [], [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target, idx_mask = targets\n",
    "    idxs = idx_mask.numpy() - 1 #tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x-1 for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target-1 for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "        list_past_items.append(seq_items.numpy()[:, :, 0])\n",
    "    if num_batch==500:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'past_items' : np.concatenate(list_past_items).tolist(),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "df_val['qt_trues'] = df_val['trues'].apply(lambda x : len(x))\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "\n",
    "# compare to\n",
    "# (seq_len=20)model_bert4rec_complete_0.10 - ckpt28\n",
    "# {'carts': 0.3811865255508249,\n",
    "#  'clicks': 0.32103439425051333,\n",
    "#  'orders': 0.5298270555929199}\n",
    "# Kaggle Metric: 0.4644\n",
    "\n",
    "# import wandb\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"<path to run>\")\n",
    "# run.summary[\"kaggle_metric\"] = kaggle_metric\n",
    "# run.update()\n",
    "\n",
    "# {'carts': 0.3667671564987321,\n",
    "#  'clicks': 0.315515159219475,\n",
    "#  'orders': 0.512318307921184}\n",
    "# Kaggle Metric: 0.4490"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 19:15:23.433225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "0it [00:00, ?it/s]2022-11-20 19:15:24.337587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "26122it [55:08,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.7/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.5/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.5/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, idxs, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    idxs = idxs.numpy() - 1\n",
    "    # idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 26122it [54:28,  7.99it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")\n",
    "\n",
    "import gzip\n",
    "with open(f'../3_Submissions/{name_submission}.csv', 'rb') as f_in, gzip.open(f'../3_Submissions/{name_submission}.csv.gz', 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0432fa0070c5c9f7d9e158f590013ccc765eb84f02e6f69521746370c3bf6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
