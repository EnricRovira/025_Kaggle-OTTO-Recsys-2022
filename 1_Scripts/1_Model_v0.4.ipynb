{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.3_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 3307669.59it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "SEED = 12\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.3/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False, drop_remainder=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "        self.drop_remainder = drop_remainder\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*50, reshuffle_each_iteration=True)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=self.drop_remainder).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_time_encoding, seq_time_encoding_target = seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding), (seq_items_target_all[:, 0], seq_type_target_all[:, 0]), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "\n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items)), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), tf.zeros(tf.shape(seq_items))\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding), seq_target[:, 0]\n",
    "  \n",
    "  \n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 10, 1]), TensorShape([32, 10, 1]), TensorShape([32, 10, 8])]\n",
      "[      0 1078084       0  591718       0  863885       0       0       0\n",
      "       0]\n",
      "[1 1 1 1 1 1 0 0 0 0]\n",
      "[ 432286       0  987942       0 1166894       0       0       0       0\n",
      "       0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.3/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=train')]\n",
    "\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=10, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.4, \n",
    "                                     reverse_prob=0.2, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# # Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    break\n",
    "\n",
    "# # # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     target, type_target = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 15\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            # embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(3+1, model_cfg.emb_dim)\n",
    "        self.mlp_proj_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-7)\n",
    "        ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_encoding(x_seq_encoding, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_time_encoding + x_seq_past_type)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        ones = tf.ones(tf.shape(y_true))\n",
    "        y_pred = y_pred\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "def recall_top_k(top_k=1):\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_true)[0]\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.float32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.float32)\n",
    "        cum_sum = tf.zeros(n_samples)\n",
    "        for i in tf.range(top_k):\n",
    "            indexes_i = top_index[:, :, i]\n",
    "            is_true = tf.reduce_sum(tf.cast(tf.equal(y_true, indexes_i), tf.float32), axis=-1)/tf.reduce_sum(mask, -1)\n",
    "            cum_sum += (is_true/tf.cast(i+1, tf.float32))\n",
    "        return tf.reduce_mean(cum_sum)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "plt.plot(tmp_lr(tf.range(12_000_000 // (32 * 4), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g)\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        global_gradients = zip(global_gradients, model.trainable_variables)\n",
    "        optimizer.apply_gradients(global_gradients)\n",
    "        global_gradients = []\n",
    "    return global_gradients\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    num_accum_steps = tf.cast(kwargs['num_accum_steps'], tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss / num_accum_steps)\n",
    "\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    # gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions)\n",
    "    l_loss(loss)\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.4f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n",
      "Latest checkpoint restored!!\n",
      "================================================================================\n",
      "Epoch 1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Out of memory while trying to allocate 1695808256 bytes. [Op:__inference_train_step_3164]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 103\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m batch_num, batch_data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m    102\u001b[0m     inputs, target \u001b[39m=\u001b[39m batch_data\n\u001b[1;32m--> 103\u001b[0m     step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39;49mtarget, loss\u001b[39m=\u001b[39;49mtrain_loss, num_accum_steps\u001b[39m=\u001b[39;49mBERT4REC_CONFIG\u001b[39m.\u001b[39;49mnum_grad_accum_steps)\n\u001b[0;32m    104\u001b[0m     global_gradients \u001b[39m=\u001b[39m backward_optimization(BERT4REC_CONFIG\u001b[39m.\u001b[39mnum_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n\u001b[0;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Out of memory while trying to allocate 1695808256 bytes. [Op:__inference_train_step_3164]"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.3/'\n",
    "    restore_last_chekpoint = (True, 'model_bert4rec_complete_0.4.1/checkpoints/', 'ckpt-9')\n",
    "    model_name = 'model_bert4rec_complete_0.4.1'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 12_000_000\n",
    "    batch_size = 24\n",
    "    num_grad_accum_steps = 6\n",
    "    seq_len = 10\n",
    "    mask_prob = 0.35\n",
    "    reverse_prob = 0.25\n",
    "    emb_dim = 32\n",
    "    trf_dim = 32\n",
    "    num_heads = 2\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 5\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 200\n",
    "    batch_num_printer_val = 100\n",
    "    clipnorm = 1\n",
    "    num_iters_save_checkpoint = 10_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    log_wandb = False\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.restore_last_chekpoint[1]}/', compile=False)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "                            warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = custom_loss_bert4rec()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "##############################################\n",
    "\n",
    "total_step, val_step = 0, 0\n",
    "global_gradients = []\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        step_gradients = train_step(inputs, target=target, loss=train_loss, num_accum_steps=BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "        global_gradients = backward_optimization(BERT4REC_CONFIG.num_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss]}\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics) \n",
    "        \n",
    "        total_step += 1  \n",
    "\n",
    "        if total_step % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')        \n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            \n",
    "    for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "        inputs, target = val_batch_data\n",
    "        test_step(inputs, target=target, loss=val_loss)\n",
    "        val_step += 1\n",
    "        if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "            val_dict_metrics = {x.name : x.result() for x in [val_loss]}\n",
    "            fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics)    \n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "                # if val_batch_num==0:\n",
    "                #     log_wandb_metrics(step=None, plot_image=True, \n",
    "                #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [02:34,  6.48it/s]\n",
      "100%|██████████| 96096/96096 [00:01<00:00, 72908.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.609600e+04</td>\n",
       "      <td>40454.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.358616e+06</td>\n",
       "      <td>0.117692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.721860e+06</td>\n",
       "      <td>0.316083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.200000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.118926e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.336554e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.541742e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289966e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session         score\n",
       "count  9.609600e+04  40454.000000\n",
       "mean   6.358616e+06      0.117692\n",
       "std    3.721860e+06      0.316083\n",
       "min    2.200000e+02      0.000000\n",
       "25%    3.118926e+06      0.000000\n",
       "50%    6.336554e+06      0.000000\n",
       "75%    9.541742e+06      0.000000\n",
       "max    1.289966e+07      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.14735728765090225,\n",
       " 'clicks': 0.10318137094129223,\n",
       " 'orders': 0.19717041401234073}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.1728\n"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0\n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.4_finetuned/', compile=False)\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.3/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=10, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_predictions, list_trues, list_types = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    target, type_target = targets\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "    if num_batch==1_000:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# v0.4 seqlen=10\n",
    "# {'carts': 0.222143,\n",
    "#  'clicks': 0.163726,\n",
    "#  'orders': 0.301489}\n",
    "# Kaggle Metric: 0.2639089\n",
    "\n",
    "# v0.4_finetuned seqlen=10\n",
    "# {'carts': 0.23272587826464677,\n",
    "#  'clicks': 0.16818629058707774,\n",
    "#  'orders': 0.31957377011651095}\n",
    "# Kaggle Metric: 0.2783808"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.keras.backend.clear_session()\n",
    "model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.4/', compile=False)\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.3/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=10,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, target, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 52244it [2:47:45,  5.19it/s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c4b929e2472036a63dc2b4145b104daea13432f82a7dbc65e279332da4f8b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
