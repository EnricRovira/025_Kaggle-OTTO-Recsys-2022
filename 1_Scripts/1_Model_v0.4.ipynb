{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 3306507.47it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "SEED = 12\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.4/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False, drop_remainder=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "        self.drop_remainder = drop_remainder\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        \n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        # dataset = dataset.map(self.normalize_features, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*50, reshuffle_each_iteration=True)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=self.drop_remainder).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        seq_recency = tf.concat([seq_recency, tf.zeros((1, tf.shape(seq_recency)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding, seq_recency), (seq_items_target_all[:, 0], seq_type_target_all[:, 0]), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        seq_recency = seq_recency[-self.seq_len:, :]\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        seq_recency = tf.concat([seq_recency, tf.zeros((1, tf.shape(seq_recency)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding, seq_recency), tf.zeros(tf.shape(seq_items)), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), tf.zeros(tf.shape(seq_items))\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            seq_recency = tf.reverse(seq_recency, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_recency = seq_recency[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_recency = tf.zeros((len(idxs_inputs), seq_recency.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_recency = tf.tensor_scatter_nd_update(seq_recency, idxs_inputs, updates_recency)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32) \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), seq_target[:, 0]\n",
    "  \n",
    "    def normalize_features(self, features):\n",
    "        return (features - tf.constant(5.45)/tf.constant(1.09))\n",
    "\n",
    "    # def normalize_features(self, features, targets=None, session=None):\n",
    "    #     seq_items, seq_type, seq_time_encoding, seq_recency = features\n",
    "    #     seq_recency = (seq_recency - tf.constant(5.45)/tf.constant(1.09))\n",
    "    #     features = (seq_items, seq_type, seq_time_encoding, seq_recency)\n",
    "    #     return features, targets, session\n",
    "\n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        features[3].set_shape((self.seq_len, 1))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 20, 1]), TensorShape([32, 20, 1]), TensorShape([32, 20, 8]), TensorShape([32, 20, 1])]\n",
      "[1212417       0       0  526989  505110       0       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0]\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[      0  400243 1159498       0       0  171550       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.4/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=train')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.4, \n",
    "                                     reverse_prob=0.25, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# # Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    break\n",
    "\n",
    "# # # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time = features\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     target, type_target = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 2\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(\n",
    "            3+1, \n",
    "            model_cfg.emb_dim,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)\n",
    "        )\n",
    "        self.mlp_proj_time_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        ])\n",
    "        self.mlp_proj_conts = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.02)),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding, x_seq_recency = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_time_encoding(x_seq_encoding, training=training)\n",
    "        x_seq_recency = self.mlp_proj_conts(x_seq_recency, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_past_type + x_seq_time_encoding + x_seq_recency)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        ones = tf.ones(tf.shape(y_true))\n",
    "        y_pred = y_pred\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "def recall_top_k(top_k=1):\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_true)[0]\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.float32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.float32)\n",
    "        cum_sum = tf.zeros(n_samples)\n",
    "        for i in tf.range(top_k):\n",
    "            indexes_i = top_index[:, :, i]\n",
    "            is_true = tf.reduce_sum(tf.cast(tf.equal(y_true, indexes_i), tf.float32), axis=-1)/tf.reduce_sum(mask, -1)\n",
    "            cum_sum += (is_true/tf.cast(i+1, tf.float32))\n",
    "        return tf.reduce_mean(cum_sum)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "# plt.plot(tmp_lr(tf.range(12_000_000 // (32 * 4), dtype=tf.float32)))\n",
    "plt.plot(tmp_lr(tf.range(12_000_000 // (8 * 20), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g)\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        global_gradients = zip(global_gradients, model.trainable_variables)\n",
    "        optimizer.apply_gradients(global_gradients)\n",
    "        global_gradients = []\n",
    "    return global_gradients\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    num_accum_steps = tf.cast(kwargs['num_accum_steps'], tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss / num_accum_steps)\n",
    "\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    # gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss = kwargs['loss']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions)\n",
    "    l_loss(loss)\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.6f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name='', dict_config=None):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"),\n",
    "               config=dict_config)\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menric1296\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\KAGGLE\\025_Kaggle-OTTO Recsys-2022\\1_Scripts\\wandb\\run-20221114_205735-xuhptm5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/xuhptm5r\" target=\"_blank\">model_bert4rec_complete_0.6_2022-11-14 20:57:33</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n",
      "================================================================================\n",
      "Epoch 1\n",
      "[Train Epoch]1/5 [Time]24.01 [Step]0 [Batch]0 [Speed]24014.41ms/step [Loss]14.1000 [Metrics]{'train_loss:14.099976 lr:0.000000'}\n",
      "[Train Epoch]1/5 [Time]46.48 [Step]31 [Batch]500 [Speed]92.95ms/step [Loss]14.0914 [Metrics]{'train_loss:14.091438 lr:0.000003'}\n",
      "[Train Epoch]1/5 [Time]68.03 [Step]62 [Batch]1000 [Speed]68.03ms/step [Loss]14.0911 [Metrics]{'train_loss:14.091129 lr:0.000005'}\n",
      "[Train Epoch]1/5 [Time]89.65 [Step]93 [Batch]1500 [Speed]59.77ms/step [Loss]14.0903 [Metrics]{'train_loss:14.090343 lr:0.000008'}\n",
      "[Train Epoch]1/5 [Time]111.29 [Step]125 [Batch]2000 [Speed]55.65ms/step [Loss]14.0895 [Metrics]{'train_loss:14.089512 lr:0.000011'}\n",
      "[Train Epoch]1/5 [Time]132.91 [Step]156 [Batch]2500 [Speed]53.16ms/step [Loss]14.0881 [Metrics]{'train_loss:14.088091 lr:0.000014'}\n",
      "[Train Epoch]1/5 [Time]154.46 [Step]187 [Batch]3000 [Speed]51.49ms/step [Loss]14.0865 [Metrics]{'train_loss:14.086502 lr:0.000017'}\n",
      "[Train Epoch]1/5 [Time]176.12 [Step]218 [Batch]3500 [Speed]50.32ms/step [Loss]14.0842 [Metrics]{'train_loss:14.084248 lr:0.000019'}\n",
      "[Train Epoch]1/5 [Time]199.09 [Step]250 [Batch]4000 [Speed]49.77ms/step [Loss]14.0815 [Metrics]{'train_loss:14.081545 lr:0.000022'}\n",
      "[Train Epoch]1/5 [Time]221.87 [Step]281 [Batch]4500 [Speed]49.30ms/step [Loss]14.0783 [Metrics]{'train_loss:14.078265 lr:0.000025'}\n",
      "[Train Epoch]1/5 [Time]244.65 [Step]312 [Batch]5000 [Speed]48.93ms/step [Loss]14.0743 [Metrics]{'train_loss:14.074265 lr:0.000028'}\n",
      "[Train Epoch]1/5 [Time]267.56 [Step]343 [Batch]5500 [Speed]48.65ms/step [Loss]14.0698 [Metrics]{'train_loss:14.069807 lr:0.000030'}\n",
      "[Train Epoch]1/5 [Time]290.35 [Step]375 [Batch]6000 [Speed]48.39ms/step [Loss]14.0647 [Metrics]{'train_loss:14.064742 lr:0.000033'}\n",
      "[Train Epoch]1/5 [Time]313.21 [Step]406 [Batch]6500 [Speed]48.19ms/step [Loss]14.0590 [Metrics]{'train_loss:14.059049 lr:0.000036'}\n",
      "[Train Epoch]1/5 [Time]336.01 [Step]437 [Batch]7000 [Speed]48.00ms/step [Loss]14.0527 [Metrics]{'train_loss:14.052713 lr:0.000039'}\n",
      "[Train Epoch]1/5 [Time]358.80 [Step]468 [Batch]7500 [Speed]47.84ms/step [Loss]14.0458 [Metrics]{'train_loss:14.045836 lr:0.000041'}\n",
      "[Train Epoch]1/5 [Time]381.29 [Step]500 [Batch]8000 [Speed]47.66ms/step [Loss]14.0381 [Metrics]{'train_loss:14.038129 lr:0.000044'}\n",
      "[Train Epoch]1/5 [Time]402.86 [Step]531 [Batch]8500 [Speed]47.40ms/step [Loss]14.0304 [Metrics]{'train_loss:14.030362 lr:0.000047'}\n",
      "[Train Epoch]1/5 [Time]424.44 [Step]562 [Batch]9000 [Speed]47.16ms/step [Loss]14.0220 [Metrics]{'train_loss:14.021997 lr:0.000050'}\n",
      "[Train Epoch]1/5 [Time]446.10 [Step]593 [Batch]9500 [Speed]46.96ms/step [Loss]14.0130 [Metrics]{'train_loss:14.013002 lr:0.000052'}\n",
      "[Train Epoch]1/5 [Time]467.64 [Step]625 [Batch]10000 [Speed]46.76ms/step [Loss]14.0041 [Metrics]{'train_loss:14.004081 lr:0.000055'}\n",
      "[Train Epoch]1/5 [Time]489.25 [Step]656 [Batch]10500 [Speed]46.60ms/step [Loss]13.9947 [Metrics]{'train_loss:13.994733 lr:0.000058'}\n",
      "[Train Epoch]1/5 [Time]510.86 [Step]687 [Batch]11000 [Speed]46.44ms/step [Loss]13.9849 [Metrics]{'train_loss:13.984875 lr:0.000061'}\n",
      "[Train Epoch]1/5 [Time]532.54 [Step]718 [Batch]11500 [Speed]46.31ms/step [Loss]13.9743 [Metrics]{'train_loss:13.974338 lr:0.000063'}\n",
      "[Train Epoch]1/5 [Time]554.16 [Step]750 [Batch]12000 [Speed]46.18ms/step [Loss]13.9632 [Metrics]{'train_loss:13.963182 lr:0.000066'}\n",
      "[Train Epoch]1/5 [Time]575.82 [Step]781 [Batch]12500 [Speed]46.07ms/step [Loss]13.9519 [Metrics]{'train_loss:13.951910 lr:0.000069'}\n",
      "[Train Epoch]1/5 [Time]597.45 [Step]812 [Batch]13000 [Speed]45.96ms/step [Loss]13.9399 [Metrics]{'train_loss:13.939896 lr:0.000072'}\n",
      "[Train Epoch]1/5 [Time]619.09 [Step]843 [Batch]13500 [Speed]45.86ms/step [Loss]13.9275 [Metrics]{'train_loss:13.927468 lr:0.000075'}\n",
      "[Train Epoch]1/5 [Time]640.82 [Step]875 [Batch]14000 [Speed]45.77ms/step [Loss]13.9142 [Metrics]{'train_loss:13.914209 lr:0.000077'}\n",
      "[Train Epoch]1/5 [Time]662.44 [Step]906 [Batch]14500 [Speed]45.69ms/step [Loss]13.9009 [Metrics]{'train_loss:13.900949 lr:0.000080'}\n",
      "[Train Epoch]1/5 [Time]684.12 [Step]937 [Batch]15000 [Speed]45.61ms/step [Loss]13.8862 [Metrics]{'train_loss:13.886153 lr:0.000083'}\n",
      "[Train Epoch]1/5 [Time]705.74 [Step]968 [Batch]15500 [Speed]45.53ms/step [Loss]13.8713 [Metrics]{'train_loss:13.871254 lr:0.000086'}\n",
      "[Train Epoch]1/5 [Time]727.45 [Step]1000 [Batch]16000 [Speed]45.47ms/step [Loss]13.8566 [Metrics]{'train_loss:13.856552 lr:0.000088'}\n",
      "[Train Epoch]1/5 [Time]749.09 [Step]1031 [Batch]16500 [Speed]45.40ms/step [Loss]13.8408 [Metrics]{'train_loss:13.840833 lr:0.000091'}\n",
      "[Train Epoch]1/5 [Time]770.70 [Step]1062 [Batch]17000 [Speed]45.34ms/step [Loss]13.8265 [Metrics]{'train_loss:13.826545 lr:0.000094'}\n",
      "[Train Epoch]1/5 [Time]792.38 [Step]1093 [Batch]17500 [Speed]45.28ms/step [Loss]13.8122 [Metrics]{'train_loss:13.812241 lr:0.000097'}\n",
      "[Train Epoch]1/5 [Time]814.06 [Step]1125 [Batch]18000 [Speed]45.23ms/step [Loss]13.7977 [Metrics]{'train_loss:13.797679 lr:0.000099'}\n",
      "[Train Epoch]1/5 [Time]835.66 [Step]1156 [Batch]18500 [Speed]45.17ms/step [Loss]13.7835 [Metrics]{'train_loss:13.783523 lr:0.000102'}\n",
      "[Train Epoch]1/5 [Time]857.26 [Step]1187 [Batch]19000 [Speed]45.12ms/step [Loss]13.7694 [Metrics]{'train_loss:13.769432 lr:0.000105'}\n",
      "[Train Epoch]1/5 [Time]879.14 [Step]1218 [Batch]19500 [Speed]45.08ms/step [Loss]13.7550 [Metrics]{'train_loss:13.755020 lr:0.000108'}\n",
      "[Train Epoch]1/5 [Time]900.80 [Step]1250 [Batch]20000 [Speed]45.04ms/step [Loss]13.7408 [Metrics]{'train_loss:13.740755 lr:0.000110'}\n",
      "[Train Epoch]1/5 [Time]922.47 [Step]1281 [Batch]20500 [Speed]45.00ms/step [Loss]13.7258 [Metrics]{'train_loss:13.725815 lr:0.000113'}\n",
      "[Train Epoch]1/5 [Time]944.11 [Step]1312 [Batch]21000 [Speed]44.96ms/step [Loss]13.7111 [Metrics]{'train_loss:13.711082 lr:0.000116'}\n",
      "[Train Epoch]1/5 [Time]965.99 [Step]1343 [Batch]21500 [Speed]44.93ms/step [Loss]13.6968 [Metrics]{'train_loss:13.696756 lr:0.000119'}\n",
      "[Train Epoch]1/5 [Time]987.83 [Step]1375 [Batch]22000 [Speed]44.90ms/step [Loss]13.6819 [Metrics]{'train_loss:13.681877 lr:0.000122'}\n",
      "[Train Epoch]1/5 [Time]1009.83 [Step]1406 [Batch]22500 [Speed]44.88ms/step [Loss]13.6682 [Metrics]{'train_loss:13.668245 lr:0.000124'}\n",
      "[Train Epoch]1/5 [Time]1031.82 [Step]1437 [Batch]23000 [Speed]44.86ms/step [Loss]13.6545 [Metrics]{'train_loss:13.654537 lr:0.000127'}\n",
      "[Train Epoch]1/5 [Time]1053.87 [Step]1468 [Batch]23500 [Speed]44.85ms/step [Loss]13.6410 [Metrics]{'train_loss:13.640968 lr:0.000130'}\n",
      "[Train Epoch]1/5 [Time]1075.55 [Step]1500 [Batch]24000 [Speed]44.81ms/step [Loss]13.6282 [Metrics]{'train_loss:13.628218 lr:0.000133'}\n",
      "[Train Epoch]1/5 [Time]1097.24 [Step]1531 [Batch]24500 [Speed]44.79ms/step [Loss]13.6151 [Metrics]{'train_loss:13.615091 lr:0.000135'}\n",
      "[Train Epoch]1/5 [Time]1118.97 [Step]1562 [Batch]25000 [Speed]44.76ms/step [Loss]13.6018 [Metrics]{'train_loss:13.601834 lr:0.000138'}\n",
      "[Train Epoch]1/5 [Time]1140.63 [Step]1593 [Batch]25500 [Speed]44.73ms/step [Loss]13.5888 [Metrics]{'train_loss:13.588801 lr:0.000141'}\n",
      "[Train Epoch]1/5 [Time]1162.31 [Step]1625 [Batch]26000 [Speed]44.70ms/step [Loss]13.5761 [Metrics]{'train_loss:13.576138 lr:0.000144'}\n",
      "[Train Epoch]1/5 [Time]1183.98 [Step]1656 [Batch]26500 [Speed]44.68ms/step [Loss]13.5632 [Metrics]{'train_loss:13.563204 lr:0.000146'}\n",
      "[Train Epoch]1/5 [Time]1205.72 [Step]1687 [Batch]27000 [Speed]44.66ms/step [Loss]13.5509 [Metrics]{'train_loss:13.550875 lr:0.000149'}\n",
      "[Train Epoch]1/5 [Time]1227.38 [Step]1718 [Batch]27500 [Speed]44.63ms/step [Loss]13.5378 [Metrics]{'train_loss:13.537787 lr:0.000152'}\n",
      "[Train Epoch]1/5 [Time]1249.06 [Step]1750 [Batch]28000 [Speed]44.61ms/step [Loss]13.5250 [Metrics]{'train_loss:13.524965 lr:0.000155'}\n",
      "[Train Epoch]1/5 [Time]1270.73 [Step]1781 [Batch]28500 [Speed]44.59ms/step [Loss]13.5133 [Metrics]{'train_loss:13.513344 lr:0.000157'}\n",
      "[Train Epoch]1/5 [Time]1292.45 [Step]1812 [Batch]29000 [Speed]44.57ms/step [Loss]13.5011 [Metrics]{'train_loss:13.501086 lr:0.000160'}\n",
      "[Train Epoch]1/5 [Time]1314.35 [Step]1843 [Batch]29500 [Speed]44.55ms/step [Loss]13.4894 [Metrics]{'train_loss:13.489434 lr:0.000163'}\n",
      "[Train Epoch]1/5 [Time]1336.97 [Step]1875 [Batch]30000 [Speed]44.57ms/step [Loss]13.4782 [Metrics]{'train_loss:13.478189 lr:0.000166'}\n",
      "[Train Epoch]1/5 [Time]1358.66 [Step]1906 [Batch]30500 [Speed]44.55ms/step [Loss]13.4658 [Metrics]{'train_loss:13.465832 lr:0.000168'}\n",
      "[Train Epoch]1/5 [Time]1380.28 [Step]1937 [Batch]31000 [Speed]44.53ms/step [Loss]13.4543 [Metrics]{'train_loss:13.454289 lr:0.000171'}\n",
      "[Train Epoch]1/5 [Time]1401.83 [Step]1968 [Batch]31500 [Speed]44.50ms/step [Loss]13.4430 [Metrics]{'train_loss:13.442963 lr:0.000174'}\n",
      "[Train Epoch]1/5 [Time]1423.48 [Step]2000 [Batch]32000 [Speed]44.48ms/step [Loss]13.4317 [Metrics]{'train_loss:13.431697 lr:0.000177'}\n",
      "[Train Epoch]1/5 [Time]1445.18 [Step]2031 [Batch]32500 [Speed]44.47ms/step [Loss]13.4200 [Metrics]{'train_loss:13.419964 lr:0.000180'}\n",
      "[Train Epoch]1/5 [Time]1466.78 [Step]2062 [Batch]33000 [Speed]44.45ms/step [Loss]13.4092 [Metrics]{'train_loss:13.409238 lr:0.000182'}\n",
      "[Train Epoch]1/5 [Time]1488.39 [Step]2093 [Batch]33500 [Speed]44.43ms/step [Loss]13.3991 [Metrics]{'train_loss:13.399066 lr:0.000185'}\n",
      "[Train Epoch]1/5 [Time]1510.11 [Step]2125 [Batch]34000 [Speed]44.41ms/step [Loss]13.3887 [Metrics]{'train_loss:13.388704 lr:0.000188'}\n",
      "[Train Epoch]1/5 [Time]1531.73 [Step]2156 [Batch]34500 [Speed]44.40ms/step [Loss]13.3785 [Metrics]{'train_loss:13.378471 lr:0.000191'}\n",
      "[Train Epoch]1/5 [Time]1553.34 [Step]2187 [Batch]35000 [Speed]44.38ms/step [Loss]13.3686 [Metrics]{'train_loss:13.368649 lr:0.000193'}\n",
      "[Train Epoch]1/5 [Time]1574.95 [Step]2218 [Batch]35500 [Speed]44.36ms/step [Loss]13.3588 [Metrics]{'train_loss:13.358798 lr:0.000196'}\n",
      "[Train Epoch]1/5 [Time]1596.64 [Step]2250 [Batch]36000 [Speed]44.35ms/step [Loss]13.3489 [Metrics]{'train_loss:13.348880 lr:0.000199'}\n",
      "[Train Epoch]1/5 [Time]1618.32 [Step]2281 [Batch]36500 [Speed]44.34ms/step [Loss]13.3389 [Metrics]{'train_loss:13.338859 lr:0.000202'}\n",
      "[Train Epoch]1/5 [Time]1639.87 [Step]2312 [Batch]37000 [Speed]44.32ms/step [Loss]13.3294 [Metrics]{'train_loss:13.329406 lr:0.000204'}\n",
      "[Train Epoch]1/5 [Time]1661.46 [Step]2343 [Batch]37500 [Speed]44.31ms/step [Loss]13.3207 [Metrics]{'train_loss:13.320737 lr:0.000207'}\n",
      "[Train Epoch]1/5 [Time]1683.10 [Step]2375 [Batch]38000 [Speed]44.29ms/step [Loss]13.3114 [Metrics]{'train_loss:13.311399 lr:0.000210'}\n",
      "[Train Epoch]1/5 [Time]1704.65 [Step]2406 [Batch]38500 [Speed]44.28ms/step [Loss]13.3019 [Metrics]{'train_loss:13.301908 lr:0.000213'}\n",
      "[Train Epoch]1/5 [Time]1726.25 [Step]2437 [Batch]39000 [Speed]44.26ms/step [Loss]13.2931 [Metrics]{'train_loss:13.293126 lr:0.000215'}\n",
      "[Train Epoch]1/5 [Time]1747.95 [Step]2468 [Batch]39500 [Speed]44.25ms/step [Loss]13.2845 [Metrics]{'train_loss:13.284521 lr:0.000218'}\n",
      "[Train Epoch]1/5 [Time]1769.58 [Step]2500 [Batch]40000 [Speed]44.24ms/step [Loss]13.2758 [Metrics]{'train_loss:13.275842 lr:0.000221'}\n",
      "[Train Epoch]1/5 [Time]1791.31 [Step]2531 [Batch]40500 [Speed]44.23ms/step [Loss]13.2674 [Metrics]{'train_loss:13.267370 lr:0.000224'}\n",
      "[Train Epoch]1/5 [Time]1814.78 [Step]2562 [Batch]41000 [Speed]44.26ms/step [Loss]13.2589 [Metrics]{'train_loss:13.258939 lr:0.000226'}\n",
      "[Train Epoch]1/5 [Time]1837.85 [Step]2593 [Batch]41500 [Speed]44.29ms/step [Loss]13.2505 [Metrics]{'train_loss:13.250533 lr:0.000229'}\n",
      "[Train Epoch]1/5 [Time]1859.98 [Step]2625 [Batch]42000 [Speed]44.29ms/step [Loss]13.2426 [Metrics]{'train_loss:13.242552 lr:0.000232'}\n",
      "[Train Epoch]1/5 [Time]1881.76 [Step]2656 [Batch]42500 [Speed]44.28ms/step [Loss]13.2345 [Metrics]{'train_loss:13.234456 lr:0.000235'}\n",
      "[Train Epoch]1/5 [Time]1904.36 [Step]2687 [Batch]43000 [Speed]44.29ms/step [Loss]13.2256 [Metrics]{'train_loss:13.225637 lr:0.000237'}\n",
      "[Train Epoch]1/5 [Time]1926.25 [Step]2718 [Batch]43500 [Speed]44.28ms/step [Loss]13.2175 [Metrics]{'train_loss:13.217470 lr:0.000240'}\n",
      "[Train Epoch]1/5 [Time]1948.22 [Step]2750 [Batch]44000 [Speed]44.28ms/step [Loss]13.2091 [Metrics]{'train_loss:13.209127 lr:0.000243'}\n",
      "[Train Epoch]1/5 [Time]1970.06 [Step]2781 [Batch]44500 [Speed]44.27ms/step [Loss]13.2002 [Metrics]{'train_loss:13.200234 lr:0.000246'}\n",
      "[Train Epoch]1/5 [Time]1992.49 [Step]2812 [Batch]45000 [Speed]44.28ms/step [Loss]13.1922 [Metrics]{'train_loss:13.192242 lr:0.000249'}\n",
      "[Train Epoch]1/5 [Time]2014.52 [Step]2843 [Batch]45500 [Speed]44.28ms/step [Loss]13.1840 [Metrics]{'train_loss:13.184025 lr:0.000251'}\n",
      "[Train Epoch]1/5 [Time]2036.54 [Step]2875 [Batch]46000 [Speed]44.27ms/step [Loss]13.1759 [Metrics]{'train_loss:13.175886 lr:0.000254'}\n",
      "[Train Epoch]1/5 [Time]2058.38 [Step]2906 [Batch]46500 [Speed]44.27ms/step [Loss]13.1688 [Metrics]{'train_loss:13.168850 lr:0.000257'}\n",
      "[Train Epoch]1/5 [Time]2080.19 [Step]2937 [Batch]47000 [Speed]44.26ms/step [Loss]13.1617 [Metrics]{'train_loss:13.161735 lr:0.000260'}\n",
      "[Train Epoch]1/5 [Time]2102.01 [Step]2968 [Batch]47500 [Speed]44.25ms/step [Loss]13.1545 [Metrics]{'train_loss:13.154467 lr:0.000262'}\n",
      "[Train Epoch]1/5 [Time]2123.79 [Step]3000 [Batch]48000 [Speed]44.25ms/step [Loss]13.1475 [Metrics]{'train_loss:13.147504 lr:0.000265'}\n",
      "[Train Epoch]1/5 [Time]2145.73 [Step]3031 [Batch]48500 [Speed]44.24ms/step [Loss]13.1404 [Metrics]{'train_loss:13.140431 lr:0.000268'}\n",
      "[Train Epoch]1/5 [Time]2167.68 [Step]3062 [Batch]49000 [Speed]44.24ms/step [Loss]13.1338 [Metrics]{'train_loss:13.133841 lr:0.000271'}\n",
      "[Train Epoch]1/5 [Time]2190.02 [Step]3093 [Batch]49500 [Speed]44.24ms/step [Loss]13.1269 [Metrics]{'train_loss:13.126934 lr:0.000273'}\n",
      "[Train Epoch]1/5 [Time]2212.02 [Step]3125 [Batch]50000 [Speed]44.24ms/step [Loss]13.1205 [Metrics]{'train_loss:13.120454 lr:0.000276'}\n",
      "[Train Epoch]1/5 [Time]2234.18 [Step]3156 [Batch]50500 [Speed]44.24ms/step [Loss]13.1141 [Metrics]{'train_loss:13.114068 lr:0.000279'}\n",
      "[Train Epoch]1/5 [Time]2256.09 [Step]3187 [Batch]51000 [Speed]44.24ms/step [Loss]13.1076 [Metrics]{'train_loss:13.107618 lr:0.000282'}\n",
      "[Train Epoch]1/5 [Time]2278.29 [Step]3218 [Batch]51500 [Speed]44.24ms/step [Loss]13.1012 [Metrics]{'train_loss:13.101219 lr:0.000284'}\n",
      "[Train Epoch]1/5 [Time]2300.74 [Step]3250 [Batch]52000 [Speed]44.25ms/step [Loss]13.0943 [Metrics]{'train_loss:13.094302 lr:0.000287'}\n",
      "[Train Epoch]1/5 [Time]2323.73 [Step]3281 [Batch]52500 [Speed]44.26ms/step [Loss]13.0878 [Metrics]{'train_loss:13.087836 lr:0.000290'}\n",
      "[Train Epoch]1/5 [Time]2346.78 [Step]3312 [Batch]53000 [Speed]44.28ms/step [Loss]13.0815 [Metrics]{'train_loss:13.081473 lr:0.000293'}\n",
      "[Train Epoch]1/5 [Time]2369.80 [Step]3343 [Batch]53500 [Speed]44.30ms/step [Loss]13.0755 [Metrics]{'train_loss:13.075483 lr:0.000295'}\n",
      "[Train Epoch]1/5 [Time]2392.37 [Step]3375 [Batch]54000 [Speed]44.30ms/step [Loss]13.0696 [Metrics]{'train_loss:13.069582 lr:0.000298'}\n",
      "[Train Epoch]1/5 [Time]2414.19 [Step]3406 [Batch]54500 [Speed]44.30ms/step [Loss]13.0628 [Metrics]{'train_loss:13.062810 lr:0.000301'}\n",
      "[Train Epoch]1/5 [Time]2435.97 [Step]3437 [Batch]55000 [Speed]44.29ms/step [Loss]13.0565 [Metrics]{'train_loss:13.056494 lr:0.000304'}\n",
      "[Train Epoch]1/5 [Time]2458.07 [Step]3468 [Batch]55500 [Speed]44.29ms/step [Loss]13.0507 [Metrics]{'train_loss:13.050678 lr:0.000307'}\n",
      "[Train Epoch]1/5 [Time]2480.50 [Step]3500 [Batch]56000 [Speed]44.29ms/step [Loss]13.0445 [Metrics]{'train_loss:13.044545 lr:0.000309'}\n",
      "[Train Epoch]1/5 [Time]2502.53 [Step]3531 [Batch]56500 [Speed]44.29ms/step [Loss]13.0386 [Metrics]{'train_loss:13.038595 lr:0.000312'}\n",
      "[Train Epoch]1/5 [Time]2524.49 [Step]3562 [Batch]57000 [Speed]44.29ms/step [Loss]13.0334 [Metrics]{'train_loss:13.033399 lr:0.000315'}\n",
      "[Train Epoch]1/5 [Time]2546.80 [Step]3593 [Batch]57500 [Speed]44.29ms/step [Loss]13.0281 [Metrics]{'train_loss:13.028079 lr:0.000318'}\n",
      "[Train Epoch]1/5 [Time]2569.47 [Step]3625 [Batch]58000 [Speed]44.30ms/step [Loss]13.0228 [Metrics]{'train_loss:13.022771 lr:0.000320'}\n",
      "[Train Epoch]1/5 [Time]2592.73 [Step]3656 [Batch]58500 [Speed]44.32ms/step [Loss]13.0178 [Metrics]{'train_loss:13.017796 lr:0.000323'}\n",
      "[Train Epoch]1/5 [Time]2614.78 [Step]3687 [Batch]59000 [Speed]44.32ms/step [Loss]13.0129 [Metrics]{'train_loss:13.012862 lr:0.000326'}\n",
      "[Train Epoch]1/5 [Time]2637.07 [Step]3718 [Batch]59500 [Speed]44.32ms/step [Loss]13.0080 [Metrics]{'train_loss:13.008001 lr:0.000329'}\n",
      "[Train Epoch]1/5 [Time]2659.01 [Step]3750 [Batch]60000 [Speed]44.32ms/step [Loss]13.0026 [Metrics]{'train_loss:13.002555 lr:0.000331'}\n",
      "[Train Epoch]1/5 [Time]2681.00 [Step]3781 [Batch]60500 [Speed]44.31ms/step [Loss]12.9976 [Metrics]{'train_loss:12.997558 lr:0.000334'}\n",
      "[Train Epoch]1/5 [Time]2702.99 [Step]3812 [Batch]61000 [Speed]44.31ms/step [Loss]12.9928 [Metrics]{'train_loss:12.992781 lr:0.000337'}\n",
      "[Train Epoch]1/5 [Time]2725.10 [Step]3843 [Batch]61500 [Speed]44.31ms/step [Loss]12.9877 [Metrics]{'train_loss:12.987692 lr:0.000340'}\n",
      "[Train Epoch]1/5 [Time]2748.81 [Step]3875 [Batch]62000 [Speed]44.34ms/step [Loss]12.9826 [Metrics]{'train_loss:12.982639 lr:0.000343'}\n",
      "[Train Epoch]1/5 [Time]2772.34 [Step]3906 [Batch]62500 [Speed]44.36ms/step [Loss]12.9782 [Metrics]{'train_loss:12.978170 lr:0.000345'}\n",
      "[Train Epoch]1/5 [Time]2795.09 [Step]3937 [Batch]63000 [Speed]44.37ms/step [Loss]12.9733 [Metrics]{'train_loss:12.973270 lr:0.000348'}\n",
      "[Train Epoch]1/5 [Time]2817.06 [Step]3968 [Batch]63500 [Speed]44.36ms/step [Loss]12.9684 [Metrics]{'train_loss:12.968415 lr:0.000351'}\n",
      "[Train Epoch]1/5 [Time]2838.93 [Step]4000 [Batch]64000 [Speed]44.36ms/step [Loss]12.9637 [Metrics]{'train_loss:12.963666 lr:0.000354'}\n",
      "[Train Epoch]1/5 [Time]2861.22 [Step]4031 [Batch]64500 [Speed]44.36ms/step [Loss]12.9591 [Metrics]{'train_loss:12.959122 lr:0.000356'}\n",
      "[Train Epoch]1/5 [Time]2883.68 [Step]4062 [Batch]65000 [Speed]44.36ms/step [Loss]12.9549 [Metrics]{'train_loss:12.954883 lr:0.000359'}\n",
      "[Train Epoch]1/5 [Time]2905.36 [Step]4093 [Batch]65500 [Speed]44.36ms/step [Loss]12.9503 [Metrics]{'train_loss:12.950253 lr:0.000362'}\n",
      "[Train Epoch]1/5 [Time]2927.03 [Step]4125 [Batch]66000 [Speed]44.35ms/step [Loss]12.9455 [Metrics]{'train_loss:12.945539 lr:0.000365'}\n",
      "[Train Epoch]1/5 [Time]2948.76 [Step]4156 [Batch]66500 [Speed]44.34ms/step [Loss]12.9414 [Metrics]{'train_loss:12.941393 lr:0.000367'}\n",
      "[Train Epoch]1/5 [Time]2970.44 [Step]4187 [Batch]67000 [Speed]44.33ms/step [Loss]12.9371 [Metrics]{'train_loss:12.937086 lr:0.000370'}\n",
      "[Train Epoch]1/5 [Time]2992.14 [Step]4218 [Batch]67500 [Speed]44.33ms/step [Loss]12.9325 [Metrics]{'train_loss:12.932529 lr:0.000373'}\n",
      "[Train Epoch]1/5 [Time]3014.00 [Step]4250 [Batch]68000 [Speed]44.32ms/step [Loss]12.9280 [Metrics]{'train_loss:12.927996 lr:0.000376'}\n",
      "[Train Epoch]1/5 [Time]3036.19 [Step]4281 [Batch]68500 [Speed]44.32ms/step [Loss]12.9238 [Metrics]{'train_loss:12.923770 lr:0.000378'}\n",
      "[Train Epoch]1/5 [Time]3057.85 [Step]4312 [Batch]69000 [Speed]44.32ms/step [Loss]12.9194 [Metrics]{'train_loss:12.919443 lr:0.000381'}\n",
      "[Train Epoch]1/5 [Time]3079.60 [Step]4343 [Batch]69500 [Speed]44.31ms/step [Loss]12.9152 [Metrics]{'train_loss:12.915241 lr:0.000384'}\n",
      "[Train Epoch]1/5 [Time]3101.30 [Step]4375 [Batch]70000 [Speed]44.30ms/step [Loss]12.9108 [Metrics]{'train_loss:12.910841 lr:0.000387'}\n",
      "[Train Epoch]1/5 [Time]3122.96 [Step]4406 [Batch]70500 [Speed]44.30ms/step [Loss]12.9068 [Metrics]{'train_loss:12.906779 lr:0.000389'}\n",
      "[Train Epoch]1/5 [Time]3144.79 [Step]4437 [Batch]71000 [Speed]44.29ms/step [Loss]12.9025 [Metrics]{'train_loss:12.902525 lr:0.000392'}\n",
      "[Train Epoch]1/5 [Time]3166.50 [Step]4468 [Batch]71500 [Speed]44.29ms/step [Loss]12.8986 [Metrics]{'train_loss:12.898636 lr:0.000395'}\n",
      "[Train Epoch]1/5 [Time]3188.25 [Step]4500 [Batch]72000 [Speed]44.28ms/step [Loss]12.8950 [Metrics]{'train_loss:12.894952 lr:0.000398'}\n",
      "[Train Epoch]1/5 [Time]3209.91 [Step]4531 [Batch]72500 [Speed]44.27ms/step [Loss]12.8910 [Metrics]{'train_loss:12.890970 lr:0.000400'}\n",
      "[Train Epoch]1/5 [Time]3231.50 [Step]4562 [Batch]73000 [Speed]44.27ms/step [Loss]12.8868 [Metrics]{'train_loss:12.886828 lr:0.000403'}\n",
      "[Train Epoch]1/5 [Time]3253.15 [Step]4593 [Batch]73500 [Speed]44.26ms/step [Loss]12.8827 [Metrics]{'train_loss:12.882654 lr:0.000406'}\n",
      "[Train Epoch]1/5 [Time]3274.83 [Step]4625 [Batch]74000 [Speed]44.25ms/step [Loss]12.8783 [Metrics]{'train_loss:12.878300 lr:0.000409'}\n",
      "[Train Epoch]1/5 [Time]3296.50 [Step]4656 [Batch]74500 [Speed]44.25ms/step [Loss]12.8744 [Metrics]{'train_loss:12.874445 lr:0.000412'}\n",
      "[Train Epoch]1/5 [Time]3318.24 [Step]4687 [Batch]75000 [Speed]44.24ms/step [Loss]12.8705 [Metrics]{'train_loss:12.870489 lr:0.000414'}\n",
      "[Train Epoch]1/5 [Time]3339.91 [Step]4718 [Batch]75500 [Speed]44.24ms/step [Loss]12.8666 [Metrics]{'train_loss:12.866605 lr:0.000417'}\n",
      "[Train Epoch]1/5 [Time]3361.60 [Step]4750 [Batch]76000 [Speed]44.23ms/step [Loss]12.8629 [Metrics]{'train_loss:12.862946 lr:0.000420'}\n",
      "[Train Epoch]1/5 [Time]3383.26 [Step]4781 [Batch]76500 [Speed]44.23ms/step [Loss]12.8592 [Metrics]{'train_loss:12.859160 lr:0.000423'}\n",
      "[Train Epoch]1/5 [Time]3404.99 [Step]4812 [Batch]77000 [Speed]44.22ms/step [Loss]12.8554 [Metrics]{'train_loss:12.855448 lr:0.000425'}\n",
      "[Train Epoch]1/5 [Time]3427.09 [Step]4843 [Batch]77500 [Speed]44.22ms/step [Loss]12.8514 [Metrics]{'train_loss:12.851397 lr:0.000428'}\n",
      "[Train Epoch]1/5 [Time]3448.81 [Step]4875 [Batch]78000 [Speed]44.22ms/step [Loss]12.8473 [Metrics]{'train_loss:12.847343 lr:0.000431'}\n",
      "[Train Epoch]1/5 [Time]3470.47 [Step]4906 [Batch]78500 [Speed]44.21ms/step [Loss]12.8435 [Metrics]{'train_loss:12.843547 lr:0.000434'}\n",
      "[Train Epoch]1/5 [Time]3492.14 [Step]4937 [Batch]79000 [Speed]44.20ms/step [Loss]12.8398 [Metrics]{'train_loss:12.839846 lr:0.000436'}\n",
      "[Train Epoch]1/5 [Time]3513.81 [Step]4968 [Batch]79500 [Speed]44.20ms/step [Loss]12.8362 [Metrics]{'train_loss:12.836167 lr:0.000439'}\n",
      "Saving checkpoint for epoch 1 at step 80000 on path model_bert4rec_complete_0.6\n",
      "[Train Epoch]1/5 [Time]3537.23 [Step]5000 [Batch]80000 [Speed]44.22ms/step [Loss]12.8325 [Metrics]{'train_loss:12.832497 lr:0.000442'}\n",
      "[Train Epoch]1/5 [Time]3558.94 [Step]5031 [Batch]80500 [Speed]44.21ms/step [Loss]12.8289 [Metrics]{'train_loss:12.828922 lr:0.000445'}\n",
      "[Train Epoch]1/5 [Time]3580.60 [Step]5062 [Batch]81000 [Speed]44.20ms/step [Loss]12.8250 [Metrics]{'train_loss:12.825010 lr:0.000447'}\n",
      "[Train Epoch]1/5 [Time]3602.26 [Step]5093 [Batch]81500 [Speed]44.20ms/step [Loss]12.8215 [Metrics]{'train_loss:12.821483 lr:0.000450'}\n",
      "[Train Epoch]1/5 [Time]3623.96 [Step]5125 [Batch]82000 [Speed]44.19ms/step [Loss]12.8179 [Metrics]{'train_loss:12.817927 lr:0.000453'}\n",
      "[Train Epoch]1/5 [Time]3645.62 [Step]5156 [Batch]82500 [Speed]44.19ms/step [Loss]12.8144 [Metrics]{'train_loss:12.814352 lr:0.000456'}\n",
      "[Train Epoch]1/5 [Time]3667.30 [Step]5187 [Batch]83000 [Speed]44.18ms/step [Loss]12.8108 [Metrics]{'train_loss:12.810788 lr:0.000458'}\n",
      "[Train Epoch]1/5 [Time]3688.96 [Step]5218 [Batch]83500 [Speed]44.18ms/step [Loss]12.8073 [Metrics]{'train_loss:12.807291 lr:0.000461'}\n",
      "[Train Epoch]1/5 [Time]3711.30 [Step]5250 [Batch]84000 [Speed]44.18ms/step [Loss]12.8039 [Metrics]{'train_loss:12.803940 lr:0.000464'}\n",
      "[Train Epoch]1/5 [Time]3733.05 [Step]5281 [Batch]84500 [Speed]44.18ms/step [Loss]12.8004 [Metrics]{'train_loss:12.800436 lr:0.000467'}\n",
      "[Train Epoch]1/5 [Time]3754.71 [Step]5312 [Batch]85000 [Speed]44.17ms/step [Loss]12.7968 [Metrics]{'train_loss:12.796835 lr:0.000470'}\n",
      "[Train Epoch]1/5 [Time]3776.31 [Step]5343 [Batch]85500 [Speed]44.17ms/step [Loss]12.7931 [Metrics]{'train_loss:12.793112 lr:0.000472'}\n",
      "[Train Epoch]1/5 [Time]3798.00 [Step]5375 [Batch]86000 [Speed]44.16ms/step [Loss]12.7892 [Metrics]{'train_loss:12.789208 lr:0.000475'}\n",
      "[Train Epoch]1/5 [Time]3819.73 [Step]5406 [Batch]86500 [Speed]44.16ms/step [Loss]12.7856 [Metrics]{'train_loss:12.785645 lr:0.000478'}\n",
      "[Train Epoch]1/5 [Time]3841.35 [Step]5437 [Batch]87000 [Speed]44.15ms/step [Loss]12.7822 [Metrics]{'train_loss:12.782195 lr:0.000481'}\n",
      "[Train Epoch]1/5 [Time]3863.09 [Step]5468 [Batch]87500 [Speed]44.15ms/step [Loss]12.7788 [Metrics]{'train_loss:12.778755 lr:0.000483'}\n",
      "[Train Epoch]1/5 [Time]3885.04 [Step]5500 [Batch]88000 [Speed]44.15ms/step [Loss]12.7753 [Metrics]{'train_loss:12.775296 lr:0.000486'}\n",
      "[Train Epoch]1/5 [Time]3906.67 [Step]5531 [Batch]88500 [Speed]44.14ms/step [Loss]12.7718 [Metrics]{'train_loss:12.771778 lr:0.000489'}\n",
      "[Train Epoch]1/5 [Time]3928.11 [Step]5562 [Batch]89000 [Speed]44.14ms/step [Loss]12.7684 [Metrics]{'train_loss:12.768351 lr:0.000492'}\n",
      "[Train Epoch]1/5 [Time]3949.73 [Step]5593 [Batch]89500 [Speed]44.13ms/step [Loss]12.7650 [Metrics]{'train_loss:12.764999 lr:0.000494'}\n",
      "[Train Epoch]1/5 [Time]3971.07 [Step]5625 [Batch]90000 [Speed]44.12ms/step [Loss]12.7615 [Metrics]{'train_loss:12.761474 lr:0.000497'}\n",
      "[Train Epoch]1/5 [Time]3992.40 [Step]5656 [Batch]90500 [Speed]44.11ms/step [Loss]12.7582 [Metrics]{'train_loss:12.758195 lr:0.000500'}\n",
      "[Train Epoch]1/5 [Time]4013.74 [Step]5687 [Batch]91000 [Speed]44.11ms/step [Loss]12.7547 [Metrics]{'train_loss:12.754676 lr:0.000503'}\n",
      "[Train Epoch]1/5 [Time]4035.06 [Step]5718 [Batch]91500 [Speed]44.10ms/step [Loss]12.7514 [Metrics]{'train_loss:12.751412 lr:0.000505'}\n",
      "[Train Epoch]1/5 [Time]4056.42 [Step]5750 [Batch]92000 [Speed]44.09ms/step [Loss]12.7479 [Metrics]{'train_loss:12.747940 lr:0.000508'}\n",
      "[Train Epoch]1/5 [Time]4077.75 [Step]5781 [Batch]92500 [Speed]44.08ms/step [Loss]12.7442 [Metrics]{'train_loss:12.744192 lr:0.000511'}\n",
      "[Train Epoch]1/5 [Time]4099.05 [Step]5812 [Batch]93000 [Speed]44.08ms/step [Loss]12.7408 [Metrics]{'train_loss:12.740814 lr:0.000514'}\n",
      "[Train Epoch]1/5 [Time]4120.37 [Step]5843 [Batch]93500 [Speed]44.07ms/step [Loss]12.7376 [Metrics]{'train_loss:12.737564 lr:0.000516'}\n",
      "[Train Epoch]1/5 [Time]4141.71 [Step]5875 [Batch]94000 [Speed]44.06ms/step [Loss]12.7341 [Metrics]{'train_loss:12.734101 lr:0.000519'}\n",
      "[Train Epoch]1/5 [Time]4163.02 [Step]5906 [Batch]94500 [Speed]44.05ms/step [Loss]12.7306 [Metrics]{'train_loss:12.730617 lr:0.000522'}\n",
      "[Train Epoch]1/5 [Time]4184.33 [Step]5937 [Batch]95000 [Speed]44.05ms/step [Loss]12.7268 [Metrics]{'train_loss:12.726817 lr:0.000525'}\n",
      "[Train Epoch]1/5 [Time]4205.65 [Step]5968 [Batch]95500 [Speed]44.04ms/step [Loss]12.7236 [Metrics]{'train_loss:12.723619 lr:0.000528'}\n",
      "[Train Epoch]1/5 [Time]4227.02 [Step]6000 [Batch]96000 [Speed]44.03ms/step [Loss]12.7203 [Metrics]{'train_loss:12.720305 lr:0.000530'}\n",
      "[Train Epoch]1/5 [Time]4248.35 [Step]6031 [Batch]96500 [Speed]44.02ms/step [Loss]12.7170 [Metrics]{'train_loss:12.716964 lr:0.000533'}\n",
      "[Train Epoch]1/5 [Time]4269.71 [Step]6062 [Batch]97000 [Speed]44.02ms/step [Loss]12.7136 [Metrics]{'train_loss:12.713603 lr:0.000536'}\n",
      "[Train Epoch]1/5 [Time]4291.69 [Step]6093 [Batch]97500 [Speed]44.02ms/step [Loss]12.7104 [Metrics]{'train_loss:12.710357 lr:0.000539'}\n",
      "[Train Epoch]1/5 [Time]4314.03 [Step]6125 [Batch]98000 [Speed]44.02ms/step [Loss]12.7068 [Metrics]{'train_loss:12.706812 lr:0.000541'}\n",
      "[Train Epoch]1/5 [Time]4335.49 [Step]6156 [Batch]98500 [Speed]44.02ms/step [Loss]12.7032 [Metrics]{'train_loss:12.703167 lr:0.000544'}\n",
      "[Train Epoch]1/5 [Time]4356.95 [Step]6187 [Batch]99000 [Speed]44.01ms/step [Loss]12.6999 [Metrics]{'train_loss:12.699924 lr:0.000547'}\n",
      "[Train Epoch]1/5 [Time]4378.54 [Step]6218 [Batch]99500 [Speed]44.01ms/step [Loss]12.6966 [Metrics]{'train_loss:12.696589 lr:0.000550'}\n",
      "[Train Epoch]1/5 [Time]4399.86 [Step]6250 [Batch]100000 [Speed]44.00ms/step [Loss]12.6933 [Metrics]{'train_loss:12.693275 lr:0.000552'}\n",
      "[Train Epoch]1/5 [Time]4421.18 [Step]6281 [Batch]100500 [Speed]43.99ms/step [Loss]12.6899 [Metrics]{'train_loss:12.689936 lr:0.000555'}\n",
      "[Train Epoch]1/5 [Time]4442.49 [Step]6312 [Batch]101000 [Speed]43.99ms/step [Loss]12.6866 [Metrics]{'train_loss:12.686575 lr:0.000558'}\n",
      "[Train Epoch]1/5 [Time]4463.79 [Step]6343 [Batch]101500 [Speed]43.98ms/step [Loss]12.6832 [Metrics]{'train_loss:12.683177 lr:0.000561'}\n",
      "[Train Epoch]1/5 [Time]4485.14 [Step]6375 [Batch]102000 [Speed]43.97ms/step [Loss]12.6798 [Metrics]{'train_loss:12.679752 lr:0.000563'}\n",
      "[Train Epoch]1/5 [Time]4506.43 [Step]6406 [Batch]102500 [Speed]43.97ms/step [Loss]12.6760 [Metrics]{'train_loss:12.676023 lr:0.000566'}\n",
      "[Train Epoch]1/5 [Time]4527.74 [Step]6437 [Batch]103000 [Speed]43.96ms/step [Loss]12.6718 [Metrics]{'train_loss:12.671768 lr:0.000569'}\n",
      "[Train Epoch]1/5 [Time]4549.07 [Step]6468 [Batch]103500 [Speed]43.95ms/step [Loss]12.6677 [Metrics]{'train_loss:12.667689 lr:0.000572'}\n",
      "[Train Epoch]1/5 [Time]4570.45 [Step]6500 [Batch]104000 [Speed]43.95ms/step [Loss]12.6631 [Metrics]{'train_loss:12.663054 lr:0.000575'}\n",
      "[Train Epoch]1/5 [Time]4591.78 [Step]6531 [Batch]104500 [Speed]43.94ms/step [Loss]12.6588 [Metrics]{'train_loss:12.658783 lr:0.000577'}\n",
      "[Train Epoch]1/5 [Time]4613.09 [Step]6562 [Batch]105000 [Speed]43.93ms/step [Loss]12.6549 [Metrics]{'train_loss:12.654942 lr:0.000580'}\n",
      "[Train Epoch]1/5 [Time]4634.42 [Step]6593 [Batch]105500 [Speed]43.93ms/step [Loss]12.6514 [Metrics]{'train_loss:12.651383 lr:0.000583'}\n",
      "[Train Epoch]1/5 [Time]4655.74 [Step]6625 [Batch]106000 [Speed]43.92ms/step [Loss]12.6482 [Metrics]{'train_loss:12.648176 lr:0.000586'}\n",
      "[Train Epoch]1/5 [Time]4677.05 [Step]6656 [Batch]106500 [Speed]43.92ms/step [Loss]12.6447 [Metrics]{'train_loss:12.644656 lr:0.000588'}\n",
      "[Train Epoch]1/5 [Time]4698.35 [Step]6687 [Batch]107000 [Speed]43.91ms/step [Loss]12.6412 [Metrics]{'train_loss:12.641185 lr:0.000591'}\n",
      "[Train Epoch]1/5 [Time]4719.68 [Step]6718 [Batch]107500 [Speed]43.90ms/step [Loss]12.6378 [Metrics]{'train_loss:12.637759 lr:0.000594'}\n",
      "[Train Epoch]1/5 [Time]4741.00 [Step]6750 [Batch]108000 [Speed]43.90ms/step [Loss]12.6343 [Metrics]{'train_loss:12.634339 lr:0.000597'}\n",
      "[Train Epoch]1/5 [Time]4762.32 [Step]6781 [Batch]108500 [Speed]43.89ms/step [Loss]12.6310 [Metrics]{'train_loss:12.630993 lr:0.000599'}\n",
      "[Train Epoch]1/5 [Time]4783.65 [Step]6812 [Batch]109000 [Speed]43.89ms/step [Loss]12.6275 [Metrics]{'train_loss:12.627499 lr:0.000602'}\n",
      "[Train Epoch]1/5 [Time]4804.94 [Step]6843 [Batch]109500 [Speed]43.88ms/step [Loss]12.6241 [Metrics]{'train_loss:12.624085 lr:0.000605'}\n",
      "[Train Epoch]1/5 [Time]4826.26 [Step]6875 [Batch]110000 [Speed]43.88ms/step [Loss]12.6205 [Metrics]{'train_loss:12.620546 lr:0.000608'}\n",
      "[Train Epoch]1/5 [Time]4847.55 [Step]6906 [Batch]110500 [Speed]43.87ms/step [Loss]12.6168 [Metrics]{'train_loss:12.616819 lr:0.000610'}\n",
      "[Train Epoch]1/5 [Time]4868.83 [Step]6937 [Batch]111000 [Speed]43.86ms/step [Loss]12.6132 [Metrics]{'train_loss:12.613169 lr:0.000613'}\n",
      "[Train Epoch]1/5 [Time]4890.11 [Step]6968 [Batch]111500 [Speed]43.86ms/step [Loss]12.6097 [Metrics]{'train_loss:12.609734 lr:0.000616'}\n",
      "[Train Epoch]1/5 [Time]4911.42 [Step]7000 [Batch]112000 [Speed]43.85ms/step [Loss]12.6061 [Metrics]{'train_loss:12.606055 lr:0.000619'}\n",
      "[Train Epoch]1/5 [Time]4932.70 [Step]7031 [Batch]112500 [Speed]43.85ms/step [Loss]12.6025 [Metrics]{'train_loss:12.602527 lr:0.000621'}\n",
      "[Train Epoch]1/5 [Time]4953.98 [Step]7062 [Batch]113000 [Speed]43.84ms/step [Loss]12.5987 [Metrics]{'train_loss:12.598720 lr:0.000624'}\n",
      "[Train Epoch]1/5 [Time]4975.27 [Step]7093 [Batch]113500 [Speed]43.83ms/step [Loss]12.5951 [Metrics]{'train_loss:12.595131 lr:0.000627'}\n",
      "[Train Epoch]1/5 [Time]4996.58 [Step]7125 [Batch]114000 [Speed]43.83ms/step [Loss]12.5920 [Metrics]{'train_loss:12.591979 lr:0.000630'}\n",
      "[Train Epoch]1/5 [Time]5017.88 [Step]7156 [Batch]114500 [Speed]43.82ms/step [Loss]12.5882 [Metrics]{'train_loss:12.588218 lr:0.000633'}\n",
      "[Train Epoch]1/5 [Time]5039.19 [Step]7187 [Batch]115000 [Speed]43.82ms/step [Loss]12.5846 [Metrics]{'train_loss:12.584606 lr:0.000635'}\n",
      "[Train Epoch]1/5 [Time]5060.46 [Step]7218 [Batch]115500 [Speed]43.81ms/step [Loss]12.5810 [Metrics]{'train_loss:12.580959 lr:0.000638'}\n",
      "[Train Epoch]1/5 [Time]5081.77 [Step]7250 [Batch]116000 [Speed]43.81ms/step [Loss]12.5773 [Metrics]{'train_loss:12.577315 lr:0.000641'}\n",
      "[Train Epoch]1/5 [Time]5103.05 [Step]7281 [Batch]116500 [Speed]43.80ms/step [Loss]12.5733 [Metrics]{'train_loss:12.573339 lr:0.000644'}\n",
      "[Train Epoch]1/5 [Time]5124.33 [Step]7312 [Batch]117000 [Speed]43.80ms/step [Loss]12.5697 [Metrics]{'train_loss:12.569677 lr:0.000646'}\n",
      "[Train Epoch]1/5 [Time]5145.61 [Step]7343 [Batch]117500 [Speed]43.79ms/step [Loss]12.5659 [Metrics]{'train_loss:12.565885 lr:0.000649'}\n",
      "[Train Epoch]1/5 [Time]5166.92 [Step]7375 [Batch]118000 [Speed]43.79ms/step [Loss]12.5618 [Metrics]{'train_loss:12.561794 lr:0.000652'}\n",
      "[Train Epoch]1/5 [Time]5188.21 [Step]7406 [Batch]118500 [Speed]43.78ms/step [Loss]12.5580 [Metrics]{'train_loss:12.557987 lr:0.000655'}\n",
      "[Train Epoch]1/5 [Time]5209.51 [Step]7437 [Batch]119000 [Speed]43.78ms/step [Loss]12.5541 [Metrics]{'train_loss:12.554145 lr:0.000657'}\n",
      "[Train Epoch]1/5 [Time]5230.81 [Step]7468 [Batch]119500 [Speed]43.77ms/step [Loss]12.5504 [Metrics]{'train_loss:12.550440 lr:0.000660'}\n",
      "[Train Epoch]1/5 [Time]5252.13 [Step]7500 [Batch]120000 [Speed]43.77ms/step [Loss]12.5461 [Metrics]{'train_loss:12.546124 lr:0.000663'}\n",
      "[Train Epoch]1/5 [Time]5273.43 [Step]7531 [Batch]120500 [Speed]43.76ms/step [Loss]12.5422 [Metrics]{'train_loss:12.542157 lr:0.000666'}\n",
      "[Train Epoch]1/5 [Time]5294.70 [Step]7562 [Batch]121000 [Speed]43.76ms/step [Loss]12.5381 [Metrics]{'train_loss:12.538138 lr:0.000668'}\n",
      "[Train Epoch]1/5 [Time]5315.99 [Step]7593 [Batch]121500 [Speed]43.75ms/step [Loss]12.5340 [Metrics]{'train_loss:12.534037 lr:0.000671'}\n",
      "[Train Epoch]1/5 [Time]5337.32 [Step]7625 [Batch]122000 [Speed]43.75ms/step [Loss]12.5301 [Metrics]{'train_loss:12.530102 lr:0.000674'}\n",
      "[Train Epoch]1/5 [Time]5358.60 [Step]7656 [Batch]122500 [Speed]43.74ms/step [Loss]12.5258 [Metrics]{'train_loss:12.525846 lr:0.000677'}\n",
      "[Train Epoch]1/5 [Time]5379.90 [Step]7687 [Batch]123000 [Speed]43.74ms/step [Loss]12.5218 [Metrics]{'train_loss:12.521770 lr:0.000679'}\n",
      "[Train Epoch]1/5 [Time]5401.20 [Step]7718 [Batch]123500 [Speed]43.73ms/step [Loss]12.5176 [Metrics]{'train_loss:12.517622 lr:0.000682'}\n",
      "[Train Epoch]1/5 [Time]5422.50 [Step]7750 [Batch]124000 [Speed]43.73ms/step [Loss]12.5134 [Metrics]{'train_loss:12.513371 lr:0.000685'}\n",
      "[Train Epoch]1/5 [Time]5443.79 [Step]7781 [Batch]124500 [Speed]43.73ms/step [Loss]12.5090 [Metrics]{'train_loss:12.509045 lr:0.000688'}\n",
      "[Train Epoch]1/5 [Time]5465.07 [Step]7812 [Batch]125000 [Speed]43.72ms/step [Loss]12.5047 [Metrics]{'train_loss:12.504721 lr:0.000690'}\n",
      "[Train Epoch]1/5 [Time]5486.36 [Step]7843 [Batch]125500 [Speed]43.72ms/step [Loss]12.5008 [Metrics]{'train_loss:12.500775 lr:0.000693'}\n",
      "[Train Epoch]1/5 [Time]5507.69 [Step]7875 [Batch]126000 [Speed]43.71ms/step [Loss]12.4965 [Metrics]{'train_loss:12.496494 lr:0.000696'}\n",
      "[Train Epoch]1/5 [Time]5528.97 [Step]7906 [Batch]126500 [Speed]43.71ms/step [Loss]12.4921 [Metrics]{'train_loss:12.492139 lr:0.000699'}\n",
      "[Train Epoch]1/5 [Time]5550.25 [Step]7937 [Batch]127000 [Speed]43.70ms/step [Loss]12.4879 [Metrics]{'train_loss:12.487877 lr:0.000702'}\n",
      "[Train Epoch]1/5 [Time]5571.55 [Step]7968 [Batch]127500 [Speed]43.70ms/step [Loss]12.4837 [Metrics]{'train_loss:12.483666 lr:0.000704'}\n",
      "[Train Epoch]1/5 [Time]5592.85 [Step]8000 [Batch]128000 [Speed]43.69ms/step [Loss]12.4794 [Metrics]{'train_loss:12.479352 lr:0.000707'}\n",
      "[Train Epoch]1/5 [Time]5614.16 [Step]8031 [Batch]128500 [Speed]43.69ms/step [Loss]12.4750 [Metrics]{'train_loss:12.475041 lr:0.000710'}\n",
      "[Train Epoch]1/5 [Time]5635.43 [Step]8062 [Batch]129000 [Speed]43.69ms/step [Loss]12.4710 [Metrics]{'train_loss:12.470973 lr:0.000713'}\n",
      "[Train Epoch]1/5 [Time]5656.70 [Step]8093 [Batch]129500 [Speed]43.68ms/step [Loss]12.4666 [Metrics]{'train_loss:12.466572 lr:0.000715'}\n",
      "[Train Epoch]1/5 [Time]5678.01 [Step]8125 [Batch]130000 [Speed]43.68ms/step [Loss]12.4623 [Metrics]{'train_loss:12.462341 lr:0.000718'}\n",
      "[Train Epoch]1/5 [Time]5699.30 [Step]8156 [Batch]130500 [Speed]43.67ms/step [Loss]12.4580 [Metrics]{'train_loss:12.458026 lr:0.000721'}\n",
      "[Train Epoch]1/5 [Time]5720.59 [Step]8187 [Batch]131000 [Speed]43.67ms/step [Loss]12.4536 [Metrics]{'train_loss:12.453555 lr:0.000724'}\n",
      "[Train Epoch]1/5 [Time]5741.88 [Step]8218 [Batch]131500 [Speed]43.66ms/step [Loss]12.4489 [Metrics]{'train_loss:12.448887 lr:0.000726'}\n",
      "[Train Epoch]1/5 [Time]5763.18 [Step]8250 [Batch]132000 [Speed]43.66ms/step [Loss]12.4446 [Metrics]{'train_loss:12.444589 lr:0.000729'}\n",
      "[Train Epoch]1/5 [Time]5784.49 [Step]8281 [Batch]132500 [Speed]43.66ms/step [Loss]12.4402 [Metrics]{'train_loss:12.440164 lr:0.000732'}\n",
      "[Train Epoch]1/5 [Time]5805.79 [Step]8312 [Batch]133000 [Speed]43.65ms/step [Loss]12.4358 [Metrics]{'train_loss:12.435822 lr:0.000735'}\n",
      "[Train Epoch]1/5 [Time]5827.08 [Step]8343 [Batch]133500 [Speed]43.65ms/step [Loss]12.4313 [Metrics]{'train_loss:12.431323 lr:0.000737'}\n",
      "[Train Epoch]1/5 [Time]5848.39 [Step]8375 [Batch]134000 [Speed]43.64ms/step [Loss]12.4272 [Metrics]{'train_loss:12.427155 lr:0.000740'}\n",
      "[Train Epoch]1/5 [Time]5869.69 [Step]8406 [Batch]134500 [Speed]43.64ms/step [Loss]12.4229 [Metrics]{'train_loss:12.422895 lr:0.000743'}\n",
      "[Train Epoch]1/5 [Time]5890.97 [Step]8437 [Batch]135000 [Speed]43.64ms/step [Loss]12.4188 [Metrics]{'train_loss:12.418755 lr:0.000746'}\n",
      "[Train Epoch]1/5 [Time]5912.26 [Step]8468 [Batch]135500 [Speed]43.63ms/step [Loss]12.4143 [Metrics]{'train_loss:12.414286 lr:0.000748'}\n",
      "[Train Epoch]1/5 [Time]5933.57 [Step]8500 [Batch]136000 [Speed]43.63ms/step [Loss]12.4098 [Metrics]{'train_loss:12.409842 lr:0.000751'}\n",
      "[Train Epoch]1/5 [Time]5954.86 [Step]8531 [Batch]136500 [Speed]43.63ms/step [Loss]12.4056 [Metrics]{'train_loss:12.405609 lr:0.000754'}\n",
      "[Train Epoch]1/5 [Time]5976.14 [Step]8562 [Batch]137000 [Speed]43.62ms/step [Loss]12.4012 [Metrics]{'train_loss:12.401152 lr:0.000757'}\n",
      "[Train Epoch]1/5 [Time]5997.43 [Step]8593 [Batch]137500 [Speed]43.62ms/step [Loss]12.3968 [Metrics]{'train_loss:12.396791 lr:0.000760'}\n",
      "[Train Epoch]1/5 [Time]6018.72 [Step]8625 [Batch]138000 [Speed]43.61ms/step [Loss]12.3925 [Metrics]{'train_loss:12.392490 lr:0.000762'}\n",
      "[Train Epoch]1/5 [Time]6040.01 [Step]8656 [Batch]138500 [Speed]43.61ms/step [Loss]12.3881 [Metrics]{'train_loss:12.388146 lr:0.000765'}\n",
      "[Train Epoch]1/5 [Time]6061.28 [Step]8687 [Batch]139000 [Speed]43.61ms/step [Loss]12.3838 [Metrics]{'train_loss:12.383838 lr:0.000768'}\n",
      "[Train Epoch]1/5 [Time]6082.56 [Step]8718 [Batch]139500 [Speed]43.60ms/step [Loss]12.3796 [Metrics]{'train_loss:12.379558 lr:0.000771'}\n",
      "[Train Epoch]1/5 [Time]6103.86 [Step]8750 [Batch]140000 [Speed]43.60ms/step [Loss]12.3752 [Metrics]{'train_loss:12.375205 lr:0.000773'}\n",
      "[Train Epoch]1/5 [Time]6125.14 [Step]8781 [Batch]140500 [Speed]43.60ms/step [Loss]12.3708 [Metrics]{'train_loss:12.370776 lr:0.000776'}\n",
      "[Train Epoch]1/5 [Time]6146.43 [Step]8812 [Batch]141000 [Speed]43.59ms/step [Loss]12.3666 [Metrics]{'train_loss:12.366602 lr:0.000779'}\n",
      "[Train Epoch]1/5 [Time]6167.71 [Step]8843 [Batch]141500 [Speed]43.59ms/step [Loss]12.3621 [Metrics]{'train_loss:12.362105 lr:0.000782'}\n",
      "[Train Epoch]1/5 [Time]6189.00 [Step]8875 [Batch]142000 [Speed]43.58ms/step [Loss]12.3578 [Metrics]{'train_loss:12.357811 lr:0.000784'}\n",
      "[Train Epoch]1/5 [Time]6210.30 [Step]8906 [Batch]142500 [Speed]43.58ms/step [Loss]12.3534 [Metrics]{'train_loss:12.353401 lr:0.000787'}\n",
      "[Train Epoch]1/5 [Time]6231.58 [Step]8937 [Batch]143000 [Speed]43.58ms/step [Loss]12.3490 [Metrics]{'train_loss:12.348970 lr:0.000790'}\n",
      "[Train Epoch]1/5 [Time]6252.87 [Step]8968 [Batch]143500 [Speed]43.57ms/step [Loss]12.3447 [Metrics]{'train_loss:12.344702 lr:0.000793'}\n",
      "[Train Epoch]1/5 [Time]6274.17 [Step]9000 [Batch]144000 [Speed]43.57ms/step [Loss]12.3402 [Metrics]{'train_loss:12.340240 lr:0.000795'}\n",
      "[Train Epoch]1/5 [Time]6295.46 [Step]9031 [Batch]144500 [Speed]43.57ms/step [Loss]12.3358 [Metrics]{'train_loss:12.335835 lr:0.000798'}\n",
      "[Train Epoch]1/5 [Time]6316.74 [Step]9062 [Batch]145000 [Speed]43.56ms/step [Loss]12.3316 [Metrics]{'train_loss:12.331597 lr:0.000801'}\n",
      "[Train Epoch]1/5 [Time]6338.04 [Step]9093 [Batch]145500 [Speed]43.56ms/step [Loss]12.3272 [Metrics]{'train_loss:12.327233 lr:0.000804'}\n",
      "[Train Epoch]1/5 [Time]6359.34 [Step]9125 [Batch]146000 [Speed]43.56ms/step [Loss]12.3230 [Metrics]{'train_loss:12.323005 lr:0.000807'}\n",
      "[Train Epoch]1/5 [Time]6380.63 [Step]9156 [Batch]146500 [Speed]43.55ms/step [Loss]12.3188 [Metrics]{'train_loss:12.318761 lr:0.000809'}\n",
      "[Train Epoch]1/5 [Time]6401.91 [Step]9187 [Batch]147000 [Speed]43.55ms/step [Loss]12.3144 [Metrics]{'train_loss:12.314420 lr:0.000812'}\n",
      "[Train Epoch]1/5 [Time]6423.19 [Step]9218 [Batch]147500 [Speed]43.55ms/step [Loss]12.3100 [Metrics]{'train_loss:12.310003 lr:0.000815'}\n",
      "[Train Epoch]1/5 [Time]6444.49 [Step]9250 [Batch]148000 [Speed]43.54ms/step [Loss]12.3055 [Metrics]{'train_loss:12.305480 lr:0.000818'}\n",
      "[Train Epoch]1/5 [Time]6465.77 [Step]9281 [Batch]148500 [Speed]43.54ms/step [Loss]12.3009 [Metrics]{'train_loss:12.300936 lr:0.000820'}\n",
      "[Train Epoch]1/5 [Time]6487.05 [Step]9312 [Batch]149000 [Speed]43.54ms/step [Loss]12.2966 [Metrics]{'train_loss:12.296569 lr:0.000823'}\n",
      "[Train Epoch]1/5 [Time]6508.35 [Step]9343 [Batch]149500 [Speed]43.53ms/step [Loss]12.2921 [Metrics]{'train_loss:12.292119 lr:0.000826'}\n",
      "[Train Epoch]1/5 [Time]6529.67 [Step]9375 [Batch]150000 [Speed]43.53ms/step [Loss]12.2875 [Metrics]{'train_loss:12.287525 lr:0.000829'}\n",
      "[Train Epoch]1/5 [Time]6550.95 [Step]9406 [Batch]150500 [Speed]43.53ms/step [Loss]12.2830 [Metrics]{'train_loss:12.282975 lr:0.000831'}\n",
      "[Train Epoch]1/5 [Time]6572.24 [Step]9437 [Batch]151000 [Speed]43.52ms/step [Loss]12.2787 [Metrics]{'train_loss:12.278684 lr:0.000834'}\n",
      "[Train Epoch]1/5 [Time]6593.54 [Step]9468 [Batch]151500 [Speed]43.52ms/step [Loss]12.2743 [Metrics]{'train_loss:12.274280 lr:0.000837'}\n",
      "[Train Epoch]1/5 [Time]6614.86 [Step]9500 [Batch]152000 [Speed]43.52ms/step [Loss]12.2699 [Metrics]{'train_loss:12.269909 lr:0.000840'}\n",
      "[Train Epoch]1/5 [Time]6636.15 [Step]9531 [Batch]152500 [Speed]43.52ms/step [Loss]12.2656 [Metrics]{'train_loss:12.265630 lr:0.000842'}\n",
      "[Train Epoch]1/5 [Time]6657.43 [Step]9562 [Batch]153000 [Speed]43.51ms/step [Loss]12.2614 [Metrics]{'train_loss:12.261384 lr:0.000845'}\n",
      "[Train Epoch]1/5 [Time]6678.72 [Step]9593 [Batch]153500 [Speed]43.51ms/step [Loss]12.2571 [Metrics]{'train_loss:12.257137 lr:0.000848'}\n",
      "[Train Epoch]1/5 [Time]6700.05 [Step]9625 [Batch]154000 [Speed]43.51ms/step [Loss]12.2528 [Metrics]{'train_loss:12.252773 lr:0.000851'}\n",
      "[Train Epoch]1/5 [Time]6721.35 [Step]9656 [Batch]154500 [Speed]43.50ms/step [Loss]12.2485 [Metrics]{'train_loss:12.248494 lr:0.000853'}\n",
      "[Train Epoch]1/5 [Time]6742.64 [Step]9687 [Batch]155000 [Speed]43.50ms/step [Loss]12.2441 [Metrics]{'train_loss:12.244108 lr:0.000856'}\n",
      "[Train Epoch]1/5 [Time]6763.93 [Step]9718 [Batch]155500 [Speed]43.50ms/step [Loss]12.2397 [Metrics]{'train_loss:12.239672 lr:0.000859'}\n",
      "[Train Epoch]1/5 [Time]6785.23 [Step]9750 [Batch]156000 [Speed]43.50ms/step [Loss]12.2349 [Metrics]{'train_loss:12.234881 lr:0.000862'}\n",
      "[Train Epoch]1/5 [Time]6806.53 [Step]9781 [Batch]156500 [Speed]43.49ms/step [Loss]12.2305 [Metrics]{'train_loss:12.230453 lr:0.000865'}\n",
      "[Train Epoch]1/5 [Time]6827.83 [Step]9812 [Batch]157000 [Speed]43.49ms/step [Loss]12.2260 [Metrics]{'train_loss:12.225984 lr:0.000867'}\n",
      "[Train Epoch]1/5 [Time]6849.14 [Step]9843 [Batch]157500 [Speed]43.49ms/step [Loss]12.2217 [Metrics]{'train_loss:12.221706 lr:0.000870'}\n",
      "[Train Epoch]1/5 [Time]6870.47 [Step]9875 [Batch]158000 [Speed]43.48ms/step [Loss]12.2174 [Metrics]{'train_loss:12.217360 lr:0.000873'}\n",
      "[Train Epoch]1/5 [Time]6891.78 [Step]9906 [Batch]158500 [Speed]43.48ms/step [Loss]12.2133 [Metrics]{'train_loss:12.213255 lr:0.000876'}\n",
      "[Train Epoch]1/5 [Time]6913.10 [Step]9937 [Batch]159000 [Speed]43.48ms/step [Loss]12.2092 [Metrics]{'train_loss:12.209193 lr:0.000878'}\n",
      "[Train Epoch]1/5 [Time]6934.40 [Step]9968 [Batch]159500 [Speed]43.48ms/step [Loss]12.2049 [Metrics]{'train_loss:12.204927 lr:0.000881'}\n",
      "Saving checkpoint for epoch 1 at step 160000 on path model_bert4rec_complete_0.6\n",
      "[Train Epoch]1/5 [Time]6957.45 [Step]10000 [Batch]160000 [Speed]43.48ms/step [Loss]12.2008 [Metrics]{'train_loss:12.200779 lr:0.000884'}\n",
      "[Train Epoch]1/5 [Time]6978.74 [Step]10031 [Batch]160500 [Speed]43.48ms/step [Loss]12.1965 [Metrics]{'train_loss:12.196523 lr:0.000883'}\n",
      "[Train Epoch]1/5 [Time]7000.03 [Step]10062 [Batch]161000 [Speed]43.48ms/step [Loss]12.1921 [Metrics]{'train_loss:12.192052 lr:0.000881'}\n",
      "[Train Epoch]1/5 [Time]7021.32 [Step]10093 [Batch]161500 [Speed]43.48ms/step [Loss]12.1878 [Metrics]{'train_loss:12.187841 lr:0.000880'}\n",
      "[Train Epoch]1/5 [Time]7042.61 [Step]10125 [Batch]162000 [Speed]43.47ms/step [Loss]12.1835 [Metrics]{'train_loss:12.183520 lr:0.000878'}\n",
      "[Train Epoch]1/5 [Time]7063.90 [Step]10156 [Batch]162500 [Speed]43.47ms/step [Loss]12.1790 [Metrics]{'train_loss:12.179004 lr:0.000877'}\n",
      "[Train Epoch]1/5 [Time]7085.16 [Step]10187 [Batch]163000 [Speed]43.47ms/step [Loss]12.1747 [Metrics]{'train_loss:12.174668 lr:0.000876'}\n",
      "[Train Epoch]1/5 [Time]7106.42 [Step]10218 [Batch]163500 [Speed]43.46ms/step [Loss]12.1702 [Metrics]{'train_loss:12.170155 lr:0.000874'}\n",
      "[Train Epoch]1/5 [Time]7127.69 [Step]10250 [Batch]164000 [Speed]43.46ms/step [Loss]12.1656 [Metrics]{'train_loss:12.165566 lr:0.000873'}\n",
      "[Train Epoch]1/5 [Time]7148.96 [Step]10281 [Batch]164500 [Speed]43.46ms/step [Loss]12.1612 [Metrics]{'train_loss:12.161157 lr:0.000872'}\n",
      "[Train Epoch]1/5 [Time]7170.22 [Step]10312 [Batch]165000 [Speed]43.46ms/step [Loss]12.1569 [Metrics]{'train_loss:12.156904 lr:0.000870'}\n",
      "[Train Epoch]1/5 [Time]7191.49 [Step]10343 [Batch]165500 [Speed]43.45ms/step [Loss]12.1525 [Metrics]{'train_loss:12.152496 lr:0.000869'}\n",
      "[Train Epoch]1/5 [Time]7212.78 [Step]10375 [Batch]166000 [Speed]43.45ms/step [Loss]12.1481 [Metrics]{'train_loss:12.148123 lr:0.000868'}\n",
      "[Train Epoch]1/5 [Time]7234.04 [Step]10406 [Batch]166500 [Speed]43.45ms/step [Loss]12.1437 [Metrics]{'train_loss:12.143653 lr:0.000866'}\n",
      "[Train Epoch]1/5 [Time]7255.31 [Step]10437 [Batch]167000 [Speed]43.44ms/step [Loss]12.1395 [Metrics]{'train_loss:12.139529 lr:0.000865'}\n",
      "[Train Epoch]1/5 [Time]7276.58 [Step]10468 [Batch]167500 [Speed]43.44ms/step [Loss]12.1352 [Metrics]{'train_loss:12.135190 lr:0.000864'}\n",
      "[Train Epoch]1/5 [Time]7297.85 [Step]10500 [Batch]168000 [Speed]43.44ms/step [Loss]12.1309 [Metrics]{'train_loss:12.130857 lr:0.000863'}\n",
      "[Train Epoch]1/5 [Time]7319.13 [Step]10531 [Batch]168500 [Speed]43.44ms/step [Loss]12.1268 [Metrics]{'train_loss:12.126759 lr:0.000861'}\n",
      "[Train Epoch]1/5 [Time]7340.40 [Step]10562 [Batch]169000 [Speed]43.43ms/step [Loss]12.1224 [Metrics]{'train_loss:12.122385 lr:0.000860'}\n",
      "[Train Epoch]1/5 [Time]7361.68 [Step]10593 [Batch]169500 [Speed]43.43ms/step [Loss]12.1181 [Metrics]{'train_loss:12.118149 lr:0.000859'}\n",
      "[Train Epoch]1/5 [Time]7382.96 [Step]10625 [Batch]170000 [Speed]43.43ms/step [Loss]12.1140 [Metrics]{'train_loss:12.113976 lr:0.000857'}\n",
      "[Train Epoch]1/5 [Time]7404.22 [Step]10656 [Batch]170500 [Speed]43.43ms/step [Loss]12.1098 [Metrics]{'train_loss:12.109844 lr:0.000856'}\n",
      "[Train Epoch]1/5 [Time]7425.48 [Step]10687 [Batch]171000 [Speed]43.42ms/step [Loss]12.1059 [Metrics]{'train_loss:12.105890 lr:0.000855'}\n",
      "[Train Epoch]1/5 [Time]7446.74 [Step]10718 [Batch]171500 [Speed]43.42ms/step [Loss]12.1019 [Metrics]{'train_loss:12.101896 lr:0.000854'}\n",
      "[Train Epoch]1/5 [Time]7468.03 [Step]10750 [Batch]172000 [Speed]43.42ms/step [Loss]12.0979 [Metrics]{'train_loss:12.097917 lr:0.000852'}\n",
      "[Train Epoch]1/5 [Time]7489.30 [Step]10781 [Batch]172500 [Speed]43.42ms/step [Loss]12.0936 [Metrics]{'train_loss:12.093631 lr:0.000851'}\n",
      "[Train Epoch]1/5 [Time]7510.59 [Step]10812 [Batch]173000 [Speed]43.41ms/step [Loss]12.0894 [Metrics]{'train_loss:12.089423 lr:0.000850'}\n",
      "[Train Epoch]1/5 [Time]7531.87 [Step]10843 [Batch]173500 [Speed]43.41ms/step [Loss]12.0853 [Metrics]{'train_loss:12.085270 lr:0.000849'}\n",
      "[Train Epoch]1/5 [Time]7553.17 [Step]10875 [Batch]174000 [Speed]43.41ms/step [Loss]12.0810 [Metrics]{'train_loss:12.080979 lr:0.000848'}\n",
      "[Train Epoch]1/5 [Time]7574.44 [Step]10906 [Batch]174500 [Speed]43.41ms/step [Loss]12.0770 [Metrics]{'train_loss:12.076998 lr:0.000846'}\n",
      "[Train Epoch]1/5 [Time]7595.71 [Step]10937 [Batch]175000 [Speed]43.40ms/step [Loss]12.0728 [Metrics]{'train_loss:12.072832 lr:0.000845'}\n",
      "[Train Epoch]1/5 [Time]7616.97 [Step]10968 [Batch]175500 [Speed]43.40ms/step [Loss]12.0688 [Metrics]{'train_loss:12.068828 lr:0.000844'}\n",
      "[Train Epoch]1/5 [Time]7638.29 [Step]11000 [Batch]176000 [Speed]43.40ms/step [Loss]12.0647 [Metrics]{'train_loss:12.064680 lr:0.000843'}\n",
      "[Train Epoch]1/5 [Time]7659.58 [Step]11031 [Batch]176500 [Speed]43.40ms/step [Loss]12.0606 [Metrics]{'train_loss:12.060563 lr:0.000842'}\n",
      "[Train Epoch]1/5 [Time]7680.85 [Step]11062 [Batch]177000 [Speed]43.39ms/step [Loss]12.0566 [Metrics]{'train_loss:12.056572 lr:0.000840'}\n",
      "[Train Epoch]1/5 [Time]7702.14 [Step]11093 [Batch]177500 [Speed]43.39ms/step [Loss]12.0527 [Metrics]{'train_loss:12.052730 lr:0.000839'}\n",
      "[Train Epoch]1/5 [Time]7723.44 [Step]11125 [Batch]178000 [Speed]43.39ms/step [Loss]12.0486 [Metrics]{'train_loss:12.048638 lr:0.000838'}\n",
      "[Train Epoch]1/5 [Time]7744.74 [Step]11156 [Batch]178500 [Speed]43.39ms/step [Loss]12.0444 [Metrics]{'train_loss:12.044431 lr:0.000837'}\n",
      "[Train Epoch]1/5 [Time]7766.03 [Step]11187 [Batch]179000 [Speed]43.39ms/step [Loss]12.0402 [Metrics]{'train_loss:12.040214 lr:0.000836'}\n",
      "[Train Epoch]1/5 [Time]7787.30 [Step]11218 [Batch]179500 [Speed]43.38ms/step [Loss]12.0363 [Metrics]{'train_loss:12.036300 lr:0.000835'}\n",
      "[Train Epoch]1/5 [Time]7808.59 [Step]11250 [Batch]180000 [Speed]43.38ms/step [Loss]12.0323 [Metrics]{'train_loss:12.032339 lr:0.000833'}\n",
      "[Train Epoch]1/5 [Time]7829.90 [Step]11281 [Batch]180500 [Speed]43.38ms/step [Loss]12.0285 [Metrics]{'train_loss:12.028481 lr:0.000832'}\n",
      "[Train Epoch]1/5 [Time]7851.18 [Step]11312 [Batch]181000 [Speed]43.38ms/step [Loss]12.0245 [Metrics]{'train_loss:12.024487 lr:0.000831'}\n",
      "[Train Epoch]1/5 [Time]7872.46 [Step]11343 [Batch]181500 [Speed]43.37ms/step [Loss]12.0204 [Metrics]{'train_loss:12.020383 lr:0.000830'}\n",
      "[Train Epoch]1/5 [Time]7893.76 [Step]11375 [Batch]182000 [Speed]43.37ms/step [Loss]12.0163 [Metrics]{'train_loss:12.016271 lr:0.000829'}\n",
      "[Train Epoch]1/5 [Time]7915.03 [Step]11406 [Batch]182500 [Speed]43.37ms/step [Loss]12.0123 [Metrics]{'train_loss:12.012321 lr:0.000828'}\n",
      "[Train Epoch]1/5 [Time]7936.28 [Step]11437 [Batch]183000 [Speed]43.37ms/step [Loss]12.0084 [Metrics]{'train_loss:12.008424 lr:0.000826'}\n",
      "[Train Epoch]1/5 [Time]7957.54 [Step]11468 [Batch]183500 [Speed]43.37ms/step [Loss]12.0046 [Metrics]{'train_loss:12.004587 lr:0.000825'}\n",
      "[Train Epoch]1/5 [Time]7978.82 [Step]11500 [Batch]184000 [Speed]43.36ms/step [Loss]12.0006 [Metrics]{'train_loss:12.000605 lr:0.000824'}\n",
      "[Train Epoch]1/5 [Time]8000.08 [Step]11531 [Batch]184500 [Speed]43.36ms/step [Loss]11.9965 [Metrics]{'train_loss:11.996526 lr:0.000823'}\n",
      "[Train Epoch]1/5 [Time]8021.33 [Step]11562 [Batch]185000 [Speed]43.36ms/step [Loss]11.9923 [Metrics]{'train_loss:11.992332 lr:0.000822'}\n",
      "[Train Epoch]1/5 [Time]8042.58 [Step]11593 [Batch]185500 [Speed]43.36ms/step [Loss]11.9885 [Metrics]{'train_loss:11.988505 lr:0.000821'}\n",
      "[Train Epoch]1/5 [Time]8063.88 [Step]11625 [Batch]186000 [Speed]43.35ms/step [Loss]11.9844 [Metrics]{'train_loss:11.984381 lr:0.000820'}\n",
      "[Train Epoch]1/5 [Time]8085.14 [Step]11656 [Batch]186500 [Speed]43.35ms/step [Loss]11.9805 [Metrics]{'train_loss:11.980500 lr:0.000819'}\n",
      "[Train Epoch]1/5 [Time]8106.40 [Step]11687 [Batch]187000 [Speed]43.35ms/step [Loss]11.9766 [Metrics]{'train_loss:11.976564 lr:0.000818'}\n",
      "[Train Epoch]1/5 [Time]8127.66 [Step]11718 [Batch]187500 [Speed]43.35ms/step [Loss]11.9727 [Metrics]{'train_loss:11.972703 lr:0.000817'}\n",
      "[Train Epoch]1/5 [Time]8148.95 [Step]11750 [Batch]188000 [Speed]43.35ms/step [Loss]11.9687 [Metrics]{'train_loss:11.968651 lr:0.000815'}\n",
      "[Train Epoch]1/5 [Time]8170.20 [Step]11781 [Batch]188500 [Speed]43.34ms/step [Loss]11.9647 [Metrics]{'train_loss:11.964740 lr:0.000814'}\n",
      "[Train Epoch]1/5 [Time]8191.44 [Step]11812 [Batch]189000 [Speed]43.34ms/step [Loss]11.9608 [Metrics]{'train_loss:11.960827 lr:0.000813'}\n",
      "[Train Epoch]1/5 [Time]8212.70 [Step]11843 [Batch]189500 [Speed]43.34ms/step [Loss]11.9570 [Metrics]{'train_loss:11.957046 lr:0.000812'}\n",
      "[Train Epoch]1/5 [Time]8233.99 [Step]11875 [Batch]190000 [Speed]43.34ms/step [Loss]11.9532 [Metrics]{'train_loss:11.953180 lr:0.000811'}\n",
      "[Train Epoch]1/5 [Time]8255.24 [Step]11906 [Batch]190500 [Speed]43.33ms/step [Loss]11.9493 [Metrics]{'train_loss:11.949327 lr:0.000810'}\n",
      "[Train Epoch]1/5 [Time]8276.51 [Step]11937 [Batch]191000 [Speed]43.33ms/step [Loss]11.9454 [Metrics]{'train_loss:11.945381 lr:0.000809'}\n",
      "[Train Epoch]1/5 [Time]8297.77 [Step]11968 [Batch]191500 [Speed]43.33ms/step [Loss]11.9414 [Metrics]{'train_loss:11.941412 lr:0.000808'}\n",
      "[Train Epoch]1/5 [Time]8319.04 [Step]12000 [Batch]192000 [Speed]43.33ms/step [Loss]11.9376 [Metrics]{'train_loss:11.937581 lr:0.000807'}\n",
      "[Train Epoch]1/5 [Time]8340.32 [Step]12031 [Batch]192500 [Speed]43.33ms/step [Loss]11.9338 [Metrics]{'train_loss:11.933816 lr:0.000806'}\n",
      "[Train Epoch]1/5 [Time]8361.58 [Step]12062 [Batch]193000 [Speed]43.32ms/step [Loss]11.9297 [Metrics]{'train_loss:11.929674 lr:0.000805'}\n",
      "[Train Epoch]1/5 [Time]8382.86 [Step]12093 [Batch]193500 [Speed]43.32ms/step [Loss]11.9260 [Metrics]{'train_loss:11.926034 lr:0.000804'}\n",
      "[Train Epoch]1/5 [Time]8404.15 [Step]12125 [Batch]194000 [Speed]43.32ms/step [Loss]11.9221 [Metrics]{'train_loss:11.922122 lr:0.000803'}\n",
      "[Train Epoch]1/5 [Time]8425.41 [Step]12156 [Batch]194500 [Speed]43.32ms/step [Loss]11.9183 [Metrics]{'train_loss:11.918272 lr:0.000802'}\n",
      "[Train Epoch]1/5 [Time]8446.66 [Step]12187 [Batch]195000 [Speed]43.32ms/step [Loss]11.9145 [Metrics]{'train_loss:11.914499 lr:0.000801'}\n",
      "[Train Epoch]1/5 [Time]8467.93 [Step]12218 [Batch]195500 [Speed]43.31ms/step [Loss]11.9106 [Metrics]{'train_loss:11.910633 lr:0.000800'}\n",
      "[Train Epoch]1/5 [Time]8489.21 [Step]12250 [Batch]196000 [Speed]43.31ms/step [Loss]11.9070 [Metrics]{'train_loss:11.906956 lr:0.000799'}\n",
      "[Train Epoch]1/5 [Time]8510.46 [Step]12281 [Batch]196500 [Speed]43.31ms/step [Loss]11.9030 [Metrics]{'train_loss:11.903040 lr:0.000798'}\n",
      "[Train Epoch]1/5 [Time]8531.72 [Step]12312 [Batch]197000 [Speed]43.31ms/step [Loss]11.8992 [Metrics]{'train_loss:11.899156 lr:0.000797'}\n",
      "[Train Epoch]1/5 [Time]8552.98 [Step]12343 [Batch]197500 [Speed]43.31ms/step [Loss]11.8953 [Metrics]{'train_loss:11.895272 lr:0.000796'}\n",
      "[Train Epoch]1/5 [Time]8574.29 [Step]12375 [Batch]198000 [Speed]43.30ms/step [Loss]11.8916 [Metrics]{'train_loss:11.891599 lr:0.000795'}\n",
      "[Train Epoch]1/5 [Time]8595.56 [Step]12406 [Batch]198500 [Speed]43.30ms/step [Loss]11.8876 [Metrics]{'train_loss:11.887646 lr:0.000794'}\n",
      "[Train Epoch]1/5 [Time]8616.84 [Step]12437 [Batch]199000 [Speed]43.30ms/step [Loss]11.8839 [Metrics]{'train_loss:11.883874 lr:0.000793'}\n",
      "[Train Epoch]1/5 [Time]8638.12 [Step]12468 [Batch]199500 [Speed]43.30ms/step [Loss]11.8802 [Metrics]{'train_loss:11.880199 lr:0.000792'}\n",
      "[Train Epoch]1/5 [Time]8659.39 [Step]12500 [Batch]200000 [Speed]43.30ms/step [Loss]11.8763 [Metrics]{'train_loss:11.876319 lr:0.000791'}\n",
      "[Train Epoch]1/5 [Time]8680.68 [Step]12531 [Batch]200500 [Speed]43.30ms/step [Loss]11.8725 [Metrics]{'train_loss:11.872471 lr:0.000790'}\n",
      "[Train Epoch]1/5 [Time]8701.95 [Step]12562 [Batch]201000 [Speed]43.29ms/step [Loss]11.8689 [Metrics]{'train_loss:11.868864 lr:0.000789'}\n",
      "[Train Epoch]1/5 [Time]8723.22 [Step]12593 [Batch]201500 [Speed]43.29ms/step [Loss]11.8652 [Metrics]{'train_loss:11.865177 lr:0.000788'}\n",
      "[Train Epoch]1/5 [Time]8744.51 [Step]12625 [Batch]202000 [Speed]43.29ms/step [Loss]11.8614 [Metrics]{'train_loss:11.861385 lr:0.000787'}\n",
      "[Train Epoch]1/5 [Time]8765.77 [Step]12656 [Batch]202500 [Speed]43.29ms/step [Loss]11.8575 [Metrics]{'train_loss:11.857527 lr:0.000786'}\n",
      "[Train Epoch]1/5 [Time]8787.04 [Step]12687 [Batch]203000 [Speed]43.29ms/step [Loss]11.8538 [Metrics]{'train_loss:11.853778 lr:0.000785'}\n",
      "[Train Epoch]1/5 [Time]8808.31 [Step]12718 [Batch]203500 [Speed]43.28ms/step [Loss]11.8499 [Metrics]{'train_loss:11.849906 lr:0.000784'}\n",
      "[Train Epoch]1/5 [Time]8829.62 [Step]12750 [Batch]204000 [Speed]43.28ms/step [Loss]11.8462 [Metrics]{'train_loss:11.846229 lr:0.000783'}\n",
      "[Train Epoch]1/5 [Time]8850.90 [Step]12781 [Batch]204500 [Speed]43.28ms/step [Loss]11.8426 [Metrics]{'train_loss:11.842588 lr:0.000782'}\n",
      "[Train Epoch]1/5 [Time]8872.18 [Step]12812 [Batch]205000 [Speed]43.28ms/step [Loss]11.8387 [Metrics]{'train_loss:11.838706 lr:0.000781'}\n",
      "[Train Epoch]1/5 [Time]8893.48 [Step]12843 [Batch]205500 [Speed]43.28ms/step [Loss]11.8352 [Metrics]{'train_loss:11.835170 lr:0.000780'}\n",
      "[Train Epoch]1/5 [Time]8914.78 [Step]12875 [Batch]206000 [Speed]43.28ms/step [Loss]11.8315 [Metrics]{'train_loss:11.831502 lr:0.000779'}\n",
      "[Train Epoch]1/5 [Time]8936.05 [Step]12906 [Batch]206500 [Speed]43.27ms/step [Loss]11.8280 [Metrics]{'train_loss:11.827958 lr:0.000778'}\n",
      "[Train Epoch]1/5 [Time]8957.32 [Step]12937 [Batch]207000 [Speed]43.27ms/step [Loss]11.8242 [Metrics]{'train_loss:11.824231 lr:0.000777'}\n",
      "[Train Epoch]1/5 [Time]8978.61 [Step]12968 [Batch]207500 [Speed]43.27ms/step [Loss]11.8206 [Metrics]{'train_loss:11.820552 lr:0.000776'}\n",
      "[Train Epoch]1/5 [Time]8999.90 [Step]13000 [Batch]208000 [Speed]43.27ms/step [Loss]11.8171 [Metrics]{'train_loss:11.817078 lr:0.000775'}\n",
      "[Train Epoch]1/5 [Time]9021.18 [Step]13031 [Batch]208500 [Speed]43.27ms/step [Loss]11.8134 [Metrics]{'train_loss:11.813369 lr:0.000774'}\n",
      "[Train Epoch]1/5 [Time]9042.46 [Step]13062 [Batch]209000 [Speed]43.27ms/step [Loss]11.8098 [Metrics]{'train_loss:11.809839 lr:0.000773'}\n",
      "[Train Epoch]1/5 [Time]9063.75 [Step]13093 [Batch]209500 [Speed]43.26ms/step [Loss]11.8063 [Metrics]{'train_loss:11.806312 lr:0.000772'}\n",
      "[Train Epoch]1/5 [Time]9085.06 [Step]13125 [Batch]210000 [Speed]43.26ms/step [Loss]11.8026 [Metrics]{'train_loss:11.802570 lr:0.000772'}\n",
      "[Train Epoch]1/5 [Time]9106.34 [Step]13156 [Batch]210500 [Speed]43.26ms/step [Loss]11.7989 [Metrics]{'train_loss:11.798893 lr:0.000771'}\n",
      "[Train Epoch]1/5 [Time]9127.62 [Step]13187 [Batch]211000 [Speed]43.26ms/step [Loss]11.7953 [Metrics]{'train_loss:11.795305 lr:0.000770'}\n",
      "[Train Epoch]1/5 [Time]9148.90 [Step]13218 [Batch]211500 [Speed]43.26ms/step [Loss]11.7919 [Metrics]{'train_loss:11.791895 lr:0.000769'}\n",
      "[Train Epoch]1/5 [Time]9170.18 [Step]13250 [Batch]212000 [Speed]43.26ms/step [Loss]11.7883 [Metrics]{'train_loss:11.788300 lr:0.000768'}\n",
      "[Train Epoch]1/5 [Time]9191.44 [Step]13281 [Batch]212500 [Speed]43.25ms/step [Loss]11.7847 [Metrics]{'train_loss:11.784729 lr:0.000767'}\n",
      "[Train Epoch]1/5 [Time]9212.70 [Step]13312 [Batch]213000 [Speed]43.25ms/step [Loss]11.7813 [Metrics]{'train_loss:11.781257 lr:0.000766'}\n",
      "[Train Epoch]1/5 [Time]9233.96 [Step]13343 [Batch]213500 [Speed]43.25ms/step [Loss]11.7774 [Metrics]{'train_loss:11.777412 lr:0.000765'}\n",
      "[Train Epoch]1/5 [Time]9255.25 [Step]13375 [Batch]214000 [Speed]43.25ms/step [Loss]11.7739 [Metrics]{'train_loss:11.773944 lr:0.000764'}\n",
      "[Train Epoch]1/5 [Time]9276.53 [Step]13406 [Batch]214500 [Speed]43.25ms/step [Loss]11.7702 [Metrics]{'train_loss:11.770182 lr:0.000763'}\n",
      "[Train Epoch]1/5 [Time]9297.79 [Step]13437 [Batch]215000 [Speed]43.25ms/step [Loss]11.7668 [Metrics]{'train_loss:11.766791 lr:0.000763'}\n",
      "[Train Epoch]1/5 [Time]9319.04 [Step]13468 [Batch]215500 [Speed]43.24ms/step [Loss]11.7633 [Metrics]{'train_loss:11.763317 lr:0.000762'}\n",
      "[Train Epoch]1/5 [Time]9340.32 [Step]13500 [Batch]216000 [Speed]43.24ms/step [Loss]11.7598 [Metrics]{'train_loss:11.759837 lr:0.000761'}\n",
      "[Train Epoch]1/5 [Time]9361.57 [Step]13531 [Batch]216500 [Speed]43.24ms/step [Loss]11.7561 [Metrics]{'train_loss:11.756118 lr:0.000760'}\n",
      "[Train Epoch]1/5 [Time]9382.82 [Step]13562 [Batch]217000 [Speed]43.24ms/step [Loss]11.7526 [Metrics]{'train_loss:11.752648 lr:0.000759'}\n",
      "[Train Epoch]1/5 [Time]9404.08 [Step]13593 [Batch]217500 [Speed]43.24ms/step [Loss]11.7492 [Metrics]{'train_loss:11.749197 lr:0.000758'}\n",
      "[Train Epoch]1/5 [Time]9425.35 [Step]13625 [Batch]218000 [Speed]43.24ms/step [Loss]11.7456 [Metrics]{'train_loss:11.745592 lr:0.000757'}\n",
      "[Train Epoch]1/5 [Time]9446.61 [Step]13656 [Batch]218500 [Speed]43.23ms/step [Loss]11.7422 [Metrics]{'train_loss:11.742225 lr:0.000756'}\n",
      "[Train Epoch]1/5 [Time]9467.86 [Step]13687 [Batch]219000 [Speed]43.23ms/step [Loss]11.7387 [Metrics]{'train_loss:11.738677 lr:0.000756'}\n",
      "[Train Epoch]1/5 [Time]9489.13 [Step]13718 [Batch]219500 [Speed]43.23ms/step [Loss]11.7351 [Metrics]{'train_loss:11.735131 lr:0.000755'}\n",
      "[Train Epoch]1/5 [Time]9510.42 [Step]13750 [Batch]220000 [Speed]43.23ms/step [Loss]11.7316 [Metrics]{'train_loss:11.731604 lr:0.000754'}\n",
      "[Train Epoch]1/5 [Time]9531.69 [Step]13781 [Batch]220500 [Speed]43.23ms/step [Loss]11.7280 [Metrics]{'train_loss:11.728016 lr:0.000753'}\n",
      "[Train Epoch]1/5 [Time]9554.53 [Step]13812 [Batch]221000 [Speed]43.23ms/step [Loss]11.7246 [Metrics]{'train_loss:11.724639 lr:0.000752'}\n",
      "[Train Epoch]1/5 [Time]9575.92 [Step]13843 [Batch]221500 [Speed]43.23ms/step [Loss]11.7212 [Metrics]{'train_loss:11.721212 lr:0.000751'}\n",
      "[Train Epoch]1/5 [Time]9597.35 [Step]13875 [Batch]222000 [Speed]43.23ms/step [Loss]11.7178 [Metrics]{'train_loss:11.717753 lr:0.000750'}\n",
      "[Train Epoch]1/5 [Time]9618.82 [Step]13906 [Batch]222500 [Speed]43.23ms/step [Loss]11.7144 [Metrics]{'train_loss:11.714396 lr:0.000750'}\n",
      "[Train Epoch]1/5 [Time]9640.28 [Step]13937 [Batch]223000 [Speed]43.23ms/step [Loss]11.7111 [Metrics]{'train_loss:11.711080 lr:0.000749'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 111\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m batch_num, batch_data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m    110\u001b[0m     inputs, target \u001b[39m=\u001b[39m batch_data\n\u001b[1;32m--> 111\u001b[0m     step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39;49mtarget, loss\u001b[39m=\u001b[39;49mtrain_loss, num_accum_steps\u001b[39m=\u001b[39;49mBERT4REC_CONFIG\u001b[39m.\u001b[39;49mnum_grad_accum_steps)\n\u001b[0;32m    112\u001b[0m     global_gradients \u001b[39m=\u001b[39m backward_optimization(BERT4REC_CONFIG\u001b[39m.\u001b[39mnum_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '1_Model_v0.4.ipynb'\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.4/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.5/checkpoints/', 'ckpt-7')\n",
    "    model_name = 'model_bert4rec_complete_0.6'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 12_000_000\n",
    "    batch_size = 10\n",
    "    num_grad_accum_steps = 16\n",
    "    seq_len = 20\n",
    "    mask_prob = 0.4\n",
    "    reverse_prob = 0.25\n",
    "    emb_dim = 32\n",
    "    trf_dim = 32\n",
    "    num_heads = 2\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 5\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 200\n",
    "    clipnorm = 1\n",
    "    num_iters_save_checkpoint = 5_000 * num_grad_accum_steps\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    log_wandb = True\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}', dict_config=dict_config)\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# model = tf.keras.models.load_model(f'../2_Models/seq_len{BERT4REC_CONFIG.seq_len}_{BERT4REC_CONFIG.restore_last_chekpoint[1]}/', compile=False)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "                            warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "# optimizer = AdamW(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, \n",
    "#                     warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "#                     clipnorm=BERT4REC_CONFIG.clipnorm,\n",
    "#                     weight_decay=1e-4)                            \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = custom_loss_bert4rec()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "##############################################\n",
    "\n",
    "global_gradients = []\n",
    "total_step, val_step = 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        step_gradients = train_step(inputs, target=target, loss=train_loss, num_accum_steps=BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "        global_gradients = backward_optimization(BERT4REC_CONFIG.num_grad_accum_steps, global_gradients, step_gradients, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss]}\n",
    "            train_dict_metrics.update({'lr' : optimizer.lr(total_step//BERT4REC_CONFIG.num_grad_accum_steps).numpy().astype(np.float32)})\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step // BERT4REC_CONFIG.num_grad_accum_steps)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                train_dict_metrics.update({'step_grad' : total_step//BERT4REC_CONFIG.num_grad_accum_steps, 'step' : total_step})\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics)     \n",
    "        total_step += 1  \n",
    "        if total_step % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')        \n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            \n",
    "    for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "        inputs, target = val_batch_data\n",
    "        test_step(inputs, target=target, loss=val_loss)\n",
    "        val_step += 1\n",
    "        if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "            val_dict_metrics = {x.name : x.result() for x in [val_loss]}\n",
    "            fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "                # if val_batch_num==0:\n",
    "                #     log_wandb_metrics(step=None, plot_image=True, \n",
    "                #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [03:59,  8.37it/s]\n",
      "100%|██████████| 96048/96048 [00:01<00:00, 71570.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.604800e+04</td>\n",
       "      <td>40529.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.415337e+06</td>\n",
       "      <td>0.179148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.709874e+06</td>\n",
       "      <td>0.375212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.209861e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.393869e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.608573e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289973e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session         score\n",
       "count  9.604800e+04  40529.000000\n",
       "mean   6.415337e+06      0.179148\n",
       "std    3.709874e+06      0.375212\n",
       "min    1.600000e+01      0.000000\n",
       "25%    3.209861e+06      0.000000\n",
       "50%    6.393869e+06      0.000000\n",
       "75%    9.608573e+06      0.000000\n",
       "max    1.289973e+07      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.21947965580562268,\n",
       " 'clicks': 0.15735708205094623,\n",
       " 'orders': 0.30921648080971853}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.2671\n"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0\n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# ckpt = tf.train.Checkpoint(model=model)\n",
    "# ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.6_v11/checkpoints'))\n",
    "# model = models.load_model('../2_Models/seq_len10_model_bert4rec_complete_v0.4_finetuned/', compile=False)\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.4/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=16, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_predictions, list_trues, list_types = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target = targets\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "    if num_batch==2_000:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# v0.4_finetuned seqlen=10\n",
    "# {'carts': 0.23272587826464677,\n",
    "#  'clicks': 0.16818629058707774,\n",
    "#  'orders': 0.31957377011651095}\n",
    "# Kaggle Metric: 0.2783808\n",
    "\n",
    "# model_bert4rec_complete_0.4.1 - ckpt42\n",
    "# mean = 0.202564\n",
    "# {'carts': 0.2417327288193879,\n",
    "#  'clicks': 0.18081338143653658,\n",
    "#  'orders': 0.33429939670611314}\n",
    "# Kaggle Metric: 0.2912\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.5 - ckpt10\n",
    "# {'carts': 0.2597342763878702,\n",
    "#  'clicks': 0.18694624926166567,\n",
    "#  'orders': 0.3624662713766583}\n",
    "# Kaggle Metric: 0.3141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.current_loss_scale\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.loss_scale.good_steps\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.mlp_proj_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_items.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.embed_type.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.mlp_proj_encoding.layer_with_weights-1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm1.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.gamma\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.layernorm2.beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._query_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._key_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._value_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.att._output_dense.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).model.list_transformer_block.0.ffn.layer_with_weights-1.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18995it [37:50,  8.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m type_ \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mclicks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcarts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morders\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m---> 26\u001b[0m     seq_type_new \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mconcat([\n\u001b[0;32m     27\u001b[0m                     seq_type[i, :ix],\n\u001b[0;32m     28\u001b[0m                     tf\u001b[39m.\u001b[39mconstant([[dict_map_type[type_]]], tf\u001b[39m.\u001b[39mint64),\n\u001b[0;32m     29\u001b[0m                     seq_type[i, ix\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m                 \u001b[39mfor\u001b[39;00m i, ix \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idxs)]\n\u001b[0;32m     31\u001b[0m     features \u001b[39m=\u001b[39m (seq_items, tf\u001b[39m.\u001b[39mstack(seq_type_new, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), seq_time)\n\u001b[0;32m     32\u001b[0m     preds \u001b[39m=\u001b[39m model(features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [11], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m###\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m type_ \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mclicks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcarts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morders\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     26\u001b[0m     seq_type_new \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mconcat([\n\u001b[1;32m---> 27\u001b[0m                     seq_type[i, :ix],\n\u001b[0;32m     28\u001b[0m                     tf\u001b[39m.\u001b[39mconstant([[dict_map_type[type_]]], tf\u001b[39m.\u001b[39mint64),\n\u001b[0;32m     29\u001b[0m                     seq_type[i, ix\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m                 \u001b[39mfor\u001b[39;00m i, ix \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idxs)]\n\u001b[0;32m     31\u001b[0m     features \u001b[39m=\u001b[39m (seq_items, tf\u001b[39m.\u001b[39mstack(seq_type_new, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), seq_time)\n\u001b[0;32m     32\u001b[0m     preds \u001b[39m=\u001b[39m model(features, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1038\u001b[0m, in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\n\u001b[0;32m   1034\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1035\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstrided_slice\u001b[39m\u001b[39m\"\u001b[39m, [tensor] \u001b[39m+\u001b[39m begin \u001b[39m+\u001b[39m end \u001b[39m+\u001b[39m strides,\n\u001b[0;32m   1036\u001b[0m     skip_on_eager\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m name:\n\u001b[0;32m   1037\u001b[0m   \u001b[39mif\u001b[39;00m begin:\n\u001b[1;32m-> 1038\u001b[0m     packed_begin, packed_end, packed_strides \u001b[39m=\u001b[39m (stack(begin), stack(end),\n\u001b[0;32m   1039\u001b[0m                                                 stack(strides))\n\u001b[0;32m   1040\u001b[0m     \u001b[39mif\u001b[39;00m (packed_begin\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64 \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m         packed_end\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64 \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m         packed_strides\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64):\n\u001b[0;32m   1043\u001b[0m       \u001b[39mif\u001b[39;00m packed_begin\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtypes\u001b[39m.\u001b[39mint64:\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1424\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1422\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1423\u001b[0m     \u001b[39m# If the input is a constant list, it can be converted to a constant op\u001b[39;00m\n\u001b[1;32m-> 1424\u001b[0m     \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(values, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1425\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1426\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Input list contains non-constant tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1691\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1692\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   1694\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1695\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1697\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1698\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    342\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\Enric\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.5/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.3/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.3/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=16, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, target, session = batch\n",
    "    seq_items, seq_type, seq_time = features\n",
    "    idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 52244it [2:47:45,  5.19it/s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c4b929e2472036a63dc2b4145b104daea13432f82a7dbc65e279332da4f8b2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
