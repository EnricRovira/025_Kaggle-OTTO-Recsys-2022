{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 20:58:37.672630: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 20:58:37.729092: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-25 20:58:37.744263: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-25 20:58:37.999859: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-25 20:58:37.999887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-11-25 20:58:37.999889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 20:58:38.284436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 20:58:38.297594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 20:58:38.297678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 8290216.57it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.4/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "\n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4RecDataLoader:\n",
    "    \"\"\"\n",
    "    Class that iterates over tfrecords in order to get the sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_paths, num_items, seq_len, batch_size, num_targets=-1, mask_prob=0.4, \n",
    "                 reverse_prob=0.2, get_session=False, get_only_first_on_val=False, seq_len_target=None,\n",
    "                 min_size_seq_to_mask=2, is_val=False, is_test=False, avoid_repeats=False, shuffle=False, drop_remainder=False):\n",
    "        self.list_paths = list_paths\n",
    "        self.num_items = num_items\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_targets = num_targets\n",
    "        self.mask_prob = mask_prob\n",
    "        self.reverse_prob = tf.constant(reverse_prob)\n",
    "        self.shuffle = shuffle\n",
    "        self.min_size_seq_to_mask = min_size_seq_to_mask\n",
    "        self.avoid_repeats = avoid_repeats\n",
    "        self.get_session = get_session\n",
    "        self.seq_len_target = seq_len if not seq_len_target else seq_len_target\n",
    "        self.get_only_first_on_val = get_only_first_on_val\n",
    "        self.is_val = is_val\n",
    "        self.is_test = is_test\n",
    "        self.drop_remainder = drop_remainder\n",
    "\n",
    "    def get_generator(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.list_paths, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "        dataset = dataset.map(self.parse_tf_record, num_parallel_calls=AUTO)\n",
    "        if self.is_val:\n",
    "            dataset = dataset.map(self.make_transforms_val, num_parallel_calls=AUTO)\n",
    "        elif self.is_test:\n",
    "            dataset = dataset.map(self.make_transforms_test, num_parallel_calls=AUTO)\n",
    "        else:\n",
    "            dataset = dataset.map(self.make_transforms_train, num_parallel_calls=AUTO)\n",
    "        \n",
    "        dataset = dataset.map(self.set_shapes, num_parallel_calls=AUTO)\n",
    "        # dataset = dataset.map(self.normalize_features, num_parallel_calls=AUTO)\n",
    "        if self.shuffle:\n",
    "            dataset = dataset.shuffle(self.batch_size*50, reshuffle_each_iteration=True)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, num_parallel_calls=AUTO, drop_remainder=self.drop_remainder).prefetch(AUTO)\n",
    "        return dataset\n",
    "\n",
    "    def parse_tf_record(self, data):\n",
    "        features_context = {\n",
    "             \"session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "             \"size_session\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if not self.is_val:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        else:\n",
    "            features_seq = {\n",
    "                \"seq_aid\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_aid_target\" : tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_type_target\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=False),\n",
    "                \"seq_time_encoding\": tf.io.FixedLenSequenceFeature(shape=[8], dtype=tf.float32, allow_missing=False),\n",
    "                \"seq_recency_aid\": tf.io.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=False)\n",
    "            }\n",
    "        data_context, data_sequence = tf.io.parse_single_sequence_example(data, context_features=features_context, sequence_features=features_seq)\n",
    "        return data_context, data_sequence\n",
    "\n",
    "    def pad_sequence(self, seq_to_pad, maxlen, return_pad_mask=False, dtype=tf.float32):\n",
    "        length, num_feats = tf.shape(seq_to_pad)[0], tf.shape(seq_to_pad)[-1]\n",
    "        ###\n",
    "        if length < maxlen:\n",
    "            pad = tf.zeros((maxlen - length, num_feats), dtype)\n",
    "            seq = tf.concat([seq_to_pad, pad], axis=0)\n",
    "            pad_mask = tf.concat([tf.ones(tf.shape(seq_to_pad), dtype=seq_to_pad.dtype), \n",
    "                                 pad], axis=0)\n",
    "        else:\n",
    "            seq = seq_to_pad[-maxlen:, :]\n",
    "            pad_mask = tf.ones((maxlen, tf.shape(seq_to_pad)[-1]), dtype=seq_to_pad.dtype)\n",
    "        if return_pad_mask:\n",
    "            return seq, pad_mask\n",
    "        return seq \n",
    "\n",
    "    def make_transforms_val(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        seq_items_target_raw, seq_type_target_raw =  dict_sequences['seq_aid_target'], dict_sequences['seq_type_target']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ###\n",
    "        # Build target\n",
    "        seq_items, seq_target = seq_items, seq_items_target_raw[:1] if not self.get_session else seq_items_target_raw[:self.seq_len_target]\n",
    "        seq_type, seq_type_target = seq_type, seq_type_target_raw[:1] if not self.get_session else seq_type_target_raw[:self.seq_len_target]\n",
    "        seq_items_target = tf.concat([seq_items, seq_target], axis=0)\n",
    "        seq_type_target = tf.concat([seq_type, seq_type_target], axis=0)\n",
    "        ###\n",
    "        #Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, seq_type_target[:1]], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        seq_recency = tf.concat([seq_recency, tf.zeros((1, tf.shape(seq_recency)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        idx_masked = tf.clip_by_value(tf.shape(seq_items)[0], 0, self.seq_len-1)\n",
    "        seq_items, _ = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_items_target = self.pad_sequence(seq_items_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "        seq_type_target = self.pad_sequence(seq_type_target, maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)\n",
    "        \n",
    "        if self.get_session:\n",
    "            seq_items_target_all = self.pad_sequence(seq_items_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64)  \n",
    "            seq_type_target_all = self.pad_sequence(seq_type_target_raw[:self.seq_len_target], maxlen=self.seq_len_target, return_pad_mask=False, dtype=tf.int64) \n",
    "            return (seq_items, seq_type, seq_time_encoding, seq_recency), (seq_items_target_all[:, 0], seq_type_target_all[:, 0], idx_masked), session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), seq_items_target[:, 0]\n",
    "\n",
    "    def make_transforms_test(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        session, qt_size_seq = dict_context['session'], dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ###\n",
    "        seq_items = seq_items[-self.seq_len:, :]\n",
    "        seq_type = seq_type[-self.seq_len:, :]\n",
    "        seq_time_encoding = seq_time_encoding[-self.seq_len:, :]\n",
    "        seq_recency = seq_recency[-self.seq_len:, :]\n",
    "        idx_masked = tf.clip_by_value(tf.shape(seq_items)[0], 0, self.seq_len-1)\n",
    "        # Mask last position\n",
    "        seq_items = tf.concat([seq_items, tf.zeros((1, tf.shape(seq_items)[1]), tf.int64)], axis=0)\n",
    "        seq_type = tf.concat([seq_type, tf.zeros((1, tf.shape(seq_type)[1]), tf.int64)], axis=0)\n",
    "        seq_time_encoding = tf.concat([seq_time_encoding, tf.zeros((1, tf.shape(seq_time_encoding)[1]), tf.float32)], axis=0)\n",
    "        seq_recency = tf.concat([seq_recency, tf.zeros((1, tf.shape(seq_recency)[1]), tf.float32)], axis=0)\n",
    "        ###\n",
    "        seq_items, _ = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)   \n",
    "        if self.get_session:\n",
    "            return (seq_items, seq_type, seq_time_encoding, seq_recency), idx_masked, session\n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), idx_masked\n",
    "\n",
    "  \n",
    "    def make_transforms_train(self, dict_context, dict_sequences):\n",
    "        seq_items, seq_type, seq_time_encoding, seq_recency =  dict_sequences['seq_aid'], dict_sequences['seq_type'], dict_sequences['seq_time_encoding'], dict_sequences['seq_recency_aid']\n",
    "        qt_size_seq = dict_context['size_session']\n",
    "        seq_recency = self.normalize_features(seq_recency)\n",
    "        ### \n",
    "        # With prob reverse\n",
    "        if tf.random.uniform(shape=(1,1)) <= self.reverse_prob:\n",
    "            seq_items = tf.reverse(seq_items, axis=[0])\n",
    "            seq_type = tf.reverse(seq_type, axis=[0])\n",
    "            seq_time_encoding = tf.reverse(seq_time_encoding, axis=[0])\n",
    "            seq_recency = tf.reverse(seq_recency, axis=[0])\n",
    "            \n",
    "        # If our seq is longer than seq_len we can use it for data augmentation purpose \n",
    "        # and select a random idx to begin with.\n",
    "        if tf.shape(seq_items)[0] > self.seq_len:\n",
    "            idx_list = tf.range(tf.shape(seq_items)[0]-self.seq_len) \n",
    "            rand_idx = tf.random.shuffle(idx_list)[0]\n",
    "            seq_items = seq_items[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_type = seq_type[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_time_encoding = seq_time_encoding[rand_idx:(rand_idx+self.seq_len), :]\n",
    "            seq_recency = seq_recency[rand_idx:(rand_idx+self.seq_len), :]\n",
    "        \n",
    "        qt_size_seq = tf.shape(seq_items)[0]\n",
    "\n",
    "        ## Get idxs to mask for inputs and targets\n",
    "        probs = tf.random.uniform(shape=(qt_size_seq,), minval=0, maxval=1)\n",
    "        idxs_inputs = tf.cast(tf.where(probs >= (1-self.mask_prob)), tf.int64) # -> we mask to zero the inputs as we dont want to leak \n",
    "        idxs_target = tf.cast(tf.where(probs < (1-self.mask_prob)), tf.int64) # -> we mask to zero the targets as the loss will only be applied on non zero\n",
    "\n",
    "        # If all items are masked we leave an item unmasked\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.cast(qt_size_seq, tf.int64):\n",
    "            idxs_target = idxs_inputs[-1:]\n",
    "            idxs_inputs = idxs_inputs[:-1]\n",
    "            \n",
    "        # If no item has been masked we leave at least one item masked(be careful of size=1 seqs)\n",
    "        if tf.cast(tf.shape(idxs_inputs)[0], tf.int64) == tf.constant(0, dtype=tf.int64):\n",
    "            all_idxs = tf.cast(tf.random.shuffle(tf.range(0, qt_size_seq)), dtype=tf.int64)\n",
    "            idxs_inputs = all_idxs[:1][:, tf.newaxis]\n",
    "            idxs_target = all_idxs[1:][:, tf.newaxis]\n",
    "\n",
    "        # Mask inputs and targets\n",
    "        seq_items_raw = seq_items\n",
    "        updates_items = tf.zeros((len(idxs_inputs), seq_items.shape[-1]), tf.int64)\n",
    "        # updates_type = tf.zeros((len(idxs_inputs), seq_type.shape[-1]), tf.int64)\n",
    "        updates_time_encoding = tf.zeros((len(idxs_inputs), seq_time_encoding.shape[-1]), tf.float32)\n",
    "        updates_recency = tf.zeros((len(idxs_inputs), seq_recency.shape[-1]), tf.float32)\n",
    "        updates_target = tf.zeros((len(idxs_target), seq_items_raw.shape[-1]), tf.int64)\n",
    "        \n",
    "        seq_items = tf.tensor_scatter_nd_update(seq_items, idxs_inputs, updates_items)\n",
    "        # seq_type = tf.tensor_scatter_nd_update(seq_type, idxs_inputs, updates_type)\n",
    "        seq_time_encoding = tf.tensor_scatter_nd_update(seq_time_encoding, idxs_inputs, updates_time_encoding)\n",
    "        seq_recency = tf.tensor_scatter_nd_update(seq_recency, idxs_inputs, updates_recency)\n",
    "        seq_target = tf.tensor_scatter_nd_update(seq_items_raw, idxs_target, updates_target)\n",
    "        \n",
    "        # Padding\n",
    "        seq_items, pad_mask = self.pad_sequence(seq_items, maxlen=self.seq_len, return_pad_mask=True, dtype=tf.int64)\n",
    "        seq_type = self.pad_sequence(seq_type, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)\n",
    "        seq_time_encoding = self.pad_sequence(seq_time_encoding, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32) \n",
    "        seq_recency = self.pad_sequence(seq_recency, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.float32)  \n",
    "        seq_target = self.pad_sequence(seq_target, maxlen=self.seq_len, return_pad_mask=False, dtype=tf.int64)  \n",
    "\n",
    "        return (seq_items, seq_type, seq_time_encoding, seq_recency), seq_target[:, 0]\n",
    "  \n",
    "    def normalize_features(self, features):\n",
    "        return (features - tf.constant(5.45)/tf.constant(1.09))\n",
    "\n",
    "    # def normalize_features(self, features, targets=None, session=None):\n",
    "    #     seq_items, seq_type, seq_time_encoding, seq_recency = features\n",
    "    #     seq_recency = (seq_recency - tf.constant(5.45)/tf.constant(1.09))\n",
    "    #     features = (seq_items, seq_type, seq_time_encoding, seq_recency)\n",
    "    #     return features, targets, session\n",
    "\n",
    "    def set_shapes(self, features, targets=None, session=None):\n",
    "        features[0].set_shape((self.seq_len, 1))\n",
    "        features[1].set_shape((self.seq_len, 1))\n",
    "        features[2].set_shape((self.seq_len, 8))\n",
    "        features[3].set_shape((self.seq_len, 1))\n",
    "        if self.get_session:\n",
    "            return features, targets, session\n",
    "        return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 20:58:39.982173: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 20:58:39.982864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 20:58:39.982969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 20:58:39.983020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 20:58:40.248065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 20:58:40.248150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 20:58:40.248198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 20:58:40.248246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21843 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 20, 1]), TensorShape([32, 20, 1]), TensorShape([32, 20, 8]), TensorShape([32, 20, 1])]\n",
      "[1212417       0       0       0       0  171550       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0]\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[      0  400243 1159498  526989  505110       0       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.4/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=train')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=None,\n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.4, \n",
    "                                     reverse_prob=0.25, \n",
    "                                     get_session=False,\n",
    "                                     is_val=False,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "# Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    break\n",
    "\n",
    "# # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     idx_mask = target\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     target, type_target, idx_mask = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 2\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(idx_mask[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time, seq_recency\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
    "    def __init__(self, tied_to=None, activation=None, **kwargs):\n",
    "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.custom_weights = self.tied_to.weights[0]\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.tied_to.weights[0].shape[0]\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'activation': tf.keras.activations.serialize(self.activation)}\n",
    "        base_config = super(EmbeddingTransposed, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class EncoderTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, attention_axes=None, drop_rate=0.1, att_drop_rate=0.1):\n",
    "        super(EncoderTransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, attention_axes=attention_axes, dropout=att_drop_rate)\n",
    "        self.ffn = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation='gelu'), \n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, query, key, training, attention_mask=None):\n",
    "        attn_output = self.att(query, key, attention_mask=attention_mask, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "      \n",
    "                 \n",
    "class ModelBert4Rec(tf.keras.models.Model):\n",
    "    def __init__(self, num_items, model_cfg):\n",
    "        super(ModelBert4Rec, self).__init__()\n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        self.num_items = num_items\n",
    "        self.model_cfg = model_cfg\n",
    "        self.std_init = np.sqrt(1/(model_cfg.emb_dim*3)).round(4) #0.02 if model_cfg.trf_dim < 1024 else \n",
    "        self.embed_items = tf.keras.layers.Embedding(\n",
    "            num_items, model_cfg.emb_dim, \n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)\n",
    "        )\n",
    "        self.embed_type = tf.keras.layers.Embedding(\n",
    "            3+1, \n",
    "            model_cfg.emb_dim,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)\n",
    "        )\n",
    "        self.mlp_proj_time_encoding = tf.keras.models.Sequential([\n",
    "           tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "           tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)),\n",
    "           tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        ])\n",
    "        # self.mlp_proj_conts = tf.keras.models.Sequential([\n",
    "        #    tf.keras.layers.Dropout(model_cfg.drop_rate), \n",
    "        #    tf.keras.layers.Dense(model_cfg.trf_dim, kernel_initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev=self.std_init)),\n",
    "        #    tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        # ])\n",
    "        self.list_transformer_block = [EncoderTransformerBlock(model_cfg.trf_dim, model_cfg.num_heads, \n",
    "                                                               model_cfg.ff_dim, attention_axes=None, \n",
    "                                                               drop_rate=model_cfg.drop_rate, \n",
    "                                                               att_drop_rate=model_cfg.att_drop_rate) \n",
    "                                       for _ in range(model_cfg.num_layers)]\n",
    "        # policy = mixed_precision.Policy('float32')\n",
    "        self.pred_layer = EmbeddingTransposed(tied_to=self.embed_items, activation='linear', dtype='float32')\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x_seq_past, x_seq_type, x_seq_encoding, x_seq_recency = inputs\n",
    "        pad_mask = tf.cast(tf.where(tf.equal(x_seq_type, 0), 0, 1), tf.float32)\n",
    "        ###########\n",
    "        x_seq_past_items = self.embed_items(x_seq_past[:, :, 0])\n",
    "        x_seq_past_type = self.embed_type(x_seq_type[:, :, 0])\n",
    "        x_seq_time_encoding = self.mlp_proj_time_encoding(x_seq_encoding, training=training)\n",
    "        # x_seq_recency = self.mlp_proj_conts(x_seq_recency, training=training)\n",
    "        x_ones = tf.ones(tf.shape(x_seq_past_items))\n",
    "        ########### \n",
    "        x = x_seq_past_items * (x_ones + x_seq_past_type + x_seq_time_encoding)# + x_seq_recency)\n",
    "        for i in range(len(self.list_transformer_block)):\n",
    "            x = self.list_transformer_block[i](x, x, training=training, attention_mask=pad_mask)\n",
    "        probs = self.pred_layer(x)\n",
    "        return probs\n",
    "      \n",
    "\n",
    "def build_model_bert4Rec(num_items, model_cfg):\n",
    "    return ModelBert4Rec(num_items, model_cfg)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "def custom_loss_bert4rec(tensor_weights=None):\n",
    "    # @tf.function(jit_compile=True)\n",
    "    def loss(y_true, y_pred):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if tensor_weights is not None:\n",
    "            weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "            return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'loss_bert4rec'\n",
    "    return loss\n",
    "\n",
    "def weighted_loss_bert4rec():\n",
    "    # @tf.function(jit_compile=True)\n",
    "    def loss(y_true, y_pred, y_type):\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        y_type = tf.squeeze(y_type, -1)\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "        # w_clicks = tf.cast(y_type==1, tf.float32) * 1#0.1\n",
    "        # w_cart = tf.cast(y_type==2, tf.float32) * 1#0.3\n",
    "        # w_order = tf.cast(y_type==3, tf.float32) * 1#0.6\n",
    "        # weights = tf.reduce_max(tf.stack([w_clicks, w_cart, w_order], axis=-1), -1)\n",
    "        # return tf.reduce_sum(loss * mask * weights) / (tf.reduce_sum(mask * weights) + 1e-8)\n",
    "    loss.__name__ = f'weighted_loss_bert4rec'\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def custom_accuracy():\n",
    "    def masked_accuracy(y_true, y_pred, y_type):\n",
    "        y_pred = tf.argmax(y_pred, axis=2)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        y_type = y_type[:, :, 0]\n",
    "        mask_padding = y_true != 0\n",
    "        mask_clicks = y_type == 1\n",
    "        mask_carts = y_type == 2\n",
    "        mask_orders = y_type == 3\n",
    "        match = y_true == y_pred\n",
    "        match_clicks = match & mask_padding & mask_clicks\n",
    "        match_carts = match & mask_padding & mask_carts\n",
    "        match_orders = match & mask_padding & mask_orders\n",
    "        match_clicks, mask_clicks = tf.cast(match_clicks, dtype=tf.float32), tf.cast(mask_clicks, dtype=tf.float32)\n",
    "        match_carts, mask_carts = tf.cast(match_carts, dtype=tf.float32), tf.cast(mask_carts, dtype=tf.float32)\n",
    "        match_orders, mask_orders = tf.cast(match_orders, dtype=tf.float32), tf.cast(mask_orders, dtype=tf.float32)\n",
    "        mask_padding = tf.cast(mask_padding, dtype=tf.float32)\n",
    "        acc_clicks = tf.reduce_sum(match_clicks)/(tf.reduce_sum(mask_clicks * mask_padding)+1e-8)\n",
    "        acc_carts = tf.reduce_sum(match_carts)/(tf.reduce_sum(mask_carts * mask_padding)+1e-8)\n",
    "        acc_orders = tf.reduce_sum(match_orders)/(tf.reduce_sum(mask_orders * mask_padding)+1e-8)\n",
    "        # score = 0.1*acc_clicks + 0.3*acc_carts + 0.6*acc_orders\n",
    "        return acc_clicks, acc_carts, acc_orders\n",
    "    masked_accuracy.__name__ = f'seq_acc'\n",
    "    return masked_accuracy\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "\n",
    "def recall_top_k(top_k=1, seq_len=10):\n",
    "    # @tf.function\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_pred)[0]\n",
    "        y_true = tf.cast(y_true, tf.int64)\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.int32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.int64)\n",
    "        # cum_sum = tf.zeros(n_samples, tf.int32)\n",
    "        result = tf.constant(0, tf.int32)\n",
    "        for i in tf.range(seq_len):\n",
    "            indexes_i = top_index[:, i, :]\n",
    "            is_true = tf.reduce_sum(tf.reduce_max(tf.where(y_true[:, i:i+1]==indexes_i, 1, 0), -1) * mask[:, i])\n",
    "            result += is_true\n",
    "        return tf.cast(result, tf.float32) / (tf.cast(tf.reduce_sum(mask), tf.float32) + 1e-8)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name\n",
    "\n",
    "def set_seed(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAGwCAYAAABiu4tnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZ1UlEQVR4nO3dd3hUZdoG8Hsm01InDVJIpyaEQBIgBKkWQnGtC9iirqsruoog60dxXcvuCu6qq6wCFta+gBhAdEUJCJESeggloSaQkEJISGZSSJt5vz9CRoaEkEnhTLl/1zWX5Mw75zxzNsvcvOed58iEEAJEREREZDG51AUQERER2SoGKSIiIqIOYpAiIiIi6iAGKSIiIqIOYpAiIiIi6iAGKSIiIqIOYpAiIiIi6iCF1AXYM6PRiMLCQri7u0Mmk0ldDhEREbWDEAKVlZUIDAyEXN72nBODVDcqLCxEcHCw1GUQERFRB+Tn5yMoKKjNMQxS3cjd3R1A0/8QHh4eEldDRERE7aHX6xEcHGz6HG8Lg1Q3ar6c5+HhwSBFRERkY9qzLIeLzYmIiIg6iEGKiIiIqIMYpIiIiIg6iEGKiIiIqIMYpIiIiIg6iEGKiIiIqIMYpIiIiIg6iEGKiIiIqIMYpIiIiIg6iEGKiIiIqIMYpIiIiIg6iEGKiIiIqIMYpMgu1TcaYTQKqcsgIiI7xyBFdudUSSWiX/kJL317ROpSiIjIzjFIkd1Zve8c6huN+Gp3HvIv1khdDhER2TEGKbI7OaXVpj9/suOMdIUQEZHdY5AiuyKEwMH8CtPPq/bmQV/bIF1BRERk1xikyK4U6mpxobIOTnIZQrxdUF1vwKo9+VKXRUREdopBiuzKwbwKAEBkgDv+OL43AOCTHbloNBglrIqIiOwVgxTZlYP55QCAIcGeuHNIL/i4qlCoq8WGI8USV0ZERPaIQYrsSvP6qCHBXtAonZCcGAoA+HhbDoRgXykiIupaDFJkNxoMRhwu0AFompECgOQRoVAp5Mg8p8Oe3IsSVkdERPaIQYrsxvHiStQ2GOGuUSDC1xUA4OOmxr1xQQCApWmnpSyPiIjsEIMU2Y1fL+t5Qi6XmbbPGBsBuQzYevwCjlyesSIiIuoKDFJkNzIvB6nBQZ5m20N9XHHH4EAAwJKtp25wVUREZM8YpMhuXDkjdbWnxvUBAGw4UoxTJVU3sCoiIrJnDFJkFyprG3DqQlNAGhLi2eL5/v7uuC3KD0IAy7hWioiIugiDFNmFQ+d0EAII8nKGr5u61TF/HN80K7UuowDnynkzYyIi6jwGKbILbV3WazYk2BOj+vii0SjwQVrOjSmMiIjsGoMU2YWMy7eGaStIAcDTl28bs2pfPop0l7q5KiIisncMUmTzhBCmGanYVtZHXSkxwgfDw71R32jE+1v4DT4iIuocBimyeQUVl1BaVQeFXIaBgdo2x8pkMsy5rR8AYNXefORf5FopIiLqOAYpsnnNs1GRAR7QKJ2uOz4hwgej+viiwSDw759PdnN1RERkzxikyOYdbOf6qCs9P6FpVirlQAFyS6u7oSoiInIEDFJk89rzjb2rxYV44eYBPWEwCry76UT3FEZERHaPQYpsWoPBiMOX75/XWiPOtjx/ea3Ut5mFOHG+sqtLIyIiB8AgRTbteHEl6hqN8NAoEO7jatFro3tpkTSwqdv52xs5K0VERJZjkCKbltF8o+JgT8jlMotf//xt/SGXAT8eLcb+s+VdXB0REdk7Bimyac0LzWMtWB91pf7+7vhtfBAA4PUfsiGE6KLKiIjIETBIkU07mN80i2Tp+qgrPX9bf2iUcuw/W46fjp7vosqIiMgRMEiRzdJdasDpC02tCwYHeXZ4P/5aDR4fFQEAeOPHY2gwGLuiPCIicgAMUmSzDp2rAACEeLvAx03dqX09OTYCPq4q5JZWY+WevC6ojoiIHIHkQWrJkiUIDw+HRqNBfHw8tm3b1ub4tLQ0xMfHQ6PRICIiAsuWLWsxJiUlBVFRUVCr1YiKisLatWstPm5VVRWeeeYZBAUFwdnZGZGRkVi6dGnn3ix1qY404rwWd40Sz93aFwDwzqaTqKxt6PQ+iYjI/kkapFatWoVZs2bhxRdfREZGBkaPHo1JkyYhL6/1GYHc3FxMnjwZo0ePRkZGBhYsWICZM2ciJSXFNCY9PR3Tp09HcnIyMjMzkZycjGnTpmH37t0WHXf27Nn48ccf8eWXXyI7OxuzZ8/Gs88+i2+//bb7TghZpCONONty//AQRPi6oqy6Hku3nu6SfRIRkX2TCQm/ppSQkIC4uDizmZ7IyEjcddddWLhwYYvxc+fOxfr165GdnW3aNmPGDGRmZiI9PR0AMH36dOj1emzYsME0ZuLEifDy8sKKFSvafdzo6GhMnz4dL730kmlMfHw8Jk+ejL/+9a/ten96vR5arRY6nQ4eHh7teg21jxACQ/+2CWXV9Vjz9EjEhXh1yX43Hi3GH77YD5WTHBtnj0GYr2W9qYiIyPZZ8vkt2YxUfX099u/fjwkTJphtnzBhAnbu3Nnqa9LT01uMT0pKwr59+9DQ0NDmmOZ9tve4o0aNwvr161FQUAAhBLZs2YITJ04gKSnpmu+prq4Oer3e7EHd41z5JZRV10PpJENUQNeF1Nui/DC6ry/qDUb87X9ZXbZfIiKyT5IFqdLSUhgMBvj5+Zlt9/PzQ3FxcauvKS4ubnV8Y2MjSktL2xzTvM/2Hnfx4sWIiopCUFAQVCoVJk6ciCVLlmDUqFHXfE8LFy6EVqs1PYKDg69zFqijmhtxRgV4QKN06rL9ymQyvPybKCjkMmzKLsGW4yVdtm8iIrI/ki82l8nMu1ELIVpsu974q7e3Z5/XG7N48WLs2rUL69evx/79+/HWW2/h6aefxqZNm65Z2/z586HT6UyP/Pz8a46lzunKheZX69PTHY+ODAMA/PW7LNQ3sh0CERG1TiHVgX19feHk5NRi9qmkpKTFbFEzf3//VscrFAr4+Pi0OaZ5n+057qVLl7BgwQKsXbsWU6ZMAQDExMTg4MGDePPNN3Hrrbe2Wp9arYZa3bmv4VP7dEUjzrY8d2tfrDtYiJzSanyyIxdPju3dLcchIiLbJtmMlEqlQnx8PFJTU822p6amYuTIka2+JjExscX4jRs3YujQoVAqlW2Oad5ne47b0NCAhoYGyOXmp8fJyQlGI2cnpFbfaMSRwqb1Z0OCu2aR+dXcNUrMndgfALB480mU6Gu75ThERGTjhIRWrlwplEqlWL58ucjKyhKzZs0Srq6u4syZM0IIIebNmyeSk5NN43NycoSLi4uYPXu2yMrKEsuXLxdKpVJ88803pjE7duwQTk5OYtGiRSI7O1ssWrRIKBQKsWvXrnYfVwghxo4dKwYOHCi2bNkicnJyxCeffCI0Go1YsmRJu9+fTqcTAIROp+vMaaKrZOaXi9C534vBr/4kjEZjtx3HYDCKO97bLkLnfi+e+e+BbjsOERFZF0s+vyUNUkII8f7774vQ0FChUqlEXFycSEtLMz33yCOPiLFjx5qN37p1q4iNjRUqlUqEhYWJpUuXttjn6tWrRf/+/YVSqRQDBgwQKSkpFh1XCCGKiorEo48+KgIDA4VGoxH9+/cXb731lkUf3AxS3eOznbkidO734uHlu7v9WIfyK0T4vO9F6NzvxZZj57v9eEREJD1LPr8l7SNl79hHqns8v+og1mQU4Llb+mL2bf26/XivfZeF/+zIRbC3MzbOGgtnVdd9S5CIiKyPTfSRIuooU0fzblpofrU5E/ohUKtB/sVLeHfzyRtyTCIisg0MUmRTdDUNyCmtBgAMCfK8Icd0VSvw2p3RAICPt+XgWDEbrRIRURMGKbIpB89VAADCfFzg5aq6Yce9NcoPEwf6o9EoMH/NYRiNvCJOREQMUmRjurMR5/W8csdAuKkVyMirwBe7zt7w4xMRkfVhkCKb0tyIc7AEQcpfqzH1llq04RjOllXf8BqIiMi6MEiRzRBCIPOcDoA0M1IA8GBCKEZEeONSgwEvfHOIl/iIiBwcgxTZjPyLl3Cxuh4qJzmiAqVpJyGXy/DP3w6Gi8oJe3Iv4vP0M5LUQURE1oFBimxGxuXLepGBHlArpOvlFOztgnmTBgAA3vjxOC/xERE5MAYpshnN/aNiJbqsd6WHeImPiIjAIEU2xNSI0wqC1NWX+P6zI1fqkoiISAIMUmQT6huNOFrY1AjTGoIU0HSJb8HkSADAP348juwiNuokInI0DFJkE7KL9KhvNMLLRYlQHxepyzF5MCEEtwzoiXqDEc+tzEBtg0HqkoiI6AZikCKb0HxZb3CwJ2QymbTFXEEmk+GN38bA102NE+ersGjDMalLIiKiG4hBimyCNa2PupqvmxpvTo0BAHy68wy2HC+RuCIiIrpRGKTIJlhzkAKAcf174tGRYQCAF1YfQmlVnbQFERHRDcEgRVavoqYeuaVNvZqsNUgBwLxJA9Dfzx2lVXWY83UmWyIQETkABimyes2zUeG+rvB0UUlbTBs0Sie8e/8QqBVypJ24gKVpp6UuiYiIuhmDFFk9a7+sd6UB/h74653RAIC3Nh7HrpwyiSsiIqLuxCBFVs+WghQATB0ahHviesEogJkrMnChkuuliIjsFYMUWTUhBDJtLEjJZDL87a5o9O3phpLKOsxalQED10sREdklBimyamfLalBe0wCVQo7IAA+py2k3F5UCSx6Mg7PSCTtOlWHx5pNSl0RERN2AQYqsWvNlvYGBHlApbOvXta+fO16/p2m91OKfT+LnY+clroiIiLqabX0ykcOxtfVRV7s7NggPJoRACOC5FQdx+kKV1CUREVEXYpAiq5Zh40EKAF7+zUAMC/NCZV0j/vD5PlTWNkhdEhERdREGKbJadY0GZBfqAQCxwV4SV9NxKoUcSx6Mh7+HBqcvVGP2qoNs1klEZCcYpMhqZRXqUW8wwttVhWBvZ6nL6ZQe7mp8kBwPlUKOTdkleGfTCalLIiKiLsAgRVbryvVRMplM2mK6wOBgTyy8exAAYPHPp/DjkSKJKyIios5ikCKrZesLzVtzb3wQHrspHAAwe1UmDp2rkLYgIiLqFAYpslr2GKQAYMHkARjbrwcuNRjw+8/2oaDiktQlERFRBzFIkVW6WF2Ps2U1AJouidkThZMc7z0QiwH+7rhQWYfff7qX3+QjIrJRDFJklZpvCxPRwxVaZ6W0xXQDd40Syx8dhh7uahwrrsQf/5uBRoNR6rKIiMhCDFJkleyhf9T19PJ0xn8eGQZnpRN+OXEBL68/CiHYFoGIyJYwSJFVal4fFWvHQQoABgVp8e59QyCTAV/tzsOytBypSyIiIgswSJHVEUKYLu0NseFGnO01YaA//jwlCgDwxo/H8PXefIkrIiKi9mKQIquTW1oN3aUGqBVyDAhwl7qcG+L3o8Lx5NgIAMC8NYeQmsUbHBMR2QIGKbI6zZf1ontpoXRynF/ReRMHYGp8EIwCeOa/B7An96LUJRER0XU4zqcU2Qx77R91PTKZDAvvGYRbI3uirtGI33+2F9lFeqnLIiKiNjBIkdVpDlL21j+qPRROcvz7/jgMC/NCZW0jHvnPHpwprZa6LCIiugYGKbIqtQ0G0yyMvX9j71qcVU74+OFhGODvjpLKOjz48W6cK6+RuiwiImoFgxRZlawiPRoMAj6uKgR5OUtdjmS0Lkp88fsERPRwRUHFJTzw0W4U62qlLouIiK7CIEVW5WBeBYCm9VEymUzaYiTWw12N/z4+AiHeLsi7WIMHPtqFkkqGKSIia8IgRVbFUReaX4u/VoP/PpGAXp7OyCmtxkMf78bF6nqpyyIiossYpMiqmIJUiKekdViTIC8XfPV4Avw81DhxvgoPfbwb5QxTRERWgUGKrEZZVR3yLjYtqo4J8pS2GCsT5uuKrx4fAV83FbKK9Lj/o10oraqTuiwiIofHIEVWI/NcBQCgdw9XaJ2V0hZjhfr0dMOKJ0agh7sax4orcf+Hu1Ci55opIiIpMUiR1fh1obn931+vo/r6uWPVH0bA30ODkyVVmP7hLhTpLkldFhGRw2KQIquRwfVR7RLRww1fP5mIXp7OyC2txrQP0pF/kX2miIikwCBFVsFoFMi8HKQctRGnJUJ8XPD1jESE+rgg/+IlTP8gnR3QiYgkwCBFViG3rBr62kaoFXL093eXuhyb0MvTGV8/mYjePVxRqKvFb5ftxJECndRlERE5FAYpsgrN66MG9dJC6cRfy/by89Bg5R8SMTDQA6VV9bjvw11IP10mdVlERA6Dn1hkFdiIs+N6uKux4g8jMCLCG1V1TTc6/vFIkdRlERE5BAYpsgpsxNk5HholPv3dcCQN9EO9wYinvzqA/+7Ok7osIiK7xyBFkqttMCC7SA+AM1KdoVE6YcmD8bh/eDCMAliw9jD+vfkkhBBSl0ZEZLcYpEhyRwt1aDQK+Lqp0cvTWepybJqTXIbX7x6EZ2/uAwB4K/UE5qUcRoPBKHFlRET2iUGKJJdhasTpCZlMJm0xdkAmk2HOhP547c6BkMuAVfvy8egne6C71CB1aUREdodBiiTXvD4qluujutTDiWH4+JGhcFE5YcepMvx26U6cK2fjTiKirsQgRZLjN/a6z80D/LB6RiL8PNQ4WVKFu97faWp8SkREnccgRZIqrarDufJLkMmAmCCt1OXYpYGBWqz7402IDPBAaVUdpn+Yju8PFUpdFhGRXWCQIkk1N+Ls08MN7hqltMXYsQCtM1bPSMT4/j1Q22DEM//NwD9/Ogajkd/oIyLqDAYpkhQv6904bmoFPn5kGJ4cEwEAeH/LaTzx+T7oa7kInYiooxikSFJsxHljOcllmD85Eu9MHwK1Qo7Nx0pw9/s7kHOhSurSiIhsEoMUScZoFKaFz5yRurHuiu2Fb2aMRIBWg9MXqnHn+zuw9XiJ1GUREdkcBimSTE5pFSrrGuGsdEJ/P3epy3E4g4K0WP/MKAwN9UJlbSN+9+levLvpJNdNERFZgEGKJNPciHNQLy0UTvxVlEIPdzX++8QIPJAQAiGAf206gUc/3YuL1fVSl0ZEZBP46UWS4foo66BSyPH63YPw9rTB0Cjl+OXEBUxZvA0H8sqlLo2IyOpJHqSWLFmC8PBwaDQaxMfHY9u2bW2OT0tLQ3x8PDQaDSIiIrBs2bIWY1JSUhAVFQW1Wo2oqCisXbu2Q8fNzs7GHXfcAa1WC3d3d4wYMQJ5eXkdf7Nkht/Ysy73xAVh3R9vQoSvK4p0tZi2LB3/2Z7Lmx4TEbVB0iC1atUqzJo1Cy+++CIyMjIwevRoTJo06ZphJTc3F5MnT8bo0aORkZGBBQsWYObMmUhJSTGNSU9Px/Tp05GcnIzMzEwkJydj2rRp2L17t0XHPX36NEaNGoUBAwZg69atyMzMxEsvvQSNRtN9J8SBXKo34FhxJQAGKWsywN8D3z5zE6YMCkCjUeC177Pw9FcHoKthiwQiotbIhIT/3ExISEBcXByWLl1q2hYZGYm77roLCxcubDF+7ty5WL9+PbKzs03bZsyYgczMTKSnpwMApk+fDr1ejw0bNpjGTJw4EV5eXlixYkW7j3vfffdBqVTiiy++6PD70+v10Gq10Ol08PDw6PB+7NHeMxcxdVk6erqrsXvBLbxZsZURQuDTnWfw+g/ZaDAIBGo1eOe+WAwP95a6NCKibmfJ57dkM1L19fXYv38/JkyYYLZ9woQJ2LlzZ6uvSU9PbzE+KSkJ+/btQ0NDQ5tjmvfZnuMajUb873//Q79+/ZCUlISePXsiISEB69ata/M91dXVQa/Xmz2odc0dzYcEezJEWSGZTIbf3RSOlKdGIszHBYW6Wtz3YTreTj2BRoNR6vKIiKyGZEGqtLQUBoMBfn5+Ztv9/PxQXFzc6muKi4tbHd/Y2IjS0tI2xzTvsz3HLSkpQVVVFRYtWoSJEydi48aNuPvuu3HPPfcgLS3tmu9p4cKF0Gq1pkdwcHA7zoRj4kJz2xAT5InvZ47GvXFBMApg8eaTmP7hLuRfrJG6NCIiqyD5YvOrZyOEEG3OULQ2/urt7dlnW2OMxqZ/cd95552YPXs2hgwZgnnz5uH2229vdXF7s/nz50On05ke+fn51xzr6LjQ3Ha4qRV4a9pgvHvfELirFdh/thyTF2/Dd5m88TERkWRBytfXF05OTi1mn0pKSlrMFjXz9/dvdbxCoYCPj0+bY5r32Z7j+vr6QqFQICoqymxMZGRkm9/aU6vV8PDwMHtQSyWVtSiouASZrKmHFNmGO4f0wg/PjUZsiCcqaxvx7IoMPL/qIBeiE5FDkyxIqVQqxMfHIzU11Wx7amoqRo4c2eprEhMTW4zfuHEjhg4dCqVS2eaY5n2257gqlQrDhg3D8ePHzcacOHECoaGhFr5Tulpmvg4A0LenG9w1SomrIUsEe7vg6ycT8ezNfSCXAWsyCpD0zi9IO3FB6tKIiKQhJLRy5UqhVCrF8uXLRVZWlpg1a5ZwdXUVZ86cEUIIMW/ePJGcnGwan5OTI1xcXMTs2bNFVlaWWL58uVAqleKbb74xjdmxY4dwcnISixYtEtnZ2WLRokVCoVCIXbt2tfu4QgixZs0aoVQqxYcffihOnjwp/v3vfwsnJyexbdu2dr8/nU4nAAidTteZ02R3/vFjtgid+714YfVBqUuhTth35qIY988tInTu9yJ07vdiXsohUVnbIHVZRESdZsnnt6RBSggh3n//fREaGipUKpWIi4sTaWlppuceeeQRMXbsWLPxW7duFbGxsUKlUomwsDCxdOnSFvtcvXq16N+/v1AqlWLAgAEiJSXFouM2W758uejTp4/QaDRi8ODBYt26dRa9Nwap1j3wUboInfu9+GrXWalLoU6qqWsUr6w/YgpTNy3aLHaeKpW6LCKiTrHk81vSPlL2jn2kWjIaBQa/uhGVdY34YeZoRAXyvNiD9NNleOGbTJwrvwQAeHRkGF5I6g9XtULiyoiILGcTfaTIMZ2+UIXKukY4K53Qz89N6nKoiyT29sGPs8bg/uEhAIBPd57BhH/9gi3HSySujIioezFI0Q2VcbntwaAgLRRO/PWzJ25qBRbeMwifPTYcvTydUVBxCb/7ZC9mrcxAWVWd1OUREXULfpLRDdXcPyqW/aPs1th+PbBx9hj8flQ45DJg3cFC3Pp2GtYcOMcbIBOR3WGQohvqylvDkP1yVSvw0u1RWPv0TRjg747ymgY8/3UmHv7PHnZFJyK7wiBFN8ylegOOn68EwFvDOIrBwZ747tlReCGpP1QKObadLMWtb6dh8eaTqG0wSF0eEVGnMUjRDXO4QAeDUcDPQ40ArbPU5dANonSS44/j++DH50ZjZG8f1DUa8XbqCSS9w8XoRGT7Ohyk6uvrcfz4cTQ2NnZlPWTHDuaXA+BlPUcV0cMNXz2egMX3x6Knuxpny2rwu0/24skv9qGg4pLU5RERdYjFQaqmpga///3v4eLigoEDB5ruPTdz5kwsWrSoywsk+/HrjYq9pC2EJCOTyXDH4EBsnjMWj48Kh5Nchp+Onsctb23F+1tOoa6Rl/uIyLZYHKTmz5+PzMxMbN26FRqNxrT91ltvxapVq7q0OLIvXGhOzdw1Svz59ij8MHM0hod7o7bBiH/+dBwT/vULfjxSzG/3EZHNsDhIrVu3Du+99x5GjRoFmUxm2h4VFYXTp093aXFkP0r0tSjU1UIuA2KCtFKXQ1aiv787Vv1hBN6eNhg9Ll/um/Hlftz34S4cKdBJXR4R0XVZHKQuXLiAnj17ttheXV1tFqyIrtTciLOfnztvG0JmZDIZ7okLwtY/jcMz4/tArZBjd+5F/Oa97fi/bzJRUlkrdYlERNdkcZAaNmwY/ve//5l+bg5PH330ERITE7uuMrIrv66P8pS0DrJermoF/pTUH5vnjMVvBgdCCODrfecw/p9N66fYLoGIrJHFUwMLFy7ExIkTkZWVhcbGRrz77rs4evQo0tPTkZaW1h01kh3g+ihqryAvF/z7/lg8OjIUr32fjcz8Cvzzp+P47+48zL6tH+6O7QUnOWe/icg6WDwjNXLkSOzYsQM1NTXo3bs3Nm7cCD8/P6SnpyM+Pr47aiQbZzAKHDpXAYCNOKn94kO9sfapkXhn+hAEaDUoqLiEP63OxKR3f0Fq1nkuSCciqyAT/Nuo2+j1emi1Wuh0Onh4eEhdjmSOF1ci6Z1f4KpywqFXkjibQBarbTDg051nsGTLKehrm3rXDQ31wtxJAzAszFvi6ojI3ljy+W3xjJSTkxNKSlp2Iy4rK4OTk5OluyMH0NyIc1CQliGKOkSjdMKMsb2x7f9uxlPjekOjlGPf2XJMXZaO33+6F8eK9VKXSEQOyuIgda0JrLq6OqhUqk4XRPaHjTipq2hdlJg7cQDSXhiP+4eHwEkuw+ZjJZj07jY8v+ogzpZVS10iETmYdi82X7x4MYCmb+l9/PHHcHNzMz1nMBjwyy+/YMCAAV1fIdm8DC40py7m56HBwnsG4fHR4Xh74wn873AR1mQU4NvMQtwT2wvP3NwHoT6uUpdJRA6g3WukwsPDAQBnz55FUFCQ2WU8lUqFsLAwvPbaa0hISOieSm0Q10gB1XWNGPTKTzAKYPeCW+Dnobn+i4gslJlfgX9tOoGtxy8AAJzkMtwb1wvPjO+LEB8XiasjIltjyed3u2ekcnNzAQDjx4/HmjVr4OXFyzR0fYcLdDAKIECrYYiibjM42BOf/m44DuSV491NJ5F24gK+3ncOKQcKGKiIqFtZvEZqy5YtDFHUbmzESTdSXIgXPntsONY8PRJj+/WAwSiamnq+tRX/900m8spqpC6RiOxMh+7Vce7cOaxfvx55eXmor683e+7tt9/uksLIPrARJ0mhOVBdPUP1zf5z+M3gQMwY2xuRAY55uZ2IupbFQWrz5s244447EB4ejuPHjyM6OhpnzpyBEAJxcXHdUSPZMM5IkZSaA9X+s+VYvLkpUH17sBDfHizE+P498NS4Phgezj5URNRxFl/amz9/PubMmYMjR45Ao9EgJSUF+fn5GDt2LKZOndodNZKNKtbVolhfCye5DIOCtFKXQw4sPrQpUH3/7CjcHhMAuQzYcvwCpn2Qjt8u3YnN2edhNLI3MRFZzuIglZ2djUceeQQAoFAocOnSJbi5ueG1117DG2+80eUFku1qbsTZz88dLqoOXUUm6lLRvbR474E4/DxnHB5ICIHKqamx5+8/24dJ727D2oxzaDAYpS6TiGyIxUHK1dUVdXV1AIDAwECcPn3a9FxpaWnXVUY2L4OX9chKhfm64vW7B2H73PF4cmwE3NQKHD9fidmrMjHmH1uwLO00dDUNUpdJRDbA4mmCESNGYMeOHYiKisKUKVMwZ84cHD58GGvWrMGIESO6o0ayUc0LzWMZpMhK9fTQYP6kSDw9rg++3HUWn+zIRZGuFos2HMPizScxNT4Iv7spHGG+bO5JRK2z+KbFOTk5qKqqQkxMDGpqavCnP/0J27dvR58+ffCvf/0LoaGh3VWrzXHkhpwGo8CgV35CTb0BG2ePQT8/d6lLIrquukYD1h8sxPLtuThWXAkAkMmAWwb44fHR4UgI94ZMxvtFEtk7Sz6/LQ5S1H6OHKSyi/SY9O42uKqccOiVJN6smGyKEAI7T5fh42052HK5WzoADAz0wO9HhWPyoABolLxJO5G9suTz2+I1UteyZs0axMTEdNXuyMZlXl4fFRPkyRBFNkcmk+GmPr745HfDsen5sXgwIQQapRxHC/V4/utMjFz0M9748RjOlbPBJ5GjsyhIffTRR5g6dSoeeOAB7N69GwDw888/IzY2Fg899BASExO7pUiyPab+USGektZB1Fl9errh73cPQvq8W/BCUn8EaDW4WF2PpVtPY8w/tuDxz/Yi7cQFtk8gclDtvrT35ptvYsGCBYiJiUF2djYA4MUXX8Tbb7+NZ599Fn/84x/h6+vbrcXaGke+tDfxnV9wrLgSHyTHI2mgv9TlEHWZRoMRm7JL8OWus9h+6tdvKof5uOChEaGYGh8MrYtSwgqJqLO6ZY1UZGQkXnjhBTz22GPYunUrbr75Ztx888345ptv4Onp2RV12x1HDVLVdY0Y9MpPMApgz4Jb0JM3KyY7dfpCFb5IP4uU/edQWdcIANAo5bhzcC88kBCCmCAtF6cT2aBuCVIuLi44duwYQkJCAABqtRq//PILEhISOl+xnXLUIJV+ugz3f7QLgVoNds6/RepyiLpdTX0j1mUU4vP0M6Zv+wFAZIAH7hsWjLuG9OIsFZENseTzu919pGpra6HR/DqzoFKp0KNHj45XSXaL66PI0bioFHggIQT3Dw/G/rPl+HLXWfxwpBjZRXq8vP4oXv8hG5MHBWD6sGC2UCCyMxY15Pz444/h5uYGAGhsbMSnn37aYl3UzJkzu646sknNt4ZhR3NyNDKZDEPDvDE0zBuv1jRg3cECrNiTh2PFlVibUYC1GQUI93XF9GHBuDcuCD3c1VKXTESd1O5Le2FhYdf9V5RMJkNOTk6XFGYPHPXSXsLrm3BeX4evn0zE8HBvqcshkpQQAofO6bBybx7WHyxEdb0BAKCQy3DzgJ64Jy4INw/oCZWiy7rREFEnsSGnlXDEIFWku4TEhT/DSS7DkVeS4Kxi00KiZtV1jfjfoSKs2JuHjMu3UAIATxcl7hgciHvigjCYC9SJJNcta6SI2qP5/nr9/dwZooiu4qpWYNqwYEwbFowT5yuRcuAc1mUU4Ly+Dp+nn8Xn6WfRu4cr7okLwt2xvRDo6Sx1yUR0HZyR6kaOOCO18IdsfPBLDh5ICMHrdw+Suhwiq2cwCuw4VYo1B87hx6PFqG0wAmi6x19ihA/uiQvCpGh/uKr5716iG4UzUiSZjOZv7HGhOVG7OMllGNOvB8b064HK2gZsOFKMNQfOYVfORew8XYadp8vw0rojSBrohzuGBGJUnx5cT0VkRRikqMs0Gow4fE4HAIhlkCKymLtGiWlDgzFtaDDOlddgXUYBUg4UILe0GusOFmLdwUJ4uigxKdofv4kJREKED+9lSSQxXtrrRo52aS+rUI/Ji7fBXa1A5ssTIOdf8ESdJoRARn4F1h8sxP8OF+FCZZ3puR7uakwZFIA7hgQiNtiTi9SJuki3XtrT6/WtbpfJZFCr1VCpVJbukuxEcyPOmGAtQxRRF5HJZIgL8UJciBdeuj0Ku3PK8N2hQvxwuBgXKuvw6c4z+HTnGQR5OeP2mED8ZnAAogI8GKqIbhCLg5SnZ9v/6gkKCsKjjz6Kl19+GXI5r+M7EjbiJOpeTnIZRvbxxcg+vnj1jmhsO3kB32UWYmPWeZwrv4RlaaexLO00QrxdMCnaHxOj/TGEM1VE3criIPXpp5/ixRdfxKOPPorhw4dDCIG9e/fis88+w5///GdcuHABb775JtRqNRYsWNAdNZOVMt0aJthL2kKIHIBKIcctkX64JdIPl+oN+PlYCdZnFmDr8QvIu1iDD37JwQe/5CBAq0HSQH9MHhSA+FAvrqki6mIWr5G65ZZb8OSTT2LatGlm27/++mt88MEH2Lx5M7744gv8/e9/x7Fjx7q0WFvjSGukKmsbEPPqRggB7H3xVt76gkgi1XWN2Hr8AjYcKcKWYyWmTuoA4OumRtJAP0yKDkBChDeUTrxqQNSabu1s7uLigszMTPTt29ds+8mTJzF48GDU1NQgNzcXAwcORE1NjeXV2xFHClI7T5XigY93o5enM3bMu1nqcogIQG2DAdtOlmLDkSJsyjoPfW2j6TlPFyVui/TDxGh/3NTHFxolG+gSNevWxeZBQUFYvnw5Fi1aZLZ9+fLlCA4OBgCUlZXBy4uXdxyJqX9UiKekdRDRrzRKJ9wW5YfbovxQ32hEek4ZfjxShI1Hz6Osuh6r95/D6v3n4Kx0wqi+vrgt0g/jB/TkjDKRBSwOUm+++SamTp2KDRs2YNiwYZDJZNi7dy+OHTuGb775BgCwd+9eTJ8+vcuLJevVvD6K/aOIrJNKIcfYfj0wtl8P/O0ugT25F/HjkSJsyi5BQcUlpGadR2rWechkTf8/vjXKD7dF+qFPTzcuVidqQ4f6SJ05cwbLli3DiRMnIITAgAED8OSTTyIsLKwbSrRdjnJpTwiB4a9vxoXKOnwzIxFDw7ylLomI2kkIgeyiSmzKPo9N2edx6HJT3WahPi64NdIPt0b6YWiYF9dVkUPo1jVS1H6OEqQKKi7hpkU/QyGX4cirSVxrQWTDinW12HzsPDZlnceO02WobzSanvPQKDCmXw+M698TY/v14CVAslvdfq+9iooK7NmzByUlJTAajWbPPfzwwx3ZJdmwg3kVAIABAe4MUUQ2zl+rwYMJoXgwIRTVdY3YdrIUm7LP4+djJbhYXY/vDxXh+0NFAIBBvbQY178HxvXvgSHBbK1AjsniIPXdd9/hwQcfRHV1Ndzd3c2unctkMgYpB8RGnET2yVWtwMTLjT0NRoGMvHJsPX4BW0+U4EiBHocLdDhcoMO/fz4FrbOyabbq8g2YOVtFjsLiS3v9+vXD5MmT8frrr8PFxaW76rILjnJpb+qyndh7phxvTh2M38YHSV0OEd0AJZW1+OVEKbYcL8G2ExfMWisAv85Wje7bA7EhnlxbRTalW9dIubq64vDhw4iIiOhUkY7AEYJUg8GIQa/8hNoGIzY9PxZ9erpJXRIR3WCNBiMO5ldg6/EL2HK8BEcLze/J6qpywogIH4zq64vRfX3Ruwe/CUjWrVvXSCUlJWHfvn0MUgQAOF5cidoGI9w1CkT4ukpdDhFJQOEkx9AwbwwN88afkvqjpLIWaccvIO3EBew4VYrymgZsPlaCzcdKAAABWg1u6tMUqm7q4wtfN14GJNtlcZCaMmUKXnjhBWRlZWHQoEFQKpVmz99xxx1dVhxZv1/vr+cJOReaEhGAnu4aTB0ajKlDg2E0CmQV6bHtZCm2n7qAvWfKUaSrxTf7z+Gb/ecAAJEBHhjd1xej+vhiWJg3nFX80grZDosv7cnl177OLZPJYDAYrvm8o3GES3t/Wp2Jb/afw7M398GcCf2lLoeIrFxtgwF7ci9i+6lSbDtZiuwi88uASicZhgR7IjHCByN6+yAuxIvfBqYbrlsv7V3d7oAc25UzUkRE16NROmHM5W/2AcCFyjrsPN0UqnacKkWRrhZ7z5Rj75lyLP75FFQKOWKDPZHY2weJET4YEuIJtYLBiqxHh/pIEQGAvrYBpy9UAWCQIqKO6eGuxp1DeuHOIb0ghEDexRqkny5Dek4Z0k+XoaSyDrtzL2J37kW8g5PQKOWID/VCYoQPEnv7ICaI3wgkabUrSC1evBh/+MMfoNFosHjx4jbHzpw5s0sKI+t3KF8HIYBgb2f4cLEoEXWSTCZDqI8rQn1ccd/wEAghkFNajfTTZdiV0/QorarHjlNl2HGqDADgonJCXIgXhoV5Y1i4F2KDvbjGim6odq2RCg8Px759++Dj44Pw8PBr70wmQ05OTpcWaMvsfY3U+1tO4Z8/HcftMQF474E4qcshIjsnhMCpkirTbNWunDKU1zSYjVHIZYjupcXwcO+mcBXmBU8XlUQVk63q8jVSubm5rf6ZHFvG5VvD8LIeEd0IMpkMff3c0dfPHQ8nhsFoFDhRUom9uRex50w59uZeRLG+FgfzK3AwvwIf/tL0D/t+fm6XQ5U3hoV7o5ens8TvhOwJ10hRhwghTAvNY0M8Ja2FiByTXC7DAH8PDPD3QHJiGIQQOFd+CXtyL2Lf2YvYk3sRpy9U48T5Kpw4X4WvducBAHp5OmNYmBeGhXsjLsQL/fzceZ9A6jCLV+gZDAYsX74cDzzwAG699VbcfPPNZg9LLVmyBOHh4dBoNIiPj8e2bdvaHJ+Wlob4+HhoNBpERERg2bJlLcakpKQgKioKarUaUVFRWLt2baeO++STT0Imk+Gdd96x+P3Zq4KKSyitqoNCLsPAQK3U5RARQSaTIdjbBffGB2HhPTHYPGcc9v/5Vix7KB6/HxWOmCAtnOQyFFRcwrqDhXhx7RFMencbBr+6EQ9+vAtv/nQcPx87j/LqeqnfCtkQi2eknnvuOXz66aeYMmUKoqOjO9Xmf9WqVZg1axaWLFmCm266CR988AEmTZqErKwshISEtBifm5uLyZMn44knnsCXX36JHTt24Omnn0aPHj1w7733AgDS09Mxffp0/PWvf8Xdd9+NtWvXYtq0adi+fTsSEhIsPu66deuwe/duBAYGdvh92qPm2ajIAA/2eCEiq+XjpjbdeBkAqusakZFXgT1nLmLfmYvIzK9AVV2j2QJ2AIjwdcWQEE/EhXghLsQL/f05a0Wts7ghp6+vLz7//HNMnjy50wdPSEhAXFwcli5datoWGRmJu+66CwsXLmwxfu7cuVi/fj2ys7NN22bMmIHMzEykp6cDAKZPnw69Xo8NGzaYxkycOBFeXl5YsWKFRcctKChAQkICfvrpJ0yZMgWzZs3CrFmz2v3+7Hmx+d++z8LH23ORPCIUf70rWupyiIg6xGAUOHG+EgfyynHgbAUy8suRc6G6xTgXlRMGB3kiLrQpXMWGeMHblYvY7VW3NuRUqVTo06dPh4trVl9fj/3792PevHlm2ydMmICdO3e2+pr09HRMmDDBbFtSUhKWL1+OhoYGKJVKpKenY/bs2S3GNF+Wa+9xjUYjkpOT8cILL2DgwIHtek91dXWoq6sz/azX69sYbdvYiJOI7IGTXIbIAA9EBnjgwYRQAEB5dT0O5lfgQF45MvKaFq5X1TU2fVsw59dZqzAfF8SGeCEmSIuYIE8MDOQMvSOyOEjNmTMH7777Lt57771OXdYrLS2FwWCAn5+f2XY/Pz8UFxe3+pri4uJWxzc2NqK0tBQBAQHXHNO8z/Ye94033oBCobCoL9bChQvx6quvtnu8rWowGHG4QAcAGMKF5kRkZ7xcVRg/oCfGD+gJoGnW6mRJJQ6cbQ5X5Th9oRpnympwpqwGazMKADS1Xujn547BwU3BKiZIi35+7mwYaucsDlLbt2/Hli1bsGHDBgwcOLDFTYvXrFlj0f6uDmNCiDYDWmvjr97enn22NWb//v149913ceDAAYvC4vz58/H888+bftbr9QgODm73623F8eJK1DUa4aFRINzHVepyiIi6ldMV3w58IKFpHW1FTT0y8iuQmV+BQ+d0OHSuAqVV9cgq0iOrSI8Ve/IBAGqFHAMDPRAT5InBwVoMDvJEmI8rb/JuRywOUp6enrj77rs7fWBfX184OTm1mH0qKSlpMVvUzN/fv9XxCoUCPj4+bY5p3md7jrtt2zaUlJSYLTw3GAyYM2cO3nnnHZw5c6bV+tRqNdRq++/wnXH5st7gYE/+ZUBEDsnTRYXx/XtifP+mWSshBAp1tTiUX4HMy8Hq8DkdKusacSCvAgcu990DAHeNAjFBWgzq5YnoXh6IDtQixNuFf5/aKIuCVGNjI8aNG4ekpCT4+/t36sAqlQrx8fFITU01C2apqam48847W31NYmIivvvuO7NtGzduxNChQ00zY4mJiUhNTTVbJ7Vx40aMHDmy3cdNTk7GrbfeanacpKQkJCcn43e/+10n3rV9OHj5L4RYro8iIgLQdJWjl6czenk6Y9KgAACA0SiQW1aNQ+cqkJnfFK6OFupRWdvyW4LuagUiA5tCVXQvD0T30iLC1xUKXha0ehYFKYVCgaeeesrsW3Od8fzzzyM5ORlDhw5FYmIiPvzwQ+Tl5WHGjBkAmi6VFRQU4PPPPwfQ9A299957D88//zyeeOIJpKenY/ny5aZv4wFN7RnGjBmDN954A3feeSe+/fZbbNq0Cdu3b2/3cX18fEwzXM2USiX8/f3Rv3//LnnvtuxgfjkAro8iImqLXC5D7x5u6N3DDXfHBgFoWmN64nzl5cuBOmQV6pBdXInKukbsyW1qItpMrZAjMsAD0b08MDBQi+hALfr5u0Gt4IJ2a2Lxpb2EhARkZGQgNDS00wefPn06ysrK8Nprr6GoqAjR0dH44YcfTPsuKipCXl6eaXx4eDh++OEHzJ49G++//z4CAwOxePFiUw8pABg5ciRWrlyJP//5z3jppZfQu3dvrFq1ytRDqj3HpWvTXWrA6ctfDR4c5CltMURENkbpJMfAQC0GBmpx//CmbQ0GI06VVOFooR5HCnQ4WqhDVqEe1fUG0+1uminkTbfJiQ5smrWKCvTAAH93uGuUrR+Qup3FfaRWr16NefPmYfbs2YiPj4erq/li45iYmC4t0JbZYx+pbScvIHn5HoR4u+CX/xsvdTlERHbJaBQ4U1aNI4V6HC3Q4UihDkcL9ai46ibNzYK9nRHp74EBAR6ICnDHAH8PrrvqBEs+vy0OUnJ5y+u1MpnM9K03g8FgWbV2zB6D1L83n8RbqSdwx+BALL4/VupyiIgchhACBRWXcKRAj6OFOhwp0CG7qBLF+tpWx7uonNDf393UJyvS3x0DAjzgpuZtdq+nWxty5ubmdrgwsn1sxElEJA2ZTIYgLxcEebmYbnkDABer63GsWI/sokocK9Iju1iPE+erUFNvQEZeBTKu+MYgAIR4u2CAKWA1zV4Fe7vwFjgdZHGQ4joixyWE+DVIcaE5EZFV8HZVYWRvX4zs7Wva1mgwIre0GllFehwrrkR2kR7HLs9e5V2sQd7FGmzMOm8ar1bI0aenG/r7uaOvnzv6+7uhb0939PJ05uXB6+jw/F5WVhby8vJQX29+l+w77rij00WRdTpXfgll1fVQOskQFWAflyqJiOyRwkmOvpdD0ZUNhVqbvTp5vgp1jUYcLdTjaKH5rc1cVE7o6+eOfj3d0N+/aX/9/Nzg76Hp1N1N7InFQSonJwd33303Dh8+bFobBfzaKZxrpOxXcyPOqADeT4qIyBa1NntlMArkX6zB8fOVOHm+EsfPV+Hk+UqcvtB0eTDzcgf3K7lrFOjn53754Wb6s6+byuEClsVB6rnnnkN4eDg2bdqEiIgI7NmzB2VlZZgzZw7efPPN7qiRrERzI06ujyIish9OchnCfF0R5uuKpIG/rr1qMBhxtqwaJ85X4cT5ysuPKuSWVqOythH7z5Zj/9lys315uShNs1Z9erihd0839Olp3zNYFgep9PR0/Pzzz+jRowfkcjnkcjlGjRqFhQsXYubMmcjIyOiOOskKsBEnEZHjUDrJ0aenO/r0dMfky93aAaCu0YDc0ssBq7jSFLLOXqxBeU1Di8aiAOCqckLvnm6XG5S6os/lP4f6uEKlsO3u7RYHKYPBADc3NwBN960rLCxE//79ERoaiuPHj3d5gWQd6huNOHL52vmQYC+JqyEiIqmoFU6mmzhj8K/baxsMOFXSNHt1qqQKp0qqcPpCFc6W1aC63mDq5n4lJ7kMod4uLUNWTzd42EiTUYuDVHR0NA4dOoSIiAgkJCTgH//4B1QqFT788ENERER0R41kBY4V61HfaISnixJhPi5Sl0NERFZGo3RCdC8tontpzbY3XSKsMQWr083/vVCNqrpG5JRWI6e0Gqk4b/a6nu5q9O7hhogeroho/q+vK4K8rKtVg8VB6s9//jOqq5tuEfK3v/0Nt99+O0aPHg0fHx+sWrWqywsk69Dc9mBwkKfdXucmIqKu13SJsGmt1JWEEDivr8PpC7/OXjX/97y+DiWVTY/0nDKz16mc5Aj1cUG4b1PAGt3XFzf18YVULA5SSUlJpj9HREQgKysLFy9ehJeXFz9g7RgXmhMRUVeSyWTw12rgr9W0CEKVtU33dT1dUoWc0irkXKhGbmnTo67RiJMlVThZUgXgPIQQthWkmp06dQqnT5/GmDFj4O3tDQvvNEM2ho04iYjoRnHXKDEk2LPFP96Nxqbb5OSWViPnQhVySquR2NtHmiIvszhIlZWVYdq0adiyZQtkMhlOnjyJiIgIPP744/D09MRbb73VHXWShHQ1DcgpbbqcOyTIU9piiIjIYcnlMgR7uyDY2wVj+vWQuhwAgMXfOZw9ezaUSiXy8vLg4vLrouPp06fjxx9/7NLiyDocPFcBAAjzcYGXq0raYoiIiKyIxTNSGzduxE8//YSgoCCz7X379sXZs2e7rDCyHlwfRURE1DqLZ6Sqq6vNZqKalZaWQq1Wd0lRZF1MjTgZpIiIiMxYHKTGjBmDzz//3PSzTCaD0WjEP//5T4wfP75LiyPpCSGuWGjORpxERERXsvjS3j//+U+MGzcO+/btQ319Pf7v//4PR48excWLF7Fjx47uqJEklHe55b/KSY7IAHepyyEiIrIqFs9IRUVF4dChQxg+fDhuu+02VFdX45577kFGRgZ69+7dHTWShJpno6ICPaBWOElbDBERkZXpUB8pf39/vPrqq2bb8vPz8dhjj+E///lPlxRG1iGDC82JiIiuqctuuXzx4kV89tlnXbU7shKZl1sfMEgRERG11GVBiuxPfaMRRwv1ABikiIiIWsMgRdeUXaRHfaMRXi5KhPq0bHlBRETk6Bik6JqaF5oPDvbkDamJiIha0e7F5vfcc0+bz1dUVHS2FrIypv5RvKxHRETUqnYHKa1We93nH3744U4XRNaDQYqIiKht7Q5Sn3zySXfWQVamoqYeuaXVABikiIiIroVrpKhVzbNR4b6u8HRRSVsMERGRlWKQolbxsh4REdH1MUhRqxikiIiIro9BiloQQiCTQYqIiOi6GKSohbNlNSivaYBKIUdkgIfU5RAREVktBilqofmy3sBAD6gU/BUhIiK6Fn5KUgtcH0VERNQ+DFLUQgaDFBERUbswSJGZukYDsgv1AIDYYC+JqyEiIrJuDFJkJqtQj3qDEd6uKgR7O0tdDhERkVVjkCIzV66Pkslk0hZDRERk5RikyAwXmhMREbUfgxSZYZAiIiJqPwYpMrlYXY+zZTUAgMEMUkRERNfFIEUmzbeFiejhCq2zUtpiiIiIbACDFJmwfxQREZFlGKTIpHl9VCyDFBERUbswSBEAQAhhurQ3hI04iYiI2oVBigAAuaXV0F1qgFohx4AAd6nLISIisgkMUgTg18t60b20UDrx14KIiKg9+IlJANg/ioiIqCMYpAgAgxQREVFHMEgRahsMyC7SA2CQIiIisgSDFOFooR4NBgFfNxWCvJylLoeIiMhmMEiR2WU9mUwmbTFEREQ2hEGKuD6KiIiogxikyNSIkzcqJiIisgyDlIMrq6pD3sUaAEBMkKe0xRAREdkYBikHl3muAgDQu4crtM5KaYshIiKyMQxSDu5gXgUA3l+PiIioIxikHFxG80LzEE9J6yAiIrJFDFIOzGgUpoXmsVxoTkREZDEGKQeWW1YNfW0j1Ao5+vu7S10OERGRzWGQcmDN66MG9dJC6cRfBSIiIkvx09OBsREnERFR5zBIObCDXGhORETUKQxSDqq2wYDsIj0AzkgRERF1FIOUgzpaqEOjUcDXTY1ens5Sl0NERGSTJA9SS5YsQXh4ODQaDeLj47Ft27Y2x6elpSE+Ph4ajQYRERFYtmxZizEpKSmIioqCWq1GVFQU1q5da9FxGxoaMHfuXAwaNAiurq4IDAzEww8/jMLCws6/YSuRYWrE6QmZTCZtMURERDZK0iC1atUqzJo1Cy+++CIyMjIwevRoTJo0CXl5ea2Oz83NxeTJkzF69GhkZGRgwYIFmDlzJlJSUkxj0tPTMX36dCQnJyMzMxPJycmYNm0adu/e3e7j1tTU4MCBA3jppZdw4MABrFmzBidOnMAdd9zRvSfkBmpeHxXL9VFEREQdJhNCCKkOnpCQgLi4OCxdutS0LTIyEnfddRcWLlzYYvzcuXOxfv16ZGdnm7bNmDEDmZmZSE9PBwBMnz4der0eGzZsMI2ZOHEivLy8sGLFig4dFwD27t2L4cOH4+zZswgJCWnX+9Pr9dBqtdDpdPDw8GjXa26UUW/8jHPll/DV4wm4qY+v1OUQERFZDUs+vyWbkaqvr8f+/fsxYcIEs+0TJkzAzp07W31Nenp6i/FJSUnYt28fGhoa2hzTvM+OHBcAdDodZDIZPD09rzmmrq4Oer3e7GGNSqvqcK78EmQyICZIK3U5RERENkuyIFVaWgqDwQA/Pz+z7X5+figuLm71NcXFxa2Ob2xsRGlpaZtjmvfZkePW1tZi3rx5eOCBB9pMpgsXLoRWqzU9goODrzlWSs2NOPv0cIO7RiltMURERDZM8sXmVy90FkK0ufi5tfFXb2/PPtt73IaGBtx3330wGo1YsmRJG+8EmD9/PnQ6nemRn5/f5nipsBEnERFR11BIdWBfX184OTm1mAUqKSlpMVvUzN/fv9XxCoUCPj4+bY5p3qclx21oaMC0adOQm5uLn3/++brXSdVqNdRqdZtjrAEbcRIREXUNyWakVCoV4uPjkZqaarY9NTUVI0eObPU1iYmJLcZv3LgRQ4cOhVKpbHNM8z7be9zmEHXy5Els2rTJFNRsndEokMkZKSIioi4h2YwUADz//PNITk7G0KFDkZiYiA8//BB5eXmYMWMGgKZLZQUFBfj8888BNH1D77333sPzzz+PJ554Aunp6Vi+fLnp23gA8Nxzz2HMmDF44403cOedd+Lbb7/Fpk2bsH379nYft7GxEb/97W9x4MABfP/99zAYDKYZLG9vb6hUqht1irpcTmkVKusa4ax0Qn8/d6nLISIism1CYu+//74IDQ0VKpVKxMXFibS0NNNzjzzyiBg7dqzZ+K1bt4rY2FihUqlEWFiYWLp0aYt9rl69WvTv318olUoxYMAAkZKSYtFxc3NzBYBWH1u2bGn3e9PpdAKA0Ol07X5Nd/t6b54Infu9mLp0p9SlEBERWSVLPr8l7SNl76yxj9SLaw/jq915+MOYCCyYHCl1OURERFbHJvpIkTT4jT0iIqKuwyDlQC7VG3CsuBIAgxQREVFXYJByIEcKdTAYBXq6qxGg1UhdDhERkc1jkHIgzR3NhwR7ttn0lIiIiNqHQcqBsBEnERFR12KQciBcaE5ERNS1GKQcREllLQoqLkEmA2KCPKUuh4iIyC4wSDmI5vVR/Xq6w00taUN7IiIiu8Eg5SB4WY+IiKjrMUg5CC40JyIi6noMUg7AYBQ4dE4HABjM9VFERERdhkHKAeRcqEJVXSOclU7o5+cmdTlERER2g0HKAWRcvqw3KEgLhRP/JyciIuoq/FR1AM3ro2K50JyIiKhLMUg5gCtvDUNERERdh0HKzl2qN+D4+UoA/MYeERFRV2OQsnOHC3QwGAX8PNQI0DpLXQ4REZFdYZCycwfzywHwsh4REVF3YJCyc792NPeSthAiIiI7xCBl57jQnIiIqPswSNmxEn0tCnW1kMuAmCCt1OUQERHZHQYpO9bciLOfnztc1QppiyEiIrJDDFJ27Nf1UZ6S1kFERGSvGKTsGNdHERERdS8GKTtlMAocOlcBgI04iYiIuguDlJ06VVKF6noDXFVO6NvTXepyiIiI7BKDlJ1qbsQ5KEgLJ7lM4mqIiIjsE4OUnWIjTiIiou7HIGWnMrjQnIiIqNsxSNmh6rpGnDhfCQCI5UJzIiKibsMgZYcOF+hgFECAVgM/D43U5RAREdktBik7xEacRERENwaDlB1iI04iIqIbg0HKDnFGioiI6MZgkLIzxbpaFOtr4SSXYVCQVupyiIiI7BqDlJ1pbsTZz88dLiqFxNUQERHZNwYpO5PBy3pEREQ3DIOUnWleaB7LIEVERNTtGKTsiMEocLhABwAYwkacRERE3Y5Byo6cOF+JmnoD3NQK9O7hJnU5REREdo9Byo40tz2ICdLCSS6TthgiIiIHwCBlR9iIk4iI6MZikLIjbMRJRER0YzFI2YmqukacKKkEwCBFRER0ozBI2YnD53QQAgjUatDTQyN1OURERA6BQcpOmC7rse0BERHRDcMgZSeabw3Dy3pEREQ3DoOUnfh1obmXtIUQERE5EAYpO1Cku4Tz+jo4yWUY1EsrdTlEREQOg0HKDjT3j+rv5w5nlZO0xRARETkQBik7wIXmRERE0mCQsgMZbMRJREQkCQYpG9doMOLwOR0AIJZBioiI6IZikLJxJ85X4VKDAe5qBXr3cJO6HCIiIofCIGXjmtdHxQRrIZfLpC2GiIjIwTBI2Tg24iQiIpIOg5SNYyNOIiIi6TBI2bDK2gacLKkCwBkpIiIiKTBI2bDD53QQAujl6Ywe7mqpyyEiInI4DFI2LIONOImIiCTFIGXDmtdHsX8UERGRNBikbJQQ4oqF5p6S1kJEROSoGKRsVKGuFhcq66CQyxDdSyt1OURERA6JQcpGHcyrAAAMCHCHRukkbTFEREQOikHKRrERJxERkfQkD1JLlixBeHg4NBoN4uPjsW3btjbHp6WlIT4+HhqNBhEREVi2bFmLMSkpKYiKioJarUZUVBTWrl1r8XGFEHjllVcQGBgIZ2dnjBs3DkePHu3cm+1CbMRJREQkPUmD1KpVqzBr1iy8+OKLyMjIwOjRozFp0iTk5eW1Oj43NxeTJ0/G6NGjkZGRgQULFmDmzJlISUkxjUlPT8f06dORnJyMzMxMJCcnY9q0adi9e7dFx/3HP/6Bt99+G++99x727t0Lf39/3HbbbaisrOy+E9JODQYjDhfoAHBGioiISEoyIYSQ6uAJCQmIi4vD0qVLTdsiIyNx1113YeHChS3Gz507F+vXr0d2drZp24wZM5CZmYn09HQAwPTp06HX67FhwwbTmIkTJ8LLywsrVqxo13GFEAgMDMSsWbMwd+5cAEBdXR38/Pzwxhtv4Mknn2zX+9Pr9dBqtdDpdPDw8LDgzLTtSIEOt/97O9w1CmT+ZQJvVkxERNSFLPn8lmxGqr6+Hvv378eECRPMtk+YMAE7d+5s9TXp6ektxiclJWHfvn1oaGhoc0zzPttz3NzcXBQXF5uNUavVGDt27DVrA5rCll6vN3t0hyvbHjBEERERSUeyIFVaWgqDwQA/Pz+z7X5+figuLm71NcXFxa2Ob2xsRGlpaZtjmvfZnuM2/9eS2gBg4cKF0Gq1pkdwcPA1x3aG7lIDNEo5L+sRERFJTPLF5jKZ+YyKEKLFtuuNv3p7e/bZVWOuNH/+fOh0OtMjPz//mmM744/j++DIK0mYMbZ3t+yfiIiI2kch1YF9fX3h5OTUYoanpKSkxUxQM39//1bHKxQK+Pj4tDmmeZ/tOa6/vz+AppmpgICAdtUGNF3+U6tvzM2DFU5yKJwkz8FEREQOTbJPYpVKhfj4eKSmppptT01NxciRI1t9TWJiYovxGzduxNChQ6FUKtsc07zP9hw3PDwc/v7+ZmPq6+uRlpZ2zdqIiIjIAQkJrVy5UiiVSrF8+XKRlZUlZs2aJVxdXcWZM2eEEELMmzdPJCcnm8bn5OQIFxcXMXv2bJGVlSWWL18ulEql+Oabb0xjduzYIZycnMSiRYtEdna2WLRokVAoFGLXrl3tPq4QQixatEhotVqxZs0acfjwYXH//feLgIAAodfr2/3+dDqdACB0Ol1nThMRERHdQJZ8fksapIQQ4v333xehoaFCpVKJuLg4kZaWZnrukUceEWPHjjUbv3XrVhEbGytUKpUICwsTS5cubbHP1atXi/79+wulUikGDBggUlJSLDquEEIYjUbx8ssvC39/f6FWq8WYMWPE4cOHLXpvDFJERES2x5LPb0n7SNm77uojRURERN3HJvpIEREREdk6BikiIiKiDmKQIiIiIuogBikiIiKiDmKQIiIiIuogBikiIiKiDmKQIiIiIuogBikiIiKiDmKQIiIiIuoghdQF2LPmpvF6vV7iSoiIiKi9mj+323PzFwapblRZWQkACA4OlrgSIiIislRlZSW0Wm2bY3ivvW5kNBpRWFgId3d3yGSyLt23Xq9HcHAw8vPzeR+/VvD8tI3np208P23j+Wkbz0/bbOH8CCFQWVmJwMBAyOVtr4LijFQ3ksvlCAoK6tZjeHh4WO0vojXg+Wkbz0/beH7axvPTNp6ftln7+bneTFQzLjYnIiIi6iAGKSIiIqIOYpCyUWq1Gi+//DLUarXUpVglnp+28fy0jeenbTw/beP5aZu9nR8uNiciIiLqIM5IEREREXUQgxQRERFRBzFIEREREXUQgxQRERFRBzFI2aAlS5YgPDwcGo0G8fHx2LZtm9Qlddovv/yC3/zmNwgMDIRMJsO6devMnhdC4JVXXkFgYCCcnZ0xbtw4HD161GxMXV0dnn32Wfj6+sLV1RV33HEHzp07ZzamvLwcycnJ0Gq10Gq1SE5ORkVFhdmYvLw8/OY3v4Grqyt8fX0xc+ZM1NfXd8fbbreFCxdi2LBhcHd3R8+ePXHXXXfh+PHjZmMc+RwtXboUMTExpgZ/iYmJ2LBhg+l5Rz43rVm4cCFkMhlmzZpl2ubI5+iVV16BTCYze/j7+5ued+Rz06ygoAAPPfQQfHx84OLigiFDhmD//v2m5x36HAmyKStXrhRKpVJ89NFHIisrSzz33HPC1dVVnD17VurSOuWHH34QL774okhJSREAxNq1a82eX7RokXB3dxcpKSni8OHDYvr06SIgIEDo9XrTmBkzZohevXqJ1NRUceDAATF+/HgxePBg0djYaBozceJEER0dLXbu3Cl27twpoqOjxe233256vrGxUURHR4vx48eLAwcOiNTUVBEYGCieeeaZbj8HbUlKShKffPKJOHLkiDh48KCYMmWKCAkJEVVVVaYxjnyO1q9fL/73v/+J48ePi+PHj4sFCxYIpVIpjhw5IoRw7HNztT179oiwsDARExMjnnvuOdN2Rz5HL7/8shg4cKAoKioyPUpKSkzPO/K5EUKIixcvitDQUPHoo4+K3bt3i9zcXLFp0yZx6tQp0xhHPkcMUjZm+PDhYsaMGWbbBgwYIObNmydRRV3v6iBlNBqFv7+/WLRokWlbbW2t0Gq1YtmyZUIIISoqKoRSqRQrV640jSkoKBByuVz8+OOPQgghsrKyBACxa9cu05j09HQBQBw7dkwI0RTo5HK5KCgoMI1ZsWKFUKvVQqfTdcv77YiSkhIBQKSlpQkheI5a4+XlJT7++GOemytUVlaKvn37itTUVDF27FhTkHL0c/Tyyy+LwYMHt/qco58bIYSYO3euGDVq1DWfd/RzxEt7NqS+vh779+/HhAkTzLZPmDABO3fulKiq7pebm4vi4mKz961WqzF27FjT+96/fz8aGhrMxgQGBiI6Oto0Jj09HVqtFgkJCaYxI0aMgFarNRsTHR2NwMBA05ikpCTU1dWZTWNLTafTAQC8vb0B8BxdyWAwYOXKlaiurkZiYiLPzRX++Mc/YsqUKbj11lvNtvMcASdPnkRgYCDCw8Nx3333IScnBwDPDQCsX78eQ4cOxdSpU9GzZ0/Exsbio48+Mj3v6OeIQcqGlJaWwmAwwM/Pz2y7n58fiouLJaqq+zW/t7bed3FxMVQqFby8vNoc07Nnzxb779mzp9mYq4/j5eUFlUplNedYCIHnn38eo0aNQnR0NACeIwA4fPgw3NzcoFarMWPGDKxduxZRUVE8N5etXLkSBw4cwMKFC1s85+jnKCEhAZ9//jl++uknfPTRRyguLsbIkSNRVlbm8OcGAHJycrB06VL07dsXP/30E2bMmIGZM2fi888/B8DfH4UkR6VOkclkZj8LIVpss0cded9Xj2ltfEfGSOmZZ57BoUOHsH379hbPOfI56t+/Pw4ePIiKigqkpKTgkUceQVpamul5Rz43+fn5eO6557Bx40ZoNJprjnPUczRp0iTTnwcNGoTExET07t0bn332GUaMGAHAcc8NABiNRgwdOhSvv/46ACA2NhZHjx7F0qVL8fDDD5vGOeo54oyUDfH19YWTk1OL1F1SUtIioduT5m/PtPW+/f39UV9fj/Ly8jbHnD9/vsX+L1y4YDbm6uOUl5ejoaHBKs7xs88+i/Xr12PLli0ICgoybec5AlQqFfr06YOhQ4di4cKFGDx4MN59912eGzRdVikpKUF8fDwUCgUUCgXS0tKwePFiKBQKU22OfI6u5OrqikGDBuHkyZP8/QEQEBCAqKgos22RkZHIy8sDwL9/GKRsiEqlQnx8PFJTU822p6amYuTIkRJV1f3Cw8Ph7+9v9r7r6+uRlpZmet/x8fFQKpVmY4qKinDkyBHTmMTEROh0OuzZs8c0Zvfu3dDpdGZjjhw5gqKiItOYjRs3Qq1WIz4+vlvfZ1uEEHjmmWewZs0a/PzzzwgPDzd7nueoJSEE6urqeG4A3HLLLTh8+DAOHjxoegwdOhQPPvggDh48iIiICIc/R1eqq6tDdnY2AgIC+PsD4KabbmrRbuXEiRMIDQ0FwL9/+K09G9Pc/mD58uUiKytLzJo1S7i6uoozZ85IXVqnVFZWioyMDJGRkSEAiLfffltkZGSY2josWrRIaLVasWbNGnH48GFx//33t/rV2qCgILFp0yZx4MABcfPNN7f61dqYmBiRnp4u0tPTxaBBg1r9au0tt9wiDhw4IDZt2iSCgoIk//rxU089JbRardi6davZV7RrampMYxz5HM2fP1/88ssvIjc3Vxw6dEgsWLBAyOVysXHjRiGEY5+ba7nyW3tCOPY5mjNnjti6davIyckRu3btErfffrtwd3c3/b3qyOdGiKaWGQqFQvz9738XJ0+eFF999ZVwcXERX375pWmMI58jBikb9P7774vQ0FChUqlEXFyc6SvwtmzLli0CQIvHI488IoRo+nrtyy+/LPz9/YVarRZjxowRhw8fNtvHpUuXxDPPPCO8vb2Fs7OzuP3220VeXp7ZmLKyMvHggw8Kd3d34e7uLh588EFRXl5uNubs2bNiypQpwtnZWXh7e4tnnnlG1NbWdufbv67Wzg0A8cknn5jGOPI5euyxx0z/n+jRo4e45ZZbTCFKCMc+N9dydZBy5HPU3PNIqVSKwMBAcc8994ijR4+annfkc9Psu+++E9HR0UKtVosBAwaIDz/80Ox5Rz5HMiGEkGYujIiIiMi2cY0UERERUQcxSBERERF1EIMUERERUQcxSBERERF1EIMUERERUQcxSBERERF1EIMUERERUQcxSBERERF1EIMUERGAcePGYdasWVKXQUQ2hkGKiGyKTCZr8/Hoo492aL9r1qzBX//6107VVlJSgieffBIhISFQq9Xw9/dHUlIS0tPTzepft25dp45DRNZDIXUBRESWuPKu76tWrcJf/vIXszvTOzs7m41vaGiAUqm87n69vb07Xdu9996LhoYGfPbZZ4iIiMD58+exefNmXLx4sdP7JiLrxBkpIrIp/v7+podWq4VMJjP9XFtbC09PT3z99dcYN24cNBoNvvzyS5SVleH+++9HUFAQXFxcMGjQIKxYscJsv1df2gsLC8Prr7+Oxx57DO7u7ggJCcGHH354zboqKiqwfft2vPHGGxg/fjxCQ0MxfPhwzJ8/H1OmTDHtEwDuvvtuyGQy088A8N133yE+Ph4ajQYRERF49dVX0djYaHpeJpNh6dKlmDRpEpydnREeHo7Vq1d3/oQSUacwSBGR3Zk7dy5mzpyJ7OxsJCUloba2FvHx8fj+++9x5MgR/OEPf0BycjJ2797d5n7eeustDB06FBkZGXj66afx1FNP4dixY62OdXNzg5ubG9atW4e6urpWx+zduxcA8Mknn6CoqMj0808//YSHHnoIM2fORFZWFj744AN8+umn+Pvf/272+pdeegn33nsvMjMz8dBDD+H+++9Hdna2paeHiLqSICKyUZ988onQarWmn3NzcwUA8c4771z3tZMnTxZz5swx/Tx27Fjx3HPPmX4ODQ0VDz30kOlno9EoevbsKZYuXXrNfX7zzTfCy8tLaDQaMXLkSDF//nyRmZlpNgaAWLt2rdm20aNHi9dff91s2xdffCECAgLMXjdjxgyzMQkJCeKpp5667nslou7DGSkisjtDhw41+9lgMODvf/87YmJi4OPjAzc3N2zcuBF5eXlt7icmJsb05+ZLiCUlJdccf++996KwsBDr169HUlIStm7diri4OHz66adtHmf//v147bXXTLNabm5ueOKJJ1BUVISamhrTuMTERLPXJSYmckaKSGJcbE5EdsfV1dXs57feegv/+te/8M4772DQoEFwdXXFrFmzUF9f3+Z+rl6kLpPJYDQa23yNRqPBbbfdhttuuw1/+ctf8Pjjj+Pll19u89uERqMRr776Ku65555W99cWmUzW5vNE1L0YpIjI7m3btg133nknHnroIQBNweXkyZOIjIzs9mNHRUWZtTtQKpUwGAxmY+Li4nD8+HH06dOnzX3t2rULDz/8sNnPsbGxXVovEVmGQYqI7F6fPn2QkpKCnTt3wsvLC2+//TaKi4u7NEiVlZVh6tSpeOyxxxATEwN3d3fs27cP//jHP3DnnXeaxoWFhWHz5s246aaboFar4eXlhb/85S+4/fbbERwcjKlTp0Iul+PQoUM4fPgw/va3v5leu3r1agwdOhSjRo3CV199hT179mD58uVd9h6IyHJcI0VEdu+ll15CXFwckpKSMG7cOPj7++Ouu+7q0mO4ubkhISEB//rXvzBmzBhER0fjpZdewhNPPIH33nvPNO6tt95CamoqgoODTbNJSUlJ+P7775Gamophw4ZhxIgRePvttxEaGmp2jFdffRUrV65ETEwMPvvsM3z11VeIiorq0vdBRJaRCSGE1EUQEVHbZDIZ1q5d2+UBkIg6hzNSRERERB3EIEVERETUQVxsTkRkA7gKg8g6cUaKiIiIqIMYpIiIiIg6iEGKiIiIqIMYpIiIiIg6iEGKiIiIqIMYpIiIiIg6iEGKiIiIqIMYpIiIiIg66P8BXQOPVixxi/AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "finetune_lr = CustomSchedule(512, 5_000, weight_decay=None)\n",
    "plt.plot(tmp_lr(tf.range(10_000_000 // (32* 5), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n",
    "\n",
    "plt.plot(finetune_lr(tf.range(2_300_000 // (32), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g)\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        optimizer.apply_gradients(zip(global_gradients, model.trainable_variables))\n",
    "        global_gradients = []\n",
    "        total_step += 1\n",
    "    return global_gradients, total_step\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, model, optimizer, num_accum_steps, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions, seq_type)\n",
    "        acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss) / num_accum_steps\n",
    "\n",
    "    gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(gradients)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions, seq_type)\n",
    "    acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.6f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name='', dict_config=None):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"),\n",
    "               config=dict_config)\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "\n",
    "def grad_accum_scheduler(num_samples, list_scheduler, max_grad_accum):\n",
    "    if num_samples >= len(list_scheduler):\n",
    "        return max_grad_accum\n",
    "    return list_scheduler[num_samples]\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menric1296\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/enric/SSD1TB/KAGGLE/025_Kaggle-OTTO Recsys-2022/1_Scripts/wandb/run-20221125_205842-1lg01qyu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/1lg01qyu\" target=\"_blank\">model_bert4rec_complete_0.8.5_2022-11-25 20:58:41</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n",
      "================================================================================\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 20:58:44.556404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:436: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2022-11-25 20:58:45.310012: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1ed24780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-25 20:58:45.310028: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2022-11-25 20:58:45.326424: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model_bert4_rec/encoder_transformer_block/dropout_1/dropout/random_uniform/RandomUniform\n",
      "2022-11-25 20:58:45.329211: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-11-25 20:58:46.547166: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-11-25 20:58:46.995055: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Epoch]1/2 [Time]2.54 [Step]1 [Batch]0 [Speed]2535.82ms/step [Loss]14.2171 [Metrics]{'train_loss:14.217128 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000000 grad_accum:1.000000 total_samples:0.000000'}\n",
      "[Train Epoch]1/2 [Time]47.40 [Step]501 [Batch]500 [Speed]94.80ms/step [Loss]14.1004 [Metrics]{'train_loss:14.100404 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000044 grad_accum:1.000000 total_samples:16000.000000'}\n",
      "[Train Epoch]1/2 [Time]92.39 [Step]1001 [Batch]1000 [Speed]92.39ms/step [Loss]13.7693 [Metrics]{'train_loss:13.769282 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000088 grad_accum:1.000000 total_samples:32000.000000'}\n",
      "[Train Epoch]1/2 [Time]137.09 [Step]1501 [Batch]1500 [Speed]91.40ms/step [Loss]13.5226 [Metrics]{'train_loss:13.522558 train_acc_clicks:0.000062 train_acc_carts:0.000048 train_acc_orders:0.000000 lr:0.000133 grad_accum:1.000000 total_samples:48000.000000'}\n",
      "[Train Epoch]1/2 [Time]181.83 [Step]2001 [Batch]2000 [Speed]90.91ms/step [Loss]13.3531 [Metrics]{'train_loss:13.353108 train_acc_clicks:0.000140 train_acc_carts:0.000188 train_acc_orders:0.000000 lr:0.000177 grad_accum:1.000000 total_samples:64000.000000'}\n",
      "[Train Epoch]1/2 [Time]226.16 [Step]2501 [Batch]2500 [Speed]90.46ms/step [Loss]13.2247 [Metrics]{'train_loss:13.224735 train_acc_clicks:0.000221 train_acc_carts:0.000225 train_acc_orders:0.000267 lr:0.000221 grad_accum:1.000000 total_samples:80000.000000'}\n",
      "[Train Epoch]1/2 [Time]270.45 [Step]3001 [Batch]3000 [Speed]90.15ms/step [Loss]13.1143 [Metrics]{'train_loss:13.114320 train_acc_clicks:0.000446 train_acc_carts:0.000698 train_acc_orders:0.000642 lr:0.000265 grad_accum:1.000000 total_samples:96000.000000'}\n",
      "[Train Epoch]1/2 [Time]314.34 [Step]3501 [Batch]3500 [Speed]89.81ms/step [Loss]13.0236 [Metrics]{'train_loss:13.023622 train_acc_clicks:0.000882 train_acc_carts:0.002506 train_acc_orders:0.002209 lr:0.000309 grad_accum:1.000000 total_samples:112000.000000'}\n",
      "[Train Epoch]1/2 [Time]358.73 [Step]4001 [Batch]4000 [Speed]89.68ms/step [Loss]12.9444 [Metrics]{'train_loss:12.944357 train_acc_clicks:0.001480 train_acc_carts:0.004849 train_acc_orders:0.005100 lr:0.000354 grad_accum:1.000000 total_samples:128000.000000'}\n",
      "[Train Epoch]1/2 [Time]403.13 [Step]4501 [Batch]4500 [Speed]89.59ms/step [Loss]12.8718 [Metrics]{'train_loss:12.871811 train_acc_clicks:0.002469 train_acc_carts:0.007993 train_acc_orders:0.009956 lr:0.000398 grad_accum:1.000000 total_samples:144000.000000'}\n",
      "[Train Epoch]1/2 [Time]447.12 [Step]5001 [Batch]5000 [Speed]89.42ms/step [Loss]12.8034 [Metrics]{'train_loss:12.803424 train_acc_clicks:0.003740 train_acc_carts:0.012212 train_acc_orders:0.014190 lr:0.000442 grad_accum:1.000000 total_samples:160000.000000'}\n",
      "[Train Epoch]1/2 [Time]491.00 [Step]5501 [Batch]5500 [Speed]89.27ms/step [Loss]12.7381 [Metrics]{'train_loss:12.738091 train_acc_clicks:0.005260 train_acc_carts:0.017879 train_acc_orders:0.019180 lr:0.000486 grad_accum:1.000000 total_samples:176000.000000'}\n",
      "[Train Epoch]1/2 [Time]535.45 [Step]6001 [Batch]6000 [Speed]89.24ms/step [Loss]12.6752 [Metrics]{'train_loss:12.675187 train_acc_clicks:0.006886 train_acc_carts:0.023189 train_acc_orders:0.025885 lr:0.000530 grad_accum:1.000000 total_samples:192000.000000'}\n",
      "[Train Epoch]1/2 [Time]580.05 [Step]6501 [Batch]6500 [Speed]89.24ms/step [Loss]12.6120 [Metrics]{'train_loss:12.612047 train_acc_clicks:0.008669 train_acc_carts:0.028119 train_acc_orders:0.031791 lr:0.000575 grad_accum:1.000000 total_samples:208000.000000'}\n",
      "[Train Epoch]1/2 [Time]623.87 [Step]7001 [Batch]7000 [Speed]89.12ms/step [Loss]12.5510 [Metrics]{'train_loss:12.551039 train_acc_clicks:0.010339 train_acc_carts:0.033569 train_acc_orders:0.038532 lr:0.000619 grad_accum:1.000000 total_samples:224000.000000'}\n",
      "[Train Epoch]1/2 [Time]667.64 [Step]7501 [Batch]7500 [Speed]89.02ms/step [Loss]12.4879 [Metrics]{'train_loss:12.487925 train_acc_clicks:0.012106 train_acc_carts:0.039944 train_acc_orders:0.045752 lr:0.000663 grad_accum:1.000000 total_samples:240000.000000'}\n",
      "[Train Epoch]1/2 [Time]709.96 [Step]7907 [Batch]8000 [Speed]88.74ms/step [Loss]12.4291 [Metrics]{'train_loss:12.429139 train_acc_clicks:0.013668 train_acc_carts:0.048167 train_acc_orders:0.051072 lr:0.000699 grad_accum:2.000000 total_samples:256032.000000'}\n",
      "[Train Epoch]1/2 [Time]749.56 [Step]8157 [Batch]8500 [Speed]88.18ms/step [Loss]12.3735 [Metrics]{'train_loss:12.373519 train_acc_clicks:0.015061 train_acc_carts:0.056188 train_acc_orders:0.055877 lr:0.000721 grad_accum:2.000000 total_samples:272032.000000'}\n",
      "[Train Epoch]1/2 [Time]789.16 [Step]8407 [Batch]9000 [Speed]87.68ms/step [Loss]12.3199 [Metrics]{'train_loss:12.319873 train_acc_clicks:0.016403 train_acc_carts:0.063015 train_acc_orders:0.059369 lr:0.000743 grad_accum:2.000000 total_samples:288032.000000'}\n",
      "[Train Epoch]1/2 [Time]828.97 [Step]8657 [Batch]9500 [Speed]87.26ms/step [Loss]12.2675 [Metrics]{'train_loss:12.267546 train_acc_clicks:0.017608 train_acc_carts:0.067847 train_acc_orders:0.063418 lr:0.000765 grad_accum:2.000000 total_samples:304032.000000'}\n",
      "[Train Epoch]1/2 [Time]868.39 [Step]8907 [Batch]10000 [Speed]86.84ms/step [Loss]12.2145 [Metrics]{'train_loss:12.214549 train_acc_clicks:0.018791 train_acc_carts:0.070956 train_acc_orders:0.066891 lr:0.000787 grad_accum:2.000000 total_samples:320032.000000'}\n",
      "[Train Epoch]1/2 [Time]907.89 [Step]9157 [Batch]10500 [Speed]86.47ms/step [Loss]12.1665 [Metrics]{'train_loss:12.166471 train_acc_clicks:0.019810 train_acc_carts:0.073743 train_acc_orders:0.070760 lr:0.000809 grad_accum:2.000000 total_samples:336032.000000'}\n",
      "[Train Epoch]1/2 [Time]947.73 [Step]9407 [Batch]11000 [Speed]86.16ms/step [Loss]12.1171 [Metrics]{'train_loss:12.117127 train_acc_clicks:0.020840 train_acc_carts:0.075712 train_acc_orders:0.074186 lr:0.000831 grad_accum:2.000000 total_samples:352032.000000'}\n",
      "[Train Epoch]1/2 [Time]987.80 [Step]9657 [Batch]11500 [Speed]85.90ms/step [Loss]12.0680 [Metrics]{'train_loss:12.068042 train_acc_clicks:0.021782 train_acc_carts:0.078060 train_acc_orders:0.078891 lr:0.000854 grad_accum:2.000000 total_samples:368032.000000'}\n",
      "[Train Epoch]1/2 [Time]1027.28 [Step]9907 [Batch]12000 [Speed]85.61ms/step [Loss]12.0234 [Metrics]{'train_loss:12.023378 train_acc_clicks:0.022600 train_acc_carts:0.079981 train_acc_orders:0.082043 lr:0.000876 grad_accum:2.000000 total_samples:384032.000000'}\n",
      "[Train Epoch]1/2 [Time]1066.80 [Step]10157 [Batch]12500 [Speed]85.34ms/step [Loss]11.9777 [Metrics]{'train_loss:11.977663 train_acc_clicks:0.023475 train_acc_carts:0.081716 train_acc_orders:0.084423 lr:0.000877 grad_accum:2.000000 total_samples:400032.000000'}\n",
      "[Train Epoch]1/2 [Time]1106.36 [Step]10407 [Batch]13000 [Speed]85.10ms/step [Loss]11.9329 [Metrics]{'train_loss:11.932917 train_acc_clicks:0.024300 train_acc_carts:0.083276 train_acc_orders:0.086848 lr:0.000866 grad_accum:2.000000 total_samples:416032.000000'}\n",
      "[Train Epoch]1/2 [Time]1145.70 [Step]10657 [Batch]13500 [Speed]84.87ms/step [Loss]11.8908 [Metrics]{'train_loss:11.890778 train_acc_clicks:0.024988 train_acc_carts:0.085000 train_acc_orders:0.088816 lr:0.000856 grad_accum:2.000000 total_samples:432032.000000'}\n",
      "[Train Epoch]1/2 [Time]1185.48 [Step]10907 [Batch]14000 [Speed]84.68ms/step [Loss]11.8509 [Metrics]{'train_loss:11.850870 train_acc_clicks:0.025653 train_acc_carts:0.086882 train_acc_orders:0.091392 lr:0.000846 grad_accum:2.000000 total_samples:448032.000000'}\n",
      "[Train Epoch]1/2 [Time]1224.92 [Step]11157 [Batch]14500 [Speed]84.48ms/step [Loss]11.8101 [Metrics]{'train_loss:11.810084 train_acc_clicks:0.026397 train_acc_carts:0.088379 train_acc_orders:0.093592 lr:0.000837 grad_accum:2.000000 total_samples:464032.000000'}\n",
      "[Train Epoch]1/2 [Time]1264.47 [Step]11407 [Batch]15000 [Speed]84.30ms/step [Loss]11.7701 [Metrics]{'train_loss:11.770059 train_acc_clicks:0.027032 train_acc_carts:0.089846 train_acc_orders:0.095783 lr:0.000828 grad_accum:2.000000 total_samples:480032.000000'}\n",
      "[Train Epoch]1/2 [Time]1303.69 [Step]11657 [Batch]15500 [Speed]84.11ms/step [Loss]11.7294 [Metrics]{'train_loss:11.729389 train_acc_clicks:0.027661 train_acc_carts:0.090710 train_acc_orders:0.097929 lr:0.000819 grad_accum:2.000000 total_samples:496032.000000'}\n",
      "[Train Epoch]1/2 [Time]1342.45 [Step]11844 [Batch]16000 [Speed]83.90ms/step [Loss]11.6886 [Metrics]{'train_loss:11.688587 train_acc_clicks:0.028258 train_acc_carts:0.091767 train_acc_orders:0.099804 lr:0.000812 grad_accum:3.000000 total_samples:512000.000000'}\n",
      "[Train Epoch]1/2 [Time]1381.16 [Step]12011 [Batch]16500 [Speed]83.71ms/step [Loss]11.6490 [Metrics]{'train_loss:11.649027 train_acc_clicks:0.028822 train_acc_carts:0.092710 train_acc_orders:0.101336 lr:0.000807 grad_accum:3.000000 total_samples:528032.000000'}\n",
      "[Train Epoch]1/2 [Time]1420.19 [Step]12178 [Batch]17000 [Speed]83.54ms/step [Loss]11.6113 [Metrics]{'train_loss:11.611312 train_acc_clicks:0.029426 train_acc_carts:0.093618 train_acc_orders:0.103215 lr:0.000801 grad_accum:3.000000 total_samples:543968.000000'}\n",
      "[Train Epoch]1/2 [Time]1458.69 [Step]12344 [Batch]17500 [Speed]83.35ms/step [Loss]11.5744 [Metrics]{'train_loss:11.574360 train_acc_clicks:0.030020 train_acc_carts:0.095913 train_acc_orders:0.104867 lr:0.000796 grad_accum:3.000000 total_samples:560000.000000'}\n",
      "[Train Epoch]1/2 [Time]1497.27 [Step]12511 [Batch]18000 [Speed]83.18ms/step [Loss]11.5403 [Metrics]{'train_loss:11.540283 train_acc_clicks:0.030536 train_acc_carts:0.097533 train_acc_orders:0.105900 lr:0.000790 grad_accum:3.000000 total_samples:576032.000000'}\n",
      "[Train Epoch]1/2 [Time]1535.84 [Step]12678 [Batch]18500 [Speed]83.02ms/step [Loss]11.5083 [Metrics]{'train_loss:11.508300 train_acc_clicks:0.031009 train_acc_carts:0.099295 train_acc_orders:0.107718 lr:0.000785 grad_accum:3.000000 total_samples:591968.000000'}\n",
      "[Train Epoch]1/2 [Time]1574.33 [Step]12844 [Batch]19000 [Speed]82.86ms/step [Loss]11.4758 [Metrics]{'train_loss:11.475756 train_acc_clicks:0.031490 train_acc_carts:0.100504 train_acc_orders:0.109218 lr:0.000780 grad_accum:3.000000 total_samples:608000.000000'}\n",
      "[Train Epoch]1/2 [Time]1613.26 [Step]13011 [Batch]19500 [Speed]82.73ms/step [Loss]11.4430 [Metrics]{'train_loss:11.443008 train_acc_clicks:0.031941 train_acc_carts:0.100986 train_acc_orders:0.110836 lr:0.000775 grad_accum:3.000000 total_samples:624032.000000'}\n",
      "[Train Epoch]1/2 [Time]1652.37 [Step]13178 [Batch]20000 [Speed]82.62ms/step [Loss]11.4102 [Metrics]{'train_loss:11.410182 train_acc_clicks:0.032387 train_acc_carts:0.101808 train_acc_orders:0.112633 lr:0.000770 grad_accum:3.000000 total_samples:639968.000000'}\n",
      "[Train Epoch]1/2 [Time]1691.11 [Step]13344 [Batch]20500 [Speed]82.49ms/step [Loss]11.3806 [Metrics]{'train_loss:11.380589 train_acc_clicks:0.032744 train_acc_carts:0.102671 train_acc_orders:0.113588 lr:0.000765 grad_accum:3.000000 total_samples:656000.000000'}\n",
      "[Train Epoch]1/2 [Time]1730.00 [Step]13511 [Batch]21000 [Speed]82.38ms/step [Loss]11.3508 [Metrics]{'train_loss:11.350806 train_acc_clicks:0.033141 train_acc_carts:0.103270 train_acc_orders:0.114935 lr:0.000760 grad_accum:3.000000 total_samples:672032.000000'}\n",
      "[Train Epoch]1/2 [Time]1769.16 [Step]13678 [Batch]21500 [Speed]82.29ms/step [Loss]11.3231 [Metrics]{'train_loss:11.323100 train_acc_clicks:0.033485 train_acc_carts:0.103632 train_acc_orders:0.116123 lr:0.000756 grad_accum:3.000000 total_samples:687968.000000'}\n",
      "[Train Epoch]1/2 [Time]1808.17 [Step]13844 [Batch]22000 [Speed]82.19ms/step [Loss]11.2948 [Metrics]{'train_loss:11.294765 train_acc_clicks:0.033850 train_acc_carts:0.103962 train_acc_orders:0.117390 lr:0.000751 grad_accum:3.000000 total_samples:704000.000000'}\n",
      "[Train Epoch]1/2 [Time]1847.26 [Step]14011 [Batch]22500 [Speed]82.10ms/step [Loss]11.2663 [Metrics]{'train_loss:11.266323 train_acc_clicks:0.034188 train_acc_carts:0.104274 train_acc_orders:0.118913 lr:0.000747 grad_accum:3.000000 total_samples:720032.000000'}\n",
      "[Train Epoch]1/2 [Time]1885.70 [Step]14178 [Batch]23000 [Speed]81.99ms/step [Loss]11.2380 [Metrics]{'train_loss:11.238044 train_acc_clicks:0.034534 train_acc_carts:0.104594 train_acc_orders:0.120048 lr:0.000742 grad_accum:3.000000 total_samples:735968.000000'}\n",
      "[Train Epoch]1/2 [Time]1924.31 [Step]14340 [Batch]23500 [Speed]81.89ms/step [Loss]11.2107 [Metrics]{'train_loss:11.210685 train_acc_clicks:0.034860 train_acc_carts:0.105022 train_acc_orders:0.120994 lr:0.000738 grad_accum:4.000000 total_samples:752128.000000'}\n",
      "[Train Epoch]1/2 [Time]1962.69 [Step]14465 [Batch]24000 [Speed]81.78ms/step [Loss]11.1832 [Metrics]{'train_loss:11.183162 train_acc_clicks:0.035242 train_acc_carts:0.105473 train_acc_orders:0.121796 lr:0.000735 grad_accum:4.000000 total_samples:768128.000000'}\n",
      "[Train Epoch]1/2 [Time]2001.05 [Step]14590 [Batch]24500 [Speed]81.68ms/step [Loss]11.1571 [Metrics]{'train_loss:11.157119 train_acc_clicks:0.035577 train_acc_carts:0.106407 train_acc_orders:0.122847 lr:0.000732 grad_accum:4.000000 total_samples:784128.000000'}\n",
      "[Train Epoch]1/2 [Time]2038.94 [Step]14715 [Batch]25000 [Speed]81.56ms/step [Loss]11.1322 [Metrics]{'train_loss:11.132189 train_acc_clicks:0.035865 train_acc_carts:0.107321 train_acc_orders:0.123778 lr:0.000729 grad_accum:4.000000 total_samples:800128.000000'}\n",
      "[Train Epoch]1/2 [Time]2076.82 [Step]14840 [Batch]25500 [Speed]81.44ms/step [Loss]11.1083 [Metrics]{'train_loss:11.108306 train_acc_clicks:0.036157 train_acc_carts:0.109145 train_acc_orders:0.124794 lr:0.000726 grad_accum:4.000000 total_samples:816128.000000'}\n",
      "[Train Epoch]1/2 [Time]2115.12 [Step]14965 [Batch]26000 [Speed]81.35ms/step [Loss]11.0858 [Metrics]{'train_loss:11.085827 train_acc_clicks:0.036462 train_acc_carts:0.111089 train_acc_orders:0.125315 lr:0.000723 grad_accum:4.000000 total_samples:832128.000000'}\n",
      "[Train Epoch]1/2 [Time]2153.64 [Step]15090 [Batch]26500 [Speed]81.27ms/step [Loss]11.0633 [Metrics]{'train_loss:11.063270 train_acc_clicks:0.036756 train_acc_carts:0.112311 train_acc_orders:0.126684 lr:0.000720 grad_accum:4.000000 total_samples:848128.000000'}\n",
      "[Train Epoch]1/2 [Time]2191.80 [Step]15215 [Batch]27000 [Speed]81.18ms/step [Loss]11.0417 [Metrics]{'train_loss:11.041691 train_acc_clicks:0.036995 train_acc_carts:0.113371 train_acc_orders:0.127425 lr:0.000717 grad_accum:4.000000 total_samples:864128.000000'}\n",
      "[Train Epoch]1/2 [Time]2230.26 [Step]15340 [Batch]27500 [Speed]81.10ms/step [Loss]11.0204 [Metrics]{'train_loss:11.020351 train_acc_clicks:0.037258 train_acc_carts:0.113979 train_acc_orders:0.128589 lr:0.000714 grad_accum:4.000000 total_samples:880128.000000'}\n",
      "[Train Epoch]1/2 [Time]2268.34 [Step]15465 [Batch]28000 [Speed]81.01ms/step [Loss]10.9987 [Metrics]{'train_loss:10.998675 train_acc_clicks:0.037497 train_acc_carts:0.114440 train_acc_orders:0.129178 lr:0.000711 grad_accum:4.000000 total_samples:896128.000000'}\n",
      "[Train Epoch]1/2 [Time]2306.22 [Step]15590 [Batch]28500 [Speed]80.92ms/step [Loss]10.9773 [Metrics]{'train_loss:10.977260 train_acc_clicks:0.037708 train_acc_carts:0.114672 train_acc_orders:0.129848 lr:0.000708 grad_accum:4.000000 total_samples:912128.000000'}\n",
      "[Train Epoch]1/2 [Time]2344.44 [Step]15715 [Batch]29000 [Speed]80.84ms/step [Loss]10.9559 [Metrics]{'train_loss:10.955918 train_acc_clicks:0.037945 train_acc_carts:0.114997 train_acc_orders:0.130915 lr:0.000705 grad_accum:4.000000 total_samples:928128.000000'}\n",
      "[Train Epoch]1/2 [Time]2382.44 [Step]15840 [Batch]29500 [Speed]80.76ms/step [Loss]10.9348 [Metrics]{'train_loss:10.934810 train_acc_clicks:0.038191 train_acc_carts:0.115238 train_acc_orders:0.131607 lr:0.000702 grad_accum:4.000000 total_samples:944128.000000'}\n",
      "[Train Epoch]1/2 [Time]2420.60 [Step]15965 [Batch]30000 [Speed]80.69ms/step [Loss]10.9143 [Metrics]{'train_loss:10.914267 train_acc_clicks:0.038410 train_acc_carts:0.115784 train_acc_orders:0.132536 lr:0.000700 grad_accum:4.000000 total_samples:960128.000000'}\n",
      "[Train Epoch]1/2 [Time]2458.92 [Step]16090 [Batch]30500 [Speed]80.62ms/step [Loss]10.8949 [Metrics]{'train_loss:10.894865 train_acc_clicks:0.038661 train_acc_carts:0.116337 train_acc_orders:0.133436 lr:0.000697 grad_accum:4.000000 total_samples:976128.000000'}\n",
      "[Train Epoch]1/2 [Time]2497.40 [Step]16215 [Batch]31000 [Speed]80.56ms/step [Loss]10.8756 [Metrics]{'train_loss:10.875570 train_acc_clicks:0.038870 train_acc_carts:0.116769 train_acc_orders:0.133603 lr:0.000694 grad_accum:4.000000 total_samples:992128.000000'}\n",
      "[Train Epoch]1/2 [Time]2536.02 [Step]16328 [Batch]31500 [Speed]80.51ms/step [Loss]10.8564 [Metrics]{'train_loss:10.856374 train_acc_clicks:0.039090 train_acc_carts:0.117173 train_acc_orders:0.134123 lr:0.000692 grad_accum:5.000000 total_samples:1008224.000000'}\n",
      "[Train Epoch]1/2 [Time]2574.39 [Step]16428 [Batch]32000 [Speed]80.45ms/step [Loss]10.8388 [Metrics]{'train_loss:10.838776 train_acc_clicks:0.039264 train_acc_carts:0.117833 train_acc_orders:0.135136 lr:0.000690 grad_accum:5.000000 total_samples:1024224.000000'}\n",
      "[Train Epoch]1/2 [Time]2612.08 [Step]16528 [Batch]32500 [Speed]80.37ms/step [Loss]10.8207 [Metrics]{'train_loss:10.820718 train_acc_clicks:0.039462 train_acc_carts:0.118319 train_acc_orders:0.135529 lr:0.000688 grad_accum:5.000000 total_samples:1040224.000000'}\n",
      "[Train Epoch]1/2 [Time]2649.92 [Step]16628 [Batch]33000 [Speed]80.30ms/step [Loss]10.8020 [Metrics]{'train_loss:10.802011 train_acc_clicks:0.039691 train_acc_carts:0.118345 train_acc_orders:0.135941 lr:0.000685 grad_accum:5.000000 total_samples:1056224.000000'}\n",
      "[Train Epoch]1/2 [Time]2687.83 [Step]16728 [Batch]33500 [Speed]80.23ms/step [Loss]10.7843 [Metrics]{'train_loss:10.784253 train_acc_clicks:0.039896 train_acc_carts:0.118429 train_acc_orders:0.136433 lr:0.000683 grad_accum:5.000000 total_samples:1072224.000000'}\n",
      "[Train Epoch]1/2 [Time]2725.51 [Step]16828 [Batch]34000 [Speed]80.16ms/step [Loss]10.7670 [Metrics]{'train_loss:10.766979 train_acc_clicks:0.040082 train_acc_carts:0.118696 train_acc_orders:0.136875 lr:0.000681 grad_accum:5.000000 total_samples:1088224.000000'}\n",
      "[Train Epoch]1/2 [Time]2763.40 [Step]16928 [Batch]34500 [Speed]80.10ms/step [Loss]10.7494 [Metrics]{'train_loss:10.749407 train_acc_clicks:0.040294 train_acc_carts:0.118931 train_acc_orders:0.137629 lr:0.000679 grad_accum:5.000000 total_samples:1104224.000000'}\n",
      "[Train Epoch]1/2 [Time]2801.47 [Step]17028 [Batch]35000 [Speed]80.04ms/step [Loss]10.7328 [Metrics]{'train_loss:10.732844 train_acc_clicks:0.040448 train_acc_carts:0.119043 train_acc_orders:0.138122 lr:0.000677 grad_accum:5.000000 total_samples:1120224.000000'}\n",
      "[Train Epoch]1/2 [Time]2839.51 [Step]17128 [Batch]35500 [Speed]79.99ms/step [Loss]10.7157 [Metrics]{'train_loss:10.715690 train_acc_clicks:0.040621 train_acc_carts:0.119326 train_acc_orders:0.138383 lr:0.000675 grad_accum:5.000000 total_samples:1136224.000000'}\n",
      "[Train Epoch]1/2 [Time]2877.29 [Step]17228 [Batch]36000 [Speed]79.92ms/step [Loss]10.6991 [Metrics]{'train_loss:10.699123 train_acc_clicks:0.040785 train_acc_carts:0.119395 train_acc_orders:0.139236 lr:0.000673 grad_accum:5.000000 total_samples:1152224.000000'}\n",
      "[Train Epoch]1/2 [Time]2915.16 [Step]17328 [Batch]36500 [Speed]79.87ms/step [Loss]10.6826 [Metrics]{'train_loss:10.682607 train_acc_clicks:0.040937 train_acc_carts:0.119663 train_acc_orders:0.139662 lr:0.000671 grad_accum:5.000000 total_samples:1168224.000000'}\n",
      "[Train Epoch]1/2 [Time]2952.96 [Step]17428 [Batch]37000 [Speed]79.81ms/step [Loss]10.6668 [Metrics]{'train_loss:10.666792 train_acc_clicks:0.041087 train_acc_carts:0.119792 train_acc_orders:0.139894 lr:0.000670 grad_accum:5.000000 total_samples:1184224.000000'}\n",
      "[Train Epoch]1/2 [Time]2991.11 [Step]17528 [Batch]37500 [Speed]79.76ms/step [Loss]10.6512 [Metrics]{'train_loss:10.651201 train_acc_clicks:0.041262 train_acc_carts:0.120171 train_acc_orders:0.140104 lr:0.000668 grad_accum:5.000000 total_samples:1200224.000000'}\n",
      "[Train Epoch]1/2 [Time]3028.94 [Step]17628 [Batch]38000 [Speed]79.71ms/step [Loss]10.6364 [Metrics]{'train_loss:10.636404 train_acc_clicks:0.041424 train_acc_carts:0.120505 train_acc_orders:0.140372 lr:0.000666 grad_accum:5.000000 total_samples:1216224.000000'}\n",
      "[Train Epoch]1/2 [Time]3066.57 [Step]17728 [Batch]38500 [Speed]79.65ms/step [Loss]10.6211 [Metrics]{'train_loss:10.621054 train_acc_clicks:0.041556 train_acc_carts:0.120663 train_acc_orders:0.140799 lr:0.000664 grad_accum:5.000000 total_samples:1232224.000000'}\n",
      "[Train Epoch]1/2 [Time]3104.21 [Step]17828 [Batch]39000 [Speed]79.60ms/step [Loss]10.6059 [Metrics]{'train_loss:10.605864 train_acc_clicks:0.041719 train_acc_carts:0.120691 train_acc_orders:0.141379 lr:0.000662 grad_accum:5.000000 total_samples:1248224.000000'}\n",
      "[Train Epoch]1/2 [Time]3142.03 [Step]17928 [Batch]39500 [Speed]79.55ms/step [Loss]10.5915 [Metrics]{'train_loss:10.591550 train_acc_clicks:0.041882 train_acc_carts:0.120798 train_acc_orders:0.141895 lr:0.000660 grad_accum:5.000000 total_samples:1264224.000000'}\n",
      "[Train Epoch]1/2 [Time]3178.57 [Step]18028 [Batch]40000 [Speed]79.46ms/step [Loss]10.5781 [Metrics]{'train_loss:10.578092 train_acc_clicks:0.042010 train_acc_carts:0.121262 train_acc_orders:0.142311 lr:0.000658 grad_accum:5.000000 total_samples:1280224.000000'}\n",
      "[Train Epoch]1/2 [Time]3215.12 [Step]18128 [Batch]40500 [Speed]79.39ms/step [Loss]10.5644 [Metrics]{'train_loss:10.564404 train_acc_clicks:0.042150 train_acc_carts:0.121703 train_acc_orders:0.142906 lr:0.000656 grad_accum:5.000000 total_samples:1296224.000000'}\n",
      "[Train Epoch]1/2 [Time]3251.63 [Step]18228 [Batch]41000 [Speed]79.31ms/step [Loss]10.5506 [Metrics]{'train_loss:10.550552 train_acc_clicks:0.042291 train_acc_carts:0.122042 train_acc_orders:0.143317 lr:0.000655 grad_accum:5.000000 total_samples:1312224.000000'}\n",
      "[Train Epoch]1/2 [Time]3288.16 [Step]18328 [Batch]41500 [Speed]79.23ms/step [Loss]10.5375 [Metrics]{'train_loss:10.537475 train_acc_clicks:0.042433 train_acc_carts:0.122298 train_acc_orders:0.143898 lr:0.000653 grad_accum:5.000000 total_samples:1328224.000000'}\n",
      "[Train Epoch]1/2 [Time]3324.65 [Step]18428 [Batch]42000 [Speed]79.16ms/step [Loss]10.5243 [Metrics]{'train_loss:10.524270 train_acc_clicks:0.042556 train_acc_carts:0.122703 train_acc_orders:0.144522 lr:0.000651 grad_accum:5.000000 total_samples:1344224.000000'}\n",
      "[Train Epoch]1/2 [Time]3361.24 [Step]18528 [Batch]42500 [Speed]79.09ms/step [Loss]10.5108 [Metrics]{'train_loss:10.510820 train_acc_clicks:0.042710 train_acc_carts:0.123096 train_acc_orders:0.145037 lr:0.000649 grad_accum:5.000000 total_samples:1360224.000000'}\n",
      "[Train Epoch]1/2 [Time]3397.81 [Step]18628 [Batch]43000 [Speed]79.02ms/step [Loss]10.4974 [Metrics]{'train_loss:10.497375 train_acc_clicks:0.042854 train_acc_carts:0.123161 train_acc_orders:0.145394 lr:0.000648 grad_accum:5.000000 total_samples:1376224.000000'}\n",
      "[Train Epoch]1/2 [Time]3434.32 [Step]18728 [Batch]43500 [Speed]78.95ms/step [Loss]10.4847 [Metrics]{'train_loss:10.484709 train_acc_clicks:0.042993 train_acc_carts:0.123314 train_acc_orders:0.145813 lr:0.000646 grad_accum:5.000000 total_samples:1392224.000000'}\n",
      "[Train Epoch]1/2 [Time]3470.82 [Step]18828 [Batch]44000 [Speed]78.88ms/step [Loss]10.4722 [Metrics]{'train_loss:10.472171 train_acc_clicks:0.043112 train_acc_carts:0.123506 train_acc_orders:0.146153 lr:0.000644 grad_accum:5.000000 total_samples:1408224.000000'}\n",
      "[Train Epoch]1/2 [Time]3507.31 [Step]18928 [Batch]44500 [Speed]78.82ms/step [Loss]10.4597 [Metrics]{'train_loss:10.459666 train_acc_clicks:0.043230 train_acc_carts:0.123943 train_acc_orders:0.146619 lr:0.000642 grad_accum:5.000000 total_samples:1424224.000000'}\n",
      "[Train Epoch]1/2 [Time]3543.79 [Step]19028 [Batch]45000 [Speed]78.75ms/step [Loss]10.4472 [Metrics]{'train_loss:10.447208 train_acc_clicks:0.043342 train_acc_carts:0.124287 train_acc_orders:0.147168 lr:0.000641 grad_accum:5.000000 total_samples:1440224.000000'}\n",
      "[Train Epoch]1/2 [Time]3580.31 [Step]19128 [Batch]45500 [Speed]78.69ms/step [Loss]10.4345 [Metrics]{'train_loss:10.434457 train_acc_clicks:0.043466 train_acc_carts:0.124563 train_acc_orders:0.147650 lr:0.000639 grad_accum:5.000000 total_samples:1456224.000000'}\n",
      "[Train Epoch]1/2 [Time]3616.89 [Step]19228 [Batch]46000 [Speed]78.63ms/step [Loss]10.4223 [Metrics]{'train_loss:10.422331 train_acc_clicks:0.043590 train_acc_carts:0.124776 train_acc_orders:0.148054 lr:0.000637 grad_accum:5.000000 total_samples:1472224.000000'}\n",
      "[Train Epoch]1/2 [Time]3653.45 [Step]19328 [Batch]46500 [Speed]78.57ms/step [Loss]10.4101 [Metrics]{'train_loss:10.410056 train_acc_clicks:0.043690 train_acc_carts:0.124834 train_acc_orders:0.148632 lr:0.000636 grad_accum:5.000000 total_samples:1488224.000000'}\n",
      "[Train Epoch]1/2 [Time]3689.95 [Step]19428 [Batch]47000 [Speed]78.51ms/step [Loss]10.3981 [Metrics]{'train_loss:10.398066 train_acc_clicks:0.043792 train_acc_carts:0.125092 train_acc_orders:0.149277 lr:0.000634 grad_accum:5.000000 total_samples:1504224.000000'}\n",
      "[Train Epoch]1/2 [Time]3726.72 [Step]19528 [Batch]47500 [Speed]78.46ms/step [Loss]10.3867 [Metrics]{'train_loss:10.386723 train_acc_clicks:0.043913 train_acc_carts:0.125383 train_acc_orders:0.149696 lr:0.000633 grad_accum:5.000000 total_samples:1520224.000000'}\n",
      "[Train Epoch]1/2 [Time]3764.68 [Step]19628 [Batch]48000 [Speed]78.43ms/step [Loss]10.3755 [Metrics]{'train_loss:10.375470 train_acc_clicks:0.044017 train_acc_carts:0.125588 train_acc_orders:0.150167 lr:0.000631 grad_accum:5.000000 total_samples:1536224.000000'}\n",
      "[Train Epoch]1/2 [Time]3803.22 [Step]19728 [Batch]48500 [Speed]78.42ms/step [Loss]10.3641 [Metrics]{'train_loss:10.364141 train_acc_clicks:0.044113 train_acc_carts:0.125720 train_acc_orders:0.150527 lr:0.000629 grad_accum:5.000000 total_samples:1552224.000000'}\n",
      "[Train Epoch]1/2 [Time]3841.27 [Step]19828 [Batch]49000 [Speed]78.39ms/step [Loss]10.3529 [Metrics]{'train_loss:10.352915 train_acc_clicks:0.044236 train_acc_carts:0.125994 train_acc_orders:0.151284 lr:0.000628 grad_accum:5.000000 total_samples:1568224.000000'}\n",
      "[Train Epoch]1/2 [Time]3878.96 [Step]19928 [Batch]49500 [Speed]78.36ms/step [Loss]10.3423 [Metrics]{'train_loss:10.342330 train_acc_clicks:0.044351 train_acc_carts:0.126601 train_acc_orders:0.151614 lr:0.000626 grad_accum:5.000000 total_samples:1584224.000000'}\n",
      "[Train Epoch]1/2 [Time]3916.69 [Step]20028 [Batch]50000 [Speed]78.33ms/step [Loss]10.3325 [Metrics]{'train_loss:10.332491 train_acc_clicks:0.044445 train_acc_carts:0.126942 train_acc_orders:0.151978 lr:0.000625 grad_accum:5.000000 total_samples:1600224.000000'}\n",
      "[Train Epoch]1/2 [Time]3954.52 [Step]20128 [Batch]50500 [Speed]78.31ms/step [Loss]10.3219 [Metrics]{'train_loss:10.321864 train_acc_clicks:0.044539 train_acc_carts:0.127296 train_acc_orders:0.152420 lr:0.000623 grad_accum:5.000000 total_samples:1616224.000000'}\n",
      "[Train Epoch]1/2 [Time]3992.35 [Step]20228 [Batch]51000 [Speed]78.28ms/step [Loss]10.3109 [Metrics]{'train_loss:10.310902 train_acc_clicks:0.044643 train_acc_carts:0.127428 train_acc_orders:0.152881 lr:0.000621 grad_accum:5.000000 total_samples:1632224.000000'}\n",
      "[Train Epoch]1/2 [Time]4030.51 [Step]20328 [Batch]51500 [Speed]78.26ms/step [Loss]10.3006 [Metrics]{'train_loss:10.300583 train_acc_clicks:0.044727 train_acc_carts:0.127545 train_acc_orders:0.153399 lr:0.000620 grad_accum:5.000000 total_samples:1648224.000000'}\n",
      "[Train Epoch]1/2 [Time]4068.90 [Step]20428 [Batch]52000 [Speed]78.25ms/step [Loss]10.2901 [Metrics]{'train_loss:10.290140 train_acc_clicks:0.044807 train_acc_carts:0.127680 train_acc_orders:0.153824 lr:0.000618 grad_accum:5.000000 total_samples:1664224.000000'}\n",
      "[Train Epoch]1/2 [Time]4107.11 [Step]20528 [Batch]52500 [Speed]78.23ms/step [Loss]10.2805 [Metrics]{'train_loss:10.280505 train_acc_clicks:0.044902 train_acc_carts:0.127849 train_acc_orders:0.154084 lr:0.000617 grad_accum:5.000000 total_samples:1680224.000000'}\n",
      "[Train Epoch]1/2 [Time]4145.26 [Step]20628 [Batch]53000 [Speed]78.21ms/step [Loss]10.2702 [Metrics]{'train_loss:10.270193 train_acc_clicks:0.044999 train_acc_carts:0.128215 train_acc_orders:0.154478 lr:0.000615 grad_accum:5.000000 total_samples:1696224.000000'}\n",
      "[Train Epoch]1/2 [Time]4183.74 [Step]20728 [Batch]53500 [Speed]78.20ms/step [Loss]10.2599 [Metrics]{'train_loss:10.259871 train_acc_clicks:0.045079 train_acc_carts:0.128371 train_acc_orders:0.154883 lr:0.000614 grad_accum:5.000000 total_samples:1712224.000000'}\n",
      "[Train Epoch]1/2 [Time]4222.89 [Step]20828 [Batch]54000 [Speed]78.20ms/step [Loss]10.2500 [Metrics]{'train_loss:10.249967 train_acc_clicks:0.045164 train_acc_carts:0.128677 train_acc_orders:0.155319 lr:0.000612 grad_accum:5.000000 total_samples:1728224.000000'}\n",
      "[Train Epoch]1/2 [Time]4261.78 [Step]20928 [Batch]54500 [Speed]78.20ms/step [Loss]10.2397 [Metrics]{'train_loss:10.239703 train_acc_clicks:0.045262 train_acc_carts:0.128869 train_acc_orders:0.155756 lr:0.000611 grad_accum:5.000000 total_samples:1744224.000000'}\n",
      "[Train Epoch]1/2 [Time]4300.09 [Step]21028 [Batch]55000 [Speed]78.18ms/step [Loss]10.2299 [Metrics]{'train_loss:10.229860 train_acc_clicks:0.045347 train_acc_carts:0.129064 train_acc_orders:0.156099 lr:0.000610 grad_accum:5.000000 total_samples:1760224.000000'}\n",
      "[Train Epoch]1/2 [Time]4338.16 [Step]21128 [Batch]55500 [Speed]78.17ms/step [Loss]10.2199 [Metrics]{'train_loss:10.219906 train_acc_clicks:0.045444 train_acc_carts:0.129193 train_acc_orders:0.156610 lr:0.000608 grad_accum:5.000000 total_samples:1776224.000000'}\n",
      "[Train Epoch]1/2 [Time]4375.96 [Step]21228 [Batch]56000 [Speed]78.14ms/step [Loss]10.2100 [Metrics]{'train_loss:10.209964 train_acc_clicks:0.045536 train_acc_carts:0.129363 train_acc_orders:0.156817 lr:0.000607 grad_accum:5.000000 total_samples:1792224.000000'}\n",
      "[Train Epoch]1/2 [Time]4413.95 [Step]21328 [Batch]56500 [Speed]78.12ms/step [Loss]10.2000 [Metrics]{'train_loss:10.200000 train_acc_clicks:0.045611 train_acc_carts:0.129544 train_acc_orders:0.157292 lr:0.000605 grad_accum:5.000000 total_samples:1808224.000000'}\n",
      "[Train Epoch]1/2 [Time]4451.89 [Step]21428 [Batch]57000 [Speed]78.10ms/step [Loss]10.1907 [Metrics]{'train_loss:10.190701 train_acc_clicks:0.045701 train_acc_carts:0.129814 train_acc_orders:0.157716 lr:0.000604 grad_accum:5.000000 total_samples:1824224.000000'}\n",
      "[Train Epoch]1/2 [Time]4490.13 [Step]21528 [Batch]57500 [Speed]78.09ms/step [Loss]10.1813 [Metrics]{'train_loss:10.181334 train_acc_clicks:0.045780 train_acc_carts:0.129900 train_acc_orders:0.158040 lr:0.000602 grad_accum:5.000000 total_samples:1840224.000000'}\n",
      "[Train Epoch]1/2 [Time]4527.97 [Step]21628 [Batch]58000 [Speed]78.07ms/step [Loss]10.1723 [Metrics]{'train_loss:10.172282 train_acc_clicks:0.045838 train_acc_carts:0.129974 train_acc_orders:0.158623 lr:0.000601 grad_accum:5.000000 total_samples:1856224.000000'}\n",
      "[Train Epoch]1/2 [Time]4565.78 [Step]21728 [Batch]58500 [Speed]78.05ms/step [Loss]10.1633 [Metrics]{'train_loss:10.163311 train_acc_clicks:0.045909 train_acc_carts:0.130145 train_acc_orders:0.158897 lr:0.000600 grad_accum:5.000000 total_samples:1872224.000000'}\n",
      "[Train Epoch]1/2 [Time]4603.48 [Step]21828 [Batch]59000 [Speed]78.03ms/step [Loss]10.1544 [Metrics]{'train_loss:10.154378 train_acc_clicks:0.046002 train_acc_carts:0.130586 train_acc_orders:0.159346 lr:0.000598 grad_accum:5.000000 total_samples:1888224.000000'}\n",
      "[Train Epoch]1/2 [Time]4641.26 [Step]21928 [Batch]59500 [Speed]78.00ms/step [Loss]10.1465 [Metrics]{'train_loss:10.146492 train_acc_clicks:0.046073 train_acc_carts:0.131419 train_acc_orders:0.159750 lr:0.000597 grad_accum:5.000000 total_samples:1904224.000000'}\n",
      "[Train Epoch]1/2 [Time]4679.29 [Step]22028 [Batch]60000 [Speed]77.99ms/step [Loss]10.1386 [Metrics]{'train_loss:10.138557 train_acc_clicks:0.046135 train_acc_carts:0.132088 train_acc_orders:0.160046 lr:0.000596 grad_accum:5.000000 total_samples:1920224.000000'}\n",
      "[Train Epoch]1/2 [Time]4717.14 [Step]22128 [Batch]60500 [Speed]77.97ms/step [Loss]10.1301 [Metrics]{'train_loss:10.130069 train_acc_clicks:0.046190 train_acc_carts:0.132446 train_acc_orders:0.160403 lr:0.000594 grad_accum:5.000000 total_samples:1936224.000000'}\n",
      "[Train Epoch]1/2 [Time]4754.90 [Step]22228 [Batch]61000 [Speed]77.95ms/step [Loss]10.1216 [Metrics]{'train_loss:10.121551 train_acc_clicks:0.046262 train_acc_carts:0.132616 train_acc_orders:0.160799 lr:0.000593 grad_accum:5.000000 total_samples:1952224.000000'}\n",
      "[Train Epoch]1/2 [Time]4793.03 [Step]22328 [Batch]61500 [Speed]77.94ms/step [Loss]10.1126 [Metrics]{'train_loss:10.112638 train_acc_clicks:0.046354 train_acc_carts:0.132761 train_acc_orders:0.161192 lr:0.000592 grad_accum:5.000000 total_samples:1968224.000000'}\n",
      "[Train Epoch]1/2 [Time]4831.18 [Step]22428 [Batch]62000 [Speed]77.92ms/step [Loss]10.1047 [Metrics]{'train_loss:10.104700 train_acc_clicks:0.046418 train_acc_carts:0.132913 train_acc_orders:0.161805 lr:0.000590 grad_accum:5.000000 total_samples:1984224.000000'}\n",
      "[Train Epoch]1/2 [Time]4869.51 [Step]22528 [Batch]62500 [Speed]77.91ms/step [Loss]10.0964 [Metrics]{'train_loss:10.096420 train_acc_clicks:0.046498 train_acc_carts:0.133191 train_acc_orders:0.162135 lr:0.000589 grad_accum:5.000000 total_samples:2000224.000000'}\n",
      "[Train Epoch]1/2 [Time]4908.00 [Step]22628 [Batch]63000 [Speed]77.90ms/step [Loss]10.0886 [Metrics]{'train_loss:10.088612 train_acc_clicks:0.046559 train_acc_carts:0.133391 train_acc_orders:0.162552 lr:0.000588 grad_accum:5.000000 total_samples:2016224.000000'}\n",
      "[Train Epoch]1/2 [Time]4946.43 [Step]22728 [Batch]63500 [Speed]77.90ms/step [Loss]10.0804 [Metrics]{'train_loss:10.080385 train_acc_clicks:0.046613 train_acc_carts:0.133699 train_acc_orders:0.162912 lr:0.000586 grad_accum:5.000000 total_samples:2032224.000000'}\n",
      "[Train Epoch]1/2 [Time]4984.71 [Step]22828 [Batch]64000 [Speed]77.89ms/step [Loss]10.0722 [Metrics]{'train_loss:10.072169 train_acc_clicks:0.046677 train_acc_carts:0.133817 train_acc_orders:0.163269 lr:0.000585 grad_accum:5.000000 total_samples:2048224.000000'}\n",
      "[Train Epoch]1/2 [Time]5023.10 [Step]22928 [Batch]64500 [Speed]77.88ms/step [Loss]10.0643 [Metrics]{'train_loss:10.064330 train_acc_clicks:0.046725 train_acc_carts:0.133831 train_acc_orders:0.163643 lr:0.000584 grad_accum:5.000000 total_samples:2064224.000000'}\n",
      "[Train Epoch]1/2 [Time]5061.20 [Step]23028 [Batch]65000 [Speed]77.86ms/step [Loss]10.0561 [Metrics]{'train_loss:10.056108 train_acc_clicks:0.046788 train_acc_carts:0.133897 train_acc_orders:0.163804 lr:0.000582 grad_accum:5.000000 total_samples:2080224.000000'}\n",
      "[Train Epoch]1/2 [Time]5099.36 [Step]23128 [Batch]65500 [Speed]77.85ms/step [Loss]10.0483 [Metrics]{'train_loss:10.048290 train_acc_clicks:0.046845 train_acc_carts:0.134015 train_acc_orders:0.164068 lr:0.000581 grad_accum:5.000000 total_samples:2096224.000000'}\n",
      "[Train Epoch]1/2 [Time]5137.26 [Step]23228 [Batch]66000 [Speed]77.84ms/step [Loss]10.0405 [Metrics]{'train_loss:10.040460 train_acc_clicks:0.046896 train_acc_carts:0.134125 train_acc_orders:0.164362 lr:0.000580 grad_accum:5.000000 total_samples:2112224.000000'}\n",
      "[Train Epoch]1/2 [Time]5174.97 [Step]23328 [Batch]66500 [Speed]77.82ms/step [Loss]10.0327 [Metrics]{'train_loss:10.032711 train_acc_clicks:0.046960 train_acc_carts:0.134255 train_acc_orders:0.164777 lr:0.000579 grad_accum:5.000000 total_samples:2128224.000000'}\n",
      "[Train Epoch]1/2 [Time]5212.91 [Step]23428 [Batch]67000 [Speed]77.80ms/step [Loss]10.0250 [Metrics]{'train_loss:10.024985 train_acc_clicks:0.047008 train_acc_carts:0.134335 train_acc_orders:0.165041 lr:0.000577 grad_accum:5.000000 total_samples:2144224.000000'}\n",
      "[Train Epoch]1/2 [Time]5250.97 [Step]23528 [Batch]67500 [Speed]77.79ms/step [Loss]10.0172 [Metrics]{'train_loss:10.017220 train_acc_clicks:0.047059 train_acc_carts:0.134375 train_acc_orders:0.165367 lr:0.000576 grad_accum:5.000000 total_samples:2160224.000000'}\n",
      "[Train Epoch]1/2 [Time]5289.18 [Step]23628 [Batch]68000 [Speed]77.78ms/step [Loss]10.0097 [Metrics]{'train_loss:10.009683 train_acc_clicks:0.047115 train_acc_carts:0.134478 train_acc_orders:0.165759 lr:0.000575 grad_accum:5.000000 total_samples:2176224.000000'}\n",
      "[Train Epoch]1/2 [Time]5327.22 [Step]23728 [Batch]68500 [Speed]77.77ms/step [Loss]10.0022 [Metrics]{'train_loss:10.002157 train_acc_clicks:0.047178 train_acc_carts:0.134555 train_acc_orders:0.166073 lr:0.000574 grad_accum:5.000000 total_samples:2192224.000000'}\n",
      "[Train Epoch]1/2 [Time]5364.96 [Step]23828 [Batch]69000 [Speed]77.75ms/step [Loss]9.9948 [Metrics]{'train_loss:9.994814 train_acc_clicks:0.047222 train_acc_carts:0.134714 train_acc_orders:0.166383 lr:0.000573 grad_accum:5.000000 total_samples:2208224.000000'}\n",
      "[Train Epoch]1/2 [Time]5402.84 [Step]23928 [Batch]69500 [Speed]77.74ms/step [Loss]9.9874 [Metrics]{'train_loss:9.987359 train_acc_clicks:0.047283 train_acc_carts:0.134812 train_acc_orders:0.166714 lr:0.000571 grad_accum:5.000000 total_samples:2224224.000000'}\n",
      "[Train Epoch]1/2 [Time]5440.57 [Step]24028 [Batch]70000 [Speed]77.72ms/step [Loss]9.9800 [Metrics]{'train_loss:9.979973 train_acc_clicks:0.047343 train_acc_carts:0.134911 train_acc_orders:0.167165 lr:0.000570 grad_accum:5.000000 total_samples:2240224.000000'}\n",
      "[Train Epoch]1/2 [Time]5478.20 [Step]24128 [Batch]70500 [Speed]77.70ms/step [Loss]9.9725 [Metrics]{'train_loss:9.972523 train_acc_clicks:0.047408 train_acc_carts:0.134939 train_acc_orders:0.167485 lr:0.000569 grad_accum:5.000000 total_samples:2256224.000000'}\n",
      "[Train Epoch]1/2 [Time]5516.19 [Step]24228 [Batch]71000 [Speed]77.69ms/step [Loss]9.9652 [Metrics]{'train_loss:9.965178 train_acc_clicks:0.047469 train_acc_carts:0.135053 train_acc_orders:0.167869 lr:0.000568 grad_accum:5.000000 total_samples:2272224.000000'}\n",
      "[Train Epoch]1/2 [Time]5554.09 [Step]24328 [Batch]71500 [Speed]77.68ms/step [Loss]9.9577 [Metrics]{'train_loss:9.957660 train_acc_clicks:0.047529 train_acc_carts:0.135133 train_acc_orders:0.168024 lr:0.000567 grad_accum:5.000000 total_samples:2288224.000000'}\n",
      "[Train Epoch]1/2 [Time]5591.75 [Step]24428 [Batch]72000 [Speed]77.66ms/step [Loss]9.9505 [Metrics]{'train_loss:9.950531 train_acc_clicks:0.047572 train_acc_carts:0.135187 train_acc_orders:0.168408 lr:0.000566 grad_accum:5.000000 total_samples:2304224.000000'}\n",
      "[Train Epoch]1/2 [Time]5629.63 [Step]24528 [Batch]72500 [Speed]77.65ms/step [Loss]9.9433 [Metrics]{'train_loss:9.943267 train_acc_clicks:0.047627 train_acc_carts:0.135217 train_acc_orders:0.168693 lr:0.000564 grad_accum:5.000000 total_samples:2320224.000000'}\n",
      "[Train Epoch]1/2 [Time]5667.59 [Step]24628 [Batch]73000 [Speed]77.64ms/step [Loss]9.9362 [Metrics]{'train_loss:9.936166 train_acc_clicks:0.047671 train_acc_carts:0.135320 train_acc_orders:0.169088 lr:0.000563 grad_accum:5.000000 total_samples:2336224.000000'}\n",
      "[Train Epoch]1/2 [Time]5705.46 [Step]24728 [Batch]73500 [Speed]77.63ms/step [Loss]9.9293 [Metrics]{'train_loss:9.929319 train_acc_clicks:0.047730 train_acc_carts:0.135405 train_acc_orders:0.169529 lr:0.000562 grad_accum:5.000000 total_samples:2352224.000000'}\n",
      "[Train Epoch]1/2 [Time]5743.39 [Step]24828 [Batch]74000 [Speed]77.61ms/step [Loss]9.9221 [Metrics]{'train_loss:9.922136 train_acc_clicks:0.047786 train_acc_carts:0.135746 train_acc_orders:0.169950 lr:0.000561 grad_accum:5.000000 total_samples:2368224.000000'}\n",
      "[Train Epoch]1/2 [Time]5781.21 [Step]24928 [Batch]74500 [Speed]77.60ms/step [Loss]9.9154 [Metrics]{'train_loss:9.915401 train_acc_clicks:0.047839 train_acc_carts:0.136045 train_acc_orders:0.170259 lr:0.000560 grad_accum:5.000000 total_samples:2384224.000000'}\n",
      "Saving checkpoint for epoch 1 at step 25000 on path model_bert4rec_complete_0.8.5\n",
      "Saving checkpoint for epoch 1 at step 25000 on path model_bert4rec_complete_0.8.5\n",
      "Saving checkpoint for epoch 1 at step 25000 on path model_bert4rec_complete_0.8.5\n",
      "Saving checkpoint for epoch 1 at step 25000 on path model_bert4rec_complete_0.8.5\n",
      "Saving checkpoint for epoch 1 at step 25000 on path model_bert4rec_complete_0.8.5\n",
      "[Train Epoch]1/2 [Time]5840.51 [Step]25028 [Batch]75000 [Speed]77.87ms/step [Loss]9.9095 [Metrics]{'train_loss:9.909548 train_acc_clicks:0.047896 train_acc_carts:0.136502 train_acc_orders:0.170714 lr:0.000559 grad_accum:5.000000 total_samples:2400224.000000'}\n",
      "[Train Epoch]1/2 [Time]5878.42 [Step]25128 [Batch]75500 [Speed]77.86ms/step [Loss]9.9034 [Metrics]{'train_loss:9.903361 train_acc_clicks:0.047950 train_acc_carts:0.136856 train_acc_orders:0.171017 lr:0.000558 grad_accum:5.000000 total_samples:2416224.000000'}\n",
      "[Train Epoch]1/2 [Time]5916.25 [Step]25228 [Batch]76000 [Speed]77.85ms/step [Loss]9.8970 [Metrics]{'train_loss:9.897000 train_acc_clicks:0.048008 train_acc_carts:0.137165 train_acc_orders:0.171362 lr:0.000556 grad_accum:5.000000 total_samples:2432224.000000'}\n",
      "[Train Epoch]1/2 [Time]5954.12 [Step]25328 [Batch]76500 [Speed]77.83ms/step [Loss]9.8905 [Metrics]{'train_loss:9.890476 train_acc_clicks:0.048065 train_acc_carts:0.137413 train_acc_orders:0.171728 lr:0.000555 grad_accum:5.000000 total_samples:2448224.000000'}\n",
      "[Train Epoch]1/2 [Time]5992.70 [Step]25428 [Batch]77000 [Speed]77.83ms/step [Loss]9.8846 [Metrics]{'train_loss:9.884569 train_acc_clicks:0.048126 train_acc_carts:0.137756 train_acc_orders:0.172159 lr:0.000554 grad_accum:5.000000 total_samples:2464224.000000'}\n",
      "[Train Epoch]1/2 [Time]6030.60 [Step]25528 [Batch]77500 [Speed]77.81ms/step [Loss]9.8787 [Metrics]{'train_loss:9.878705 train_acc_clicks:0.048173 train_acc_carts:0.138100 train_acc_orders:0.172516 lr:0.000553 grad_accum:5.000000 total_samples:2480224.000000'}\n",
      "[Train Epoch]1/2 [Time]6068.32 [Step]25628 [Batch]78000 [Speed]77.80ms/step [Loss]9.8731 [Metrics]{'train_loss:9.873056 train_acc_clicks:0.048218 train_acc_carts:0.138423 train_acc_orders:0.172807 lr:0.000552 grad_accum:5.000000 total_samples:2496224.000000'}\n",
      "[Train Epoch]1/2 [Time]6106.38 [Step]25728 [Batch]78500 [Speed]77.79ms/step [Loss]9.8673 [Metrics]{'train_loss:9.867280 train_acc_clicks:0.048272 train_acc_carts:0.138727 train_acc_orders:0.173004 lr:0.000551 grad_accum:5.000000 total_samples:2512224.000000'}\n",
      "[Train Epoch]1/2 [Time]6144.79 [Step]25828 [Batch]79000 [Speed]77.78ms/step [Loss]9.8613 [Metrics]{'train_loss:9.861321 train_acc_clicks:0.048309 train_acc_carts:0.138923 train_acc_orders:0.173451 lr:0.000550 grad_accum:5.000000 total_samples:2528224.000000'}\n",
      "[Train Epoch]1/2 [Time]6181.37 [Step]25928 [Batch]79500 [Speed]77.75ms/step [Loss]9.8554 [Metrics]{'train_loss:9.855370 train_acc_clicks:0.048344 train_acc_carts:0.139137 train_acc_orders:0.173756 lr:0.000549 grad_accum:5.000000 total_samples:2544224.000000'}\n",
      "[Train Epoch]1/2 [Time]6217.92 [Step]26028 [Batch]80000 [Speed]77.72ms/step [Loss]9.8499 [Metrics]{'train_loss:9.849899 train_acc_clicks:0.048384 train_acc_carts:0.139410 train_acc_orders:0.174016 lr:0.000548 grad_accum:5.000000 total_samples:2560224.000000'}\n",
      "[Train Epoch]1/2 [Time]6254.44 [Step]26128 [Batch]80500 [Speed]77.69ms/step [Loss]9.8446 [Metrics]{'train_loss:9.844623 train_acc_clicks:0.048440 train_acc_carts:0.139918 train_acc_orders:0.174268 lr:0.000547 grad_accum:5.000000 total_samples:2576224.000000'}\n",
      "[Train Epoch]1/2 [Time]6290.93 [Step]26228 [Batch]81000 [Speed]77.67ms/step [Loss]9.8390 [Metrics]{'train_loss:9.839033 train_acc_clicks:0.048500 train_acc_carts:0.140230 train_acc_orders:0.174493 lr:0.000546 grad_accum:5.000000 total_samples:2592224.000000'}\n",
      "[Train Epoch]1/2 [Time]6327.42 [Step]26328 [Batch]81500 [Speed]77.64ms/step [Loss]9.8331 [Metrics]{'train_loss:9.833077 train_acc_clicks:0.048565 train_acc_carts:0.140472 train_acc_orders:0.174778 lr:0.000545 grad_accum:5.000000 total_samples:2608224.000000'}\n",
      "[Train Epoch]1/2 [Time]6363.92 [Step]26428 [Batch]82000 [Speed]77.61ms/step [Loss]9.8272 [Metrics]{'train_loss:9.827170 train_acc_clicks:0.048607 train_acc_carts:0.140542 train_acc_orders:0.174965 lr:0.000544 grad_accum:5.000000 total_samples:2624224.000000'}\n",
      "[Train Epoch]1/2 [Time]6400.44 [Step]26528 [Batch]82500 [Speed]77.58ms/step [Loss]9.8217 [Metrics]{'train_loss:9.821653 train_acc_clicks:0.048644 train_acc_carts:0.140781 train_acc_orders:0.175208 lr:0.000543 grad_accum:5.000000 total_samples:2640224.000000'}\n",
      "[Train Epoch]1/2 [Time]6436.99 [Step]26628 [Batch]83000 [Speed]77.55ms/step [Loss]9.8159 [Metrics]{'train_loss:9.815863 train_acc_clicks:0.048688 train_acc_carts:0.140944 train_acc_orders:0.175444 lr:0.000542 grad_accum:5.000000 total_samples:2656224.000000'}\n",
      "[Train Epoch]1/2 [Time]6473.55 [Step]26728 [Batch]83500 [Speed]77.53ms/step [Loss]9.8103 [Metrics]{'train_loss:9.810322 train_acc_clicks:0.048725 train_acc_carts:0.141091 train_acc_orders:0.175716 lr:0.000541 grad_accum:5.000000 total_samples:2672224.000000'}\n",
      "[Train Epoch]1/2 [Time]6510.09 [Step]26828 [Batch]84000 [Speed]77.50ms/step [Loss]9.8046 [Metrics]{'train_loss:9.804630 train_acc_clicks:0.048776 train_acc_carts:0.141297 train_acc_orders:0.175966 lr:0.000540 grad_accum:5.000000 total_samples:2688224.000000'}\n",
      "[Train Epoch]1/2 [Time]6546.61 [Step]26928 [Batch]84500 [Speed]77.47ms/step [Loss]9.7991 [Metrics]{'train_loss:9.799090 train_acc_clicks:0.048820 train_acc_carts:0.141459 train_acc_orders:0.176172 lr:0.000539 grad_accum:5.000000 total_samples:2704224.000000'}\n",
      "[Train Epoch]1/2 [Time]6583.16 [Step]27028 [Batch]85000 [Speed]77.45ms/step [Loss]9.7938 [Metrics]{'train_loss:9.793752 train_acc_clicks:0.048851 train_acc_carts:0.141474 train_acc_orders:0.176386 lr:0.000538 grad_accum:5.000000 total_samples:2720224.000000'}\n",
      "[Train Epoch]1/2 [Time]6619.70 [Step]27128 [Batch]85500 [Speed]77.42ms/step [Loss]9.7882 [Metrics]{'train_loss:9.788228 train_acc_clicks:0.048894 train_acc_carts:0.141615 train_acc_orders:0.176656 lr:0.000537 grad_accum:5.000000 total_samples:2736224.000000'}\n",
      "[Train Epoch]1/2 [Time]6656.23 [Step]27228 [Batch]86000 [Speed]77.40ms/step [Loss]9.7825 [Metrics]{'train_loss:9.782547 train_acc_clicks:0.048933 train_acc_carts:0.141727 train_acc_orders:0.176976 lr:0.000536 grad_accum:5.000000 total_samples:2752224.000000'}\n",
      "[Train Epoch]1/2 [Time]6692.78 [Step]27328 [Batch]86500 [Speed]77.37ms/step [Loss]9.7774 [Metrics]{'train_loss:9.777399 train_acc_clicks:0.048982 train_acc_carts:0.142057 train_acc_orders:0.177194 lr:0.000535 grad_accum:5.000000 total_samples:2768224.000000'}\n",
      "[Train Epoch]1/2 [Time]6729.29 [Step]27428 [Batch]87000 [Speed]77.35ms/step [Loss]9.7725 [Metrics]{'train_loss:9.772479 train_acc_clicks:0.049014 train_acc_carts:0.142387 train_acc_orders:0.177493 lr:0.000534 grad_accum:5.000000 total_samples:2784224.000000'}\n",
      "[Train Epoch]1/2 [Time]6765.76 [Step]27528 [Batch]87500 [Speed]77.32ms/step [Loss]9.7676 [Metrics]{'train_loss:9.767630 train_acc_clicks:0.049052 train_acc_carts:0.142607 train_acc_orders:0.177720 lr:0.000533 grad_accum:5.000000 total_samples:2800224.000000'}\n",
      "[Train Epoch]1/2 [Time]6802.30 [Step]27628 [Batch]88000 [Speed]77.30ms/step [Loss]9.7622 [Metrics]{'train_loss:9.762206 train_acc_clicks:0.049090 train_acc_carts:0.142718 train_acc_orders:0.177963 lr:0.000532 grad_accum:5.000000 total_samples:2816224.000000'}\n",
      "[Train Epoch]1/2 [Time]6838.82 [Step]27728 [Batch]88500 [Speed]77.27ms/step [Loss]9.7568 [Metrics]{'train_loss:9.756796 train_acc_clicks:0.049142 train_acc_carts:0.142814 train_acc_orders:0.178233 lr:0.000531 grad_accum:5.000000 total_samples:2832224.000000'}\n",
      "[Train Epoch]1/2 [Time]6875.37 [Step]27828 [Batch]89000 [Speed]77.25ms/step [Loss]9.7513 [Metrics]{'train_loss:9.751288 train_acc_clicks:0.049178 train_acc_carts:0.142812 train_acc_orders:0.178526 lr:0.000530 grad_accum:5.000000 total_samples:2848224.000000'}\n",
      "[Train Epoch]1/2 [Time]6911.94 [Step]27928 [Batch]89500 [Speed]77.23ms/step [Loss]9.7459 [Metrics]{'train_loss:9.745865 train_acc_clicks:0.049222 train_acc_carts:0.142939 train_acc_orders:0.178700 lr:0.000529 grad_accum:5.000000 total_samples:2864224.000000'}\n",
      "[Train Epoch]1/2 [Time]6948.46 [Step]28028 [Batch]90000 [Speed]77.21ms/step [Loss]9.7406 [Metrics]{'train_loss:9.740641 train_acc_clicks:0.049266 train_acc_carts:0.143066 train_acc_orders:0.178883 lr:0.000528 grad_accum:5.000000 total_samples:2880224.000000'}\n",
      "[Train Epoch]1/2 [Time]6984.96 [Step]28128 [Batch]90500 [Speed]77.18ms/step [Loss]9.7354 [Metrics]{'train_loss:9.735435 train_acc_clicks:0.049308 train_acc_carts:0.143231 train_acc_orders:0.179147 lr:0.000527 grad_accum:5.000000 total_samples:2896224.000000'}\n",
      "[Train Epoch]1/2 [Time]7021.51 [Step]28228 [Batch]91000 [Speed]77.16ms/step [Loss]9.7306 [Metrics]{'train_loss:9.730645 train_acc_clicks:0.049359 train_acc_carts:0.143422 train_acc_orders:0.179358 lr:0.000526 grad_accum:5.000000 total_samples:2912224.000000'}\n",
      "[Train Epoch]1/2 [Time]7058.05 [Step]28328 [Batch]91500 [Speed]77.14ms/step [Loss]9.7256 [Metrics]{'train_loss:9.725649 train_acc_clicks:0.049405 train_acc_carts:0.143627 train_acc_orders:0.179702 lr:0.000525 grad_accum:5.000000 total_samples:2928224.000000'}\n",
      "[Train Epoch]1/2 [Time]7094.53 [Step]28428 [Batch]92000 [Speed]77.11ms/step [Loss]9.7208 [Metrics]{'train_loss:9.720809 train_acc_clicks:0.049452 train_acc_carts:0.143840 train_acc_orders:0.180090 lr:0.000524 grad_accum:5.000000 total_samples:2944224.000000'}\n",
      "[Train Epoch]1/2 [Time]7131.05 [Step]28528 [Batch]92500 [Speed]77.09ms/step [Loss]9.7159 [Metrics]{'train_loss:9.715901 train_acc_clicks:0.049488 train_acc_carts:0.143963 train_acc_orders:0.180369 lr:0.000523 grad_accum:5.000000 total_samples:2960224.000000'}\n",
      "[Train Epoch]1/2 [Time]7167.55 [Step]28628 [Batch]93000 [Speed]77.07ms/step [Loss]9.7110 [Metrics]{'train_loss:9.710952 train_acc_clicks:0.049519 train_acc_carts:0.143991 train_acc_orders:0.180684 lr:0.000522 grad_accum:5.000000 total_samples:2976224.000000'}\n",
      "[Train Epoch]1/2 [Time]7204.04 [Step]28728 [Batch]93500 [Speed]77.05ms/step [Loss]9.7058 [Metrics]{'train_loss:9.705834 train_acc_clicks:0.049556 train_acc_carts:0.144084 train_acc_orders:0.180932 lr:0.000521 grad_accum:5.000000 total_samples:2992224.000000'}\n",
      "[Train Epoch]1/2 [Time]7240.60 [Step]28828 [Batch]94000 [Speed]77.03ms/step [Loss]9.7010 [Metrics]{'train_loss:9.700972 train_acc_clicks:0.049587 train_acc_carts:0.144284 train_acc_orders:0.181116 lr:0.000521 grad_accum:5.000000 total_samples:3008224.000000'}\n",
      "[Train Epoch]1/2 [Time]7277.16 [Step]28928 [Batch]94500 [Speed]77.01ms/step [Loss]9.6963 [Metrics]{'train_loss:9.696318 train_acc_clicks:0.049629 train_acc_carts:0.144521 train_acc_orders:0.181354 lr:0.000520 grad_accum:5.000000 total_samples:3024224.000000'}\n",
      "[Train Epoch]1/2 [Time]7313.79 [Step]29028 [Batch]95000 [Speed]76.99ms/step [Loss]9.6916 [Metrics]{'train_loss:9.691614 train_acc_clicks:0.049661 train_acc_carts:0.144595 train_acc_orders:0.181701 lr:0.000519 grad_accum:5.000000 total_samples:3040224.000000'}\n",
      "[Train Epoch]1/2 [Time]7350.28 [Step]29128 [Batch]95500 [Speed]76.97ms/step [Loss]9.6869 [Metrics]{'train_loss:9.686939 train_acc_clicks:0.049689 train_acc_carts:0.144766 train_acc_orders:0.181923 lr:0.000518 grad_accum:5.000000 total_samples:3056224.000000'}\n",
      "[Train Epoch]1/2 [Time]7386.79 [Step]29228 [Batch]96000 [Speed]76.95ms/step [Loss]9.6823 [Metrics]{'train_loss:9.682273 train_acc_clicks:0.049718 train_acc_carts:0.144899 train_acc_orders:0.182146 lr:0.000517 grad_accum:5.000000 total_samples:3072224.000000'}\n",
      "[Train Epoch]1/2 [Time]7423.34 [Step]29328 [Batch]96500 [Speed]76.93ms/step [Loss]9.6775 [Metrics]{'train_loss:9.677531 train_acc_clicks:0.049759 train_acc_carts:0.145022 train_acc_orders:0.182268 lr:0.000516 grad_accum:5.000000 total_samples:3088224.000000'}\n",
      "[Train Epoch]1/2 [Time]7459.87 [Step]29428 [Batch]97000 [Speed]76.91ms/step [Loss]9.6728 [Metrics]{'train_loss:9.672828 train_acc_clicks:0.049803 train_acc_carts:0.145080 train_acc_orders:0.182424 lr:0.000515 grad_accum:5.000000 total_samples:3104224.000000'}\n",
      "[Train Epoch]1/2 [Time]7496.42 [Step]29528 [Batch]97500 [Speed]76.89ms/step [Loss]9.6684 [Metrics]{'train_loss:9.668372 train_acc_clicks:0.049837 train_acc_carts:0.145228 train_acc_orders:0.182601 lr:0.000514 grad_accum:5.000000 total_samples:3120224.000000'}\n",
      "[Train Epoch]1/2 [Time]7532.91 [Step]29628 [Batch]98000 [Speed]76.87ms/step [Loss]9.6642 [Metrics]{'train_loss:9.664178 train_acc_clicks:0.049883 train_acc_carts:0.145449 train_acc_orders:0.182811 lr:0.000514 grad_accum:5.000000 total_samples:3136224.000000'}\n",
      "[Train Epoch]1/2 [Time]7569.42 [Step]29728 [Batch]98500 [Speed]76.85ms/step [Loss]9.6598 [Metrics]{'train_loss:9.659794 train_acc_clicks:0.049908 train_acc_carts:0.145587 train_acc_orders:0.183104 lr:0.000513 grad_accum:5.000000 total_samples:3152224.000000'}\n",
      "[Train Epoch]1/2 [Time]7605.93 [Step]29828 [Batch]99000 [Speed]76.83ms/step [Loss]9.6551 [Metrics]{'train_loss:9.655144 train_acc_clicks:0.049933 train_acc_carts:0.145708 train_acc_orders:0.183254 lr:0.000512 grad_accum:5.000000 total_samples:3168224.000000'}\n",
      "[Train Epoch]1/2 [Time]7642.42 [Step]29928 [Batch]99500 [Speed]76.81ms/step [Loss]9.6510 [Metrics]{'train_loss:9.650950 train_acc_clicks:0.049963 train_acc_carts:0.145820 train_acc_orders:0.183520 lr:0.000511 grad_accum:5.000000 total_samples:3184224.000000'}\n",
      "[Train Epoch]1/2 [Time]7679.00 [Step]30028 [Batch]100000 [Speed]76.79ms/step [Loss]9.6464 [Metrics]{'train_loss:9.646387 train_acc_clicks:0.049999 train_acc_carts:0.145900 train_acc_orders:0.183706 lr:0.000510 grad_accum:5.000000 total_samples:3200224.000000'}\n",
      "[Train Epoch]1/2 [Time]7715.55 [Step]30128 [Batch]100500 [Speed]76.77ms/step [Loss]9.6419 [Metrics]{'train_loss:9.641944 train_acc_clicks:0.050032 train_acc_carts:0.146058 train_acc_orders:0.183919 lr:0.000509 grad_accum:5.000000 total_samples:3216224.000000'}\n",
      "[Train Epoch]1/2 [Time]7752.08 [Step]30228 [Batch]101000 [Speed]76.75ms/step [Loss]9.6375 [Metrics]{'train_loss:9.637541 train_acc_clicks:0.050065 train_acc_carts:0.146129 train_acc_orders:0.184104 lr:0.000508 grad_accum:5.000000 total_samples:3232224.000000'}\n",
      "[Train Epoch]1/2 [Time]7788.59 [Step]30328 [Batch]101500 [Speed]76.73ms/step [Loss]9.6330 [Metrics]{'train_loss:9.633041 train_acc_clicks:0.050090 train_acc_carts:0.146271 train_acc_orders:0.184498 lr:0.000508 grad_accum:5.000000 total_samples:3248224.000000'}\n",
      "[Train Epoch]1/2 [Time]7825.11 [Step]30428 [Batch]102000 [Speed]76.72ms/step [Loss]9.6290 [Metrics]{'train_loss:9.628962 train_acc_clicks:0.050128 train_acc_carts:0.146442 train_acc_orders:0.184676 lr:0.000507 grad_accum:5.000000 total_samples:3264224.000000'}\n",
      "[Train Epoch]1/2 [Time]7861.65 [Step]30528 [Batch]102500 [Speed]76.70ms/step [Loss]9.6248 [Metrics]{'train_loss:9.624783 train_acc_clicks:0.050161 train_acc_carts:0.146672 train_acc_orders:0.185007 lr:0.000506 grad_accum:5.000000 total_samples:3280224.000000'}\n",
      "[Train Epoch]1/2 [Time]7898.17 [Step]30628 [Batch]103000 [Speed]76.68ms/step [Loss]9.6208 [Metrics]{'train_loss:9.620817 train_acc_clicks:0.050193 train_acc_carts:0.146889 train_acc_orders:0.185067 lr:0.000505 grad_accum:5.000000 total_samples:3296224.000000'}\n",
      "[Train Epoch]1/2 [Time]7934.66 [Step]30728 [Batch]103500 [Speed]76.66ms/step [Loss]9.6166 [Metrics]{'train_loss:9.616594 train_acc_clicks:0.050223 train_acc_carts:0.147136 train_acc_orders:0.185238 lr:0.000504 grad_accum:5.000000 total_samples:3312224.000000'}\n",
      "[Train Epoch]1/2 [Time]7971.13 [Step]30828 [Batch]104000 [Speed]76.65ms/step [Loss]9.6127 [Metrics]{'train_loss:9.612707 train_acc_clicks:0.050251 train_acc_carts:0.147331 train_acc_orders:0.185513 lr:0.000503 grad_accum:5.000000 total_samples:3328224.000000'}\n",
      "[Train Epoch]1/2 [Time]8007.61 [Step]30928 [Batch]104500 [Speed]76.63ms/step [Loss]9.6086 [Metrics]{'train_loss:9.608587 train_acc_clicks:0.050276 train_acc_carts:0.147506 train_acc_orders:0.185842 lr:0.000503 grad_accum:5.000000 total_samples:3344224.000000'}\n",
      "[Train Epoch]1/2 [Time]8044.14 [Step]31028 [Batch]105000 [Speed]76.61ms/step [Loss]9.6045 [Metrics]{'train_loss:9.604493 train_acc_clicks:0.050300 train_acc_carts:0.147539 train_acc_orders:0.186068 lr:0.000502 grad_accum:5.000000 total_samples:3360224.000000'}\n",
      "[Train Epoch]1/2 [Time]8080.70 [Step]31128 [Batch]105500 [Speed]76.59ms/step [Loss]9.6003 [Metrics]{'train_loss:9.600266 train_acc_clicks:0.050326 train_acc_carts:0.147665 train_acc_orders:0.186260 lr:0.000501 grad_accum:5.000000 total_samples:3376224.000000'}\n",
      "[Train Epoch]1/2 [Time]8117.22 [Step]31228 [Batch]106000 [Speed]76.58ms/step [Loss]9.5962 [Metrics]{'train_loss:9.596166 train_acc_clicks:0.050353 train_acc_carts:0.147716 train_acc_orders:0.186539 lr:0.000500 grad_accum:5.000000 total_samples:3392224.000000'}\n",
      "[Train Epoch]1/2 [Time]8153.76 [Step]31328 [Batch]106500 [Speed]76.56ms/step [Loss]9.5922 [Metrics]{'train_loss:9.592201 train_acc_clicks:0.050375 train_acc_carts:0.147762 train_acc_orders:0.186807 lr:0.000499 grad_accum:5.000000 total_samples:3408224.000000'}\n",
      "[Train Epoch]1/2 [Time]8190.24 [Step]31428 [Batch]107000 [Speed]76.54ms/step [Loss]9.5881 [Metrics]{'train_loss:9.588092 train_acc_clicks:0.050407 train_acc_carts:0.147850 train_acc_orders:0.187054 lr:0.000499 grad_accum:5.000000 total_samples:3424224.000000'}\n",
      "[Train Epoch]1/2 [Time]8226.73 [Step]31528 [Batch]107500 [Speed]76.53ms/step [Loss]9.5843 [Metrics]{'train_loss:9.584280 train_acc_clicks:0.050431 train_acc_carts:0.147975 train_acc_orders:0.187221 lr:0.000498 grad_accum:5.000000 total_samples:3440224.000000'}\n",
      "[Train Epoch]1/2 [Time]8263.25 [Step]31628 [Batch]108000 [Speed]76.51ms/step [Loss]9.5804 [Metrics]{'train_loss:9.580404 train_acc_clicks:0.050457 train_acc_carts:0.148150 train_acc_orders:0.187573 lr:0.000497 grad_accum:5.000000 total_samples:3456224.000000'}\n",
      "[Train Epoch]1/2 [Time]8299.78 [Step]31728 [Batch]108500 [Speed]76.50ms/step [Loss]9.5765 [Metrics]{'train_loss:9.576540 train_acc_clicks:0.050484 train_acc_carts:0.148271 train_acc_orders:0.187862 lr:0.000496 grad_accum:5.000000 total_samples:3472224.000000'}\n",
      "[Train Epoch]1/2 [Time]8336.32 [Step]31828 [Batch]109000 [Speed]76.48ms/step [Loss]9.5727 [Metrics]{'train_loss:9.572665 train_acc_clicks:0.050520 train_acc_carts:0.148442 train_acc_orders:0.188204 lr:0.000495 grad_accum:5.000000 total_samples:3488224.000000'}\n",
      "[Train Epoch]1/2 [Time]8372.83 [Step]31928 [Batch]109500 [Speed]76.46ms/step [Loss]9.5689 [Metrics]{'train_loss:9.568948 train_acc_clicks:0.050545 train_acc_carts:0.148566 train_acc_orders:0.188538 lr:0.000495 grad_accum:5.000000 total_samples:3504224.000000'}\n",
      "[Train Epoch]1/2 [Time]8409.34 [Step]32028 [Batch]110000 [Speed]76.45ms/step [Loss]9.5652 [Metrics]{'train_loss:9.565174 train_acc_clicks:0.050570 train_acc_carts:0.148829 train_acc_orders:0.188762 lr:0.000494 grad_accum:5.000000 total_samples:3520224.000000'}\n",
      "[Train Epoch]1/2 [Time]8445.84 [Step]32128 [Batch]110500 [Speed]76.43ms/step [Loss]9.5616 [Metrics]{'train_loss:9.561641 train_acc_clicks:0.050608 train_acc_carts:0.149100 train_acc_orders:0.188967 lr:0.000493 grad_accum:5.000000 total_samples:3536224.000000'}\n",
      "[Train Epoch]1/2 [Time]8482.35 [Step]32228 [Batch]111000 [Speed]76.42ms/step [Loss]9.5581 [Metrics]{'train_loss:9.558082 train_acc_clicks:0.050639 train_acc_carts:0.149257 train_acc_orders:0.189217 lr:0.000492 grad_accum:5.000000 total_samples:3552224.000000'}\n",
      "[Train Epoch]1/2 [Time]8518.91 [Step]32328 [Batch]111500 [Speed]76.40ms/step [Loss]9.5542 [Metrics]{'train_loss:9.554180 train_acc_clicks:0.050675 train_acc_carts:0.149325 train_acc_orders:0.189312 lr:0.000492 grad_accum:5.000000 total_samples:3568224.000000'}\n",
      "[Train Epoch]1/2 [Time]8555.44 [Step]32428 [Batch]112000 [Speed]76.39ms/step [Loss]9.5504 [Metrics]{'train_loss:9.550422 train_acc_clicks:0.050694 train_acc_carts:0.149441 train_acc_orders:0.189453 lr:0.000491 grad_accum:5.000000 total_samples:3584224.000000'}\n",
      "[Train Epoch]1/2 [Time]8592.01 [Step]32528 [Batch]112500 [Speed]76.37ms/step [Loss]9.5466 [Metrics]{'train_loss:9.546590 train_acc_clicks:0.050717 train_acc_carts:0.149539 train_acc_orders:0.189649 lr:0.000490 grad_accum:5.000000 total_samples:3600224.000000'}\n",
      "[Train Epoch]1/2 [Time]8628.51 [Step]32628 [Batch]113000 [Speed]76.36ms/step [Loss]9.5429 [Metrics]{'train_loss:9.542928 train_acc_clicks:0.050739 train_acc_carts:0.149678 train_acc_orders:0.189914 lr:0.000489 grad_accum:5.000000 total_samples:3616224.000000'}\n",
      "[Train Epoch]1/2 [Time]8665.06 [Step]32728 [Batch]113500 [Speed]76.34ms/step [Loss]9.5392 [Metrics]{'train_loss:9.539232 train_acc_clicks:0.050768 train_acc_carts:0.149737 train_acc_orders:0.190092 lr:0.000489 grad_accum:5.000000 total_samples:3632224.000000'}\n",
      "[Train Epoch]1/2 [Time]8701.61 [Step]32828 [Batch]114000 [Speed]76.33ms/step [Loss]9.5355 [Metrics]{'train_loss:9.535537 train_acc_clicks:0.050795 train_acc_carts:0.149864 train_acc_orders:0.190278 lr:0.000488 grad_accum:5.000000 total_samples:3648224.000000'}\n",
      "[Train Epoch]1/2 [Time]8738.13 [Step]32928 [Batch]114500 [Speed]76.32ms/step [Loss]9.5317 [Metrics]{'train_loss:9.531694 train_acc_clicks:0.050821 train_acc_carts:0.149986 train_acc_orders:0.190444 lr:0.000487 grad_accum:5.000000 total_samples:3664224.000000'}\n",
      "[Train Epoch]1/2 [Time]8774.62 [Step]33028 [Batch]115000 [Speed]76.30ms/step [Loss]9.5282 [Metrics]{'train_loss:9.528211 train_acc_clicks:0.050845 train_acc_carts:0.150079 train_acc_orders:0.190661 lr:0.000486 grad_accum:5.000000 total_samples:3680224.000000'}\n",
      "[Train Epoch]1/2 [Time]8811.12 [Step]33128 [Batch]115500 [Speed]76.29ms/step [Loss]9.5245 [Metrics]{'train_loss:9.524509 train_acc_clicks:0.050864 train_acc_carts:0.150160 train_acc_orders:0.190861 lr:0.000486 grad_accum:5.000000 total_samples:3696224.000000'}\n",
      "[Train Epoch]1/2 [Time]8847.57 [Step]33228 [Batch]116000 [Speed]76.27ms/step [Loss]9.5208 [Metrics]{'train_loss:9.520783 train_acc_clicks:0.050891 train_acc_carts:0.150180 train_acc_orders:0.191062 lr:0.000485 grad_accum:5.000000 total_samples:3712224.000000'}\n",
      "[Train Epoch]1/2 [Time]8884.06 [Step]33328 [Batch]116500 [Speed]76.26ms/step [Loss]9.5173 [Metrics]{'train_loss:9.517329 train_acc_clicks:0.050922 train_acc_carts:0.150359 train_acc_orders:0.191209 lr:0.000484 grad_accum:5.000000 total_samples:3728224.000000'}\n",
      "[Train Epoch]1/2 [Time]8920.62 [Step]33428 [Batch]117000 [Speed]76.24ms/step [Loss]9.5138 [Metrics]{'train_loss:9.513764 train_acc_clicks:0.050950 train_acc_carts:0.150498 train_acc_orders:0.191363 lr:0.000483 grad_accum:5.000000 total_samples:3744224.000000'}\n",
      "[Train Epoch]1/2 [Time]8957.22 [Step]33528 [Batch]117500 [Speed]76.23ms/step [Loss]9.5102 [Metrics]{'train_loss:9.510204 train_acc_clicks:0.050979 train_acc_carts:0.150609 train_acc_orders:0.191592 lr:0.000483 grad_accum:5.000000 total_samples:3760224.000000'}\n",
      "[Train Epoch]1/2 [Time]8993.77 [Step]33628 [Batch]118000 [Speed]76.22ms/step [Loss]9.5071 [Metrics]{'train_loss:9.507091 train_acc_clicks:0.051002 train_acc_carts:0.150771 train_acc_orders:0.191783 lr:0.000482 grad_accum:5.000000 total_samples:3776224.000000'}\n",
      "[Train Epoch]1/2 [Time]9030.27 [Step]33728 [Batch]118500 [Speed]76.20ms/step [Loss]9.5037 [Metrics]{'train_loss:9.503736 train_acc_clicks:0.051025 train_acc_carts:0.150923 train_acc_orders:0.191936 lr:0.000481 grad_accum:5.000000 total_samples:3792224.000000'}\n",
      "[Train Epoch]1/2 [Time]9066.77 [Step]33828 [Batch]119000 [Speed]76.19ms/step [Loss]9.5001 [Metrics]{'train_loss:9.500076 train_acc_clicks:0.051056 train_acc_carts:0.151121 train_acc_orders:0.191999 lr:0.000481 grad_accum:5.000000 total_samples:3808224.000000'}\n",
      "[Train Epoch]1/2 [Time]9103.28 [Step]33928 [Batch]119500 [Speed]76.18ms/step [Loss]9.4968 [Metrics]{'train_loss:9.496783 train_acc_clicks:0.051083 train_acc_carts:0.151276 train_acc_orders:0.192139 lr:0.000480 grad_accum:5.000000 total_samples:3824224.000000'}\n",
      "[Train Epoch]1/2 [Time]9139.79 [Step]34028 [Batch]120000 [Speed]76.16ms/step [Loss]9.4935 [Metrics]{'train_loss:9.493478 train_acc_clicks:0.051113 train_acc_carts:0.151410 train_acc_orders:0.192293 lr:0.000479 grad_accum:5.000000 total_samples:3840224.000000'}\n",
      "[Train Epoch]1/2 [Time]9176.29 [Step]34128 [Batch]120500 [Speed]76.15ms/step [Loss]9.4901 [Metrics]{'train_loss:9.490081 train_acc_clicks:0.051148 train_acc_carts:0.151723 train_acc_orders:0.192469 lr:0.000478 grad_accum:5.000000 total_samples:3856224.000000'}\n",
      "[Train Epoch]1/2 [Time]9212.78 [Step]34228 [Batch]121000 [Speed]76.14ms/step [Loss]9.4869 [Metrics]{'train_loss:9.486879 train_acc_clicks:0.051174 train_acc_carts:0.151963 train_acc_orders:0.192662 lr:0.000478 grad_accum:5.000000 total_samples:3872224.000000'}\n",
      "[Train Epoch]1/2 [Time]9249.28 [Step]34328 [Batch]121500 [Speed]76.13ms/step [Loss]9.4836 [Metrics]{'train_loss:9.483624 train_acc_clicks:0.051194 train_acc_carts:0.152060 train_acc_orders:0.192833 lr:0.000477 grad_accum:5.000000 total_samples:3888224.000000'}\n",
      "[Train Epoch]1/2 [Time]9285.76 [Step]34428 [Batch]122000 [Speed]76.11ms/step [Loss]9.4803 [Metrics]{'train_loss:9.480309 train_acc_clicks:0.051221 train_acc_carts:0.152154 train_acc_orders:0.192963 lr:0.000476 grad_accum:5.000000 total_samples:3904224.000000'}\n",
      "[Train Epoch]1/2 [Time]9322.31 [Step]34528 [Batch]122500 [Speed]76.10ms/step [Loss]9.4769 [Metrics]{'train_loss:9.476892 train_acc_clicks:0.051252 train_acc_carts:0.152302 train_acc_orders:0.193151 lr:0.000476 grad_accum:5.000000 total_samples:3920224.000000'}\n",
      "[Train Epoch]1/2 [Time]9358.86 [Step]34628 [Batch]123000 [Speed]76.09ms/step [Loss]9.4738 [Metrics]{'train_loss:9.473809 train_acc_clicks:0.051276 train_acc_carts:0.152403 train_acc_orders:0.193378 lr:0.000475 grad_accum:5.000000 total_samples:3936224.000000'}\n",
      "[Train Epoch]1/2 [Time]9395.38 [Step]34728 [Batch]123500 [Speed]76.08ms/step [Loss]9.4707 [Metrics]{'train_loss:9.470693 train_acc_clicks:0.051307 train_acc_carts:0.152572 train_acc_orders:0.193457 lr:0.000474 grad_accum:5.000000 total_samples:3952224.000000'}\n",
      "[Train Epoch]1/2 [Time]9431.90 [Step]34828 [Batch]124000 [Speed]76.06ms/step [Loss]9.4677 [Metrics]{'train_loss:9.467654 train_acc_clicks:0.051334 train_acc_carts:0.152719 train_acc_orders:0.193580 lr:0.000474 grad_accum:5.000000 total_samples:3968224.000000'}\n",
      "[Train Epoch]1/2 [Time]9468.42 [Step]34928 [Batch]124500 [Speed]76.05ms/step [Loss]9.4644 [Metrics]{'train_loss:9.464381 train_acc_clicks:0.051358 train_acc_carts:0.152812 train_acc_orders:0.193701 lr:0.000473 grad_accum:5.000000 total_samples:3984224.000000'}\n",
      "[Train Epoch]1/2 [Time]9504.95 [Step]35028 [Batch]125000 [Speed]76.04ms/step [Loss]9.4613 [Metrics]{'train_loss:9.461314 train_acc_clicks:0.051376 train_acc_carts:0.152978 train_acc_orders:0.193817 lr:0.000472 grad_accum:5.000000 total_samples:4000224.000000'}\n",
      "[Train Epoch]1/2 [Time]9541.47 [Step]35128 [Batch]125500 [Speed]76.03ms/step [Loss]9.4582 [Metrics]{'train_loss:9.458160 train_acc_clicks:0.051404 train_acc_carts:0.153045 train_acc_orders:0.193995 lr:0.000472 grad_accum:5.000000 total_samples:4016224.000000'}\n",
      "[Train Epoch]1/2 [Time]9578.02 [Step]35228 [Batch]126000 [Speed]76.02ms/step [Loss]9.4550 [Metrics]{'train_loss:9.454951 train_acc_clicks:0.051424 train_acc_carts:0.153137 train_acc_orders:0.194178 lr:0.000471 grad_accum:5.000000 total_samples:4032224.000000'}\n",
      "[Train Epoch]1/2 [Time]9614.50 [Step]35328 [Batch]126500 [Speed]76.00ms/step [Loss]9.4518 [Metrics]{'train_loss:9.451764 train_acc_clicks:0.051443 train_acc_carts:0.153227 train_acc_orders:0.194397 lr:0.000470 grad_accum:5.000000 total_samples:4048224.000000'}\n",
      "[Train Epoch]1/2 [Time]9651.00 [Step]35428 [Batch]127000 [Speed]75.99ms/step [Loss]9.4486 [Metrics]{'train_loss:9.448622 train_acc_clicks:0.051468 train_acc_carts:0.153270 train_acc_orders:0.194575 lr:0.000470 grad_accum:5.000000 total_samples:4064224.000000'}\n",
      "[Train Epoch]1/2 [Time]9687.52 [Step]35528 [Batch]127500 [Speed]75.98ms/step [Loss]9.4454 [Metrics]{'train_loss:9.445445 train_acc_clicks:0.051492 train_acc_carts:0.153328 train_acc_orders:0.194691 lr:0.000469 grad_accum:5.000000 total_samples:4080224.000000'}\n",
      "[Train Epoch]1/2 [Time]9723.99 [Step]35628 [Batch]128000 [Speed]75.97ms/step [Loss]9.4423 [Metrics]{'train_loss:9.442318 train_acc_clicks:0.051508 train_acc_carts:0.153416 train_acc_orders:0.194849 lr:0.000468 grad_accum:5.000000 total_samples:4096224.000000'}\n",
      "[Train Epoch]1/2 [Time]9760.56 [Step]35728 [Batch]128500 [Speed]75.96ms/step [Loss]9.4395 [Metrics]{'train_loss:9.439497 train_acc_clicks:0.051533 train_acc_carts:0.153635 train_acc_orders:0.195000 lr:0.000468 grad_accum:5.000000 total_samples:4112224.000000'}\n",
      "[Train Epoch]1/2 [Time]9797.12 [Step]35828 [Batch]129000 [Speed]75.95ms/step [Loss]9.4367 [Metrics]{'train_loss:9.436690 train_acc_clicks:0.051551 train_acc_carts:0.153858 train_acc_orders:0.195176 lr:0.000467 grad_accum:5.000000 total_samples:4128224.000000'}\n",
      "[Train Epoch]1/2 [Time]9833.68 [Step]35928 [Batch]129500 [Speed]75.94ms/step [Loss]9.4336 [Metrics]{'train_loss:9.433628 train_acc_clicks:0.051565 train_acc_carts:0.153931 train_acc_orders:0.195309 lr:0.000466 grad_accum:5.000000 total_samples:4144224.000000'}\n",
      "[Train Epoch]1/2 [Time]9870.17 [Step]36028 [Batch]130000 [Speed]75.92ms/step [Loss]9.4306 [Metrics]{'train_loss:9.430606 train_acc_clicks:0.051585 train_acc_carts:0.153985 train_acc_orders:0.195492 lr:0.000466 grad_accum:5.000000 total_samples:4160224.000000'}\n",
      "[Train Epoch]1/2 [Time]9906.65 [Step]36128 [Batch]130500 [Speed]75.91ms/step [Loss]9.4274 [Metrics]{'train_loss:9.427433 train_acc_clicks:0.051608 train_acc_carts:0.154041 train_acc_orders:0.195664 lr:0.000465 grad_accum:5.000000 total_samples:4176224.000000'}\n",
      "[Train Epoch]1/2 [Time]9943.16 [Step]36228 [Batch]131000 [Speed]75.90ms/step [Loss]9.4248 [Metrics]{'train_loss:9.424759 train_acc_clicks:0.051631 train_acc_carts:0.154164 train_acc_orders:0.195834 lr:0.000464 grad_accum:5.000000 total_samples:4192224.000000'}\n",
      "[Train Epoch]1/2 [Time]9979.71 [Step]36328 [Batch]131500 [Speed]75.89ms/step [Loss]9.4217 [Metrics]{'train_loss:9.421749 train_acc_clicks:0.051653 train_acc_carts:0.154333 train_acc_orders:0.196053 lr:0.000464 grad_accum:5.000000 total_samples:4208224.000000'}\n",
      "[Train Epoch]1/2 [Time]10016.24 [Step]36428 [Batch]132000 [Speed]75.88ms/step [Loss]9.4187 [Metrics]{'train_loss:9.418679 train_acc_clicks:0.051678 train_acc_carts:0.154435 train_acc_orders:0.196262 lr:0.000463 grad_accum:5.000000 total_samples:4224224.000000'}\n",
      "[Train Epoch]1/2 [Time]10052.75 [Step]36528 [Batch]132500 [Speed]75.87ms/step [Loss]9.4159 [Metrics]{'train_loss:9.415886 train_acc_clicks:0.051702 train_acc_carts:0.154498 train_acc_orders:0.196433 lr:0.000462 grad_accum:5.000000 total_samples:4240224.000000'}\n",
      "[Train Epoch]1/2 [Time]10089.24 [Step]36628 [Batch]133000 [Speed]75.86ms/step [Loss]9.4130 [Metrics]{'train_loss:9.412959 train_acc_clicks:0.051722 train_acc_carts:0.154600 train_acc_orders:0.196546 lr:0.000462 grad_accum:5.000000 total_samples:4256224.000000'}\n",
      "[Train Epoch]1/2 [Time]10125.79 [Step]36728 [Batch]133500 [Speed]75.85ms/step [Loss]9.4099 [Metrics]{'train_loss:9.409944 train_acc_clicks:0.051755 train_acc_carts:0.154569 train_acc_orders:0.196640 lr:0.000461 grad_accum:5.000000 total_samples:4272224.000000'}\n",
      "[Train Epoch]1/2 [Time]10162.35 [Step]36828 [Batch]134000 [Speed]75.84ms/step [Loss]9.4070 [Metrics]{'train_loss:9.407043 train_acc_clicks:0.051778 train_acc_carts:0.154593 train_acc_orders:0.196685 lr:0.000461 grad_accum:5.000000 total_samples:4288224.000000'}\n",
      "[Train Epoch]1/2 [Time]10198.91 [Step]36928 [Batch]134500 [Speed]75.83ms/step [Loss]9.4040 [Metrics]{'train_loss:9.404039 train_acc_clicks:0.051805 train_acc_carts:0.154682 train_acc_orders:0.196875 lr:0.000460 grad_accum:5.000000 total_samples:4304224.000000'}\n",
      "[Train Epoch]1/2 [Time]10235.49 [Step]37028 [Batch]135000 [Speed]75.82ms/step [Loss]9.4013 [Metrics]{'train_loss:9.401337 train_acc_clicks:0.051828 train_acc_carts:0.154709 train_acc_orders:0.197074 lr:0.000459 grad_accum:5.000000 total_samples:4320224.000000'}\n",
      "[Train Epoch]1/2 [Time]10271.97 [Step]37128 [Batch]135500 [Speed]75.81ms/step [Loss]9.3986 [Metrics]{'train_loss:9.398587 train_acc_clicks:0.051850 train_acc_carts:0.154823 train_acc_orders:0.197182 lr:0.000459 grad_accum:5.000000 total_samples:4336224.000000'}\n",
      "[Train Epoch]1/2 [Time]10308.45 [Step]37228 [Batch]136000 [Speed]75.80ms/step [Loss]9.3957 [Metrics]{'train_loss:9.395742 train_acc_clicks:0.051880 train_acc_carts:0.154969 train_acc_orders:0.197283 lr:0.000458 grad_accum:5.000000 total_samples:4352224.000000'}\n",
      "[Train Epoch]1/2 [Time]10344.98 [Step]37328 [Batch]136500 [Speed]75.79ms/step [Loss]9.3929 [Metrics]{'train_loss:9.392859 train_acc_clicks:0.051893 train_acc_carts:0.155041 train_acc_orders:0.197385 lr:0.000457 grad_accum:5.000000 total_samples:4368224.000000'}\n",
      "[Train Epoch]1/2 [Time]10381.51 [Step]37428 [Batch]137000 [Speed]75.78ms/step [Loss]9.3898 [Metrics]{'train_loss:9.389850 train_acc_clicks:0.051912 train_acc_carts:0.155051 train_acc_orders:0.197556 lr:0.000457 grad_accum:5.000000 total_samples:4384224.000000'}\n",
      "[Train Epoch]1/2 [Time]10418.05 [Step]37528 [Batch]137500 [Speed]75.77ms/step [Loss]9.3870 [Metrics]{'train_loss:9.387045 train_acc_clicks:0.051940 train_acc_carts:0.155119 train_acc_orders:0.197694 lr:0.000456 grad_accum:5.000000 total_samples:4400224.000000'}\n",
      "[Train Epoch]1/2 [Time]10454.54 [Step]37628 [Batch]138000 [Speed]75.76ms/step [Loss]9.3843 [Metrics]{'train_loss:9.384258 train_acc_clicks:0.051969 train_acc_carts:0.155236 train_acc_orders:0.197783 lr:0.000456 grad_accum:5.000000 total_samples:4416224.000000'}\n",
      "[Train Epoch]1/2 [Time]10491.01 [Step]37728 [Batch]138500 [Speed]75.75ms/step [Loss]9.3817 [Metrics]{'train_loss:9.381651 train_acc_clicks:0.051987 train_acc_carts:0.155419 train_acc_orders:0.197991 lr:0.000455 grad_accum:5.000000 total_samples:4432224.000000'}\n",
      "[Train Epoch]1/2 [Time]10527.47 [Step]37828 [Batch]139000 [Speed]75.74ms/step [Loss]9.3791 [Metrics]{'train_loss:9.379080 train_acc_clicks:0.052011 train_acc_carts:0.155576 train_acc_orders:0.198170 lr:0.000454 grad_accum:5.000000 total_samples:4448224.000000'}\n",
      "[Train Epoch]1/2 [Time]10563.97 [Step]37928 [Batch]139500 [Speed]75.73ms/step [Loss]9.3765 [Metrics]{'train_loss:9.376499 train_acc_clicks:0.052028 train_acc_carts:0.155687 train_acc_orders:0.198281 lr:0.000454 grad_accum:5.000000 total_samples:4464224.000000'}\n",
      "[Train Epoch]1/2 [Time]10600.55 [Step]38028 [Batch]140000 [Speed]75.72ms/step [Loss]9.3737 [Metrics]{'train_loss:9.373747 train_acc_clicks:0.052044 train_acc_carts:0.155674 train_acc_orders:0.198458 lr:0.000453 grad_accum:5.000000 total_samples:4480224.000000'}\n",
      "[Train Epoch]1/2 [Time]10637.14 [Step]38128 [Batch]140500 [Speed]75.71ms/step [Loss]9.3712 [Metrics]{'train_loss:9.371158 train_acc_clicks:0.052052 train_acc_carts:0.155679 train_acc_orders:0.198638 lr:0.000453 grad_accum:5.000000 total_samples:4496224.000000'}\n",
      "[Train Epoch]1/2 [Time]10673.67 [Step]38228 [Batch]141000 [Speed]75.70ms/step [Loss]9.3684 [Metrics]{'train_loss:9.368436 train_acc_clicks:0.052073 train_acc_carts:0.155668 train_acc_orders:0.198758 lr:0.000452 grad_accum:5.000000 total_samples:4512224.000000'}\n",
      "[Train Epoch]1/2 [Time]10710.16 [Step]38328 [Batch]141500 [Speed]75.69ms/step [Loss]9.3655 [Metrics]{'train_loss:9.365548 train_acc_clicks:0.052100 train_acc_carts:0.155719 train_acc_orders:0.198914 lr:0.000451 grad_accum:5.000000 total_samples:4528224.000000'}\n",
      "[Train Epoch]1/2 [Time]10746.67 [Step]38428 [Batch]142000 [Speed]75.68ms/step [Loss]9.3629 [Metrics]{'train_loss:9.362928 train_acc_clicks:0.052114 train_acc_carts:0.155783 train_acc_orders:0.199009 lr:0.000451 grad_accum:5.000000 total_samples:4544224.000000'}\n",
      "[Train Epoch]1/2 [Time]10783.21 [Step]38528 [Batch]142500 [Speed]75.67ms/step [Loss]9.3603 [Metrics]{'train_loss:9.360328 train_acc_clicks:0.052133 train_acc_carts:0.155818 train_acc_orders:0.199136 lr:0.000450 grad_accum:5.000000 total_samples:4560224.000000'}\n",
      "[Train Epoch]1/2 [Time]10819.74 [Step]38628 [Batch]143000 [Speed]75.66ms/step [Loss]9.3578 [Metrics]{'train_loss:9.357841 train_acc_clicks:0.052145 train_acc_carts:0.155922 train_acc_orders:0.199319 lr:0.000450 grad_accum:5.000000 total_samples:4576224.000000'}\n",
      "[Train Epoch]1/2 [Time]10856.22 [Step]38728 [Batch]143500 [Speed]75.65ms/step [Loss]9.3552 [Metrics]{'train_loss:9.355248 train_acc_clicks:0.052160 train_acc_carts:0.156031 train_acc_orders:0.199442 lr:0.000449 grad_accum:5.000000 total_samples:4592224.000000'}\n",
      "[Train Epoch]1/2 [Time]10892.73 [Step]38828 [Batch]144000 [Speed]75.64ms/step [Loss]9.3526 [Metrics]{'train_loss:9.352631 train_acc_clicks:0.052179 train_acc_carts:0.156135 train_acc_orders:0.199590 lr:0.000449 grad_accum:5.000000 total_samples:4608224.000000'}\n",
      "[Train Epoch]1/2 [Time]10929.24 [Step]38928 [Batch]144500 [Speed]75.63ms/step [Loss]9.3501 [Metrics]{'train_loss:9.350104 train_acc_clicks:0.052197 train_acc_carts:0.156213 train_acc_orders:0.199717 lr:0.000448 grad_accum:5.000000 total_samples:4624224.000000'}\n",
      "[Train Epoch]1/2 [Time]10965.73 [Step]39028 [Batch]145000 [Speed]75.63ms/step [Loss]9.3474 [Metrics]{'train_loss:9.347449 train_acc_clicks:0.052223 train_acc_carts:0.156334 train_acc_orders:0.199805 lr:0.000447 grad_accum:5.000000 total_samples:4640224.000000'}\n",
      "[Train Epoch]1/2 [Time]11002.28 [Step]39128 [Batch]145500 [Speed]75.62ms/step [Loss]9.3449 [Metrics]{'train_loss:9.344927 train_acc_clicks:0.052239 train_acc_carts:0.156402 train_acc_orders:0.199946 lr:0.000447 grad_accum:5.000000 total_samples:4656224.000000'}\n",
      "[Train Epoch]1/2 [Time]11038.83 [Step]39228 [Batch]146000 [Speed]75.61ms/step [Loss]9.3424 [Metrics]{'train_loss:9.342424 train_acc_clicks:0.052260 train_acc_carts:0.156521 train_acc_orders:0.200110 lr:0.000446 grad_accum:5.000000 total_samples:4672224.000000'}\n",
      "[Train Epoch]1/2 [Time]11075.37 [Step]39328 [Batch]146500 [Speed]75.60ms/step [Loss]9.3400 [Metrics]{'train_loss:9.340043 train_acc_clicks:0.052281 train_acc_carts:0.156640 train_acc_orders:0.200171 lr:0.000446 grad_accum:5.000000 total_samples:4688224.000000'}\n",
      "[Train Epoch]1/2 [Time]11111.88 [Step]39428 [Batch]147000 [Speed]75.59ms/step [Loss]9.3376 [Metrics]{'train_loss:9.337581 train_acc_clicks:0.052295 train_acc_carts:0.156719 train_acc_orders:0.200346 lr:0.000445 grad_accum:5.000000 total_samples:4704224.000000'}\n",
      "[Train Epoch]1/2 [Time]11148.38 [Step]39528 [Batch]147500 [Speed]75.58ms/step [Loss]9.3351 [Metrics]{'train_loss:9.335073 train_acc_clicks:0.052307 train_acc_carts:0.156844 train_acc_orders:0.200611 lr:0.000445 grad_accum:5.000000 total_samples:4720224.000000'}\n",
      "[Train Epoch]1/2 [Time]11184.91 [Step]39628 [Batch]148000 [Speed]75.57ms/step [Loss]9.3329 [Metrics]{'train_loss:9.332871 train_acc_clicks:0.052321 train_acc_carts:0.157088 train_acc_orders:0.200670 lr:0.000444 grad_accum:5.000000 total_samples:4736224.000000'}\n",
      "[Train Epoch]1/2 [Time]11221.45 [Step]39728 [Batch]148500 [Speed]75.57ms/step [Loss]9.3306 [Metrics]{'train_loss:9.330565 train_acc_clicks:0.052344 train_acc_carts:0.157193 train_acc_orders:0.200766 lr:0.000443 grad_accum:5.000000 total_samples:4752224.000000'}\n",
      "[Train Epoch]1/2 [Time]11257.95 [Step]39828 [Batch]149000 [Speed]75.56ms/step [Loss]9.3283 [Metrics]{'train_loss:9.328328 train_acc_clicks:0.052367 train_acc_carts:0.157417 train_acc_orders:0.200945 lr:0.000443 grad_accum:5.000000 total_samples:4768224.000000'}\n",
      "[Train Epoch]1/2 [Time]11294.42 [Step]39928 [Batch]149500 [Speed]75.55ms/step [Loss]9.3261 [Metrics]{'train_loss:9.326136 train_acc_clicks:0.052383 train_acc_carts:0.157609 train_acc_orders:0.201074 lr:0.000442 grad_accum:5.000000 total_samples:4784224.000000'}\n",
      "[Train Epoch]1/2 [Time]11330.89 [Step]40028 [Batch]150000 [Speed]75.54ms/step [Loss]9.3237 [Metrics]{'train_loss:9.323746 train_acc_clicks:0.052398 train_acc_carts:0.157821 train_acc_orders:0.201217 lr:0.000442 grad_accum:5.000000 total_samples:4800224.000000'}\n",
      "[Train Epoch]1/2 [Time]11367.37 [Step]40128 [Batch]150500 [Speed]75.53ms/step [Loss]9.3213 [Metrics]{'train_loss:9.321321 train_acc_clicks:0.052419 train_acc_carts:0.157971 train_acc_orders:0.201348 lr:0.000441 grad_accum:5.000000 total_samples:4816224.000000'}\n",
      "[Train Epoch]1/2 [Time]11403.87 [Step]40228 [Batch]151000 [Speed]75.52ms/step [Loss]9.3190 [Metrics]{'train_loss:9.319038 train_acc_clicks:0.052427 train_acc_carts:0.158022 train_acc_orders:0.201398 lr:0.000441 grad_accum:5.000000 total_samples:4832224.000000'}\n",
      "[Train Epoch]1/2 [Time]11440.43 [Step]40328 [Batch]151500 [Speed]75.51ms/step [Loss]9.3167 [Metrics]{'train_loss:9.316722 train_acc_clicks:0.052443 train_acc_carts:0.158079 train_acc_orders:0.201458 lr:0.000440 grad_accum:5.000000 total_samples:4848224.000000'}\n",
      "[Train Epoch]1/2 [Time]11476.96 [Step]40428 [Batch]152000 [Speed]75.51ms/step [Loss]9.3143 [Metrics]{'train_loss:9.314335 train_acc_clicks:0.052466 train_acc_carts:0.158137 train_acc_orders:0.201589 lr:0.000440 grad_accum:5.000000 total_samples:4864224.000000'}\n",
      "[Train Epoch]1/2 [Time]11513.45 [Step]40528 [Batch]152500 [Speed]75.50ms/step [Loss]9.3119 [Metrics]{'train_loss:9.311882 train_acc_clicks:0.052483 train_acc_carts:0.158175 train_acc_orders:0.201685 lr:0.000439 grad_accum:5.000000 total_samples:4880224.000000'}\n",
      "[Train Epoch]1/2 [Time]11549.95 [Step]40628 [Batch]153000 [Speed]75.49ms/step [Loss]9.3095 [Metrics]{'train_loss:9.309492 train_acc_clicks:0.052506 train_acc_carts:0.158232 train_acc_orders:0.201833 lr:0.000439 grad_accum:5.000000 total_samples:4896224.000000'}\n",
      "[Train Epoch]1/2 [Time]11586.44 [Step]40728 [Batch]153500 [Speed]75.48ms/step [Loss]9.3072 [Metrics]{'train_loss:9.307208 train_acc_clicks:0.052522 train_acc_carts:0.158352 train_acc_orders:0.201968 lr:0.000438 grad_accum:5.000000 total_samples:4912224.000000'}\n",
      "[Train Epoch]1/2 [Time]11622.95 [Step]40828 [Batch]154000 [Speed]75.47ms/step [Loss]9.3049 [Metrics]{'train_loss:9.304890 train_acc_clicks:0.052539 train_acc_carts:0.158426 train_acc_orders:0.202071 lr:0.000437 grad_accum:5.000000 total_samples:4928224.000000'}\n",
      "[Train Epoch]1/2 [Time]11659.48 [Step]40928 [Batch]154500 [Speed]75.47ms/step [Loss]9.3025 [Metrics]{'train_loss:9.302476 train_acc_clicks:0.052561 train_acc_carts:0.158452 train_acc_orders:0.202116 lr:0.000437 grad_accum:5.000000 total_samples:4944224.000000'}\n",
      "[Train Epoch]1/2 [Time]11695.97 [Step]41028 [Batch]155000 [Speed]75.46ms/step [Loss]9.3002 [Metrics]{'train_loss:9.300157 train_acc_clicks:0.052578 train_acc_carts:0.158487 train_acc_orders:0.202275 lr:0.000436 grad_accum:5.000000 total_samples:4960224.000000'}\n",
      "[Train Epoch]1/2 [Time]11732.47 [Step]41128 [Batch]155500 [Speed]75.45ms/step [Loss]9.2979 [Metrics]{'train_loss:9.297890 train_acc_clicks:0.052596 train_acc_carts:0.158511 train_acc_orders:0.202450 lr:0.000436 grad_accum:5.000000 total_samples:4976224.000000'}\n",
      "[Train Epoch]1/2 [Time]11768.96 [Step]41228 [Batch]156000 [Speed]75.44ms/step [Loss]9.2957 [Metrics]{'train_loss:9.295706 train_acc_clicks:0.052608 train_acc_carts:0.158590 train_acc_orders:0.202518 lr:0.000435 grad_accum:5.000000 total_samples:4992224.000000'}\n",
      "[Train Epoch]1/2 [Time]11805.47 [Step]41328 [Batch]156500 [Speed]75.43ms/step [Loss]9.2935 [Metrics]{'train_loss:9.293491 train_acc_clicks:0.052620 train_acc_carts:0.158728 train_acc_orders:0.202643 lr:0.000435 grad_accum:5.000000 total_samples:5008224.000000'}\n",
      "[Train Epoch]1/2 [Time]11842.02 [Step]41428 [Batch]157000 [Speed]75.43ms/step [Loss]9.2911 [Metrics]{'train_loss:9.291131 train_acc_clicks:0.052638 train_acc_carts:0.158824 train_acc_orders:0.202817 lr:0.000434 grad_accum:5.000000 total_samples:5024224.000000'}\n",
      "[Train Epoch]1/2 [Time]11878.58 [Step]41528 [Batch]157500 [Speed]75.42ms/step [Loss]9.2889 [Metrics]{'train_loss:9.288934 train_acc_clicks:0.052657 train_acc_carts:0.158970 train_acc_orders:0.202981 lr:0.000434 grad_accum:5.000000 total_samples:5040224.000000'}\n",
      "[Train Epoch]1/2 [Time]11915.11 [Step]41628 [Batch]158000 [Speed]75.41ms/step [Loss]9.2868 [Metrics]{'train_loss:9.286790 train_acc_clicks:0.052672 train_acc_carts:0.159130 train_acc_orders:0.203117 lr:0.000433 grad_accum:5.000000 total_samples:5056224.000000'}\n",
      "[Train Epoch]1/2 [Time]11951.57 [Step]41728 [Batch]158500 [Speed]75.40ms/step [Loss]9.2848 [Metrics]{'train_loss:9.284760 train_acc_clicks:0.052680 train_acc_carts:0.159343 train_acc_orders:0.203195 lr:0.000433 grad_accum:5.000000 total_samples:5072224.000000'}\n",
      "[Train Epoch]1/2 [Time]11988.09 [Step]41828 [Batch]159000 [Speed]75.40ms/step [Loss]9.2827 [Metrics]{'train_loss:9.282675 train_acc_clicks:0.052698 train_acc_carts:0.159493 train_acc_orders:0.203326 lr:0.000432 grad_accum:5.000000 total_samples:5088224.000000'}\n",
      "[Train Epoch]1/2 [Time]12024.63 [Step]41928 [Batch]159500 [Speed]75.39ms/step [Loss]9.2808 [Metrics]{'train_loss:9.280781 train_acc_clicks:0.052714 train_acc_carts:0.159714 train_acc_orders:0.203475 lr:0.000432 grad_accum:5.000000 total_samples:5104224.000000'}\n",
      "[Train Epoch]1/2 [Time]12061.17 [Step]42028 [Batch]160000 [Speed]75.38ms/step [Loss]9.2788 [Metrics]{'train_loss:9.278804 train_acc_clicks:0.052731 train_acc_carts:0.159860 train_acc_orders:0.203586 lr:0.000431 grad_accum:5.000000 total_samples:5120224.000000'}\n",
      "[Train Epoch]1/2 [Time]12097.67 [Step]42128 [Batch]160500 [Speed]75.37ms/step [Loss]9.2765 [Metrics]{'train_loss:9.276503 train_acc_clicks:0.052747 train_acc_carts:0.159934 train_acc_orders:0.203750 lr:0.000431 grad_accum:5.000000 total_samples:5136224.000000'}\n",
      "[Train Epoch]1/2 [Time]12134.15 [Step]42228 [Batch]161000 [Speed]75.37ms/step [Loss]9.2743 [Metrics]{'train_loss:9.274282 train_acc_clicks:0.052760 train_acc_carts:0.159957 train_acc_orders:0.203797 lr:0.000430 grad_accum:5.000000 total_samples:5152224.000000'}\n",
      "[Train Epoch]1/2 [Time]12170.64 [Step]42328 [Batch]161500 [Speed]75.36ms/step [Loss]9.2721 [Metrics]{'train_loss:9.272068 train_acc_clicks:0.052772 train_acc_carts:0.159999 train_acc_orders:0.203935 lr:0.000430 grad_accum:5.000000 total_samples:5168224.000000'}\n",
      "[Train Epoch]1/2 [Time]12207.17 [Step]42428 [Batch]162000 [Speed]75.35ms/step [Loss]9.2698 [Metrics]{'train_loss:9.269804 train_acc_clicks:0.052788 train_acc_carts:0.160038 train_acc_orders:0.204079 lr:0.000429 grad_accum:5.000000 total_samples:5184224.000000'}\n",
      "[Train Epoch]1/2 [Time]12243.70 [Step]42528 [Batch]162500 [Speed]75.35ms/step [Loss]9.2676 [Metrics]{'train_loss:9.267641 train_acc_clicks:0.052806 train_acc_carts:0.160076 train_acc_orders:0.204174 lr:0.000429 grad_accum:5.000000 total_samples:5200224.000000'}\n",
      "[Train Epoch]1/2 [Time]12280.23 [Step]42628 [Batch]163000 [Speed]75.34ms/step [Loss]9.2655 [Metrics]{'train_loss:9.265477 train_acc_clicks:0.052822 train_acc_carts:0.160086 train_acc_orders:0.204212 lr:0.000428 grad_accum:5.000000 total_samples:5216224.000000'}\n",
      "[Train Epoch]1/2 [Time]12316.80 [Step]42728 [Batch]163500 [Speed]75.33ms/step [Loss]9.2632 [Metrics]{'train_loss:9.263227 train_acc_clicks:0.052834 train_acc_carts:0.160122 train_acc_orders:0.204320 lr:0.000428 grad_accum:5.000000 total_samples:5232224.000000'}\n",
      "[Train Epoch]1/2 [Time]12353.34 [Step]42828 [Batch]164000 [Speed]75.33ms/step [Loss]9.2612 [Metrics]{'train_loss:9.261196 train_acc_clicks:0.052842 train_acc_carts:0.160165 train_acc_orders:0.204414 lr:0.000427 grad_accum:5.000000 total_samples:5248224.000000'}\n",
      "[Train Epoch]1/2 [Time]12389.83 [Step]42928 [Batch]164500 [Speed]75.32ms/step [Loss]9.2590 [Metrics]{'train_loss:9.258982 train_acc_clicks:0.052859 train_acc_carts:0.160186 train_acc_orders:0.204552 lr:0.000427 grad_accum:5.000000 total_samples:5264224.000000'}\n",
      "[Train Epoch]1/2 [Time]12426.38 [Step]43028 [Batch]165000 [Speed]75.31ms/step [Loss]9.2568 [Metrics]{'train_loss:9.256783 train_acc_clicks:0.052874 train_acc_carts:0.160198 train_acc_orders:0.204642 lr:0.000426 grad_accum:5.000000 total_samples:5280224.000000'}\n",
      "[Train Epoch]1/2 [Time]12463.78 [Step]43128 [Batch]165500 [Speed]75.31ms/step [Loss]9.2545 [Metrics]{'train_loss:9.254497 train_acc_clicks:0.052886 train_acc_carts:0.160268 train_acc_orders:0.204694 lr:0.000426 grad_accum:5.000000 total_samples:5296224.000000'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 125\u001b[0m\n\u001b[1;32m    120\u001b[0m grad_accum \u001b[39m=\u001b[39m grad_accum_scheduler(total_samples,\n\u001b[1;32m    121\u001b[0m                                   list_scheduler\u001b[39m=\u001b[39mlist_scheduler, \n\u001b[1;32m    122\u001b[0m                                   max_grad_accum\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mtup_scheduler_grad_accum[\u001b[39m1\u001b[39m])                                                             \n\u001b[1;32m    123\u001b[0m step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39mtarget, model\u001b[39m=\u001b[39mmodel, optimizer\u001b[39m=\u001b[39moptimizer, num_accum_steps\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconstant(grad_accum, tf\u001b[39m.\u001b[39mfloat32), \n\u001b[1;32m    124\u001b[0m                             loss\u001b[39m=\u001b[39mtrain_loss, acc_clicks\u001b[39m=\u001b[39mtrain_acc_clicks, acc_carts\u001b[39m=\u001b[39mtrain_acc_carts, acc_orders\u001b[39m=\u001b[39mtrain_acc_orders, seq_type\u001b[39m=\u001b[39minputs[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 125\u001b[0m global_gradients, total_step \u001b[39m=\u001b[39m backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    127\u001b[0m     train_dict_metrics \u001b[39m=\u001b[39m {x\u001b[39m.\u001b[39mname : x\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
      "Cell \u001b[0;32mIn [8], line 20\u001b[0m, in \u001b[0;36mbackward_optimization\u001b[0;34m(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[39mfor\u001b[39;00m i, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(step_gradients):\n\u001b[0;32m---> 20\u001b[0m         global_gradients[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_gradients(g)\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m num_grad_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(global_gradients, model\u001b[39m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn [8], line 8\u001b[0m, in \u001b[0;36mflat_gradients\u001b[0;34m(grads_or_idx_slices)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m'''Convert gradients if it's tf.IndexedSlices.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mWhen computing gradients for operation concerning `tf.gather`, the type of gradients \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(grads_or_idx_slices) \u001b[39m==\u001b[39m tf\u001b[39m.\u001b[39mIndexedSlices:\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mscatter_nd(\n\u001b[1;32m      9\u001b[0m         tf\u001b[39m.\u001b[39;49mexpand_dims(grads_or_idx_slices\u001b[39m.\u001b[39;49mindices, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m     10\u001b[0m         grads_or_idx_slices\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     11\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(grads_or_idx_slices\u001b[39m.\u001b[39;49mdense_shape, tf\u001b[39m.\u001b[39;49mint64)\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m grads_or_idx_slices\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:9162\u001b[0m, in \u001b[0;36mscatter_nd\u001b[0;34m(indices, updates, shape, name)\u001b[0m\n\u001b[1;32m   9160\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   9161\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 9162\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   9163\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mScatterNd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, indices, updates, shape)\n\u001b[1;32m   9164\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   9165\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '1_Model_v0.4.ipynb'\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    seed = 12 #42\n",
    "    num_items = NUM_ITEMS\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.4/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.8.4/checkpoints/', 'ckpt-18')\n",
    "    model_name = 'model_bert4rec_complete_0.8.5'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 10_000_000\n",
    "    batch_size = 32\n",
    "    tup_scheduler_grad_accum = (1, 5, 1_000_000) #(start_grad_accum, max_grad_accum, ramp_up_samples)\n",
    "    seq_len = 30\n",
    "    mask_prob = 0.3\n",
    "    reverse_prob = 0.5\n",
    "    emb_dim = 128\n",
    "    trf_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 2\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 250\n",
    "    clipnorm = 1.0\n",
    "    num_iters_save_checkpoint = 25_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    weight_decay = 1e-1\n",
    "    log_wandb = True\n",
    "\n",
    "set_seed(BERT4REC_CONFIG.seed)\n",
    "\n",
    "list_scheduler = np.linspace(BERT4REC_CONFIG.tup_scheduler_grad_accum[0], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[1], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[2]).astype(np.uint8).tolist()\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}', dict_config=dict_config)\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "                            # weight_decay=BERT4REC_CONFIG.weight_decay)                  \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = weighted_loss_bert4rec()#custom_loss_bert4rec()\n",
    "acc_function = custom_accuracy()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "train_acc_clicks = tf.keras.metrics.Mean(name='train_acc_clicks')\n",
    "train_acc_carts = tf.keras.metrics.Mean(name='train_acc_carts')\n",
    "train_acc_orders = tf.keras.metrics.Mean(name='train_acc_orders')\n",
    "val_acc_clicks = tf.keras.metrics.Mean(name='val_acc_clicks')\n",
    "val_acc_carts = tf.keras.metrics.Mean(name='val_acc_carts')\n",
    "val_acc_orders = tf.keras.metrics.Mean(name='val_acc_orders')\n",
    "\n",
    "##############################################\n",
    "\n",
    "global_gradients = []\n",
    "total_step, val_step, total_samples = 0, 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders, val_acc_clicks, val_acc_carts, val_acc_orders)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        grad_accum = grad_accum_scheduler(total_samples,\n",
    "                                          list_scheduler=list_scheduler, \n",
    "                                          max_grad_accum=BERT4REC_CONFIG.tup_scheduler_grad_accum[1])                                                             \n",
    "        step_gradients = train_step(inputs, target=target, model=model, optimizer=optimizer, num_accum_steps=tf.constant(grad_accum, tf.float32), \n",
    "                                    loss=train_loss, acc_clicks=train_acc_clicks, acc_carts=train_acc_carts, acc_orders=train_acc_orders, seq_type=inputs[1])\n",
    "        global_gradients, total_step = backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "            train_dict_metrics.update({'lr' : optimizer.lr(total_step).numpy().astype(np.float32), 'grad_accum' : grad_accum, 'total_samples' : total_samples})\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                train_dict_metrics.update({'step_grad' : total_step, 'step' : total_step})\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics)     \n",
    "        total_samples += BERT4REC_CONFIG.batch_size * grad_accum if (batch_num+1) % grad_accum==0 else 0\n",
    "        if batch_num % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')\n",
    "     \n",
    "#     for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "#         inputs, target = val_batch_data\n",
    "#         predictions = test_step(inputs, target=target, loss=val_loss, acc_clicks=val_acc_clicks, acc_carts=val_acc_carts, acc_orders=val_acc_orders, seq_type=inputs[1])\n",
    "#         val_step += 1\n",
    "#         if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "#             val_dict_metrics = {x.name : x.result() for x in [val_loss, val_acc_clicks, val_acc_carts, val_acc_orders]}\n",
    "#             fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "#             if BERT4REC_CONFIG.log_wandb:\n",
    "#                 log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "#                 # if val_batch_num==0:\n",
    "#                 #     log_wandb_metrics(step=None, plot_image=True, \n",
    "#                 #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "    \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', num_step=epoch, dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:48, 10.31it/s]\n",
      "100%|██████████| 48096/48096 [00:00<00:00, 232405.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.809600e+04</td>\n",
       "      <td>20382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.386382e+06</td>\n",
       "      <td>0.257340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.733164e+06</td>\n",
       "      <td>0.426136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.040000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.110570e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.359522e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.590063e+06</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289973e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session         score\n",
       "count  4.809600e+04  20382.000000\n",
       "mean   6.386382e+06      0.257340\n",
       "std    3.733164e+06      0.426136\n",
       "min    7.040000e+02      0.000000\n",
       "25%    3.110570e+06      0.000000\n",
       "50%    6.359522e+06      0.000000\n",
       "75%    9.590063e+06      0.500000\n",
       "max    1.289973e+07      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.33289575892668677,\n",
       " 'clicks': 0.2169360643936915,\n",
       " 'orders': 0.4863323570168808}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.4134\n"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    score = 0 \n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# ckpt = tf.train.Checkpoint(model=model)\n",
    "# ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.8.4/checkpoints'))\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.4/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=30, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_past_items, list_predictions, list_trues, list_types = [], [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target, idx_mask = targets\n",
    "    idxs = idx_mask.numpy() #tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[x for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([_target for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "        list_past_items.append(seq_items.numpy()[:, :, 0])\n",
    "    if num_batch==500:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'past_items' : np.concatenate(list_past_items).tolist(),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.8.4 - ckpt10\n",
    "# {'carts': 0.3504520904714635,\n",
    "#  'clicks': 0.22126267582597317,\n",
    "#  'orders': 0.5380787421674682}\n",
    "# Kaggle Metric: 0.4501\n",
    "\n",
    "# (seq_len=20)model_bert4rec_complete_0.8.4 - ckpt18\n",
    "# 'carts': 0.3685273404345569,\n",
    "#  'clicks': 0.23584843923826976,\n",
    "#  'orders': 0.5460814923612543}\n",
    "# Kaggle Metric: 0.4618\n",
    "\n",
    "# import wandb\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"<path to run>\")\n",
    "# run.summary[\"kaggle_metric\"] = kaggle_metric\n",
    "# run.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2azkkync) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96aff4a8bf8940a29c3471a931b49af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.018 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.240576…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">model_bert4rec_complete_0.8_finetune_fold_0</strong>: <a href=\"https://wandb.ai/enric1296/otto-recsys/runs/2azkkync\" target=\"_blank\">https://wandb.ai/enric1296/otto-recsys/runs/2azkkync</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221122_114558-2azkkync/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2azkkync). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e74e0d3acf4cf0b53a2d666f6c51de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668100016666663, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/enric/SSD1TB/KAGGLE/025_Kaggle-OTTO Recsys-2022/1_Scripts/wandb/run-20221122_114635-32p0b058</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/enric1296/otto-recsys/runs/32p0b058\" target=\"_blank\">model_bert4rec_complete_0.8_finetune_fold_0</a></strong> to <a href=\"https://wandb.ai/enric1296/otto-recsys\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Fold: 0\n",
      "========================================================================================================================\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 11:46:42.819523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:436: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2022-11-22 11:46:46.800646: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14149/Unknown - 4639s 328ms/step - loss: 8.2624 - seq_acc: 0.0945"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 50\u001b[0m\n\u001b[1;32m     45\u001b[0m ckpt\u001b[39m.\u001b[39mrestore(tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mlatest_checkpoint(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/model_bert4rec_complete_0.8/checkpoints\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     46\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m4e-5\u001b[39m, clipnorm\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m),\n\u001b[1;32m     47\u001b[0m               loss\u001b[39m=\u001b[39mloss_function,\n\u001b[1;32m     48\u001b[0m               metrics\u001b[39m=\u001b[39m[acc_function])\n\u001b[0;32m---> 50\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataloader,\n\u001b[1;32m     51\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m     52\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     53\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[WandbCallback()],\n\u001b[1;32m     54\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     55\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     57\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../2_Models/model_bert4rec_complete_0.7_finetuned_fold_\u001b[39m\u001b[39m{\u001b[39;00mnum_fold\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)                   \n\u001b[1;32m     58\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/engine/training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/utils/tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/utils/tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "list_paths = ['../tfrecords/tfrecords_v0.4/na_split=test_aug/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=test_aug')]# + \\\n",
    "            #  ['../tfrecords/tfrecords_v0.4/na_split=val_aug/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=val_aug')] \n",
    "np.random.shuffle(list_paths)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for num_fold, (train_idxs, val_idxs) in enumerate(kfold.split(list_paths)):\n",
    "    train_paths = np.asarray(list_paths)[train_idxs]\n",
    "    val_paths = np.asarray(list_paths)[val_idxs]\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        time_suffix = datetime.now().__str__().split('.')[0]\n",
    "        dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "        init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_finetune_fold_{num_fold}', dict_config=dict_config)\n",
    "    print('===='*30)\n",
    "    print(f'Fold: {num_fold}')\n",
    "    print('===='*30)\n",
    "\n",
    "    train_dataloader = Bert4RecDataLoader(train_paths, \n",
    "                                         num_items=NUM_ITEMS, \n",
    "                                        seq_len=20,  \n",
    "                                        batch_size=32, \n",
    "                                        mask_prob=0.4, \n",
    "                                        reverse_prob=0.25,  \n",
    "                                        is_val=False,\n",
    "                                        is_test=False,\n",
    "                                        get_session=False,\n",
    "                                        shuffle=True).get_generator()\n",
    "\n",
    "    val_dataloader = Bert4RecDataLoader(val_paths, \n",
    "                                        num_items=NUM_ITEMS, \n",
    "                                        seq_len=20,  \n",
    "                                        batch_size=32, \n",
    "                                        mask_prob=0.4, \n",
    "                                        reverse_prob=0.25,  \n",
    "                                        is_val=True,\n",
    "                                        is_test=False,\n",
    "                                        get_session=False,\n",
    "                                        shuffle=False).get_generator()\n",
    "\n",
    "    loss_function = custom_loss_bert4rec()\n",
    "    acc_function = custom_accuracy()\n",
    "    model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "    ckpt = tf.train.Checkpoint(model=model)\n",
    "    ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.8/checkpoints'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=4e-5, clipnorm=1.0),\n",
    "                  loss=loss_function,\n",
    "                  metrics=[acc_function])\n",
    "\n",
    "    history = model.fit(train_dataloader,\n",
    "                        validation_data=val_dataloader,\n",
    "                        batch_size=32,\n",
    "                        callbacks=[WandbCallback()],\n",
    "                        epochs=1,\n",
    "                        verbose=1)\n",
    "\n",
    "    model.save(f'../2_Models/model_bert4rec_complete_0.7_finetuned_fold_{num_fold}/')                   \n",
    "    wandb.finish()\n",
    "\n",
    "# 173/Unknown - 22s 113ms/step - loss: 7.9368 - recall_20: 0.3452\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 19:15:23.433225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "0it [00:00, ?it/s]2022-11-20 19:15:24.337587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "26122it [55:08,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.7/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.4/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=test')]\n",
    "test_dataloader = Bert4RecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, idxs, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    idxs = idxs.numpy()\n",
    "    # idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 26122it [54:28,  7.99it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")\n",
    "\n",
    "import gzip\n",
    "with open(f'../3_Submissions/{name_submission}.csv', 'rb') as f_in, gzip.open(f'../3_Submissions/{name_submission}.csv.gz', 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0432fa0070c5c9f7d9e158f590013ccc765eb84f02e6f69521746370c3bf6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
