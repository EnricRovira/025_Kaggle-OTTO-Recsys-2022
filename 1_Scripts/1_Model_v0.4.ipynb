{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 18:55:48.520297: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-03 18:55:48.583093: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-03 18:55:48.598632: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-03 18:55:48.909732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-12-03 18:55:48.909756: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-12-03 18:55:48.909759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 18:55:49.668741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 18:55:49.682741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 18:55:49.682821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Libraries #\n",
    "\n",
    "from dataloader import Bert4RecDataLoader, SASRecDataLoader\n",
    "from models import build_model_bert4Rec\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers, constraints\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import Sequence\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# tfrecords for kaggle\n",
    "\n",
    "# name_dataset = 'tfrecords_v0.4_kaggle'\n",
    "# path_out = f'../tfrecords/{name_dataset}/'\n",
    "\n",
    "# if not os.path.exists(path_out):\n",
    "#     os.mkdir(path_out)\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_train'):\n",
    "#     os.rename(path_out + 'na_split_train/' + file, \n",
    "#               path_out + 'na_split_train/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val'):\n",
    "#     os.rename(path_out + 'na_split_val/' + file, \n",
    "#               path_out + 'na_split_val/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test'):\n",
    "#     os.rename(path_out + 'na_split_test/' + file, \n",
    "#               path_out + 'na_split_test/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_val_aug'):\n",
    "#     os.rename(path_out + 'na_split_val_aug/' + file, \n",
    "#               path_out + 'na_split_val_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "# for file in os.listdir(path_out + 'na_split_test_aug'):\n",
    "#     os.rename(path_out + 'na_split_test_aug/' + file, \n",
    "#               path_out + 'na_split_test_aug/' + file.replace('-', '_').replace('gz', 'tfrec'))\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [00:00<00:00, 7978238.45it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Paths & Global Variables\n",
    "\n",
    "# Train: (datetime.datetime(2022, 7, 31, 22, 0, 0, 25000), datetime.datetime(2022, 8, 28, 21, 59, 59, 984000))\n",
    "# Test: (datetime.datetime(2022, 8, 28, 22, 0, 0, 278000), datetime.datetime(2022, 9, 4, 21, 59, 51, 563000))\n",
    "\n",
    "path_data_raw = '../0_Data/'\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "df_mapping = pd.read_csv('../tfrecords/tfrecords_v0.7_nodup/df_mapping.csv')\n",
    "NUM_ITEMS = len(df_mapping['aid_map'].unique())\n",
    "print(NUM_ITEMS)\n",
    "\n",
    "dict_map = {}\n",
    "for x in tqdm(df_mapping.to_dict('records')):\n",
    "    dict_map[x['aid_map']] = x['aid']\n",
    "# \n",
    "dict_map_type = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 2,\n",
    "    'orders' : 3\n",
    "  }\n",
    "dict_map_type_inv = {\n",
    "    1 : 'clicks',\n",
    "    2 : 'carts',\n",
    "    3 : 'orders'\n",
    "  }\n",
    "# \n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 18:55:52.459008: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-03 18:55:52.459650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 18:55:52.459735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 18:55:52.459774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 18:55:52.818959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 18:55:52.819038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 18:55:52.819082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 18:55:52.819126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21887 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 20, 1]), TensorShape([32, 20, 1]), TensorShape([32, 20, 8]), TensorShape([32, 20, 1]), TensorShape([32, 20, 1])]\n",
      "[      0  541505 1123277       0       0       0       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0]\n",
      "[ 0.         -0.18349528 -1.1834953   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[42811     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_paths = ['../tfrecords/tfrecords_v0.7_nodup/na_split=train/' + x for x in os.listdir('../tfrecords/tfrecords_v0.7_nodup/na_split=train')]\n",
    "# 5,45, 1,09\n",
    "dataloader = Bert4RecDataLoader(list_paths, \n",
    "                                num_items=NUM_ITEMS, \n",
    "                                seq_len=20, \n",
    "                                seq_len_target=None,\n",
    "                                batch_size=32, \n",
    "                                mask_prob=0.3, \n",
    "                                reverse_prob=0.0, \n",
    "                                get_session=False,\n",
    "                                is_val=False,\n",
    "                                is_test=False,\n",
    "                                shuffle=False).get_generator()\n",
    "# Train\n",
    "for batch in tqdm(dataloader):\n",
    "    features, target = batch\n",
    "    seq_items, seq_type, seq_time, seq_qt_events, seq_recency = features\n",
    "    break\n",
    "\n",
    "# # Test\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, target, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     idx_mask = target\n",
    "#     break\n",
    "\n",
    "# Val\n",
    "# for batch in tqdm(dataloader):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     target, type_target, idx_mask = targets\n",
    "#     break\n",
    "\n",
    "print([x.shape for x in features])\n",
    "\n",
    "idx = 2\n",
    "print(seq_items[idx].numpy().flatten())\n",
    "print(seq_qt_events[idx].numpy().flatten())\n",
    "print(seq_type[idx].numpy().flatten())\n",
    "print(target[idx].numpy().flatten())\n",
    "# print(idx_mask[idx].numpy().flatten())\n",
    "# print(type_target[idx].numpy().flatten())\n",
    "\n",
    "del features, target, seq_items, seq_type, seq_time, seq_recency\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, weight_decay=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.weight_decay_tensor = tf.cast(1. if not weight_decay else weight_decay, tf.float32)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'd_model': self.d_model,\n",
    "          'warmup_steps': self.warmup_steps,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        if self.weight_decay:\n",
    "            return self.weight_decay_tensor * tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "        else:\n",
    "            return tf.math.rsqrt(self.d_model) * tf.cast(tf.math.minimum(arg1, arg2), tf.float32)\n",
    "    \n",
    "    \n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "\n",
    "# def custom_loss_bert4rec(tensor_weights=None):\n",
    "#     # @tf.function(jit_compile=True)\n",
    "#     def loss(y_true, y_pred):\n",
    "#         mask = tf.where(y_true >= 1, 1., 0.)\n",
    "#         loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "#         if tensor_weights is not None:\n",
    "#             weights = tf.gather(params=tensor_weights, indices=y_true)\n",
    "#             return tf.reduce_sum(loss * weights * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "#         else:\n",
    "#             return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "#     loss.__name__ = f'loss_bert4rec'\n",
    "#     return loss\n",
    "\n",
    "def weighted_loss_bert4rec(apply_weights=False, dict_weights={1:1, 2:3, 3:6}):\n",
    "    # @tf.function(jit_compile=True)\n",
    "    def loss(y_true, y_pred, y_type):\n",
    "        y_type = tf.squeeze(y_type, -1)\n",
    "        mask = tf.where(y_true >= 1, 1., 0.)\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "        if apply_weights:\n",
    "            w_clicks = tf.cast(y_type==1, tf.float32) * dict_weights[1]\n",
    "            w_cart = tf.cast(y_type==2, tf.float32) * dict_weights[2]\n",
    "            w_order = tf.cast(y_type==3, tf.float32) * dict_weights[3]\n",
    "            weights = tf.reduce_max(tf.stack([w_clicks, w_cart, w_order], axis=-1), -1)\n",
    "            return tf.reduce_sum(loss * mask * weights) / (tf.reduce_sum(mask * weights) + 1e-8)\n",
    "        else:\n",
    "            return tf.reduce_sum(loss * mask) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    loss.__name__ = f'weighted_loss_bert4rec'\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def custom_accuracy():\n",
    "    def masked_accuracy(y_true, y_pred, y_type):\n",
    "        y_pred = tf.argmax(y_pred, axis=2)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        y_type = y_type[:, :, 0]\n",
    "        mask_padding = y_true != 0\n",
    "        mask_clicks = y_type == 1\n",
    "        mask_carts = y_type == 2\n",
    "        mask_orders = y_type == 3\n",
    "        match = y_true == y_pred\n",
    "        match_clicks = match & mask_padding & mask_clicks\n",
    "        match_carts = match & mask_padding & mask_carts\n",
    "        match_orders = match & mask_padding & mask_orders\n",
    "        match_clicks, mask_clicks = tf.cast(match_clicks, dtype=tf.float32), tf.cast(mask_clicks, dtype=tf.float32)\n",
    "        match_carts, mask_carts = tf.cast(match_carts, dtype=tf.float32), tf.cast(mask_carts, dtype=tf.float32)\n",
    "        match_orders, mask_orders = tf.cast(match_orders, dtype=tf.float32), tf.cast(mask_orders, dtype=tf.float32)\n",
    "        mask_padding = tf.cast(mask_padding, dtype=tf.float32)\n",
    "        acc_clicks = tf.reduce_sum(match_clicks)/(tf.reduce_sum(mask_clicks * mask_padding)+1e-8)\n",
    "        acc_carts = tf.reduce_sum(match_carts)/(tf.reduce_sum(mask_carts * mask_padding)+1e-8)\n",
    "        acc_orders = tf.reduce_sum(match_orders)/(tf.reduce_sum(mask_orders * mask_padding)+1e-8)\n",
    "        # score = 0.1*acc_clicks + 0.3*acc_carts + 0.6*acc_orders\n",
    "        return acc_clicks, acc_carts, acc_orders\n",
    "    masked_accuracy.__name__ = f'seq_acc'\n",
    "    return masked_accuracy\n",
    "\n",
    "\n",
    "def mrr_topk_categorical(top_k):\n",
    "  \"\"\"\n",
    "  Mrr Topk Categorical metric\n",
    "  \"\"\"\n",
    "  def mrr(y_true, y_pred):                                      \n",
    "    n_samples = tf.shape(y_true)[0]\n",
    "    n_samples_mask = tf.where(tf.reduce_sum(y_true, -1) >= 1, 1., 0.)\n",
    "    _, top_index = tf.nn.top_k(y_pred, top_k)  \n",
    "    result = tf.constant(0.0)\n",
    "    top_index = tf.cast(top_index, tf.float32)\n",
    "    idxs_not_masked = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "    for i in tf.range(n_samples):\n",
    "        ranked_indicies = tf.where(tf.equal(top_index[i, idxs_not_masked[i], :], y_true[i, :][:, tf.newaxis]))\n",
    "        if tf.shape(ranked_indicies)[0] > 0:\n",
    "            ranked_indicies = tf.cast(ranked_indicies[0], tf.int32)\n",
    "            #check that the prediction its not padding\n",
    "            if top_index[i, ranked_indicies[0], ranked_indicies[1]] != 0.0: \n",
    "                rr = tf.cast(1/(ranked_indicies[1]+1), tf.float32)\n",
    "            else:\n",
    "                rr = tf.constant(0.0)\n",
    "        else:\n",
    "            rr = tf.constant(0.0)\n",
    "        result+=rr\n",
    "    return result/(tf.reduce_sum(n_samples_mask) + 1e-8)\n",
    "  mrr.__name__ = f'mrr_{top_k}_categorical'\n",
    "  return mrr\n",
    "\n",
    "\n",
    "def recall_top_k(top_k=1, seq_len=10):\n",
    "    # @tf.function\n",
    "    def recall(y_true, y_pred):\n",
    "        n_samples = tf.shape(y_pred)[0]\n",
    "        y_true = tf.cast(y_true, tf.int64)\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), tf.int32)\n",
    "        _, top_index = tf.nn.top_k(y_pred, top_k) \n",
    "        top_index = tf.cast(top_index, tf.int64)\n",
    "        # cum_sum = tf.zeros(n_samples, tf.int32)\n",
    "        result = tf.constant(0, tf.int32)\n",
    "        for i in tf.range(seq_len):\n",
    "            indexes_i = top_index[:, i, :]\n",
    "            is_true = tf.reduce_sum(tf.reduce_max(tf.where(y_true[:, i:i+1]==indexes_i, 1, 0), -1) * mask[:, i])\n",
    "            result += is_true\n",
    "        return tf.cast(result, tf.float32) / (tf.cast(tf.reduce_sum(mask), tf.float32) + 1e-8)\n",
    "    recall.__name__ = f'recall_{top_k}'\n",
    "    return recall\n",
    "\n",
    "\n",
    "def create_folder_with_version(base_name, checkpoint_path):\n",
    "    if os.path.exists(os.path.join(checkpoint_path, base_name)):\n",
    "        version_ = base_name.split('_v')\n",
    "        if not version_ or len(version_)==1:\n",
    "            base_name_no_version = base_name\n",
    "            version_ = '_v1'\n",
    "        else:\n",
    "            base_name_no_version = '_'.join(base_name.split('_v')[:-1])\n",
    "            version_ = f'_v{int(version_[-1])+1}'\n",
    "        base_name = base_name_no_version + version_\n",
    "        return create_folder_with_version(base_name, checkpoint_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_path, base_name)\n",
    "        os.mkdir(checkpoint_path)\n",
    "        return base_name\n",
    "\n",
    "def set_seed(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_lr = CustomSchedule(128, 10_000, weight_decay=None)\n",
    "plt.plot(tmp_lr(tf.range(13_000_000 // (64* 2), dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            tf.cast(grads_or_idx_slices.dense_shape, tf.int64)\n",
    "        )\n",
    "    return grads_or_idx_slices\n",
    "\n",
    "def backward_optimization(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer):\n",
    "    if not global_gradients:\n",
    "        global_gradients = step_gradients # [flat_gradients(g) / num_grad_steps for g in step_gradients] \n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            global_gradients[i] += flat_gradients(g) #/ num_grad_steps\n",
    "    if (step + 1) % num_grad_steps == 0:\n",
    "        optimizer.apply_gradients(zip(global_gradients, model.trainable_variables))\n",
    "        global_gradients = []\n",
    "        total_step += 1\n",
    "    return global_gradients, total_step\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(*inputs, target, model, optimizer, num_accum_steps, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(*inputs, training=True)\n",
    "        loss = loss_function(target, predictions, seq_type)\n",
    "        acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss) / num_accum_steps\n",
    "\n",
    "    gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(gradients)\n",
    "    # optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return gradients\n",
    "  \n",
    "@tf.function\n",
    "def test_step(*inputs, target, **kwargs):\n",
    "    l_loss, l_acc_clicks, l_acc_carts, l_acc_orders = kwargs['loss'], kwargs['acc_clicks'], kwargs['acc_carts'], kwargs['acc_orders']\n",
    "    seq_type = kwargs['seq_type']\n",
    "    predictions = model(*inputs, training=False)\n",
    "    loss = loss_function(target, predictions, seq_type)\n",
    "    acc_clicks, acc_carts, acc_orders = acc_function(target, predictions, seq_type)\n",
    "    l_loss(loss)\n",
    "    l_acc_clicks(acc_clicks)\n",
    "    l_acc_carts(acc_carts)\n",
    "    l_acc_orders(acc_orders)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def metrics_reset_states(*metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "def fancy_printer(loss_tracker, epoch, batch_num, start, step='train', dict_metrics={}, num_epochs=1, **kwargs):\n",
    "    num_step = kwargs['num_step']\n",
    "    dict_print_metrics = {' '.join(f\"{key}:{value:.6f}\" for key, value in dict_metrics.items())}\n",
    "    if step!='epoch':\n",
    "        printer = f'[{step} Epoch]{epoch + 1}/{num_epochs} [Time]{time.time() - start:.2f} [Step]{num_step} [Batch]{batch_num} [Speed]{((time.time() - start)/max(1, batch_num))*1000:.2f}ms/step '\n",
    "        printer += f'[Loss]{loss_tracker.result():.4f} ' + '[Metrics]' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "    else:\n",
    "        train_loss, val_loss = kwargs['train_loss'], kwargs['val_loss']\n",
    "        print(f'\\nTime taken for epoch {epoch+1}/{num_epochs}: {time.time() - start:.2f} secs')\n",
    "        printer = f'[Epoch]{epoch + 1}/{num_epochs} - [Train Loss]{train_loss.result():.4f} '\n",
    "        printer += f'- [Val Loss]{val_loss.result():.4f} ' + str(dict_print_metrics)\n",
    "        print(printer)\n",
    "\n",
    "\n",
    "def log_wandb_metrics(step='train', num_step=0, dict_metrics=None, gradients=None, plot_image=False, **kwargs):\n",
    "    # Scalar metrics\n",
    "    if step=='train' or step=='val':\n",
    "        wandb.log({name : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "    if step=='epoch':\n",
    "        wandb.log({f'epoch_{name}' : value for name, value in dict_metrics.items()}, step=num_step)\n",
    "\n",
    "    # Gradients\n",
    "    if gradients:\n",
    "        wandb.log({\n",
    "            'mean_norm_gradients' : np.mean([tf.norm(x) for x in gradients]), \n",
    "            'max_norm_gradients': np.max([tf.norm(x) for x in gradients])\n",
    "        })\n",
    "\n",
    "def init_wandb(wandb_project='<your_project>', entity='', run_name='', dict_config=None):\n",
    "    wandb.init(project=wandb_project, entity=entity, name=run_name, settings=wandb.Settings(code_dir=\".\"),\n",
    "               config=dict_config)\n",
    "    wandb.run.log_code(\".\")\n",
    "\n",
    "\n",
    "def grad_accum_scheduler(num_samples, list_scheduler, max_grad_accum):\n",
    "    if num_samples >= len(list_scheduler):\n",
    "        return max_grad_accum\n",
    "    return list_scheduler[num_samples]\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n",
      "================================================================================\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 18:55:57.949373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/enric/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:436: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 167903104 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2022-12-03 18:55:58.964479: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1dbdda30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-03 18:55:58.964499: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2022-12-03 18:55:58.984383: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model_bert4_rec/encoder_transformer_block/dropout_2/dropout/random_uniform/RandomUniform\n",
      "2022-12-03 18:55:58.987558: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-03 18:56:00.521730: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-12-03 18:56:01.092067: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Epoch]1/3 [Time]3.22 [Step]1 [Batch]0 [Speed]3217.89ms/step [Loss]14.1289 [Metrics]{'train_loss:14.128902 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000000 grad_accum:1.000000 total_samples:0.000000'}\n",
      "Saving checkpoint for epoch 1 at step 1 on path model_bert4rec_complete_0.15\n",
      "[Train Epoch]1/3 [Time]49.57 [Step]501 [Batch]500 [Speed]99.14ms/step [Loss]14.1325 [Metrics]{'train_loss:14.132542 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000044 grad_accum:1.000000 total_samples:16000.000000'}\n",
      "[Train Epoch]1/3 [Time]95.23 [Step]1001 [Batch]1000 [Speed]95.23ms/step [Loss]13.8436 [Metrics]{'train_loss:13.843612 train_acc_clicks:0.000000 train_acc_carts:0.000000 train_acc_orders:0.000000 lr:0.000088 grad_accum:1.000000 total_samples:32000.000000'}\n",
      "[Train Epoch]1/3 [Time]140.74 [Step]1501 [Batch]1500 [Speed]93.83ms/step [Loss]13.5869 [Metrics]{'train_loss:13.586859 train_acc_clicks:0.000044 train_acc_carts:0.000111 train_acc_orders:0.000000 lr:0.000133 grad_accum:1.000000 total_samples:48000.000000'}\n",
      "[Train Epoch]1/3 [Time]185.99 [Step]2001 [Batch]2000 [Speed]93.00ms/step [Loss]13.3899 [Metrics]{'train_loss:13.389930 train_acc_clicks:0.000291 train_acc_carts:0.001624 train_acc_orders:0.001696 lr:0.000177 grad_accum:1.000000 total_samples:64000.000000'}\n",
      "[Train Epoch]1/3 [Time]231.89 [Step]2501 [Batch]2500 [Speed]92.76ms/step [Loss]13.2327 [Metrics]{'train_loss:13.232665 train_acc_clicks:0.000937 train_acc_carts:0.005260 train_acc_orders:0.005102 lr:0.000221 grad_accum:1.000000 total_samples:80000.000000'}\n",
      "[Train Epoch]1/3 [Time]277.63 [Step]3001 [Batch]3000 [Speed]92.54ms/step [Loss]13.1007 [Metrics]{'train_loss:13.100654 train_acc_clicks:0.001716 train_acc_carts:0.011224 train_acc_orders:0.009844 lr:0.000265 grad_accum:1.000000 total_samples:96000.000000'}\n",
      "[Train Epoch]1/3 [Time]323.41 [Step]3501 [Batch]3500 [Speed]92.40ms/step [Loss]12.9901 [Metrics]{'train_loss:12.990068 train_acc_clicks:0.002954 train_acc_carts:0.017391 train_acc_orders:0.015201 lr:0.000309 grad_accum:1.000000 total_samples:112000.000000'}\n",
      "[Train Epoch]1/3 [Time]369.21 [Step]4001 [Batch]4000 [Speed]92.30ms/step [Loss]12.8900 [Metrics]{'train_loss:12.890007 train_acc_clicks:0.004441 train_acc_carts:0.023259 train_acc_orders:0.020956 lr:0.000354 grad_accum:1.000000 total_samples:128000.000000'}\n",
      "[Train Epoch]1/3 [Time]414.37 [Step]4501 [Batch]4500 [Speed]92.08ms/step [Loss]12.7999 [Metrics]{'train_loss:12.799878 train_acc_clicks:0.006115 train_acc_carts:0.030897 train_acc_orders:0.027099 lr:0.000398 grad_accum:1.000000 total_samples:144000.000000'}\n",
      "[Train Epoch]1/3 [Time]459.44 [Step]5001 [Batch]5000 [Speed]91.89ms/step [Loss]12.7212 [Metrics]{'train_loss:12.721187 train_acc_clicks:0.008023 train_acc_carts:0.038320 train_acc_orders:0.034596 lr:0.000442 grad_accum:1.000000 total_samples:160000.000000'}\n",
      "[Train Epoch]1/3 [Time]504.41 [Step]5501 [Batch]5500 [Speed]91.71ms/step [Loss]12.6396 [Metrics]{'train_loss:12.639611 train_acc_clicks:0.010193 train_acc_carts:0.045697 train_acc_orders:0.042359 lr:0.000486 grad_accum:1.000000 total_samples:176000.000000'}\n",
      "[Train Epoch]1/3 [Time]550.76 [Step]6001 [Batch]6000 [Speed]91.79ms/step [Loss]12.5672 [Metrics]{'train_loss:12.567207 train_acc_clicks:0.012220 train_acc_carts:0.052264 train_acc_orders:0.047544 lr:0.000530 grad_accum:1.000000 total_samples:192000.000000'}\n",
      "[Train Epoch]1/3 [Time]596.91 [Step]6501 [Batch]6500 [Speed]91.83ms/step [Loss]12.4952 [Metrics]{'train_loss:12.495218 train_acc_clicks:0.014208 train_acc_carts:0.058911 train_acc_orders:0.053940 lr:0.000575 grad_accum:1.000000 total_samples:208000.000000'}\n",
      "[Train Epoch]1/3 [Time]642.52 [Step]7001 [Batch]7000 [Speed]91.79ms/step [Loss]12.4273 [Metrics]{'train_loss:12.427312 train_acc_clicks:0.016055 train_acc_carts:0.065342 train_acc_orders:0.059744 lr:0.000619 grad_accum:1.000000 total_samples:224000.000000'}\n",
      "[Train Epoch]1/3 [Time]688.65 [Step]7501 [Batch]7500 [Speed]91.82ms/step [Loss]12.3629 [Metrics]{'train_loss:12.362938 train_acc_clicks:0.017873 train_acc_carts:0.071463 train_acc_orders:0.063268 lr:0.000663 grad_accum:1.000000 total_samples:240000.000000'}\n",
      "[Train Epoch]1/3 [Time]733.60 [Step]8001 [Batch]8000 [Speed]91.70ms/step [Loss]12.2958 [Metrics]{'train_loss:12.295787 train_acc_clicks:0.019502 train_acc_carts:0.077568 train_acc_orders:0.068332 lr:0.000707 grad_accum:1.000000 total_samples:256000.000000'}\n",
      "[Train Epoch]1/3 [Time]779.69 [Step]8501 [Batch]8500 [Speed]91.73ms/step [Loss]12.2336 [Metrics]{'train_loss:12.233553 train_acc_clicks:0.020927 train_acc_carts:0.082814 train_acc_orders:0.072722 lr:0.000751 grad_accum:1.000000 total_samples:272000.000000'}\n",
      "[Train Epoch]1/3 [Time]825.26 [Step]9001 [Batch]9000 [Speed]91.70ms/step [Loss]12.1741 [Metrics]{'train_loss:12.174104 train_acc_clicks:0.022196 train_acc_carts:0.086446 train_acc_orders:0.076095 lr:0.000796 grad_accum:1.000000 total_samples:288000.000000'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 130\u001b[0m\n\u001b[1;32m    125\u001b[0m grad_accum \u001b[39m=\u001b[39m grad_accum_scheduler(total_samples,\n\u001b[1;32m    126\u001b[0m                                   list_scheduler\u001b[39m=\u001b[39mlist_scheduler, \n\u001b[1;32m    127\u001b[0m                                   max_grad_accum\u001b[39m=\u001b[39mBERT4REC_CONFIG\u001b[39m.\u001b[39mtup_scheduler_grad_accum[\u001b[39m1\u001b[39m])                                                             \n\u001b[1;32m    128\u001b[0m step_gradients \u001b[39m=\u001b[39m train_step(inputs, target\u001b[39m=\u001b[39mtarget, model\u001b[39m=\u001b[39mmodel, optimizer\u001b[39m=\u001b[39moptimizer, num_accum_steps\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconstant(grad_accum, tf\u001b[39m.\u001b[39mfloat32), \n\u001b[1;32m    129\u001b[0m                             loss\u001b[39m=\u001b[39mtrain_loss, acc_clicks\u001b[39m=\u001b[39mtrain_acc_clicks, acc_carts\u001b[39m=\u001b[39mtrain_acc_carts, acc_orders\u001b[39m=\u001b[39mtrain_acc_orders, seq_type\u001b[39m=\u001b[39minputs[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 130\u001b[0m global_gradients, total_step \u001b[39m=\u001b[39m backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m batch_num \u001b[39m%\u001b[39m BERT4REC_CONFIG\u001b[39m.\u001b[39mbatch_num_printer_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    132\u001b[0m     train_dict_metrics \u001b[39m=\u001b[39m {x\u001b[39m.\u001b[39mname : x\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
      "Cell \u001b[0;32mIn [7], line 22\u001b[0m, in \u001b[0;36mbackward_optimization\u001b[0;34m(num_grad_steps, global_gradients, step_gradients, step, total_step, model, optimizer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         global_gradients[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_gradients(g) \u001b[39m#/ num_grad_steps\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m num_grad_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 22\u001b[0m     optimizer\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(global_gradients, model\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[1;32m     23\u001b[0m     global_gradients \u001b[39m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m     total_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py:830\u001b[0m, in \u001b[0;36mLossScaleOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[39mreturn\u001b[39;00m (tf\u001b[39m.\u001b[39mno_op(), \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    829\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mstrategy_supports_no_merge_call():\n\u001b[0;32m--> 830\u001b[0m     loss_scale_update_op, should_apply_grads \u001b[39m=\u001b[39m _if_should_apply_grads(\n\u001b[1;32m    831\u001b[0m         grads\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m():\n\u001b[1;32m    835\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_gradients(grads, wrapped_vars, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py:825\u001b[0m, in \u001b[0;36mLossScaleOptimizer.apply_gradients.<locals>._if_should_apply_grads\u001b[0;34m(grads)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_if_should_apply_grads\u001b[39m(grads):\n\u001b[1;32m    824\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss_scale, _DynamicLossScaleState):\n\u001b[0;32m--> 825\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss_scale\u001b[39m.\u001b[39;49mupdate(grads)\n\u001b[1;32m    826\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m         \u001b[39mreturn\u001b[39;00m (tf\u001b[39m.\u001b[39mno_op(), \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py:278\u001b[0m, in \u001b[0;36m_DynamicLossScaleState.update\u001b[0;34m(self, grads)\u001b[0m\n\u001b[1;32m    274\u001b[0m     is_finite \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39mexperimental_local_results(\n\u001b[1;32m    275\u001b[0m         is_finite_per_replica\n\u001b[1;32m    276\u001b[0m     )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    277\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 278\u001b[0m     is_finite \u001b[39m=\u001b[39m _is_all_finite(grads)\n\u001b[1;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_if_finite_grads\u001b[39m():\n\u001b[1;32m    281\u001b[0m     \u001b[39m\"\"\"Update assuming the gradients are finite.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py:57\u001b[0m, in \u001b[0;36m_is_all_finite\u001b[0;34m(grads)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_all_finite\u001b[39m(grads):\n\u001b[1;32m     55\u001b[0m     \u001b[39m\"\"\"Returns a scalar boolean tensor indicating if all gradients are\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    finite.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     is_finite_per_grad \u001b[39m=\u001b[39m [\n\u001b[1;32m     58\u001b[0m         tf\u001b[39m.\u001b[39mreduce_all(tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mis_finite(g)) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grads \u001b[39mif\u001b[39;00m g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[1;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mreduce_all(is_finite_per_grad)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_all_finite\u001b[39m(grads):\n\u001b[1;32m     55\u001b[0m     \u001b[39m\"\"\"Returns a scalar boolean tensor indicating if all gradients are\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    finite.\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     is_finite_per_grad \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 58\u001b[0m         tf\u001b[39m.\u001b[39mreduce_all(tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mis_finite(g)) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grads \u001b[39mif\u001b[39;00m g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[1;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mreduce_all(is_finite_per_grad)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:4835\u001b[0m, in \u001b[0;36mis_finite\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   4833\u001b[0m   \u001b[39mif\u001b[39;00m _result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   4834\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m-> 4835\u001b[0m   \u001b[39mreturn\u001b[39;00m is_finite_eager_fallback(\n\u001b[1;32m   4836\u001b[0m       x, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[1;32m   4837\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[1;32m   4838\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:4876\u001b[0m, in \u001b[0;36mis_finite_eager_fallback\u001b[0;34m(x, name, ctx)\u001b[0m\n\u001b[1;32m   4875\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_finite_eager_fallback\u001b[39m(x, name, ctx):\n\u001b[0;32m-> 4876\u001b[0m   _attr_T, (x,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49margs_to_matching_eager([x], ctx, [_dtypes\u001b[39m.\u001b[39;49mbfloat16, _dtypes\u001b[39m.\u001b[39;49mhalf, _dtypes\u001b[39m.\u001b[39;49mfloat32, _dtypes\u001b[39m.\u001b[39;49mfloat64, ])\n\u001b[1;32m   4877\u001b[0m   _inputs_flat \u001b[39m=\u001b[39m [x]\n\u001b[1;32m   4878\u001b[0m   _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:256\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39m# First see if we can get a valid dtype with the default conversion\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39m# and see if it matches an allowed dtypes. Some ops like ConcatV2 may\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m# not list allowed dtypes, in which case we should skip this.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m allowed_dtypes:\n\u001b[0;32m--> 256\u001b[0m   tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    257\u001b[0m   \u001b[39m# If we did not match an allowed dtype, try again with the default\u001b[39;00m\n\u001b[1;32m    258\u001b[0m   \u001b[39m# dtype. This could be because we have an empty tensor and thus we\u001b[39;00m\n\u001b[1;32m    259\u001b[0m   \u001b[39m# picked the wrong type.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m   \u001b[39mif\u001b[39;00m tensor\u001b[39m.\u001b[39mdtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_dtypes:\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:448\u001b[0m, in \u001b[0;36m_indexed_slices_to_tensor\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mdense_shape\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mVariableShape\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    442\u001b[0m       \u001b[39m# VariableShape may hide static shapes behind a resource handle\u001b[39;00m\n\u001b[1;32m    443\u001b[0m       \u001b[39m# producing a warning that isn't that useful to users.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    445\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mConverting sparse IndexedSlices(\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) to a dense Tensor of unknown \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mshape. This may consume a large amount of memory.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m value)\n\u001b[1;32m    447\u001b[0m \u001b[39mreturn\u001b[39;00m math_ops\u001b[39m.\u001b[39munsorted_segment_sum(\n\u001b[0;32m--> 448\u001b[0m     value\u001b[39m.\u001b[39mvalues, value\u001b[39m.\u001b[39mindices, value\u001b[39m.\u001b[39;49mdense_shape[\u001b[39m0\u001b[39;49m], name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1096\u001b[0m, in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1094\u001b[0m   var_empty \u001b[39m=\u001b[39m constant([], dtype\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32)\n\u001b[1;32m   1095\u001b[0m   packed_begin \u001b[39m=\u001b[39m packed_end \u001b[39m=\u001b[39m packed_strides \u001b[39m=\u001b[39m var_empty\n\u001b[0;32m-> 1096\u001b[0m \u001b[39mreturn\u001b[39;00m strided_slice(\n\u001b[1;32m   1097\u001b[0m     tensor,\n\u001b[1;32m   1098\u001b[0m     packed_begin,\n\u001b[1;32m   1099\u001b[0m     packed_end,\n\u001b[1;32m   1100\u001b[0m     packed_strides,\n\u001b[1;32m   1101\u001b[0m     begin_mask\u001b[39m=\u001b[39;49mbegin_mask,\n\u001b[1;32m   1102\u001b[0m     end_mask\u001b[39m=\u001b[39;49mend_mask,\n\u001b[1;32m   1103\u001b[0m     shrink_axis_mask\u001b[39m=\u001b[39;49mshrink_axis_mask,\n\u001b[1;32m   1104\u001b[0m     new_axis_mask\u001b[39m=\u001b[39;49mnew_axis_mask,\n\u001b[1;32m   1105\u001b[0m     ellipsis_mask\u001b[39m=\u001b[39;49mellipsis_mask,\n\u001b[1;32m   1106\u001b[0m     var\u001b[39m=\u001b[39;49mvar,\n\u001b[1;32m   1107\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1269\u001b[0m, in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[39mif\u001b[39;00m strides \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1267\u001b[0m   strides \u001b[39m=\u001b[39m ones_like(begin)\n\u001b[0;32m-> 1269\u001b[0m op \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mstrided_slice(\n\u001b[1;32m   1270\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49minput_,\n\u001b[1;32m   1271\u001b[0m     begin\u001b[39m=\u001b[39;49mbegin,\n\u001b[1;32m   1272\u001b[0m     end\u001b[39m=\u001b[39;49mend,\n\u001b[1;32m   1273\u001b[0m     strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m   1274\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1275\u001b[0m     begin_mask\u001b[39m=\u001b[39;49mbegin_mask,\n\u001b[1;32m   1276\u001b[0m     end_mask\u001b[39m=\u001b[39;49mend_mask,\n\u001b[1;32m   1277\u001b[0m     ellipsis_mask\u001b[39m=\u001b[39;49mellipsis_mask,\n\u001b[1;32m   1278\u001b[0m     new_axis_mask\u001b[39m=\u001b[39;49mnew_axis_mask,\n\u001b[1;32m   1279\u001b[0m     shrink_axis_mask\u001b[39m=\u001b[39;49mshrink_axis_mask)\n\u001b[1;32m   1281\u001b[0m parent_name \u001b[39m=\u001b[39m name\n\u001b[1;32m   1283\u001b[0m \u001b[39mif\u001b[39;00m var \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py38_tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:10672\u001b[0m, in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10670\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m  10671\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m> 10672\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m  10673\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mStridedSlice\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, begin, end, strides, \u001b[39m\"\u001b[39;49m\u001b[39mbegin_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m  10674\u001b[0m       begin_mask, \u001b[39m\"\u001b[39;49m\u001b[39mend_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m, end_mask, \u001b[39m\"\u001b[39;49m\u001b[39mellipsis_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m, ellipsis_mask,\n\u001b[1;32m  10675\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mnew_axis_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m, new_axis_mask, \u001b[39m\"\u001b[39;49m\u001b[39mshrink_axis_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m, shrink_axis_mask)\n\u001b[1;32m  10676\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m  10677\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '1_Model_v0.4.ipynb'\n",
    "\n",
    "class BERT4REC_CONFIG:\n",
    "    seed = 12 #42 \n",
    "    num_items = NUM_ITEMS\n",
    "    model_arch = 'bert4rec'\n",
    "    path_tfrecords = '../tfrecords/tfrecords_v0.7_nodup/'\n",
    "    restore_last_chekpoint = (False, 'model_bert4rec_complete_0.14/checkpoints/', 'ckpt-59')\n",
    "    model_name = f'model_{model_arch}_complete_0.15'\n",
    "    checkpoint_filepath = f'../2_Models/'\n",
    "    num_records_dataset = 13_000_000\n",
    "    batch_size = 32\n",
    "    tup_scheduler_grad_accum = (1, 5, 2_000_000) #(start_grad_accum, max_grad_accum, ramp_up_samples)\n",
    "    loss_apply_weights = True\n",
    "    loss_dict_weights={1:1, 2:3, 3:6}\n",
    "    seq_len = 20\n",
    "    mask_prob = 0.3\n",
    "    reverse_prob = 0.25\n",
    "    emb_dim = 128\n",
    "    trf_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 1\n",
    "    ff_dim = trf_dim*4\n",
    "    drop_rate = 0.1\n",
    "    att_drop_rate = 0.1\n",
    "    epochs = 3\n",
    "    early_stopping = 5\n",
    "    batch_num_printer_train = 500\n",
    "    batch_num_printer_val = 250\n",
    "    clipnorm = 1.0\n",
    "    num_iters_save_checkpoint = 20_000\n",
    "    scheduler_scaler = 128 \n",
    "    warmup_steps = 10_000\n",
    "    weight_decay = 1e-1\n",
    "    log_wandb = False\n",
    "\n",
    "set_seed(BERT4REC_CONFIG.seed)\n",
    "\n",
    "list_scheduler = np.linspace(BERT4REC_CONFIG.tup_scheduler_grad_accum[0], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[1], \n",
    "                             BERT4REC_CONFIG.tup_scheduler_grad_accum[2]).astype(np.uint8).tolist()\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    time_suffix = datetime.now().__str__().split('.')[0]\n",
    "    dict_config = {k : v for k, v in zip(BERT4REC_CONFIG.__dict__.keys(), BERT4REC_CONFIG.__dict__.values()) if not k.startswith('__')}\n",
    "    init_wandb(wandb_project='otto-recsys', entity='enric1296', run_name=f'{BERT4REC_CONFIG.model_name}_{time_suffix}', dict_config=dict_config)\n",
    "    \n",
    "\n",
    "list_paths_train = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=train/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=train')] + \\\n",
    "                   [f'{BERT4REC_CONFIG.path_tfrecords}na_split=test_aug/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=test_aug')]\n",
    "np.random.shuffle(list_paths_train)\n",
    "list_paths_val = [f'{BERT4REC_CONFIG.path_tfrecords}na_split=val/' + x for x in os.listdir(f'{BERT4REC_CONFIG.path_tfrecords}na_split=val')]\n",
    "\n",
    "train_dataloader = Bert4RecDataLoader(list_paths_train, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len, \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=BERT4REC_CONFIG.mask_prob, \n",
    "                                     reverse_prob=BERT4REC_CONFIG.reverse_prob, \n",
    "                                     is_test=False,\n",
    "                                     is_val=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_remainder=True).get_generator()\n",
    "\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=BERT4REC_CONFIG.num_items, \n",
    "                                     seq_len=BERT4REC_CONFIG.seq_len,  \n",
    "                                     batch_size=BERT4REC_CONFIG.batch_size, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     get_session=False,\n",
    "                                     is_val=True,\n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "optimizer = optimizers.Adam(learning_rate=CustomSchedule(BERT4REC_CONFIG.scheduler_scaler, warmup_steps=BERT4REC_CONFIG.warmup_steps),\n",
    "                            clipnorm=BERT4REC_CONFIG.clipnorm)\n",
    "                            # weight_decay=BERT4REC_CONFIG.weight_decay)                  \n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer)                           \n",
    "                            \n",
    "# Build utils\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "if BERT4REC_CONFIG.restore_last_chekpoint[0]:\n",
    "    checkpoint_path = os.path.join(BERT4REC_CONFIG.checkpoint_filepath, BERT4REC_CONFIG.restore_last_chekpoint[1])\n",
    "    ckpt.restore(os.path.join(checkpoint_path, BERT4REC_CONFIG.restore_last_chekpoint[2]))\n",
    "    print('Latest checkpoint restored!!')\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "else:\n",
    "    checkpoint_path = create_folder_with_version(BERT4REC_CONFIG.model_name, BERT4REC_CONFIG.checkpoint_filepath)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, os.path.join(BERT4REC_CONFIG.checkpoint_filepath, checkpoint_path, 'checkpoints'), \n",
    "                                            max_to_keep=10)\n",
    "\n",
    "# Loss function\n",
    "loss_function = weighted_loss_bert4rec(apply_weights=BERT4REC_CONFIG.loss_apply_weights, \n",
    "                                       dict_weights=BERT4REC_CONFIG.loss_dict_weights)\n",
    "acc_function = custom_accuracy()\n",
    "\n",
    "# Trackers\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "train_acc_clicks = tf.keras.metrics.Mean(name='train_acc_clicks')\n",
    "train_acc_carts = tf.keras.metrics.Mean(name='train_acc_carts')\n",
    "train_acc_orders = tf.keras.metrics.Mean(name='train_acc_orders')\n",
    "val_acc_clicks = tf.keras.metrics.Mean(name='val_acc_clicks')\n",
    "val_acc_carts = tf.keras.metrics.Mean(name='val_acc_carts')\n",
    "val_acc_orders = tf.keras.metrics.Mean(name='val_acc_orders')\n",
    "\n",
    "##############################################\n",
    "\n",
    "global_gradients = []\n",
    "total_step, val_step, total_samples = 0, 0, 0\n",
    "for epoch in range(BERT4REC_CONFIG.epochs):\n",
    "    start = time.time()\n",
    "    print('===='*20)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    metrics_reset_states(train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders, val_acc_clicks, val_acc_carts, val_acc_orders)\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        inputs, target = batch_data\n",
    "        grad_accum = grad_accum_scheduler(total_samples,\n",
    "                                          list_scheduler=list_scheduler, \n",
    "                                          max_grad_accum=BERT4REC_CONFIG.tup_scheduler_grad_accum[1])                                                             \n",
    "        step_gradients = train_step(inputs, target=target, model=model, optimizer=optimizer, num_accum_steps=tf.constant(grad_accum, tf.float32), \n",
    "                                    loss=train_loss, acc_clicks=train_acc_clicks, acc_carts=train_acc_carts, acc_orders=train_acc_orders, seq_type=inputs[1])\n",
    "        global_gradients, total_step = backward_optimization(grad_accum, global_gradients, step_gradients, batch_num, total_step, model, optimizer)\n",
    "        if batch_num % BERT4REC_CONFIG.batch_num_printer_train == 0:\n",
    "            train_dict_metrics = {x.name : x.result() for x in [train_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "            train_dict_metrics.update({'lr' : optimizer.lr(total_step).numpy().astype(np.float32), 'grad_accum' : grad_accum, 'total_samples' : total_samples})\n",
    "            fancy_printer(train_loss, epoch, batch_num, start, step='Train', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=train_dict_metrics, num_step=total_step)\n",
    "            if BERT4REC_CONFIG.log_wandb:\n",
    "                train_dict_metrics.update({'step_grad' : total_step, 'step' : total_step})\n",
    "                log_wandb_metrics(step='train', num_step=total_step, gradients=global_gradients, dict_metrics=train_dict_metrics)     \n",
    "        total_samples += BERT4REC_CONFIG.batch_size * grad_accum if (batch_num+1) % grad_accum==0 else 0\n",
    "        if batch_num % BERT4REC_CONFIG.num_iters_save_checkpoint==0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print(f'Saving checkpoint for epoch {epoch+1} at step {total_step} on path {checkpoint_path}')\n",
    "     \n",
    "#     for val_batch_num, val_batch_data in enumerate(val_dataloader):\n",
    "#         inputs, target = val_batch_data\n",
    "#         predictions = test_step(inputs, target=target, loss=val_loss, acc_clicks=val_acc_clicks, acc_carts=val_acc_carts, acc_orders=val_acc_orders, seq_type=inputs[1])\n",
    "#         val_step += 1\n",
    "#         if val_batch_num % BERT4REC_CONFIG.batch_num_printer_val == 0:\n",
    "#             val_dict_metrics = {x.name : x.result() for x in [val_loss, val_acc_clicks, val_acc_carts, val_acc_orders]}\n",
    "#             fancy_printer(val_loss, epoch, val_batch_num, start, step='Val', num_epochs=BERT4REC_CONFIG.epochs, dict_metrics=val_dict_metrics, num_step=val_step)    \n",
    "#             if BERT4REC_CONFIG.log_wandb:\n",
    "#                 log_wandb_metrics(step='val', num_step=val_step, dict_metrics=val_dict_metrics) \n",
    "#                 # if val_batch_num==0:\n",
    "#                 #     log_wandb_metrics(step=None, plot_image=True, \n",
    "#                 #                       model=model, inputs=inputs, epoch=epoch, target=target, stats=stats)\n",
    "    \n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {checkpoint_path}')        \n",
    "    \n",
    "    epoch_dict_metrics = {x.name : x.result() for x in [train_loss, val_loss, train_acc_clicks, train_acc_carts, train_acc_orders]}\n",
    "    printer = fancy_printer(None, epoch, epoch, start, step='epoch', num_step=epoch, dict_metrics=epoch_dict_metrics, \n",
    "                            train_loss=train_loss, val_loss=val_loss)\n",
    "    if BERT4REC_CONFIG.log_wandb:\n",
    "        log_wandb_metrics(step='epoch', num_step=total_step, dict_metrics=epoch_dict_metrics)\n",
    "\n",
    "if BERT4REC_CONFIG.log_wandb:\n",
    "    # wandb.save(checkpoint_path)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    y_pred = list(set(y_pred[:k]))\n",
    "    y_true = list(set(y_true))[:k]\n",
    "    score = 0 \n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "# model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# ckpt = tf.train.Checkpoint(model=model)\n",
    "# ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.14/checkpoints'))\n",
    "\n",
    "# list_paths_val = ['../tfrecords/tfrecords_v0.7/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.7/na_split=val')]\n",
    "# val_dataloader = SASRecDataLoader(list_paths_val, \n",
    "#                                      num_items=NUM_ITEMS, \n",
    "#                                      seq_len=20, \n",
    "#                                      seq_len_target=50, \n",
    "#                                      batch_size=32, \n",
    "#                                      mask_prob=0.0, \n",
    "#                                      reverse_prob=0.0, \n",
    "#                                      is_val=True,\n",
    "#                                      get_session=True, \n",
    "#                                      is_test=False,\n",
    "#                                      shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "# list_sessions, list_past_items, list_past_types, list_predictions, list_trues, list_types = [], [], [], [], [], []\n",
    "# for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "#     features, targets, session = batch\n",
    "#     seq_items, seq_type, seq_time, seq_recency = features\n",
    "#     target, type_target, idx_mask = targets\n",
    "#     idxs = idx_mask.numpy()#tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "#     preds = model(features, training=False)\n",
    "#     preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "#     topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "#     type_ = type_target[:, 0].numpy()\n",
    "#     topk_idxs = np.asarray([[dict_map[x]-1 for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "#     labels = [list(set([dict_map[x]-1 for x, y in zip(target.numpy()[i], type_target.numpy()[i]) if type_[i]==y and x!=0])) for i in range(target.shape[0])]\n",
    "#     # labels = [list(set([dict_map[_target]-1 for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_[i]]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "#     ###\n",
    "#     list_sessions.append(session.numpy())\n",
    "#     list_predictions.append(topk_idxs)\n",
    "#     list_types.append([dict_map_type_inv[type_[i]] for i in range(seq_items.shape[0])])\n",
    "#     list_trues = list_trues + labels\n",
    "#     list_past_items.append(seq_items.numpy()[:, :, 0])\n",
    "#     list_past_types.append(seq_type.numpy()[:, :, 0])\n",
    "#     if num_batch==500:\n",
    "#         break\n",
    "\n",
    "# df_val = pd.DataFrame({\n",
    "#     'session' : np.concatenate(list_sessions),\n",
    "#     'past_items' : np.concatenate(list_past_items).tolist(),\n",
    "#     'past_types' : np.concatenate(list_past_types).tolist(),\n",
    "#     'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "#     'trues' : list_trues,\n",
    "#     'type' : np.concatenate(list_types)\n",
    "# })\n",
    "# df_val['past_items'] = df_val['past_items'].apply(lambda seq : [dict_map[x]-1 if x!=0 else 'pad' for x in seq ])\n",
    "# df_val['qt_trues'] = df_val['trues'].apply(lambda x : len(x))\n",
    "# df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "# display(df_val.describe())\n",
    "# dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "# display(dict_scores)\n",
    "# kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "# print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# wandb.run.summary['kaggle_metric'] = kaggle_metric\n",
    "# wandb.run.summary['dict_scores'] = dict_scores\n",
    "\n",
    "# {'carts': 0.5812250271177338,\n",
    "#  'clicks': 0.16014138118542687,\n",
    "#  'orders': 0.4602882819794584}\n",
    "# Kaggle Metric: 0.4666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:55,  8.93it/s]\n",
      "100%|██████████| 48096/48096 [00:00<00:00, 177702.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>qt_trues</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.809600e+04</td>\n",
       "      <td>48096.000000</td>\n",
       "      <td>20238.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.350257e+06</td>\n",
       "      <td>1.499480</td>\n",
       "      <td>0.249953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.702025e+06</td>\n",
       "      <td>3.148354</td>\n",
       "      <td>0.422038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.079000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.133794e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.290090e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.550685e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.289704e+07</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session      qt_trues         score\n",
       "count  4.809600e+04  48096.000000  20238.000000\n",
       "mean   6.350257e+06      1.499480      0.249953\n",
       "std    3.702025e+06      3.148354      0.422038\n",
       "min    2.079000e+03      0.000000      0.000000\n",
       "25%    3.133794e+06      0.000000      0.000000\n",
       "50%    6.290090e+06      0.000000      0.000000\n",
       "75%    9.550685e+06      1.000000      0.500000\n",
       "max    1.289704e+07     20.000000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'carts': 0.3305744622896034,\n",
       " 'clicks': 0.20930689181229137,\n",
       " 'orders': 0.4829410106269611}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Metric: 0.4099\n"
     ]
    }
   ],
   "source": [
    "def get_score_metric(y_true, y_pred, type_target, k=20):\n",
    "    y_pred = list(set(y_pred[:k]))\n",
    "    y_true = list(set(y_true))[:k]\n",
    "    score = 0 \n",
    "    if len(y_true)==0:\n",
    "        return None\n",
    "    if type_target=='clicks':\n",
    "        num_targets = 1\n",
    "        hits = len([x for x in y_pred if x==y_true[0]])\n",
    "    else:\n",
    "        num_targets = min(k, len(y_true))\n",
    "        hits = len([x for x in y_pred if x in y_true])\n",
    "    score = hits / num_targets\n",
    "    return score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# ckpt = tf.train.Checkpoint(model=model)\n",
    "# ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.14/checkpoints'))\n",
    "list_paths_val = ['../tfrecords/tfrecords_v0.7_nodup/na_split=val/' + x for x in os.listdir('../tfrecords/tfrecords_v0.7_nodup/na_split=val')]\n",
    "val_dataloader = Bert4RecDataLoader(list_paths_val, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20, \n",
    "                                     seq_len_target=20, \n",
    "                                     batch_size=32, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0, \n",
    "                                     is_val=True,\n",
    "                                     get_session=True, \n",
    "                                     is_test=False,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "\n",
    "list_sessions, list_past_items, list_predictions, list_trues, list_types = [], [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(val_dataloader)):\n",
    "    features, targets, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    target, type_target, idx_mask = targets\n",
    "    idxs = idx_mask.numpy() #tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x]-1 for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        labels = [list(set([dict_map[_target]-1 for _type, _target in zip(type_target.numpy()[i], target.numpy()[i]) if dict_map_type[type_]==_type and _target!=0])) for i in range(target.shape[0])]\n",
    "        ###\n",
    "        list_sessions.append(session.numpy())\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_trues = list_trues + labels\n",
    "        list_past_items.append(seq_items.numpy()[:, :, 0])\n",
    "    if num_batch==500:\n",
    "        break\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'past_items' : np.concatenate(list_past_items).tolist(),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'trues' : list_trues,\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "df_val['past_items'] = df_val['past_items'].apply(lambda seq : [dict_map[x]-1 if x!=0 else 'pad' for x in seq ])\n",
    "df_val['qt_trues'] = df_val['trues'].apply(lambda x : len(x))\n",
    "df_val['score'] = df_val.progress_apply(lambda x: get_score_metric(x['trues'], x['predictions'], x['type']), axis=1)\n",
    "\n",
    "display(df_val.describe())\n",
    "dict_scores = df_val.groupby('type')['score'].mean().to_dict()\n",
    "display(dict_scores)\n",
    "kaggle_metric = 0.1*dict_scores['clicks'] + 0.3*dict_scores['carts'] + 0.6*dict_scores['orders']\n",
    "print(f'Kaggle Metric: {kaggle_metric:.4f}')\n",
    "\n",
    "# compare to\n",
    "# (seq_len=20)model_bert4rec_complete_0.10 - ckpt28\n",
    "# {'carts': 0.3811865255508249,\n",
    "#  'clicks': 0.32103439425051333,\n",
    "#  'orders': 0.5298270555929199}\n",
    "# Kaggle Metric: 0.4644\n",
    "\n",
    "# import wandb\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"<path to run>\")\n",
    "# run.summary[\"kaggle_metric\"] = kaggle_metric\n",
    "# run.update()\n",
    "\n",
    "# num_targets=20 - seq_len=20 - model_bert4rec_complete_0.14 - ckpt59\n",
    "# {'carts': 0.394584, \n",
    "# 'clicks': 0.3397670977288812, \n",
    "# 'orders': 0.5443738794875159}\n",
    "# Kaggle Metric: 0.4790"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 20:42:53.462456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "0it [00:00, ?it/s]2022-12-02 20:42:54.497138: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "26122it [15:20, 28.37it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_sasrec_complete_0.14/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.7/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.7/na_split=test')]\n",
    "test_dataloader = SASRecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, idxs, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    idxs = idxs.numpy()\n",
    "    ###\n",
    "    preds = model(features, training=False)\n",
    "    preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "    topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "    topk_idxs = np.asarray([[dict_map[x]-1 for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "    ### \n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    \n",
    "\n",
    "# 26122it [54:28,  7.99it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090 Ti, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 19:15:23.433225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "0it [00:00, ?it/s]2022-11-20 19:15:24.337587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "26122it [55:08,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# model = build_model_bert4Rec(num_items=BERT4REC_CONFIG.num_items, model_cfg=BERT4REC_CONFIG)\n",
    "# ckpt = tf.train.Checkpoint(model=model)\n",
    "# ckpt.restore(tf.train.latest_checkpoint(f'../2_Models/model_bert4rec_complete_0.7/checkpoints'))\n",
    "\n",
    "\n",
    "list_paths_test = ['../tfrecords/tfrecords_v0.4/na_split=test/' + x for x in os.listdir('../tfrecords/tfrecords_v0.4/na_split=test')]\n",
    "test_dataloader = SASRecDataLoader(list_paths_test, \n",
    "                                     num_items=NUM_ITEMS, \n",
    "                                     seq_len=20,  \n",
    "                                     batch_size=64, \n",
    "                                     mask_prob=0.0, \n",
    "                                     reverse_prob=0.0,  \n",
    "                                     is_val=False,\n",
    "                                     is_test=True,\n",
    "                                     get_session=True,\n",
    "                                     shuffle=False).get_generator()\n",
    "\n",
    "list_predictions, list_sessions, list_types, list_scores = [], [], [], []\n",
    "for num_batch, batch in enumerate(tqdm(test_dataloader)):\n",
    "    features, idxs, session = batch\n",
    "    seq_items, seq_type, seq_time, seq_recency = features\n",
    "    idxs = idxs.numpy() - 1\n",
    "    # idxs = tf.argmin(seq_items[:, :, 0], 1).numpy()\n",
    "    ###\n",
    "    for type_ in ['clicks', 'carts', 'orders']:\n",
    "        seq_type_new = [tf.concat([\n",
    "                        seq_type[i, :ix],\n",
    "                        tf.constant([[dict_map_type[type_]]], tf.int64),\n",
    "                        seq_type[i, ix+1:]], axis=0)\n",
    "                    for i, ix in enumerate(idxs)]\n",
    "        features = (seq_items, tf.stack(seq_type_new, axis=0), seq_time, seq_recency)\n",
    "        preds = model(features, training=False)\n",
    "        preds = tf.gather(preds, indices=idxs, axis=1, batch_dims=1)\n",
    "        topk_scores, topk_idxs = tf.math.top_k(preds, k=20)\n",
    "        topk_idxs = np.asarray([[dict_map[x] for x in topk_idxs.numpy()[i, :]] for i in range(topk_idxs.numpy().shape[0])])\n",
    "        topk_idxs = topk_idxs - 1\n",
    "        list_predictions.append(topk_idxs)\n",
    "        list_types.append([type_ for _ in range(seq_items.shape[0])])\n",
    "        list_sessions.append(session.numpy())\n",
    "    # if num_batch==100:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 26122it [54:28,  7.99it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5015409, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>predictions</th>\n",
       "      <th>type</th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13748068</td>\n",
       "      <td>[1628069, 1357920, 593368, 787553, 1264263, 16...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>13748068_clicks</td>\n",
       "      <td>1628069 1357920 593368 787553 1264263 1679916 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13782542</td>\n",
       "      <td>[1566005, 468686, 1728428, 1649665, 96165, 605...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>13782542_clicks</td>\n",
       "      <td>1566005 468686 1728428 1649665 96165 605599 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13081128</td>\n",
       "      <td>[781749, 1125756, 166666, 529213, 697164, 1413...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>13081128_clicks</td>\n",
       "      <td>781749 1125756 166666 529213 697164 1413368 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12934157</td>\n",
       "      <td>[14512, 925386, 1294924, 381455, 1314897, 5480...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>12934157_clicks</td>\n",
       "      <td>14512 925386 1294924 381455 1314897 548085 124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13815595</td>\n",
       "      <td>[944474, 155721, 649608, 496180, 861401, 51116...</td>\n",
       "      <td>clicks</td>\n",
       "      <td>13815595_clicks</td>\n",
       "      <td>944474 155721 649608 496180 861401 511161 3197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015404</th>\n",
       "      <td>13870001</td>\n",
       "      <td>[1114486, 1850954, 1691272, 110294, 393471, 16...</td>\n",
       "      <td>orders</td>\n",
       "      <td>13870001_orders</td>\n",
       "      <td>1114486 1850954 1691272 110294 393471 1603167 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015405</th>\n",
       "      <td>14006334</td>\n",
       "      <td>[651650, 891977, 743805, 1206573, 1629826, 235...</td>\n",
       "      <td>orders</td>\n",
       "      <td>14006334_orders</td>\n",
       "      <td>651650 891977 743805 1206573 1629826 235021 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015406</th>\n",
       "      <td>13499891</td>\n",
       "      <td>[560221, 120944, 263570, 721034, 1672790, 1482...</td>\n",
       "      <td>orders</td>\n",
       "      <td>13499891_orders</td>\n",
       "      <td>560221 120944 263570 721034 1672790 1482639 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015407</th>\n",
       "      <td>13126734</td>\n",
       "      <td>[818147, 417590, 55206, 1361831, 1829805, 1208...</td>\n",
       "      <td>orders</td>\n",
       "      <td>13126734_orders</td>\n",
       "      <td>818147 417590 55206 1361831 1829805 1208453 93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015408</th>\n",
       "      <td>13400486</td>\n",
       "      <td>[1357776, 54358, 292860, 1406180, 1358554, 177...</td>\n",
       "      <td>orders</td>\n",
       "      <td>13400486_orders</td>\n",
       "      <td>1357776 54358 292860 1406180 1358554 1776508 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5015409 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session                                        predictions    type  \\\n",
       "0        13748068  [1628069, 1357920, 593368, 787553, 1264263, 16...  clicks   \n",
       "1        13782542  [1566005, 468686, 1728428, 1649665, 96165, 605...  clicks   \n",
       "2        13081128  [781749, 1125756, 166666, 529213, 697164, 1413...  clicks   \n",
       "3        12934157  [14512, 925386, 1294924, 381455, 1314897, 5480...  clicks   \n",
       "4        13815595  [944474, 155721, 649608, 496180, 861401, 51116...  clicks   \n",
       "...           ...                                                ...     ...   \n",
       "5015404  13870001  [1114486, 1850954, 1691272, 110294, 393471, 16...  orders   \n",
       "5015405  14006334  [651650, 891977, 743805, 1206573, 1629826, 235...  orders   \n",
       "5015406  13499891  [560221, 120944, 263570, 721034, 1672790, 1482...  orders   \n",
       "5015407  13126734  [818147, 417590, 55206, 1361831, 1829805, 1208...  orders   \n",
       "5015408  13400486  [1357776, 54358, 292860, 1406180, 1358554, 177...  orders   \n",
       "\n",
       "            session_type                                             labels  \n",
       "0        13748068_clicks  1628069 1357920 593368 787553 1264263 1679916 ...  \n",
       "1        13782542_clicks  1566005 468686 1728428 1649665 96165 605599 47...  \n",
       "2        13081128_clicks  781749 1125756 166666 529213 697164 1413368 11...  \n",
       "3        12934157_clicks  14512 925386 1294924 381455 1314897 548085 124...  \n",
       "4        13815595_clicks  944474 155721 649608 496180 861401 511161 3197...  \n",
       "...                  ...                                                ...  \n",
       "5015404  13870001_orders  1114486 1850954 1691272 110294 393471 1603167 ...  \n",
       "5015405  14006334_orders  651650 891977 743805 1206573 1629826 235021 16...  \n",
       "5015406  13499891_orders  560221 120944 263570 721034 1672790 1482639 12...  \n",
       "5015407  13126734_orders  818147 417590 55206 1361831 1829805 1208453 93...  \n",
       "5015408  13400486_orders  1357776 54358 292860 1406180 1358554 1776508 1...  \n",
       "\n",
       "[5015409 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_submission = f\"submission_{datetime.now().__str__().split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_')}\"\n",
    "\n",
    "df_inference = pd.DataFrame({\n",
    "    'session' : np.concatenate(list_sessions),\n",
    "    'predictions' : np.concatenate(list_predictions).tolist(),\n",
    "    'type' : np.concatenate(list_types)\n",
    "})\n",
    "\n",
    "df_inference['session_type'] = df_inference['session'].astype(str) + '_' + df_inference['type']\n",
    "df_inference['labels'] = df_inference['predictions'].apply(lambda x : ' '.join([str(y) for y in x]))\n",
    "df_inference[['session_type', 'labels']].to_csv(f'../3_Submissions/{name_submission}.csv', index=False)\n",
    "\n",
    "print(df_inference.shape)\n",
    "display(\n",
    "    df_inference\n",
    ")\n",
    "\n",
    "import gzip\n",
    "with open(f'../3_Submissions/{name_submission}.csv', 'rb') as f_in, gzip.open(f'../3_Submissions/{name_submission}.csv.gz', 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0432fa0070c5c9f7d9e158f590013ccc765eb84f02e6f69521746370c3bf6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
